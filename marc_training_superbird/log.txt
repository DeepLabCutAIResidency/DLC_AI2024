2024-07-22 16:00:59 Data Transforms:
2024-07-22 16:00:59   Training:   Compose([
  HorizontalFlip(always_apply=False, p=0.5),
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 40), 'y': (0, 40)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-07-22 16:00:59   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-07-22 16:00:59 Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}
2024-07-22 16:00:59 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2024-07-22 16:00:59 Using 300 images and 300 for testing
2024-07-22 16:00:59 
Starting object detector training...
--------------------------------------------------
2024-07-22 16:01:12 Training for epoch 1 done, starting evaluation
2024-07-22 16:01:21 Epoch 1 performance:
2024-07-22 16:01:21 metrics/test.mAP@50:95:0.178
2024-07-22 16:01:21 metrics/test.mAP@50:0.559
2024-07-22 16:01:21 metrics/test.mAP@75:0.052
2024-07-22 16:01:21 metrics/test.mAR@50:95:0.341
2024-07-22 16:01:21 metrics/test.mAR@50:0.762
2024-07-22 16:01:21 metrics/test.mAR@75:0.219
2024-07-22 16:01:21 Epoch 1/250 (lr=0.0001), train loss 0.62849
2024-07-22 16:01:31 Training for epoch 2 done, starting evaluation
2024-07-22 16:01:38 Epoch 2 performance:
2024-07-22 16:01:38 metrics/test.mAP@50:95:0.258
2024-07-22 16:01:38 metrics/test.mAP@50:0.641
2024-07-22 16:01:38 metrics/test.mAP@75:0.140
2024-07-22 16:01:38 metrics/test.mAR@50:95:0.418
2024-07-22 16:01:38 metrics/test.mAR@50:0.836
2024-07-22 16:01:38 metrics/test.mAR@75:0.324
2024-07-22 16:01:38 Epoch 2/250 (lr=0.0001), train loss 0.48914
2024-07-22 16:01:48 Training for epoch 3 done, starting evaluation
2024-07-22 16:01:55 Epoch 3 performance:
2024-07-22 16:01:55 metrics/test.mAP@50:95:0.282
2024-07-22 16:01:55 metrics/test.mAP@50:0.678
2024-07-22 16:01:55 metrics/test.mAP@75:0.150
2024-07-22 16:01:55 metrics/test.mAR@50:95:0.429
2024-07-22 16:01:55 metrics/test.mAR@50:0.859
2024-07-22 16:01:55 metrics/test.mAR@75:0.324
2024-07-22 16:01:55 Epoch 3/250 (lr=0.0001), train loss 0.47524
2024-07-22 16:02:04 Training for epoch 4 done, starting evaluation
2024-07-22 16:02:12 Epoch 4 performance:
2024-07-22 16:02:12 metrics/test.mAP@50:95:0.325
2024-07-22 16:02:12 metrics/test.mAP@50:0.701
2024-07-22 16:02:12 metrics/test.mAP@75:0.255
2024-07-22 16:02:12 metrics/test.mAR@50:95:0.470
2024-07-22 16:02:12 metrics/test.mAR@50:0.895
2024-07-22 16:02:12 metrics/test.mAR@75:0.414
2024-07-22 16:02:12 Epoch 4/250 (lr=0.0001), train loss 0.43918
2024-07-22 16:02:22 Training for epoch 5 done, starting evaluation
2024-07-22 16:02:29 Epoch 5 performance:
2024-07-22 16:02:29 metrics/test.mAP@50:95:0.313
2024-07-22 16:02:29 metrics/test.mAP@50:0.724
2024-07-22 16:02:29 metrics/test.mAP@75:0.233
2024-07-22 16:02:29 metrics/test.mAR@50:95:0.475
2024-07-22 16:02:29 metrics/test.mAR@50:0.910
2024-07-22 16:02:29 metrics/test.mAR@75:0.414
2024-07-22 16:02:29 Epoch 5/250 (lr=0.0001), train loss 0.48137
2024-07-22 16:02:38 Training for epoch 6 done, starting evaluation
2024-07-22 16:02:45 Epoch 6 performance:
2024-07-22 16:02:45 metrics/test.mAP@50:95:0.253
2024-07-22 16:02:45 metrics/test.mAP@50:0.682
2024-07-22 16:02:45 metrics/test.mAP@75:0.155
2024-07-22 16:02:45 metrics/test.mAR@50:95:0.415
2024-07-22 16:02:45 metrics/test.mAR@50:0.891
2024-07-22 16:02:45 metrics/test.mAR@75:0.328
2024-07-22 16:02:45 Epoch 6/250 (lr=0.0001), train loss 0.43064
2024-07-22 16:02:55 Training for epoch 7 done, starting evaluation
2024-07-22 16:03:02 Epoch 7 performance:
2024-07-22 16:03:02 metrics/test.mAP@50:95:0.327
2024-07-22 16:03:02 metrics/test.mAP@50:0.724
2024-07-22 16:03:02 metrics/test.mAP@75:0.253
2024-07-22 16:03:02 metrics/test.mAR@50:95:0.491
2024-07-22 16:03:02 metrics/test.mAR@50:0.938
2024-07-22 16:03:02 metrics/test.mAR@75:0.445
2024-07-22 16:03:02 Epoch 7/250 (lr=0.0001), train loss 0.50925
2024-07-22 16:03:12 Training for epoch 8 done, starting evaluation
2024-07-22 16:03:19 Epoch 8 performance:
2024-07-22 16:03:19 metrics/test.mAP@50:95:0.335
2024-07-22 16:03:19 metrics/test.mAP@50:0.725
2024-07-22 16:03:19 metrics/test.mAP@75:0.277
2024-07-22 16:03:19 metrics/test.mAR@50:95:0.478
2024-07-22 16:03:19 metrics/test.mAR@50:0.926
2024-07-22 16:03:19 metrics/test.mAR@75:0.430
2024-07-22 16:03:19 Epoch 8/250 (lr=0.0001), train loss 0.51999
2024-07-22 16:03:28 Training for epoch 9 done, starting evaluation
2024-07-22 16:03:34 Epoch 9 performance:
2024-07-22 16:03:34 metrics/test.mAP@50:95:0.293
2024-07-22 16:03:34 metrics/test.mAP@50:0.725
2024-07-22 16:03:34 metrics/test.mAP@75:0.176
2024-07-22 16:03:34 metrics/test.mAR@50:95:0.424
2024-07-22 16:03:34 metrics/test.mAR@50:0.883
2024-07-22 16:03:34 metrics/test.mAR@75:0.332
2024-07-22 16:03:34 Epoch 9/250 (lr=0.0001), train loss 0.47438
2024-07-22 16:03:44 Training for epoch 10 done, starting evaluation
2024-07-22 16:03:51 Epoch 10 performance:
2024-07-22 16:03:51 metrics/test.mAP@50:95:0.320
2024-07-22 16:03:51 metrics/test.mAP@50:0.726
2024-07-22 16:03:51 metrics/test.mAP@75:0.235
2024-07-22 16:03:51 metrics/test.mAR@50:95:0.467
2024-07-22 16:03:51 metrics/test.mAR@50:0.926
2024-07-22 16:03:51 metrics/test.mAR@75:0.402
2024-07-22 16:03:51 Epoch 10/250 (lr=0.0001), train loss 0.48342
2024-07-22 16:04:01 Training for epoch 11 done, starting evaluation
2024-07-22 16:04:07 Epoch 11 performance:
2024-07-22 16:04:07 metrics/test.mAP@50:95:0.331
2024-07-22 16:04:07 metrics/test.mAP@50:0.762
2024-07-22 16:04:07 metrics/test.mAP@75:0.223
2024-07-22 16:04:07 metrics/test.mAR@50:95:0.464
2024-07-22 16:04:07 metrics/test.mAR@50:0.930
2024-07-22 16:04:07 metrics/test.mAR@75:0.371
2024-07-22 16:04:07 Epoch 11/250 (lr=0.0001), train loss 0.47606
2024-07-22 16:04:17 Training for epoch 12 done, starting evaluation
2024-07-22 16:04:23 Epoch 12 performance:
2024-07-22 16:04:23 metrics/test.mAP@50:95:0.327
2024-07-22 16:04:23 metrics/test.mAP@50:0.722
2024-07-22 16:04:23 metrics/test.mAP@75:0.248
2024-07-22 16:04:23 metrics/test.mAR@50:95:0.448
2024-07-22 16:04:23 metrics/test.mAR@50:0.863
2024-07-22 16:04:23 metrics/test.mAR@75:0.402
2024-07-22 16:04:23 Epoch 12/250 (lr=0.0001), train loss 0.50175
2024-07-22 16:04:33 Training for epoch 13 done, starting evaluation
2024-07-22 16:04:40 Epoch 13 performance:
2024-07-22 16:04:40 metrics/test.mAP@50:95:0.302
2024-07-22 16:04:40 metrics/test.mAP@50:0.727
2024-07-22 16:04:40 metrics/test.mAP@75:0.215
2024-07-22 16:04:40 metrics/test.mAR@50:95:0.457
2024-07-22 16:04:40 metrics/test.mAR@50:0.887
2024-07-22 16:04:40 metrics/test.mAR@75:0.422
2024-07-22 16:04:40 Epoch 13/250 (lr=0.0001), train loss 0.47252
2024-07-22 16:04:49 Training for epoch 14 done, starting evaluation
2024-07-22 16:04:56 Epoch 14 performance:
2024-07-22 16:04:56 metrics/test.mAP@50:95:0.263
2024-07-22 16:04:56 metrics/test.mAP@50:0.704
2024-07-22 16:04:56 metrics/test.mAP@75:0.130
2024-07-22 16:04:56 metrics/test.mAR@50:95:0.423
2024-07-22 16:04:56 metrics/test.mAR@50:0.898
2024-07-22 16:04:56 metrics/test.mAR@75:0.324
2024-07-22 16:04:56 Epoch 14/250 (lr=0.0001), train loss 0.45360
2024-07-22 16:05:04 Training for epoch 15 done, starting evaluation
2024-07-22 16:05:11 Epoch 15 performance:
2024-07-22 16:05:11 metrics/test.mAP@50:95:0.311
2024-07-22 16:05:11 metrics/test.mAP@50:0.739
2024-07-22 16:05:11 metrics/test.mAP@75:0.196
2024-07-22 16:05:11 metrics/test.mAR@50:95:0.450
2024-07-22 16:05:11 metrics/test.mAR@50:0.891
2024-07-22 16:05:11 metrics/test.mAR@75:0.395
2024-07-22 16:05:11 Epoch 15/250 (lr=0.0001), train loss 0.45055
2024-07-22 16:05:21 Training for epoch 16 done, starting evaluation
2024-07-22 16:05:27 Epoch 16 performance:
2024-07-22 16:05:27 metrics/test.mAP@50:95:0.330
2024-07-22 16:05:27 metrics/test.mAP@50:0.735
2024-07-22 16:05:27 metrics/test.mAP@75:0.271
2024-07-22 16:05:27 metrics/test.mAR@50:95:0.466
2024-07-22 16:05:27 metrics/test.mAR@50:0.906
2024-07-22 16:05:27 metrics/test.mAR@75:0.426
2024-07-22 16:05:27 Epoch 16/250 (lr=0.0001), train loss 0.45239
2024-07-22 16:05:37 Training for epoch 17 done, starting evaluation
2024-07-22 16:05:43 Epoch 17 performance:
2024-07-22 16:05:43 metrics/test.mAP@50:95:0.322
2024-07-22 16:05:43 metrics/test.mAP@50:0.697
2024-07-22 16:05:43 metrics/test.mAP@75:0.238
2024-07-22 16:05:43 metrics/test.mAR@50:95:0.463
2024-07-22 16:05:43 metrics/test.mAR@50:0.879
2024-07-22 16:05:43 metrics/test.mAR@75:0.418
2024-07-22 16:05:43 Epoch 17/250 (lr=0.0001), train loss 0.47558
2024-07-22 16:05:53 Training for epoch 18 done, starting evaluation
2024-07-22 16:05:59 Epoch 18 performance:
2024-07-22 16:05:59 metrics/test.mAP@50:95:0.336
2024-07-22 16:05:59 metrics/test.mAP@50:0.717
2024-07-22 16:05:59 metrics/test.mAP@75:0.253
2024-07-22 16:05:59 metrics/test.mAR@50:95:0.468
2024-07-22 16:05:59 metrics/test.mAR@50:0.867
2024-07-22 16:05:59 metrics/test.mAR@75:0.418
2024-07-22 16:05:59 Epoch 18/250 (lr=0.0001), train loss 0.37453
2024-07-22 16:06:09 Training for epoch 19 done, starting evaluation
2024-07-22 16:06:15 Epoch 19 performance:
2024-07-22 16:06:15 metrics/test.mAP@50:95:0.299
2024-07-22 16:06:15 metrics/test.mAP@50:0.700
2024-07-22 16:06:15 metrics/test.mAP@75:0.213
2024-07-22 16:06:15 metrics/test.mAR@50:95:0.408
2024-07-22 16:06:15 metrics/test.mAR@50:0.836
2024-07-22 16:06:15 metrics/test.mAR@75:0.363
2024-07-22 16:06:15 Epoch 19/250 (lr=0.0001), train loss 0.39410
2024-07-22 16:06:25 Training for epoch 20 done, starting evaluation
2024-07-22 16:06:31 Epoch 20 performance:
2024-07-22 16:06:31 metrics/test.mAP@50:95:0.322
2024-07-22 16:06:31 metrics/test.mAP@50:0.754
2024-07-22 16:06:31 metrics/test.mAP@75:0.181
2024-07-22 16:06:31 metrics/test.mAR@50:95:0.461
2024-07-22 16:06:31 metrics/test.mAR@50:0.906
2024-07-22 16:06:31 metrics/test.mAR@75:0.363
2024-07-22 16:06:31 Epoch 20/250 (lr=0.0001), train loss 0.43696
2024-07-22 16:06:41 Training for epoch 21 done, starting evaluation
2024-07-22 16:06:48 Epoch 21 performance:
2024-07-22 16:06:48 metrics/test.mAP@50:95:0.310
2024-07-22 16:06:48 metrics/test.mAP@50:0.708
2024-07-22 16:06:48 metrics/test.mAP@75:0.218
2024-07-22 16:06:48 metrics/test.mAR@50:95:0.446
2024-07-22 16:06:48 metrics/test.mAR@50:0.875
2024-07-22 16:06:48 metrics/test.mAR@75:0.371
2024-07-22 16:06:48 Epoch 21/250 (lr=0.0001), train loss 0.48681
2024-07-22 16:06:56 Training for epoch 22 done, starting evaluation
2024-07-22 16:07:03 Epoch 22 performance:
2024-07-22 16:07:03 metrics/test.mAP@50:95:0.352
2024-07-22 16:07:03 metrics/test.mAP@50:0.744
2024-07-22 16:07:03 metrics/test.mAP@75:0.276
2024-07-22 16:07:03 metrics/test.mAR@50:95:0.478
2024-07-22 16:07:03 metrics/test.mAR@50:0.898
2024-07-22 16:07:03 metrics/test.mAR@75:0.414
2024-07-22 16:07:03 Epoch 22/250 (lr=0.0001), train loss 0.42475
2024-07-22 16:07:13 Training for epoch 23 done, starting evaluation
2024-07-22 16:07:19 Epoch 23 performance:
2024-07-22 16:07:19 metrics/test.mAP@50:95:0.270
2024-07-22 16:07:19 metrics/test.mAP@50:0.663
2024-07-22 16:07:19 metrics/test.mAP@75:0.165
2024-07-22 16:07:19 metrics/test.mAR@50:95:0.403
2024-07-22 16:07:19 metrics/test.mAR@50:0.828
2024-07-22 16:07:19 metrics/test.mAR@75:0.332
2024-07-22 16:07:19 Epoch 23/250 (lr=0.0001), train loss 0.39422
2024-07-22 16:07:28 Training for epoch 24 done, starting evaluation
2024-07-22 16:07:35 Epoch 24 performance:
2024-07-22 16:07:35 metrics/test.mAP@50:95:0.293
2024-07-22 16:07:35 metrics/test.mAP@50:0.726
2024-07-22 16:07:35 metrics/test.mAP@75:0.150
2024-07-22 16:07:35 metrics/test.mAR@50:95:0.431
2024-07-22 16:07:35 metrics/test.mAR@50:0.895
2024-07-22 16:07:35 metrics/test.mAR@75:0.348
2024-07-22 16:07:35 Epoch 24/250 (lr=0.0001), train loss 0.44823
2024-07-22 16:07:44 Training for epoch 25 done, starting evaluation
2024-07-22 16:07:51 Epoch 25 performance:
2024-07-22 16:07:51 metrics/test.mAP@50:95:0.303
2024-07-22 16:07:51 metrics/test.mAP@50:0.687
2024-07-22 16:07:51 metrics/test.mAP@75:0.207
2024-07-22 16:07:51 metrics/test.mAR@50:95:0.454
2024-07-22 16:07:51 metrics/test.mAR@50:0.871
2024-07-22 16:07:51 metrics/test.mAR@75:0.402
2024-07-22 16:07:51 Epoch 25/250 (lr=0.0001), train loss 0.33548
2024-07-22 16:08:02 Training for epoch 26 done, starting evaluation
2024-07-22 16:08:08 Epoch 26 performance:
2024-07-22 16:08:08 metrics/test.mAP@50:95:0.281
2024-07-22 16:08:08 metrics/test.mAP@50:0.727
2024-07-22 16:08:08 metrics/test.mAP@75:0.142
2024-07-22 16:08:08 metrics/test.mAR@50:95:0.428
2024-07-22 16:08:08 metrics/test.mAR@50:0.906
2024-07-22 16:08:08 metrics/test.mAR@75:0.328
2024-07-22 16:08:08 Epoch 26/250 (lr=0.0001), train loss 0.37640
2024-07-22 16:08:19 Training for epoch 27 done, starting evaluation
2024-07-22 16:08:25 Epoch 27 performance:
2024-07-22 16:08:25 metrics/test.mAP@50:95:0.309
2024-07-22 16:08:25 metrics/test.mAP@50:0.725
2024-07-22 16:08:25 metrics/test.mAP@75:0.202
2024-07-22 16:08:25 metrics/test.mAR@50:95:0.438
2024-07-22 16:08:25 metrics/test.mAR@50:0.875
2024-07-22 16:08:25 metrics/test.mAR@75:0.355
2024-07-22 16:08:25 Epoch 27/250 (lr=0.0001), train loss 0.40671
2024-07-22 16:08:35 Training for epoch 28 done, starting evaluation
2024-07-22 16:08:42 Epoch 28 performance:
2024-07-22 16:08:42 metrics/test.mAP@50:95:0.322
2024-07-22 16:08:42 metrics/test.mAP@50:0.710
2024-07-22 16:08:42 metrics/test.mAP@75:0.233
2024-07-22 16:08:42 metrics/test.mAR@50:95:0.452
2024-07-22 16:08:42 metrics/test.mAR@50:0.871
2024-07-22 16:08:42 metrics/test.mAR@75:0.410
2024-07-22 16:08:42 Epoch 28/250 (lr=0.0001), train loss 0.40158
2024-07-22 16:08:52 Training for epoch 29 done, starting evaluation
2024-07-22 16:08:59 Epoch 29 performance:
2024-07-22 16:08:59 metrics/test.mAP@50:95:0.329
2024-07-22 16:08:59 metrics/test.mAP@50:0.724
2024-07-22 16:08:59 metrics/test.mAP@75:0.234
2024-07-22 16:08:59 metrics/test.mAR@50:95:0.458
2024-07-22 16:08:59 metrics/test.mAR@50:0.844
2024-07-22 16:08:59 metrics/test.mAR@75:0.426
2024-07-22 16:08:59 Epoch 29/250 (lr=0.0001), train loss 0.42327
2024-07-22 16:09:07 Training for epoch 30 done, starting evaluation
2024-07-22 16:09:14 Epoch 30 performance:
2024-07-22 16:09:14 metrics/test.mAP@50:95:0.297
2024-07-22 16:09:14 metrics/test.mAP@50:0.688
2024-07-22 16:09:14 metrics/test.mAP@75:0.181
2024-07-22 16:09:14 metrics/test.mAR@50:95:0.412
2024-07-22 16:09:14 metrics/test.mAR@50:0.828
2024-07-22 16:09:14 metrics/test.mAR@75:0.340
2024-07-22 16:09:14 Epoch 30/250 (lr=0.0001), train loss 0.44773
2024-07-22 16:09:23 Training for epoch 31 done, starting evaluation
2024-07-22 16:09:29 Epoch 31 performance:
2024-07-22 16:09:29 metrics/test.mAP@50:95:0.349
2024-07-22 16:09:29 metrics/test.mAP@50:0.739
2024-07-22 16:09:29 metrics/test.mAP@75:0.289
2024-07-22 16:09:29 metrics/test.mAR@50:95:0.484
2024-07-22 16:09:29 metrics/test.mAR@50:0.891
2024-07-22 16:09:29 metrics/test.mAR@75:0.461
2024-07-22 16:09:29 Epoch 31/250 (lr=0.0001), train loss 0.44688
2024-07-22 16:09:38 Training for epoch 32 done, starting evaluation
2024-07-22 16:09:44 Epoch 32 performance:
2024-07-22 16:09:44 metrics/test.mAP@50:95:0.317
2024-07-22 16:09:44 metrics/test.mAP@50:0.728
2024-07-22 16:09:44 metrics/test.mAP@75:0.245
2024-07-22 16:09:44 metrics/test.mAR@50:95:0.426
2024-07-22 16:09:44 metrics/test.mAR@50:0.840
2024-07-22 16:09:44 metrics/test.mAR@75:0.395
2024-07-22 16:09:44 Epoch 32/250 (lr=0.0001), train loss 0.49633
2024-07-22 16:09:54 Training for epoch 33 done, starting evaluation
2024-07-22 16:10:00 Epoch 33 performance:
2024-07-22 16:10:00 metrics/test.mAP@50:95:0.276
2024-07-22 16:10:00 metrics/test.mAP@50:0.708
2024-07-22 16:10:00 metrics/test.mAP@75:0.154
2024-07-22 16:10:00 metrics/test.mAR@50:95:0.414
2024-07-22 16:10:00 metrics/test.mAR@50:0.895
2024-07-22 16:10:00 metrics/test.mAR@75:0.316
2024-07-22 16:10:00 Epoch 33/250 (lr=0.0001), train loss 0.47893
2024-07-22 16:10:09 Training for epoch 34 done, starting evaluation
2024-07-22 16:10:16 Epoch 34 performance:
2024-07-22 16:10:16 metrics/test.mAP@50:95:0.271
2024-07-22 16:10:16 metrics/test.mAP@50:0.698
2024-07-22 16:10:16 metrics/test.mAP@75:0.167
2024-07-22 16:10:16 metrics/test.mAR@50:95:0.414
2024-07-22 16:10:16 metrics/test.mAR@50:0.883
2024-07-22 16:10:16 metrics/test.mAR@75:0.332
2024-07-22 16:10:16 Epoch 34/250 (lr=0.0001), train loss 0.36498
2024-07-22 16:10:25 Training for epoch 35 done, starting evaluation
2024-07-22 16:10:31 Epoch 35 performance:
2024-07-22 16:10:31 metrics/test.mAP@50:95:0.276
2024-07-22 16:10:31 metrics/test.mAP@50:0.684
2024-07-22 16:10:31 metrics/test.mAP@75:0.164
2024-07-22 16:10:31 metrics/test.mAR@50:95:0.416
2024-07-22 16:10:31 metrics/test.mAR@50:0.867
2024-07-22 16:10:31 metrics/test.mAR@75:0.348
2024-07-22 16:10:31 Epoch 35/250 (lr=0.0001), train loss 0.43146
2024-07-22 16:10:39 Training for epoch 36 done, starting evaluation
2024-07-22 16:10:46 Epoch 36 performance:
2024-07-22 16:10:46 metrics/test.mAP@50:95:0.333
2024-07-22 16:10:46 metrics/test.mAP@50:0.722
2024-07-22 16:10:46 metrics/test.mAP@75:0.288
2024-07-22 16:10:46 metrics/test.mAR@50:95:0.475
2024-07-22 16:10:46 metrics/test.mAR@50:0.910
2024-07-22 16:10:46 metrics/test.mAR@75:0.438
2024-07-22 16:10:46 Epoch 36/250 (lr=0.0001), train loss 0.45744
2024-07-22 16:10:54 Training for epoch 37 done, starting evaluation
2024-07-22 16:11:01 Epoch 37 performance:
2024-07-22 16:11:01 metrics/test.mAP@50:95:0.320
2024-07-22 16:11:01 metrics/test.mAP@50:0.705
2024-07-22 16:11:01 metrics/test.mAP@75:0.250
2024-07-22 16:11:01 metrics/test.mAR@50:95:0.458
2024-07-22 16:11:01 metrics/test.mAR@50:0.859
2024-07-22 16:11:01 metrics/test.mAR@75:0.430
2024-07-22 16:11:01 Epoch 37/250 (lr=0.0001), train loss 0.42047
2024-07-22 16:11:11 Training for epoch 38 done, starting evaluation
2024-07-22 16:11:17 Epoch 38 performance:
2024-07-22 16:11:17 metrics/test.mAP@50:95:0.349
2024-07-22 16:11:17 metrics/test.mAP@50:0.746
2024-07-22 16:11:17 metrics/test.mAP@75:0.291
2024-07-22 16:11:17 metrics/test.mAR@50:95:0.472
2024-07-22 16:11:17 metrics/test.mAR@50:0.883
2024-07-22 16:11:17 metrics/test.mAR@75:0.449
2024-07-22 16:11:17 Epoch 38/250 (lr=0.0001), train loss 0.50576
2024-07-22 16:11:26 Training for epoch 39 done, starting evaluation
2024-07-22 16:11:32 Epoch 39 performance:
2024-07-22 16:11:32 metrics/test.mAP@50:95:0.341
2024-07-22 16:11:32 metrics/test.mAP@50:0.747
2024-07-22 16:11:32 metrics/test.mAP@75:0.276
2024-07-22 16:11:32 metrics/test.mAR@50:95:0.486
2024-07-22 16:11:32 metrics/test.mAR@50:0.895
2024-07-22 16:11:32 metrics/test.mAR@75:0.457
2024-07-22 16:11:32 Epoch 39/250 (lr=0.0001), train loss 0.49449
2024-07-22 16:11:42 Training for epoch 40 done, starting evaluation
2024-07-22 16:11:48 Epoch 40 performance:
2024-07-22 16:11:48 metrics/test.mAP@50:95:0.299
2024-07-22 16:11:48 metrics/test.mAP@50:0.711
2024-07-22 16:11:48 metrics/test.mAP@75:0.184
2024-07-22 16:11:48 metrics/test.mAR@50:95:0.430
2024-07-22 16:11:48 metrics/test.mAR@50:0.871
2024-07-22 16:11:48 metrics/test.mAR@75:0.344
2024-07-22 16:11:48 Epoch 40/250 (lr=0.0001), train loss 0.39309
2024-07-22 16:11:57 Training for epoch 41 done, starting evaluation
2024-07-22 16:12:03 Epoch 41 performance:
2024-07-22 16:12:03 metrics/test.mAP@50:95:0.305
2024-07-22 16:12:03 metrics/test.mAP@50:0.698
2024-07-22 16:12:03 metrics/test.mAP@75:0.226
2024-07-22 16:12:03 metrics/test.mAR@50:95:0.419
2024-07-22 16:12:03 metrics/test.mAR@50:0.820
2024-07-22 16:12:03 metrics/test.mAR@75:0.371
2024-07-22 16:12:03 Epoch 41/250 (lr=0.0001), train loss 0.40951
2024-07-22 16:12:13 Training for epoch 42 done, starting evaluation
2024-07-22 16:12:19 Epoch 42 performance:
2024-07-22 16:12:19 metrics/test.mAP@50:95:0.280
2024-07-22 16:12:19 metrics/test.mAP@50:0.678
2024-07-22 16:12:19 metrics/test.mAP@75:0.171
2024-07-22 16:12:19 metrics/test.mAR@50:95:0.400
2024-07-22 16:12:19 metrics/test.mAR@50:0.828
2024-07-22 16:12:19 metrics/test.mAR@75:0.309
2024-07-22 16:12:19 Epoch 42/250 (lr=0.0001), train loss 0.40322
2024-07-22 16:12:28 Training for epoch 43 done, starting evaluation
2024-07-22 16:12:35 Epoch 43 performance:
2024-07-22 16:12:35 metrics/test.mAP@50:95:0.311
2024-07-22 16:12:35 metrics/test.mAP@50:0.691
2024-07-22 16:12:35 metrics/test.mAP@75:0.224
2024-07-22 16:12:35 metrics/test.mAR@50:95:0.453
2024-07-22 16:12:35 metrics/test.mAR@50:0.879
2024-07-22 16:12:35 metrics/test.mAR@75:0.395
2024-07-22 16:12:35 Epoch 43/250 (lr=0.0001), train loss 0.43505
2024-07-22 16:12:44 Training for epoch 44 done, starting evaluation
2024-07-22 16:12:51 Epoch 44 performance:
2024-07-22 16:12:51 metrics/test.mAP@50:95:0.318
2024-07-22 16:12:51 metrics/test.mAP@50:0.711
2024-07-22 16:12:51 metrics/test.mAP@75:0.224
2024-07-22 16:12:51 metrics/test.mAR@50:95:0.464
2024-07-22 16:12:51 metrics/test.mAR@50:0.879
2024-07-22 16:12:51 metrics/test.mAR@75:0.414
2024-07-22 16:12:51 Epoch 44/250 (lr=0.0001), train loss 0.36839
2024-07-22 16:13:00 Training for epoch 45 done, starting evaluation
2024-07-22 16:13:06 Epoch 45 performance:
2024-07-22 16:13:06 metrics/test.mAP@50:95:0.328
2024-07-22 16:13:06 metrics/test.mAP@50:0.719
2024-07-22 16:13:06 metrics/test.mAP@75:0.231
2024-07-22 16:13:06 metrics/test.mAR@50:95:0.455
2024-07-22 16:13:06 metrics/test.mAR@50:0.867
2024-07-22 16:13:06 metrics/test.mAR@75:0.391
2024-07-22 16:13:06 Epoch 45/250 (lr=0.0001), train loss 0.27095
2024-07-22 16:13:16 Training for epoch 46 done, starting evaluation
2024-07-22 16:13:22 Epoch 46 performance:
2024-07-22 16:13:22 metrics/test.mAP@50:95:0.332
2024-07-22 16:13:22 metrics/test.mAP@50:0.744
2024-07-22 16:13:22 metrics/test.mAP@75:0.234
2024-07-22 16:13:22 metrics/test.mAR@50:95:0.450
2024-07-22 16:13:22 metrics/test.mAR@50:0.867
2024-07-22 16:13:22 metrics/test.mAR@75:0.434
2024-07-22 16:13:22 Epoch 46/250 (lr=0.0001), train loss 0.38779
2024-07-22 16:13:32 Training for epoch 47 done, starting evaluation
2024-07-22 16:13:39 Epoch 47 performance:
2024-07-22 16:13:39 metrics/test.mAP@50:95:0.339
2024-07-22 16:13:39 metrics/test.mAP@50:0.727
2024-07-22 16:13:39 metrics/test.mAP@75:0.260
2024-07-22 16:13:39 metrics/test.mAR@50:95:0.457
2024-07-22 16:13:39 metrics/test.mAR@50:0.852
2024-07-22 16:13:39 metrics/test.mAR@75:0.410
2024-07-22 16:13:39 Epoch 47/250 (lr=0.0001), train loss 0.40258
2024-07-22 16:13:48 Training for epoch 48 done, starting evaluation
2024-07-22 16:13:54 Epoch 48 performance:
2024-07-22 16:13:54 metrics/test.mAP@50:95:0.313
2024-07-22 16:13:54 metrics/test.mAP@50:0.723
2024-07-22 16:13:54 metrics/test.mAP@75:0.217
2024-07-22 16:13:54 metrics/test.mAR@50:95:0.448
2024-07-22 16:13:54 metrics/test.mAR@50:0.898
2024-07-22 16:13:54 metrics/test.mAR@75:0.391
2024-07-22 16:13:54 Epoch 48/250 (lr=0.0001), train loss 0.39298
2024-07-22 16:14:03 Training for epoch 49 done, starting evaluation
2024-07-22 16:14:10 Epoch 49 performance:
2024-07-22 16:14:10 metrics/test.mAP@50:95:0.334
2024-07-22 16:14:10 metrics/test.mAP@50:0.725
2024-07-22 16:14:10 metrics/test.mAP@75:0.266
2024-07-22 16:14:10 metrics/test.mAR@50:95:0.479
2024-07-22 16:14:10 metrics/test.mAR@50:0.902
2024-07-22 16:14:10 metrics/test.mAR@75:0.457
2024-07-22 16:14:10 Epoch 49/250 (lr=0.0001), train loss 0.34944
2024-07-22 16:14:20 Training for epoch 50 done, starting evaluation
2024-07-22 16:14:26 Epoch 50 performance:
2024-07-22 16:14:26 metrics/test.mAP@50:95:0.336
2024-07-22 16:14:26 metrics/test.mAP@50:0.724
2024-07-22 16:14:26 metrics/test.mAP@75:0.267
2024-07-22 16:14:26 metrics/test.mAR@50:95:0.449
2024-07-22 16:14:26 metrics/test.mAR@50:0.840
2024-07-22 16:14:26 metrics/test.mAR@75:0.410
2024-07-22 16:14:26 Epoch 50/250 (lr=0.0001), train loss 0.38532
2024-07-22 16:14:35 Training for epoch 51 done, starting evaluation
2024-07-22 16:14:42 Epoch 51 performance:
2024-07-22 16:14:42 metrics/test.mAP@50:95:0.326
2024-07-22 16:14:42 metrics/test.mAP@50:0.713
2024-07-22 16:14:42 metrics/test.mAP@75:0.269
2024-07-22 16:14:42 metrics/test.mAR@50:95:0.444
2024-07-22 16:14:42 metrics/test.mAR@50:0.828
2024-07-22 16:14:42 metrics/test.mAR@75:0.438
2024-07-22 16:14:42 Epoch 51/250 (lr=0.0001), train loss 0.32216
2024-07-22 16:14:51 Training for epoch 52 done, starting evaluation
2024-07-22 16:14:58 Epoch 52 performance:
2024-07-22 16:14:58 metrics/test.mAP@50:95:0.338
2024-07-22 16:14:58 metrics/test.mAP@50:0.721
2024-07-22 16:14:58 metrics/test.mAP@75:0.263
2024-07-22 16:14:58 metrics/test.mAR@50:95:0.458
2024-07-22 16:14:58 metrics/test.mAR@50:0.836
2024-07-22 16:14:58 metrics/test.mAR@75:0.434
2024-07-22 16:14:58 Epoch 52/250 (lr=0.0001), train loss 0.34824
2024-07-22 16:15:06 Training for epoch 53 done, starting evaluation
2024-07-22 16:15:13 Epoch 53 performance:
2024-07-22 16:15:13 metrics/test.mAP@50:95:0.311
2024-07-22 16:15:13 metrics/test.mAP@50:0.694
2024-07-22 16:15:13 metrics/test.mAP@75:0.243
2024-07-22 16:15:13 metrics/test.mAR@50:95:0.396
2024-07-22 16:15:13 metrics/test.mAR@50:0.750
2024-07-22 16:15:13 metrics/test.mAR@75:0.367
2024-07-22 16:15:13 Epoch 53/250 (lr=0.0001), train loss 0.38981
2024-07-22 16:15:22 Training for epoch 54 done, starting evaluation
2024-07-22 16:15:29 Epoch 54 performance:
2024-07-22 16:15:29 metrics/test.mAP@50:95:0.299
2024-07-22 16:15:29 metrics/test.mAP@50:0.732
2024-07-22 16:15:29 metrics/test.mAP@75:0.170
2024-07-22 16:15:29 metrics/test.mAR@50:95:0.395
2024-07-22 16:15:29 metrics/test.mAR@50:0.840
2024-07-22 16:15:29 metrics/test.mAR@75:0.312
2024-07-22 16:15:29 Epoch 54/250 (lr=0.0001), train loss 0.40756
2024-07-22 16:15:37 Training for epoch 55 done, starting evaluation
2024-07-22 16:15:44 Epoch 55 performance:
2024-07-22 16:15:44 metrics/test.mAP@50:95:0.346
2024-07-22 16:15:44 metrics/test.mAP@50:0.717
2024-07-22 16:15:44 metrics/test.mAP@75:0.289
2024-07-22 16:15:44 metrics/test.mAR@50:95:0.441
2024-07-22 16:15:44 metrics/test.mAR@50:0.805
2024-07-22 16:15:44 metrics/test.mAR@75:0.414
2024-07-22 16:15:44 Epoch 55/250 (lr=0.0001), train loss 0.41902
2024-07-22 16:15:52 Training for epoch 56 done, starting evaluation
2024-07-22 16:15:59 Epoch 56 performance:
2024-07-22 16:15:59 metrics/test.mAP@50:95:0.326
2024-07-22 16:15:59 metrics/test.mAP@50:0.721
2024-07-22 16:15:59 metrics/test.mAP@75:0.259
2024-07-22 16:15:59 metrics/test.mAR@50:95:0.424
2024-07-22 16:15:59 metrics/test.mAR@50:0.805
2024-07-22 16:15:59 metrics/test.mAR@75:0.383
2024-07-22 16:15:59 Epoch 56/250 (lr=0.0001), train loss 0.40055
2024-07-22 16:16:08 Training for epoch 57 done, starting evaluation
2024-07-22 16:16:15 Epoch 57 performance:
2024-07-22 16:16:15 metrics/test.mAP@50:95:0.355
2024-07-22 16:16:15 metrics/test.mAP@50:0.750
2024-07-22 16:16:15 metrics/test.mAP@75:0.276
2024-07-22 16:16:15 metrics/test.mAR@50:95:0.480
2024-07-22 16:16:15 metrics/test.mAR@50:0.875
2024-07-22 16:16:15 metrics/test.mAR@75:0.430
2024-07-22 16:16:15 Epoch 57/250 (lr=0.0001), train loss 0.44575
2024-07-22 16:16:24 Training for epoch 58 done, starting evaluation
2024-07-22 16:16:30 Epoch 58 performance:
2024-07-22 16:16:30 metrics/test.mAP@50:95:0.318
2024-07-22 16:16:30 metrics/test.mAP@50:0.725
2024-07-22 16:16:30 metrics/test.mAP@75:0.231
2024-07-22 16:16:30 metrics/test.mAR@50:95:0.451
2024-07-22 16:16:30 metrics/test.mAR@50:0.871
2024-07-22 16:16:30 metrics/test.mAR@75:0.391
2024-07-22 16:16:30 Epoch 58/250 (lr=0.0001), train loss 0.42633
2024-07-22 16:16:38 Training for epoch 59 done, starting evaluation
2024-07-22 16:16:45 Epoch 59 performance:
2024-07-22 16:16:45 metrics/test.mAP@50:95:0.325
2024-07-22 16:16:45 metrics/test.mAP@50:0.694
2024-07-22 16:16:45 metrics/test.mAP@75:0.250
2024-07-22 16:16:45 metrics/test.mAR@50:95:0.441
2024-07-22 16:16:45 metrics/test.mAR@50:0.812
2024-07-22 16:16:45 metrics/test.mAR@75:0.395
2024-07-22 16:16:45 Epoch 59/250 (lr=0.0001), train loss 0.45379
2024-07-22 16:16:53 Training for epoch 60 done, starting evaluation
2024-07-22 16:17:00 Epoch 60 performance:
2024-07-22 16:17:00 metrics/test.mAP@50:95:0.293
2024-07-22 16:17:00 metrics/test.mAP@50:0.704
2024-07-22 16:17:00 metrics/test.mAP@75:0.192
2024-07-22 16:17:00 metrics/test.mAR@50:95:0.441
2024-07-22 16:17:00 metrics/test.mAR@50:0.879
2024-07-22 16:17:00 metrics/test.mAR@75:0.383
2024-07-22 16:17:00 Epoch 60/250 (lr=0.0001), train loss 0.43853
2024-07-22 16:17:10 Training for epoch 61 done, starting evaluation
2024-07-22 16:17:16 Epoch 61 performance:
2024-07-22 16:17:16 metrics/test.mAP@50:95:0.303
2024-07-22 16:17:16 metrics/test.mAP@50:0.720
2024-07-22 16:17:16 metrics/test.mAP@75:0.195
2024-07-22 16:17:16 metrics/test.mAR@50:95:0.419
2024-07-22 16:17:16 metrics/test.mAR@50:0.828
2024-07-22 16:17:16 metrics/test.mAR@75:0.348
2024-07-22 16:17:16 Epoch 61/250 (lr=0.0001), train loss 0.41565
2024-07-22 16:17:25 Training for epoch 62 done, starting evaluation
2024-07-22 16:17:32 Epoch 62 performance:
2024-07-22 16:17:32 metrics/test.mAP@50:95:0.294
2024-07-22 16:17:32 metrics/test.mAP@50:0.710
2024-07-22 16:17:32 metrics/test.mAP@75:0.202
2024-07-22 16:17:32 metrics/test.mAR@50:95:0.419
2024-07-22 16:17:32 metrics/test.mAR@50:0.836
2024-07-22 16:17:32 metrics/test.mAR@75:0.367
2024-07-22 16:17:32 Epoch 62/250 (lr=0.0001), train loss 0.39038
2024-07-22 16:17:41 Training for epoch 63 done, starting evaluation
2024-07-22 16:17:48 Epoch 63 performance:
2024-07-22 16:17:48 metrics/test.mAP@50:95:0.312
2024-07-22 16:17:48 metrics/test.mAP@50:0.699
2024-07-22 16:17:48 metrics/test.mAP@75:0.224
2024-07-22 16:17:48 metrics/test.mAR@50:95:0.429
2024-07-22 16:17:48 metrics/test.mAR@50:0.824
2024-07-22 16:17:48 metrics/test.mAR@75:0.355
2024-07-22 16:17:48 Epoch 63/250 (lr=0.0001), train loss 0.36098
2024-07-22 16:17:56 Training for epoch 64 done, starting evaluation
2024-07-22 16:18:02 Epoch 64 performance:
2024-07-22 16:18:02 metrics/test.mAP@50:95:0.352
2024-07-22 16:18:02 metrics/test.mAP@50:0.740
2024-07-22 16:18:02 metrics/test.mAP@75:0.260
2024-07-22 16:18:02 metrics/test.mAR@50:95:0.450
2024-07-22 16:18:02 metrics/test.mAR@50:0.840
2024-07-22 16:18:02 metrics/test.mAR@75:0.383
2024-07-22 16:18:02 Epoch 64/250 (lr=0.0001), train loss 0.44193
2024-07-22 16:18:12 Training for epoch 65 done, starting evaluation
2024-07-22 16:18:18 Epoch 65 performance:
2024-07-22 16:18:18 metrics/test.mAP@50:95:0.309
2024-07-22 16:18:18 metrics/test.mAP@50:0.677
2024-07-22 16:18:18 metrics/test.mAP@75:0.237
2024-07-22 16:18:18 metrics/test.mAR@50:95:0.438
2024-07-22 16:18:18 metrics/test.mAR@50:0.828
2024-07-22 16:18:18 metrics/test.mAR@75:0.395
2024-07-22 16:18:18 Epoch 65/250 (lr=0.0001), train loss 0.45557
2024-07-22 16:18:27 Training for epoch 66 done, starting evaluation
2024-07-22 16:18:33 Epoch 66 performance:
2024-07-22 16:18:33 metrics/test.mAP@50:95:0.354
2024-07-22 16:18:33 metrics/test.mAP@50:0.695
2024-07-22 16:18:33 metrics/test.mAP@75:0.307
2024-07-22 16:18:33 metrics/test.mAR@50:95:0.483
2024-07-22 16:18:33 metrics/test.mAR@50:0.875
2024-07-22 16:18:33 metrics/test.mAR@75:0.457
2024-07-22 16:18:33 Epoch 66/250 (lr=0.0001), train loss 0.43934
2024-07-22 16:18:42 Training for epoch 67 done, starting evaluation
2024-07-22 16:18:49 Epoch 67 performance:
2024-07-22 16:18:49 metrics/test.mAP@50:95:0.354
2024-07-22 16:18:49 metrics/test.mAP@50:0.732
2024-07-22 16:18:49 metrics/test.mAP@75:0.278
2024-07-22 16:18:49 metrics/test.mAR@50:95:0.471
2024-07-22 16:18:49 metrics/test.mAR@50:0.859
2024-07-22 16:18:49 metrics/test.mAR@75:0.410
2024-07-22 16:18:49 Epoch 67/250 (lr=0.0001), train loss 0.41532
2024-07-22 16:18:58 Training for epoch 68 done, starting evaluation
2024-07-22 16:19:04 Epoch 68 performance:
2024-07-22 16:19:04 metrics/test.mAP@50:95:0.293
2024-07-22 16:19:04 metrics/test.mAP@50:0.664
2024-07-22 16:19:04 metrics/test.mAP@75:0.203
2024-07-22 16:19:04 metrics/test.mAR@50:95:0.399
2024-07-22 16:19:04 metrics/test.mAR@50:0.805
2024-07-22 16:19:04 metrics/test.mAR@75:0.320
2024-07-22 16:19:04 Epoch 68/250 (lr=0.0001), train loss 0.40235
2024-07-22 16:19:13 Training for epoch 69 done, starting evaluation
2024-07-22 16:19:19 Epoch 69 performance:
2024-07-22 16:19:19 metrics/test.mAP@50:95:0.365
2024-07-22 16:19:19 metrics/test.mAP@50:0.728
2024-07-22 16:19:19 metrics/test.mAP@75:0.307
2024-07-22 16:19:19 metrics/test.mAR@50:95:0.486
2024-07-22 16:19:19 metrics/test.mAR@50:0.844
2024-07-22 16:19:19 metrics/test.mAR@75:0.465
2024-07-22 16:19:19 Epoch 69/250 (lr=0.0001), train loss 0.40407
2024-07-22 16:19:28 Training for epoch 70 done, starting evaluation
2024-07-22 16:19:35 Epoch 70 performance:
2024-07-22 16:19:35 metrics/test.mAP@50:95:0.346
2024-07-22 16:19:35 metrics/test.mAP@50:0.730
2024-07-22 16:19:35 metrics/test.mAP@75:0.272
2024-07-22 16:19:35 metrics/test.mAR@50:95:0.447
2024-07-22 16:19:35 metrics/test.mAR@50:0.824
2024-07-22 16:19:35 metrics/test.mAR@75:0.395
2024-07-22 16:19:35 Epoch 70/250 (lr=0.0001), train loss 0.37572
2024-07-22 16:19:44 Training for epoch 71 done, starting evaluation
2024-07-22 16:19:50 Epoch 71 performance:
2024-07-22 16:19:50 metrics/test.mAP@50:95:0.337
2024-07-22 16:19:50 metrics/test.mAP@50:0.728
2024-07-22 16:19:50 metrics/test.mAP@75:0.269
2024-07-22 16:19:50 metrics/test.mAR@50:95:0.434
2024-07-22 16:19:50 metrics/test.mAR@50:0.816
2024-07-22 16:19:50 metrics/test.mAR@75:0.402
2024-07-22 16:19:50 Epoch 71/250 (lr=0.0001), train loss 0.36047
2024-07-22 16:20:00 Training for epoch 72 done, starting evaluation
2024-07-22 16:20:06 Epoch 72 performance:
2024-07-22 16:20:06 metrics/test.mAP@50:95:0.321
2024-07-22 16:20:06 metrics/test.mAP@50:0.666
2024-07-22 16:20:06 metrics/test.mAP@75:0.258
2024-07-22 16:20:06 metrics/test.mAR@50:95:0.453
2024-07-22 16:20:06 metrics/test.mAR@50:0.832
2024-07-22 16:20:06 metrics/test.mAR@75:0.406
2024-07-22 16:20:06 Epoch 72/250 (lr=0.0001), train loss 0.40641
2024-07-22 16:20:15 Training for epoch 73 done, starting evaluation
2024-07-22 16:20:22 Epoch 73 performance:
2024-07-22 16:20:22 metrics/test.mAP@50:95:0.320
2024-07-22 16:20:22 metrics/test.mAP@50:0.691
2024-07-22 16:20:22 metrics/test.mAP@75:0.211
2024-07-22 16:20:22 metrics/test.mAR@50:95:0.455
2024-07-22 16:20:22 metrics/test.mAR@50:0.863
2024-07-22 16:20:22 metrics/test.mAR@75:0.375
2024-07-22 16:20:22 Epoch 73/250 (lr=0.0001), train loss 0.40903
2024-07-22 16:20:31 Training for epoch 74 done, starting evaluation
2024-07-22 16:20:37 Epoch 74 performance:
2024-07-22 16:20:37 metrics/test.mAP@50:95:0.310
2024-07-22 16:20:37 metrics/test.mAP@50:0.662
2024-07-22 16:20:37 metrics/test.mAP@75:0.249
2024-07-22 16:20:37 metrics/test.mAR@50:95:0.432
2024-07-22 16:20:37 metrics/test.mAR@50:0.801
2024-07-22 16:20:37 metrics/test.mAR@75:0.398
2024-07-22 16:20:37 Epoch 74/250 (lr=0.0001), train loss 0.41355
2024-07-22 16:20:46 Training for epoch 75 done, starting evaluation
2024-07-22 16:20:53 Epoch 75 performance:
2024-07-22 16:20:53 metrics/test.mAP@50:95:0.329
2024-07-22 16:20:53 metrics/test.mAP@50:0.686
2024-07-22 16:20:53 metrics/test.mAP@75:0.268
2024-07-22 16:20:53 metrics/test.mAR@50:95:0.458
2024-07-22 16:20:53 metrics/test.mAR@50:0.836
2024-07-22 16:20:53 metrics/test.mAR@75:0.422
2024-07-22 16:20:53 Epoch 75/250 (lr=0.0001), train loss 0.39169
2024-07-22 16:21:01 Training for epoch 76 done, starting evaluation
2024-07-22 16:21:07 Epoch 76 performance:
2024-07-22 16:21:07 metrics/test.mAP@50:95:0.322
2024-07-22 16:21:07 metrics/test.mAP@50:0.686
2024-07-22 16:21:07 metrics/test.mAP@75:0.237
2024-07-22 16:21:07 metrics/test.mAR@50:95:0.435
2024-07-22 16:21:07 metrics/test.mAR@50:0.816
2024-07-22 16:21:07 metrics/test.mAR@75:0.375
2024-07-22 16:21:07 Epoch 76/250 (lr=0.0001), train loss 0.40435
2024-07-22 16:21:16 Training for epoch 77 done, starting evaluation
2024-07-22 16:21:23 Epoch 77 performance:
2024-07-22 16:21:23 metrics/test.mAP@50:95:0.314
2024-07-22 16:21:23 metrics/test.mAP@50:0.668
2024-07-22 16:21:23 metrics/test.mAP@75:0.247
2024-07-22 16:21:23 metrics/test.mAR@50:95:0.444
2024-07-22 16:21:23 metrics/test.mAR@50:0.801
2024-07-22 16:21:23 metrics/test.mAR@75:0.402
2024-07-22 16:21:23 Epoch 77/250 (lr=0.0001), train loss 0.41955
2024-07-22 16:21:31 Training for epoch 78 done, starting evaluation
2024-07-22 16:21:37 Epoch 78 performance:
2024-07-22 16:21:37 metrics/test.mAP@50:95:0.349
2024-07-22 16:21:37 metrics/test.mAP@50:0.711
2024-07-22 16:21:37 metrics/test.mAP@75:0.268
2024-07-22 16:21:37 metrics/test.mAR@50:95:0.446
2024-07-22 16:21:37 metrics/test.mAR@50:0.805
2024-07-22 16:21:37 metrics/test.mAR@75:0.402
2024-07-22 16:21:37 Epoch 78/250 (lr=0.0001), train loss 0.38482
2024-07-22 16:21:46 Training for epoch 79 done, starting evaluation
2024-07-22 16:21:53 Epoch 79 performance:
2024-07-22 16:21:53 metrics/test.mAP@50:95:0.300
2024-07-22 16:21:53 metrics/test.mAP@50:0.659
2024-07-22 16:21:53 metrics/test.mAP@75:0.217
2024-07-22 16:21:53 metrics/test.mAR@50:95:0.413
2024-07-22 16:21:53 metrics/test.mAR@50:0.805
2024-07-22 16:21:53 metrics/test.mAR@75:0.355
2024-07-22 16:21:53 Epoch 79/250 (lr=0.0001), train loss 0.45162
2024-07-22 16:22:02 Training for epoch 80 done, starting evaluation
2024-07-22 16:22:09 Epoch 80 performance:
2024-07-22 16:22:09 metrics/test.mAP@50:95:0.309
2024-07-22 16:22:09 metrics/test.mAP@50:0.659
2024-07-22 16:22:09 metrics/test.mAP@75:0.234
2024-07-22 16:22:09 metrics/test.mAR@50:95:0.425
2024-07-22 16:22:09 metrics/test.mAR@50:0.773
2024-07-22 16:22:09 metrics/test.mAR@75:0.395
2024-07-22 16:22:09 Epoch 80/250 (lr=0.0001), train loss 0.44230
2024-07-22 16:22:17 Training for epoch 81 done, starting evaluation
2024-07-22 16:22:24 Epoch 81 performance:
2024-07-22 16:22:24 metrics/test.mAP@50:95:0.308
2024-07-22 16:22:24 metrics/test.mAP@50:0.665
2024-07-22 16:22:24 metrics/test.mAP@75:0.227
2024-07-22 16:22:24 metrics/test.mAR@50:95:0.413
2024-07-22 16:22:24 metrics/test.mAR@50:0.789
2024-07-22 16:22:24 metrics/test.mAR@75:0.355
2024-07-22 16:22:24 Epoch 81/250 (lr=0.0001), train loss 0.43296
2024-07-22 16:22:32 Training for epoch 82 done, starting evaluation
2024-07-22 16:22:38 Epoch 82 performance:
2024-07-22 16:22:38 metrics/test.mAP@50:95:0.360
2024-07-22 16:22:38 metrics/test.mAP@50:0.720
2024-07-22 16:22:38 metrics/test.mAP@75:0.303
2024-07-22 16:22:38 metrics/test.mAR@50:95:0.473
2024-07-22 16:22:38 metrics/test.mAR@50:0.828
2024-07-22 16:22:38 metrics/test.mAR@75:0.465
2024-07-22 16:22:38 Epoch 82/250 (lr=0.0001), train loss 0.44932
2024-07-22 16:22:47 Training for epoch 83 done, starting evaluation
2024-07-22 16:22:54 Epoch 83 performance:
2024-07-22 16:22:54 metrics/test.mAP@50:95:0.336
2024-07-22 16:22:54 metrics/test.mAP@50:0.738
2024-07-22 16:22:54 metrics/test.mAP@75:0.249
2024-07-22 16:22:54 metrics/test.mAR@50:95:0.427
2024-07-22 16:22:54 metrics/test.mAR@50:0.828
2024-07-22 16:22:54 metrics/test.mAR@75:0.371
2024-07-22 16:22:54 Epoch 83/250 (lr=0.0001), train loss 0.41297
2024-07-22 16:23:03 Training for epoch 84 done, starting evaluation
2024-07-22 16:23:10 Epoch 84 performance:
2024-07-22 16:23:10 metrics/test.mAP@50:95:0.330
2024-07-22 16:23:10 metrics/test.mAP@50:0.730
2024-07-22 16:23:10 metrics/test.mAP@75:0.247
2024-07-22 16:23:10 metrics/test.mAR@50:95:0.445
2024-07-22 16:23:10 metrics/test.mAR@50:0.863
2024-07-22 16:23:10 metrics/test.mAR@75:0.402
2024-07-22 16:23:10 Epoch 84/250 (lr=0.0001), train loss 0.38289
2024-07-22 16:23:20 Training for epoch 85 done, starting evaluation
2024-07-22 16:23:26 Epoch 85 performance:
2024-07-22 16:23:26 metrics/test.mAP@50:95:0.333
2024-07-22 16:23:26 metrics/test.mAP@50:0.708
2024-07-22 16:23:26 metrics/test.mAP@75:0.274
2024-07-22 16:23:26 metrics/test.mAR@50:95:0.429
2024-07-22 16:23:26 metrics/test.mAR@50:0.789
2024-07-22 16:23:26 metrics/test.mAR@75:0.391
2024-07-22 16:23:26 Epoch 85/250 (lr=0.0001), train loss 0.27524
2024-07-22 16:23:34 Training for epoch 86 done, starting evaluation
2024-07-22 16:23:41 Epoch 86 performance:
2024-07-22 16:23:41 metrics/test.mAP@50:95:0.345
2024-07-22 16:23:41 metrics/test.mAP@50:0.741
2024-07-22 16:23:41 metrics/test.mAP@75:0.276
2024-07-22 16:23:41 metrics/test.mAR@50:95:0.459
2024-07-22 16:23:41 metrics/test.mAR@50:0.871
2024-07-22 16:23:41 metrics/test.mAR@75:0.410
2024-07-22 16:23:41 Epoch 86/250 (lr=0.0001), train loss 0.37384
2024-07-22 16:23:50 Training for epoch 87 done, starting evaluation
2024-07-22 16:23:56 Epoch 87 performance:
2024-07-22 16:23:56 metrics/test.mAP@50:95:0.320
2024-07-22 16:23:56 metrics/test.mAP@50:0.721
2024-07-22 16:23:56 metrics/test.mAP@75:0.233
2024-07-22 16:23:56 metrics/test.mAR@50:95:0.417
2024-07-22 16:23:56 metrics/test.mAR@50:0.801
2024-07-22 16:23:56 metrics/test.mAR@75:0.375
2024-07-22 16:23:56 Epoch 87/250 (lr=0.0001), train loss 0.35786
2024-07-22 16:24:06 Training for epoch 88 done, starting evaluation
2024-07-22 16:24:12 Epoch 88 performance:
2024-07-22 16:24:12 metrics/test.mAP@50:95:0.335
2024-07-22 16:24:12 metrics/test.mAP@50:0.715
2024-07-22 16:24:12 metrics/test.mAP@75:0.250
2024-07-22 16:24:12 metrics/test.mAR@50:95:0.443
2024-07-22 16:24:12 metrics/test.mAR@50:0.812
2024-07-22 16:24:12 metrics/test.mAR@75:0.395
2024-07-22 16:24:12 Epoch 88/250 (lr=0.0001), train loss 0.33781
2024-07-22 16:24:20 Training for epoch 89 done, starting evaluation
2024-07-22 16:24:27 Epoch 89 performance:
2024-07-22 16:24:27 metrics/test.mAP@50:95:0.302
2024-07-22 16:24:27 metrics/test.mAP@50:0.693
2024-07-22 16:24:27 metrics/test.mAP@75:0.205
2024-07-22 16:24:27 metrics/test.mAR@50:95:0.424
2024-07-22 16:24:27 metrics/test.mAR@50:0.832
2024-07-22 16:24:27 metrics/test.mAR@75:0.363
2024-07-22 16:24:27 Epoch 89/250 (lr=0.0001), train loss 0.41104
2024-07-22 16:24:36 Training for epoch 90 done, starting evaluation
2024-07-22 16:24:43 Epoch 90 performance:
2024-07-22 16:24:43 metrics/test.mAP@50:95:0.318
2024-07-22 16:24:43 metrics/test.mAP@50:0.678
2024-07-22 16:24:43 metrics/test.mAP@75:0.231
2024-07-22 16:24:43 metrics/test.mAR@50:95:0.420
2024-07-22 16:24:43 metrics/test.mAR@50:0.789
2024-07-22 16:24:43 metrics/test.mAR@75:0.379
2024-07-22 16:24:43 Epoch 90/250 (lr=0.0001), train loss 0.42692
2024-07-22 16:24:52 Training for epoch 91 done, starting evaluation
2024-07-22 16:24:58 Epoch 91 performance:
2024-07-22 16:24:58 metrics/test.mAP@50:95:0.314
2024-07-22 16:24:58 metrics/test.mAP@50:0.653
2024-07-22 16:24:58 metrics/test.mAP@75:0.233
2024-07-22 16:24:58 metrics/test.mAR@50:95:0.431
2024-07-22 16:24:58 metrics/test.mAR@50:0.789
2024-07-22 16:24:58 metrics/test.mAR@75:0.367
2024-07-22 16:24:58 Epoch 91/250 (lr=0.0001), train loss 0.38945
2024-07-22 16:25:08 Training for epoch 92 done, starting evaluation
2024-07-22 16:25:15 Epoch 92 performance:
2024-07-22 16:25:15 metrics/test.mAP@50:95:0.348
2024-07-22 16:25:15 metrics/test.mAP@50:0.699
2024-07-22 16:25:15 metrics/test.mAP@75:0.279
2024-07-22 16:25:15 metrics/test.mAR@50:95:0.447
2024-07-22 16:25:15 metrics/test.mAR@50:0.809
2024-07-22 16:25:15 metrics/test.mAR@75:0.402
2024-07-22 16:25:15 Epoch 92/250 (lr=0.0001), train loss 0.35891
2024-07-22 16:25:24 Training for epoch 93 done, starting evaluation
2024-07-22 16:25:30 Epoch 93 performance:
2024-07-22 16:25:30 metrics/test.mAP@50:95:0.330
2024-07-22 16:25:30 metrics/test.mAP@50:0.695
2024-07-22 16:25:30 metrics/test.mAP@75:0.249
2024-07-22 16:25:30 metrics/test.mAR@50:95:0.425
2024-07-22 16:25:30 metrics/test.mAR@50:0.781
2024-07-22 16:25:30 metrics/test.mAR@75:0.383
2024-07-22 16:25:30 Epoch 93/250 (lr=0.0001), train loss 0.38623
2024-07-22 16:25:40 Training for epoch 94 done, starting evaluation
2024-07-22 16:25:47 Epoch 94 performance:
2024-07-22 16:25:47 metrics/test.mAP@50:95:0.309
2024-07-22 16:25:47 metrics/test.mAP@50:0.682
2024-07-22 16:25:47 metrics/test.mAP@75:0.243
2024-07-22 16:25:47 metrics/test.mAR@50:95:0.398
2024-07-22 16:25:47 metrics/test.mAR@50:0.781
2024-07-22 16:25:47 metrics/test.mAR@75:0.363
2024-07-22 16:25:47 Epoch 94/250 (lr=0.0001), train loss 0.44804
2024-07-22 16:25:56 Training for epoch 95 done, starting evaluation
2024-07-22 16:26:03 Epoch 95 performance:
2024-07-22 16:26:03 metrics/test.mAP@50:95:0.330
2024-07-22 16:26:03 metrics/test.mAP@50:0.709
2024-07-22 16:26:03 metrics/test.mAP@75:0.257
2024-07-22 16:26:03 metrics/test.mAR@50:95:0.427
2024-07-22 16:26:03 metrics/test.mAR@50:0.789
2024-07-22 16:26:03 metrics/test.mAR@75:0.387
2024-07-22 16:26:03 Epoch 95/250 (lr=0.0001), train loss 0.38736
2024-07-22 16:26:13 Training for epoch 96 done, starting evaluation
2024-07-22 16:26:19 Epoch 96 performance:
2024-07-22 16:26:19 metrics/test.mAP@50:95:0.314
2024-07-22 16:26:19 metrics/test.mAP@50:0.666
2024-07-22 16:26:19 metrics/test.mAP@75:0.229
2024-07-22 16:26:19 metrics/test.mAR@50:95:0.407
2024-07-22 16:26:19 metrics/test.mAR@50:0.730
2024-07-22 16:26:19 metrics/test.mAR@75:0.375
2024-07-22 16:26:19 Epoch 96/250 (lr=0.0001), train loss 0.30666
2024-07-22 16:26:28 Training for epoch 97 done, starting evaluation
2024-07-22 16:26:34 Epoch 97 performance:
2024-07-22 16:26:34 metrics/test.mAP@50:95:0.313
2024-07-22 16:26:34 metrics/test.mAP@50:0.678
2024-07-22 16:26:34 metrics/test.mAP@75:0.224
2024-07-22 16:26:34 metrics/test.mAR@50:95:0.411
2024-07-22 16:26:34 metrics/test.mAR@50:0.777
2024-07-22 16:26:34 metrics/test.mAR@75:0.363
2024-07-22 16:26:34 Epoch 97/250 (lr=0.0001), train loss 0.38009
2024-07-22 16:26:44 Training for epoch 98 done, starting evaluation
2024-07-22 16:26:50 Epoch 98 performance:
2024-07-22 16:26:50 metrics/test.mAP@50:95:0.312
2024-07-22 16:26:50 metrics/test.mAP@50:0.669
2024-07-22 16:26:50 metrics/test.mAP@75:0.226
2024-07-22 16:26:50 metrics/test.mAR@50:95:0.416
2024-07-22 16:26:50 metrics/test.mAR@50:0.785
2024-07-22 16:26:50 metrics/test.mAR@75:0.367
2024-07-22 16:26:50 Epoch 98/250 (lr=0.0001), train loss 0.36503
2024-07-22 16:26:58 Training for epoch 99 done, starting evaluation
2024-07-22 16:27:05 Epoch 99 performance:
2024-07-22 16:27:05 metrics/test.mAP@50:95:0.337
2024-07-22 16:27:05 metrics/test.mAP@50:0.703
2024-07-22 16:27:05 metrics/test.mAP@75:0.266
2024-07-22 16:27:05 metrics/test.mAR@50:95:0.443
2024-07-22 16:27:05 metrics/test.mAR@50:0.824
2024-07-22 16:27:05 metrics/test.mAR@75:0.398
2024-07-22 16:27:05 Epoch 99/250 (lr=0.0001), train loss 0.47534
2024-07-22 16:27:14 Training for epoch 100 done, starting evaluation
2024-07-22 16:27:21 Epoch 100 performance:
2024-07-22 16:27:21 metrics/test.mAP@50:95:0.315
2024-07-22 16:27:21 metrics/test.mAP@50:0.694
2024-07-22 16:27:21 metrics/test.mAP@75:0.219
2024-07-22 16:27:21 metrics/test.mAR@50:95:0.422
2024-07-22 16:27:21 metrics/test.mAR@50:0.820
2024-07-22 16:27:21 metrics/test.mAR@75:0.344
2024-07-22 16:27:21 Epoch 100/250 (lr=0.0001), train loss 0.43244
2024-07-22 16:27:31 Training for epoch 101 done, starting evaluation
2024-07-22 16:27:37 Epoch 101 performance:
2024-07-22 16:27:37 metrics/test.mAP@50:95:0.333
2024-07-22 16:27:37 metrics/test.mAP@50:0.695
2024-07-22 16:27:37 metrics/test.mAP@75:0.268
2024-07-22 16:27:37 metrics/test.mAR@50:95:0.427
2024-07-22 16:27:37 metrics/test.mAR@50:0.789
2024-07-22 16:27:37 metrics/test.mAR@75:0.395
2024-07-22 16:27:37 Epoch 101/250 (lr=0.0001), train loss 0.33835
2024-07-22 16:27:45 Training for epoch 102 done, starting evaluation
2024-07-22 16:27:52 Epoch 102 performance:
2024-07-22 16:27:52 metrics/test.mAP@50:95:0.325
2024-07-22 16:27:52 metrics/test.mAP@50:0.717
2024-07-22 16:27:52 metrics/test.mAP@75:0.234
2024-07-22 16:27:52 metrics/test.mAR@50:95:0.412
2024-07-22 16:27:52 metrics/test.mAR@50:0.777
2024-07-22 16:27:52 metrics/test.mAR@75:0.352
2024-07-22 16:27:52 Epoch 102/250 (lr=0.0001), train loss 0.38631
2024-07-22 16:28:01 Training for epoch 103 done, starting evaluation
2024-07-22 16:28:07 Epoch 103 performance:
2024-07-22 16:28:07 metrics/test.mAP@50:95:0.306
2024-07-22 16:28:07 metrics/test.mAP@50:0.703
2024-07-22 16:28:07 metrics/test.mAP@75:0.224
2024-07-22 16:28:07 metrics/test.mAR@50:95:0.417
2024-07-22 16:28:07 metrics/test.mAR@50:0.809
2024-07-22 16:28:07 metrics/test.mAR@75:0.371
2024-07-22 16:28:07 Epoch 103/250 (lr=0.0001), train loss 0.31512
2024-07-22 16:28:15 Training for epoch 104 done, starting evaluation
2024-07-22 16:28:21 Epoch 104 performance:
2024-07-22 16:28:21 metrics/test.mAP@50:95:0.316
2024-07-22 16:28:21 metrics/test.mAP@50:0.682
2024-07-22 16:28:21 metrics/test.mAP@75:0.248
2024-07-22 16:28:21 metrics/test.mAR@50:95:0.427
2024-07-22 16:28:21 metrics/test.mAR@50:0.785
2024-07-22 16:28:21 metrics/test.mAR@75:0.391
2024-07-22 16:28:21 Epoch 104/250 (lr=0.0001), train loss 0.38444
2024-07-22 16:28:31 Training for epoch 105 done, starting evaluation
2024-07-22 16:28:37 Epoch 105 performance:
2024-07-22 16:28:37 metrics/test.mAP@50:95:0.340
2024-07-22 16:28:37 metrics/test.mAP@50:0.727
2024-07-22 16:28:37 metrics/test.mAP@75:0.249
2024-07-22 16:28:37 metrics/test.mAR@50:95:0.431
2024-07-22 16:28:37 metrics/test.mAR@50:0.801
2024-07-22 16:28:37 metrics/test.mAR@75:0.379
2024-07-22 16:28:37 Epoch 105/250 (lr=0.0001), train loss 0.38792
2024-07-22 16:28:47 Training for epoch 106 done, starting evaluation
2024-07-22 16:28:53 Epoch 106 performance:
2024-07-22 16:28:53 metrics/test.mAP@50:95:0.312
2024-07-22 16:28:53 metrics/test.mAP@50:0.709
2024-07-22 16:28:53 metrics/test.mAP@75:0.220
2024-07-22 16:28:53 metrics/test.mAR@50:95:0.418
2024-07-22 16:28:53 metrics/test.mAR@50:0.809
2024-07-22 16:28:53 metrics/test.mAR@75:0.359
2024-07-22 16:28:53 Epoch 106/250 (lr=0.0001), train loss 0.41624
2024-07-22 16:29:02 Training for epoch 107 done, starting evaluation
2024-07-22 16:29:08 Epoch 107 performance:
2024-07-22 16:29:08 metrics/test.mAP@50:95:0.311
2024-07-22 16:29:08 metrics/test.mAP@50:0.681
2024-07-22 16:29:08 metrics/test.mAP@75:0.234
2024-07-22 16:29:08 metrics/test.mAR@50:95:0.416
2024-07-22 16:29:08 metrics/test.mAR@50:0.773
2024-07-22 16:29:08 metrics/test.mAR@75:0.383
2024-07-22 16:29:08 Epoch 107/250 (lr=0.0001), train loss 0.36643
2024-07-22 16:29:17 Training for epoch 108 done, starting evaluation
2024-07-22 16:29:24 Epoch 108 performance:
2024-07-22 16:29:24 metrics/test.mAP@50:95:0.313
2024-07-22 16:29:24 metrics/test.mAP@50:0.639
2024-07-22 16:29:24 metrics/test.mAP@75:0.247
2024-07-22 16:29:24 metrics/test.mAR@50:95:0.437
2024-07-22 16:29:24 metrics/test.mAR@50:0.766
2024-07-22 16:29:24 metrics/test.mAR@75:0.426
2024-07-22 16:29:24 Epoch 108/250 (lr=0.0001), train loss 0.40324
2024-07-22 16:29:32 Training for epoch 109 done, starting evaluation
2024-07-22 16:29:38 Epoch 109 performance:
2024-07-22 16:29:38 metrics/test.mAP@50:95:0.314
2024-07-22 16:29:38 metrics/test.mAP@50:0.680
2024-07-22 16:29:38 metrics/test.mAP@75:0.232
2024-07-22 16:29:38 metrics/test.mAR@50:95:0.430
2024-07-22 16:29:38 metrics/test.mAR@50:0.805
2024-07-22 16:29:38 metrics/test.mAR@75:0.371
2024-07-22 16:29:38 Epoch 109/250 (lr=0.0001), train loss 0.40290
2024-07-22 16:29:47 Training for epoch 110 done, starting evaluation
2024-07-22 16:29:54 Epoch 110 performance:
2024-07-22 16:29:54 metrics/test.mAP@50:95:0.308
2024-07-22 16:29:54 metrics/test.mAP@50:0.687
2024-07-22 16:29:54 metrics/test.mAP@75:0.229
2024-07-22 16:29:54 metrics/test.mAR@50:95:0.408
2024-07-22 16:29:54 metrics/test.mAR@50:0.793
2024-07-22 16:29:54 metrics/test.mAR@75:0.367
2024-07-22 16:29:54 Epoch 110/250 (lr=0.0001), train loss 0.46399
2024-07-22 16:30:02 Training for epoch 111 done, starting evaluation
2024-07-22 16:30:09 Epoch 111 performance:
2024-07-22 16:30:09 metrics/test.mAP@50:95:0.287
2024-07-22 16:30:09 metrics/test.mAP@50:0.643
2024-07-22 16:30:09 metrics/test.mAP@75:0.214
2024-07-22 16:30:09 metrics/test.mAR@50:95:0.403
2024-07-22 16:30:09 metrics/test.mAR@50:0.750
2024-07-22 16:30:09 metrics/test.mAR@75:0.375
2024-07-22 16:30:09 Epoch 111/250 (lr=0.0001), train loss 0.38480
2024-07-22 16:30:18 Training for epoch 112 done, starting evaluation
2024-07-22 16:30:24 Epoch 112 performance:
2024-07-22 16:30:24 metrics/test.mAP@50:95:0.265
2024-07-22 16:30:24 metrics/test.mAP@50:0.614
2024-07-22 16:30:24 metrics/test.mAP@75:0.181
2024-07-22 16:30:24 metrics/test.mAR@50:95:0.361
2024-07-22 16:30:24 metrics/test.mAR@50:0.703
2024-07-22 16:30:24 metrics/test.mAR@75:0.312
2024-07-22 16:30:24 Epoch 112/250 (lr=0.0001), train loss 0.34122
2024-07-22 16:30:33 Training for epoch 113 done, starting evaluation
2024-07-22 16:30:40 Epoch 113 performance:
2024-07-22 16:30:40 metrics/test.mAP@50:95:0.303
2024-07-22 16:30:40 metrics/test.mAP@50:0.668
2024-07-22 16:30:40 metrics/test.mAP@75:0.226
2024-07-22 16:30:40 metrics/test.mAR@50:95:0.409
2024-07-22 16:30:40 metrics/test.mAR@50:0.762
2024-07-22 16:30:40 metrics/test.mAR@75:0.371
2024-07-22 16:30:40 Epoch 113/250 (lr=0.0001), train loss 0.43057
2024-07-22 16:30:49 Training for epoch 114 done, starting evaluation
2024-07-22 16:30:55 Epoch 114 performance:
2024-07-22 16:30:55 metrics/test.mAP@50:95:0.306
2024-07-22 16:30:55 metrics/test.mAP@50:0.671
2024-07-22 16:30:55 metrics/test.mAP@75:0.208
2024-07-22 16:30:55 metrics/test.mAR@50:95:0.417
2024-07-22 16:30:55 metrics/test.mAR@50:0.793
2024-07-22 16:30:55 metrics/test.mAR@75:0.348
2024-07-22 16:30:55 Epoch 114/250 (lr=0.0001), train loss 0.31289
2024-07-22 16:31:05 Training for epoch 115 done, starting evaluation
2024-07-22 16:31:11 Epoch 115 performance:
2024-07-22 16:31:11 metrics/test.mAP@50:95:0.307
2024-07-22 16:31:11 metrics/test.mAP@50:0.673
2024-07-22 16:31:11 metrics/test.mAP@75:0.215
2024-07-22 16:31:11 metrics/test.mAR@50:95:0.407
2024-07-22 16:31:11 metrics/test.mAR@50:0.766
2024-07-22 16:31:11 metrics/test.mAR@75:0.355
2024-07-22 16:31:11 Epoch 115/250 (lr=0.0001), train loss 0.33548
2024-07-22 16:31:19 Training for epoch 116 done, starting evaluation
2024-07-22 16:31:26 Epoch 116 performance:
2024-07-22 16:31:26 metrics/test.mAP@50:95:0.311
2024-07-22 16:31:26 metrics/test.mAP@50:0.683
2024-07-22 16:31:26 metrics/test.mAP@75:0.228
2024-07-22 16:31:26 metrics/test.mAR@50:95:0.420
2024-07-22 16:31:26 metrics/test.mAR@50:0.812
2024-07-22 16:31:26 metrics/test.mAR@75:0.363
2024-07-22 16:31:26 Epoch 116/250 (lr=0.0001), train loss 0.36820
2024-07-22 16:31:35 Training for epoch 117 done, starting evaluation
2024-07-22 16:31:42 Epoch 117 performance:
2024-07-22 16:31:42 metrics/test.mAP@50:95:0.273
2024-07-22 16:31:42 metrics/test.mAP@50:0.634
2024-07-22 16:31:42 metrics/test.mAP@75:0.187
2024-07-22 16:31:42 metrics/test.mAR@50:95:0.394
2024-07-22 16:31:42 metrics/test.mAR@50:0.789
2024-07-22 16:31:42 metrics/test.mAR@75:0.324
2024-07-22 16:31:42 Epoch 117/250 (lr=0.0001), train loss 0.35758
2024-07-22 16:31:50 Training for epoch 118 done, starting evaluation
2024-07-22 16:31:57 Epoch 118 performance:
2024-07-22 16:31:57 metrics/test.mAP@50:95:0.329
2024-07-22 16:31:57 metrics/test.mAP@50:0.691
2024-07-22 16:31:57 metrics/test.mAP@75:0.232
2024-07-22 16:31:57 metrics/test.mAR@50:95:0.446
2024-07-22 16:31:57 metrics/test.mAR@50:0.820
2024-07-22 16:31:57 metrics/test.mAR@75:0.375
2024-07-22 16:31:57 Epoch 118/250 (lr=0.0001), train loss 0.35402
2024-07-22 16:32:05 Training for epoch 119 done, starting evaluation
2024-07-22 16:32:11 Epoch 119 performance:
2024-07-22 16:32:11 metrics/test.mAP@50:95:0.275
2024-07-22 16:32:11 metrics/test.mAP@50:0.641
2024-07-22 16:32:11 metrics/test.mAP@75:0.164
2024-07-22 16:32:11 metrics/test.mAR@50:95:0.385
2024-07-22 16:32:11 metrics/test.mAR@50:0.762
2024-07-22 16:32:11 metrics/test.mAR@75:0.312
2024-07-22 16:32:11 Epoch 119/250 (lr=0.0001), train loss 0.37658
2024-07-22 16:32:20 Training for epoch 120 done, starting evaluation
2024-07-22 16:32:26 Epoch 120 performance:
2024-07-22 16:32:26 metrics/test.mAP@50:95:0.315
2024-07-22 16:32:26 metrics/test.mAP@50:0.678
2024-07-22 16:32:26 metrics/test.mAP@75:0.244
2024-07-22 16:32:26 metrics/test.mAR@50:95:0.435
2024-07-22 16:32:26 metrics/test.mAR@50:0.828
2024-07-22 16:32:26 metrics/test.mAR@75:0.387
2024-07-22 16:32:26 Epoch 120/250 (lr=0.0001), train loss 0.39210
2024-07-22 16:32:36 Training for epoch 121 done, starting evaluation
2024-07-22 16:32:43 Epoch 121 performance:
2024-07-22 16:32:43 metrics/test.mAP@50:95:0.322
2024-07-22 16:32:43 metrics/test.mAP@50:0.673
2024-07-22 16:32:43 metrics/test.mAP@75:0.264
2024-07-22 16:32:43 metrics/test.mAR@50:95:0.424
2024-07-22 16:32:43 metrics/test.mAR@50:0.773
2024-07-22 16:32:43 metrics/test.mAR@75:0.402
2024-07-22 16:32:43 Epoch 121/250 (lr=0.0001), train loss 0.36726
2024-07-22 16:32:52 Training for epoch 122 done, starting evaluation
2024-07-22 16:32:59 Epoch 122 performance:
2024-07-22 16:32:59 metrics/test.mAP@50:95:0.325
2024-07-22 16:32:59 metrics/test.mAP@50:0.673
2024-07-22 16:32:59 metrics/test.mAP@75:0.222
2024-07-22 16:32:59 metrics/test.mAR@50:95:0.437
2024-07-22 16:32:59 metrics/test.mAR@50:0.793
2024-07-22 16:32:59 metrics/test.mAR@75:0.371
2024-07-22 16:32:59 Epoch 122/250 (lr=0.0001), train loss 0.36236
2024-07-22 16:33:08 Training for epoch 123 done, starting evaluation
2024-07-22 16:33:14 Epoch 123 performance:
2024-07-22 16:33:14 metrics/test.mAP@50:95:0.306
2024-07-22 16:33:14 metrics/test.mAP@50:0.657
2024-07-22 16:33:14 metrics/test.mAP@75:0.233
2024-07-22 16:33:14 metrics/test.mAR@50:95:0.407
2024-07-22 16:33:14 metrics/test.mAR@50:0.758
2024-07-22 16:33:14 metrics/test.mAR@75:0.387
2024-07-22 16:33:14 Epoch 123/250 (lr=0.0001), train loss 0.41256
2024-07-22 16:33:24 Training for epoch 124 done, starting evaluation
2024-07-22 16:33:30 Epoch 124 performance:
2024-07-22 16:33:30 metrics/test.mAP@50:95:0.296
2024-07-22 16:33:30 metrics/test.mAP@50:0.659
2024-07-22 16:33:30 metrics/test.mAP@75:0.216
2024-07-22 16:33:30 metrics/test.mAR@50:95:0.410
2024-07-22 16:33:30 metrics/test.mAR@50:0.773
2024-07-22 16:33:30 metrics/test.mAR@75:0.363
2024-07-22 16:33:30 Epoch 124/250 (lr=0.0001), train loss 0.43484
2024-07-22 16:33:40 Training for epoch 125 done, starting evaluation
2024-07-22 16:33:46 Epoch 125 performance:
2024-07-22 16:33:46 metrics/test.mAP@50:95:0.313
2024-07-22 16:33:46 metrics/test.mAP@50:0.678
2024-07-22 16:33:46 metrics/test.mAP@75:0.244
2024-07-22 16:33:46 metrics/test.mAR@50:95:0.414
2024-07-22 16:33:46 metrics/test.mAR@50:0.762
2024-07-22 16:33:46 metrics/test.mAR@75:0.387
2024-07-22 16:33:47 Epoch 125/250 (lr=0.0001), train loss 0.38880
2024-07-22 16:33:54 Training for epoch 126 done, starting evaluation
2024-07-22 16:34:01 Epoch 126 performance:
2024-07-22 16:34:01 metrics/test.mAP@50:95:0.320
2024-07-22 16:34:01 metrics/test.mAP@50:0.701
2024-07-22 16:34:01 metrics/test.mAP@75:0.248
2024-07-22 16:34:01 metrics/test.mAR@50:95:0.420
2024-07-22 16:34:01 metrics/test.mAR@50:0.809
2024-07-22 16:34:01 metrics/test.mAR@75:0.375
2024-07-22 16:34:01 Epoch 126/250 (lr=0.0001), train loss 0.40400
2024-07-22 16:34:09 Training for epoch 127 done, starting evaluation
2024-07-22 16:34:16 Epoch 127 performance:
2024-07-22 16:34:16 metrics/test.mAP@50:95:0.304
2024-07-22 16:34:16 metrics/test.mAP@50:0.671
2024-07-22 16:34:16 metrics/test.mAP@75:0.241
2024-07-22 16:34:16 metrics/test.mAR@50:95:0.412
2024-07-22 16:34:16 metrics/test.mAR@50:0.777
2024-07-22 16:34:16 metrics/test.mAR@75:0.383
2024-07-22 16:34:16 Epoch 127/250 (lr=0.0001), train loss 0.35658
2024-07-22 16:34:25 Training for epoch 128 done, starting evaluation
2024-07-22 16:34:31 Epoch 128 performance:
2024-07-22 16:34:31 metrics/test.mAP@50:95:0.342
2024-07-22 16:34:31 metrics/test.mAP@50:0.707
2024-07-22 16:34:31 metrics/test.mAP@75:0.265
2024-07-22 16:34:31 metrics/test.mAR@50:95:0.427
2024-07-22 16:34:31 metrics/test.mAR@50:0.770
2024-07-22 16:34:31 metrics/test.mAR@75:0.379
2024-07-22 16:34:31 Epoch 128/250 (lr=0.0001), train loss 0.35685
2024-07-22 16:34:40 Training for epoch 129 done, starting evaluation
2024-07-22 16:34:46 Epoch 129 performance:
2024-07-22 16:34:46 metrics/test.mAP@50:95:0.315
2024-07-22 16:34:46 metrics/test.mAP@50:0.643
2024-07-22 16:34:46 metrics/test.mAP@75:0.246
2024-07-22 16:34:46 metrics/test.mAR@50:95:0.417
2024-07-22 16:34:46 metrics/test.mAR@50:0.758
2024-07-22 16:34:46 metrics/test.mAR@75:0.379
2024-07-22 16:34:46 Epoch 129/250 (lr=0.0001), train loss 0.42372
2024-07-22 16:34:55 Training for epoch 130 done, starting evaluation
2024-07-22 16:35:01 Epoch 130 performance:
2024-07-22 16:35:01 metrics/test.mAP@50:95:0.300
2024-07-22 16:35:01 metrics/test.mAP@50:0.692
2024-07-22 16:35:01 metrics/test.mAP@75:0.198
2024-07-22 16:35:01 metrics/test.mAR@50:95:0.384
2024-07-22 16:35:01 metrics/test.mAR@50:0.773
2024-07-22 16:35:01 metrics/test.mAR@75:0.320
2024-07-22 16:35:01 Epoch 130/250 (lr=0.0001), train loss 0.43371
2024-07-22 16:35:09 Training for epoch 131 done, starting evaluation
2024-07-22 16:35:16 Epoch 131 performance:
2024-07-22 16:35:16 metrics/test.mAP@50:95:0.325
2024-07-22 16:35:16 metrics/test.mAP@50:0.667
2024-07-22 16:35:16 metrics/test.mAP@75:0.278
2024-07-22 16:35:16 metrics/test.mAR@50:95:0.431
2024-07-22 16:35:16 metrics/test.mAR@50:0.770
2024-07-22 16:35:16 metrics/test.mAR@75:0.426
2024-07-22 16:35:16 Epoch 131/250 (lr=0.0001), train loss 0.45005
2024-07-22 16:35:25 Training for epoch 132 done, starting evaluation
2024-07-22 16:35:32 Epoch 132 performance:
2024-07-22 16:35:32 metrics/test.mAP@50:95:0.329
2024-07-22 16:35:32 metrics/test.mAP@50:0.664
2024-07-22 16:35:32 metrics/test.mAP@75:0.246
2024-07-22 16:35:32 metrics/test.mAR@50:95:0.429
2024-07-22 16:35:32 metrics/test.mAR@50:0.773
2024-07-22 16:35:32 metrics/test.mAR@75:0.398
2024-07-22 16:35:32 Epoch 132/250 (lr=0.0001), train loss 0.42667
2024-07-22 16:35:40 Training for epoch 133 done, starting evaluation
2024-07-22 16:35:47 Epoch 133 performance:
2024-07-22 16:35:47 metrics/test.mAP@50:95:0.304
2024-07-22 16:35:47 metrics/test.mAP@50:0.644
2024-07-22 16:35:47 metrics/test.mAP@75:0.219
2024-07-22 16:35:47 metrics/test.mAR@50:95:0.391
2024-07-22 16:35:47 metrics/test.mAR@50:0.727
2024-07-22 16:35:47 metrics/test.mAR@75:0.336
2024-07-22 16:35:47 Epoch 133/250 (lr=0.0001), train loss 0.43213
2024-07-22 16:35:55 Training for epoch 134 done, starting evaluation
2024-07-22 16:36:02 Epoch 134 performance:
2024-07-22 16:36:02 metrics/test.mAP@50:95:0.336
2024-07-22 16:36:02 metrics/test.mAP@50:0.717
2024-07-22 16:36:02 metrics/test.mAP@75:0.253
2024-07-22 16:36:02 metrics/test.mAR@50:95:0.429
2024-07-22 16:36:02 metrics/test.mAR@50:0.789
2024-07-22 16:36:02 metrics/test.mAR@75:0.383
2024-07-22 16:36:02 Epoch 134/250 (lr=0.0001), train loss 0.38844
2024-07-22 16:36:10 Training for epoch 135 done, starting evaluation
2024-07-22 16:36:16 Epoch 135 performance:
2024-07-22 16:36:16 metrics/test.mAP@50:95:0.318
2024-07-22 16:36:16 metrics/test.mAP@50:0.678
2024-07-22 16:36:16 metrics/test.mAP@75:0.253
2024-07-22 16:36:16 metrics/test.mAR@50:95:0.423
2024-07-22 16:36:16 metrics/test.mAR@50:0.773
2024-07-22 16:36:16 metrics/test.mAR@75:0.398
2024-07-22 16:36:16 Epoch 135/250 (lr=0.0001), train loss 0.36129
2024-07-22 16:36:25 Training for epoch 136 done, starting evaluation
2024-07-22 16:36:32 Epoch 136 performance:
2024-07-22 16:36:32 metrics/test.mAP@50:95:0.295
2024-07-22 16:36:32 metrics/test.mAP@50:0.650
2024-07-22 16:36:32 metrics/test.mAP@75:0.189
2024-07-22 16:36:32 metrics/test.mAR@50:95:0.387
2024-07-22 16:36:32 metrics/test.mAR@50:0.727
2024-07-22 16:36:32 metrics/test.mAR@75:0.320
2024-07-22 16:36:32 Epoch 136/250 (lr=0.0001), train loss 0.41253
2024-07-22 16:36:40 Training for epoch 137 done, starting evaluation
2024-07-22 16:36:46 Epoch 137 performance:
2024-07-22 16:36:46 metrics/test.mAP@50:95:0.325
2024-07-22 16:36:46 metrics/test.mAP@50:0.660
2024-07-22 16:36:46 metrics/test.mAP@75:0.230
2024-07-22 16:36:46 metrics/test.mAR@50:95:0.416
2024-07-22 16:36:46 metrics/test.mAR@50:0.746
2024-07-22 16:36:46 metrics/test.mAR@75:0.367
2024-07-22 16:36:46 Epoch 137/250 (lr=0.0001), train loss 0.38396
2024-07-22 16:36:55 Training for epoch 138 done, starting evaluation
2024-07-22 16:37:01 Epoch 138 performance:
2024-07-22 16:37:01 metrics/test.mAP@50:95:0.331
2024-07-22 16:37:01 metrics/test.mAP@50:0.675
2024-07-22 16:37:01 metrics/test.mAP@75:0.267
2024-07-22 16:37:01 metrics/test.mAR@50:95:0.412
2024-07-22 16:37:01 metrics/test.mAR@50:0.754
2024-07-22 16:37:01 metrics/test.mAR@75:0.387
2024-07-22 16:37:01 Epoch 138/250 (lr=0.0001), train loss 0.30534
2024-07-22 16:37:11 Training for epoch 139 done, starting evaluation
2024-07-22 16:37:17 Epoch 139 performance:
2024-07-22 16:37:17 metrics/test.mAP@50:95:0.335
2024-07-22 16:37:17 metrics/test.mAP@50:0.690
2024-07-22 16:37:17 metrics/test.mAP@75:0.259
2024-07-22 16:37:17 metrics/test.mAR@50:95:0.437
2024-07-22 16:37:17 metrics/test.mAR@50:0.789
2024-07-22 16:37:17 metrics/test.mAR@75:0.406
2024-07-22 16:37:17 Epoch 139/250 (lr=0.0001), train loss 0.31473
2024-07-22 16:37:26 Training for epoch 140 done, starting evaluation
2024-07-22 16:37:32 Epoch 140 performance:
2024-07-22 16:37:32 metrics/test.mAP@50:95:0.341
2024-07-22 16:37:32 metrics/test.mAP@50:0.714
2024-07-22 16:37:32 metrics/test.mAP@75:0.285
2024-07-22 16:37:32 metrics/test.mAR@50:95:0.434
2024-07-22 16:37:32 metrics/test.mAR@50:0.812
2024-07-22 16:37:32 metrics/test.mAR@75:0.402
2024-07-22 16:37:32 Epoch 140/250 (lr=0.0001), train loss 0.39100
2024-07-22 16:37:41 Training for epoch 141 done, starting evaluation
2024-07-22 16:37:47 Epoch 141 performance:
2024-07-22 16:37:47 metrics/test.mAP@50:95:0.336
2024-07-22 16:37:47 metrics/test.mAP@50:0.679
2024-07-22 16:37:47 metrics/test.mAP@75:0.284
2024-07-22 16:37:47 metrics/test.mAR@50:95:0.411
2024-07-22 16:37:47 metrics/test.mAR@50:0.738
2024-07-22 16:37:47 metrics/test.mAR@75:0.398
2024-07-22 16:37:47 Epoch 141/250 (lr=0.0001), train loss 0.40705
2024-07-22 16:37:56 Training for epoch 142 done, starting evaluation
2024-07-22 16:38:03 Epoch 142 performance:
2024-07-22 16:38:03 metrics/test.mAP@50:95:0.314
2024-07-22 16:38:03 metrics/test.mAP@50:0.678
2024-07-22 16:38:03 metrics/test.mAP@75:0.250
2024-07-22 16:38:03 metrics/test.mAR@50:95:0.398
2024-07-22 16:38:03 metrics/test.mAR@50:0.766
2024-07-22 16:38:03 metrics/test.mAR@75:0.359
2024-07-22 16:38:03 Epoch 142/250 (lr=0.0001), train loss 0.40997
2024-07-22 16:38:11 Training for epoch 143 done, starting evaluation
2024-07-22 16:38:18 Epoch 143 performance:
2024-07-22 16:38:18 metrics/test.mAP@50:95:0.347
2024-07-22 16:38:18 metrics/test.mAP@50:0.699
2024-07-22 16:38:18 metrics/test.mAP@75:0.302
2024-07-22 16:38:18 metrics/test.mAR@50:95:0.437
2024-07-22 16:38:18 metrics/test.mAR@50:0.770
2024-07-22 16:38:18 metrics/test.mAR@75:0.434
2024-07-22 16:38:18 Epoch 143/250 (lr=0.0001), train loss 0.40638
2024-07-22 16:38:26 Training for epoch 144 done, starting evaluation
2024-07-22 16:38:32 Epoch 144 performance:
2024-07-22 16:38:32 metrics/test.mAP@50:95:0.337
2024-07-22 16:38:32 metrics/test.mAP@50:0.680
2024-07-22 16:38:32 metrics/test.mAP@75:0.286
2024-07-22 16:38:32 metrics/test.mAR@50:95:0.438
2024-07-22 16:38:32 metrics/test.mAR@50:0.773
2024-07-22 16:38:32 metrics/test.mAR@75:0.434
2024-07-22 16:38:32 Epoch 144/250 (lr=0.0001), train loss 0.46570
2024-07-22 16:38:41 Training for epoch 145 done, starting evaluation
2024-07-22 16:38:47 Epoch 145 performance:
2024-07-22 16:38:47 metrics/test.mAP@50:95:0.327
2024-07-22 16:38:47 metrics/test.mAP@50:0.658
2024-07-22 16:38:47 metrics/test.mAP@75:0.281
2024-07-22 16:38:47 metrics/test.mAR@50:95:0.427
2024-07-22 16:38:47 metrics/test.mAR@50:0.754
2024-07-22 16:38:47 metrics/test.mAR@75:0.414
2024-07-22 16:38:47 Epoch 145/250 (lr=0.0001), train loss 0.43794
2024-07-22 16:38:56 Training for epoch 146 done, starting evaluation
2024-07-22 16:39:02 Epoch 146 performance:
2024-07-22 16:39:02 metrics/test.mAP@50:95:0.339
2024-07-22 16:39:02 metrics/test.mAP@50:0.682
2024-07-22 16:39:02 metrics/test.mAP@75:0.286
2024-07-22 16:39:02 metrics/test.mAR@50:95:0.436
2024-07-22 16:39:02 metrics/test.mAR@50:0.766
2024-07-22 16:39:03 metrics/test.mAR@75:0.430
2024-07-22 16:39:03 Epoch 146/250 (lr=0.0001), train loss 0.43229
2024-07-22 16:39:11 Training for epoch 147 done, starting evaluation
2024-07-22 16:39:18 Epoch 147 performance:
2024-07-22 16:39:18 metrics/test.mAP@50:95:0.325
2024-07-22 16:39:18 metrics/test.mAP@50:0.660
2024-07-22 16:39:18 metrics/test.mAP@75:0.245
2024-07-22 16:39:18 metrics/test.mAR@50:95:0.427
2024-07-22 16:39:18 metrics/test.mAR@50:0.766
2024-07-22 16:39:18 metrics/test.mAR@75:0.375
2024-07-22 16:39:18 Epoch 147/250 (lr=0.0001), train loss 0.31046
2024-07-22 16:39:26 Training for epoch 148 done, starting evaluation
2024-07-22 16:39:33 Epoch 148 performance:
2024-07-22 16:39:33 metrics/test.mAP@50:95:0.325
2024-07-22 16:39:33 metrics/test.mAP@50:0.664
2024-07-22 16:39:33 metrics/test.mAP@75:0.270
2024-07-22 16:39:33 metrics/test.mAR@50:95:0.430
2024-07-22 16:39:33 metrics/test.mAR@50:0.762
2024-07-22 16:39:33 metrics/test.mAR@75:0.414
2024-07-22 16:39:33 Epoch 148/250 (lr=0.0001), train loss 0.36559
2024-07-22 16:39:42 Training for epoch 149 done, starting evaluation
2024-07-22 16:39:48 Epoch 149 performance:
2024-07-22 16:39:48 metrics/test.mAP@50:95:0.332
2024-07-22 16:39:48 metrics/test.mAP@50:0.660
2024-07-22 16:39:48 metrics/test.mAP@75:0.275
2024-07-22 16:39:48 metrics/test.mAR@50:95:0.411
2024-07-22 16:39:48 metrics/test.mAR@50:0.727
2024-07-22 16:39:48 metrics/test.mAR@75:0.387
2024-07-22 16:39:48 Epoch 149/250 (lr=0.0001), train loss 0.39321
2024-07-22 16:39:58 Training for epoch 150 done, starting evaluation
2024-07-22 16:40:04 Epoch 150 performance:
2024-07-22 16:40:04 metrics/test.mAP@50:95:0.325
2024-07-22 16:40:04 metrics/test.mAP@50:0.658
2024-07-22 16:40:04 metrics/test.mAP@75:0.248
2024-07-22 16:40:04 metrics/test.mAR@50:95:0.432
2024-07-22 16:40:04 metrics/test.mAR@50:0.773
2024-07-22 16:40:04 metrics/test.mAR@75:0.395
2024-07-22 16:40:04 Epoch 150/250 (lr=0.0001), train loss 0.40182
2024-07-22 16:40:14 Training for epoch 151 done, starting evaluation
2024-07-22 16:40:20 Epoch 151 performance:
2024-07-22 16:40:20 metrics/test.mAP@50:95:0.317
2024-07-22 16:40:20 metrics/test.mAP@50:0.658
2024-07-22 16:40:20 metrics/test.mAP@75:0.232
2024-07-22 16:40:20 metrics/test.mAR@50:95:0.413
2024-07-22 16:40:20 metrics/test.mAR@50:0.742
2024-07-22 16:40:20 metrics/test.mAR@75:0.367
2024-07-22 16:40:20 Epoch 151/250 (lr=0.0001), train loss 0.36270
2024-07-22 16:40:29 Training for epoch 152 done, starting evaluation
2024-07-22 16:40:36 Epoch 152 performance:
2024-07-22 16:40:36 metrics/test.mAP@50:95:0.323
2024-07-22 16:40:36 metrics/test.mAP@50:0.658
2024-07-22 16:40:36 metrics/test.mAP@75:0.267
2024-07-22 16:40:36 metrics/test.mAR@50:95:0.421
2024-07-22 16:40:36 metrics/test.mAR@50:0.742
2024-07-22 16:40:36 metrics/test.mAR@75:0.410
2024-07-22 16:40:36 Epoch 152/250 (lr=0.0001), train loss 0.40882
2024-07-22 16:40:45 Training for epoch 153 done, starting evaluation
2024-07-22 16:40:51 Epoch 153 performance:
2024-07-22 16:40:51 metrics/test.mAP@50:95:0.336
2024-07-22 16:40:51 metrics/test.mAP@50:0.682
2024-07-22 16:40:51 metrics/test.mAP@75:0.279
2024-07-22 16:40:51 metrics/test.mAR@50:95:0.433
2024-07-22 16:40:51 metrics/test.mAR@50:0.766
2024-07-22 16:40:51 metrics/test.mAR@75:0.414
2024-07-22 16:40:51 Epoch 153/250 (lr=0.0001), train loss 0.39822
2024-07-22 16:41:00 Training for epoch 154 done, starting evaluation
2024-07-22 16:41:07 Epoch 154 performance:
2024-07-22 16:41:07 metrics/test.mAP@50:95:0.312
2024-07-22 16:41:07 metrics/test.mAP@50:0.657
2024-07-22 16:41:07 metrics/test.mAP@75:0.229
2024-07-22 16:41:07 metrics/test.mAR@50:95:0.408
2024-07-22 16:41:07 metrics/test.mAR@50:0.766
2024-07-22 16:41:07 metrics/test.mAR@75:0.348
2024-07-22 16:41:07 Epoch 154/250 (lr=0.0001), train loss 0.40666
2024-07-22 16:41:16 Training for epoch 155 done, starting evaluation
2024-07-22 16:41:23 Epoch 155 performance:
2024-07-22 16:41:23 metrics/test.mAP@50:95:0.302
2024-07-22 16:41:23 metrics/test.mAP@50:0.636
2024-07-22 16:41:23 metrics/test.mAP@75:0.205
2024-07-22 16:41:23 metrics/test.mAR@50:95:0.413
2024-07-22 16:41:23 metrics/test.mAR@50:0.754
2024-07-22 16:41:23 metrics/test.mAR@75:0.371
2024-07-22 16:41:23 Epoch 155/250 (lr=0.0001), train loss 0.42052
2024-07-22 16:41:31 Training for epoch 156 done, starting evaluation
2024-07-22 16:41:38 Epoch 156 performance:
2024-07-22 16:41:38 metrics/test.mAP@50:95:0.307
2024-07-22 16:41:38 metrics/test.mAP@50:0.677
2024-07-22 16:41:38 metrics/test.mAP@75:0.227
2024-07-22 16:41:38 metrics/test.mAR@50:95:0.411
2024-07-22 16:41:38 metrics/test.mAR@50:0.773
2024-07-22 16:41:38 metrics/test.mAR@75:0.371
2024-07-22 16:41:38 Epoch 156/250 (lr=0.0001), train loss 0.38308
2024-07-22 16:41:46 Training for epoch 157 done, starting evaluation
2024-07-22 16:41:53 Epoch 157 performance:
2024-07-22 16:41:53 metrics/test.mAP@50:95:0.297
2024-07-22 16:41:53 metrics/test.mAP@50:0.643
2024-07-22 16:41:53 metrics/test.mAP@75:0.203
2024-07-22 16:41:53 metrics/test.mAR@50:95:0.419
2024-07-22 16:41:53 metrics/test.mAR@50:0.793
2024-07-22 16:41:53 metrics/test.mAR@75:0.367
2024-07-22 16:41:53 Epoch 157/250 (lr=0.0001), train loss 0.40751
2024-07-22 16:42:01 Training for epoch 158 done, starting evaluation
2024-07-22 16:42:08 Epoch 158 performance:
2024-07-22 16:42:08 metrics/test.mAP@50:95:0.295
2024-07-22 16:42:08 metrics/test.mAP@50:0.642
2024-07-22 16:42:08 metrics/test.mAP@75:0.243
2024-07-22 16:42:08 metrics/test.mAR@50:95:0.445
2024-07-22 16:42:08 metrics/test.mAR@50:0.855
2024-07-22 16:42:08 metrics/test.mAR@75:0.414
2024-07-22 16:42:08 Epoch 158/250 (lr=0.0001), train loss 0.38926
2024-07-22 16:42:17 Training for epoch 159 done, starting evaluation
2024-07-22 16:42:23 Epoch 159 performance:
2024-07-22 16:42:23 metrics/test.mAP@50:95:0.325
2024-07-22 16:42:23 metrics/test.mAP@50:0.665
2024-07-22 16:42:23 metrics/test.mAP@75:0.273
2024-07-22 16:42:23 metrics/test.mAR@50:95:0.443
2024-07-22 16:42:23 metrics/test.mAR@50:0.801
2024-07-22 16:42:23 metrics/test.mAR@75:0.430
2024-07-22 16:42:23 Epoch 159/250 (lr=0.0001), train loss 0.36927
2024-07-22 16:42:32 Training for epoch 160 done, starting evaluation
2024-07-22 16:42:38 Epoch 160 performance:
2024-07-22 16:42:38 metrics/test.mAP@50:95:0.297
2024-07-22 16:42:38 metrics/test.mAP@50:0.626
2024-07-22 16:42:38 metrics/test.mAP@75:0.230
2024-07-22 16:42:38 metrics/test.mAR@50:95:0.400
2024-07-22 16:42:38 metrics/test.mAR@50:0.742
2024-07-22 16:42:38 metrics/test.mAR@75:0.367
2024-07-22 16:42:38 Epoch 160/250 (lr=1e-05), train loss 0.39562
2024-07-22 16:42:47 Training for epoch 161 done, starting evaluation
2024-07-22 16:42:53 Epoch 161 performance:
2024-07-22 16:42:53 metrics/test.mAP@50:95:0.323
2024-07-22 16:42:53 metrics/test.mAP@50:0.667
2024-07-22 16:42:53 metrics/test.mAP@75:0.258
2024-07-22 16:42:53 metrics/test.mAR@50:95:0.430
2024-07-22 16:42:53 metrics/test.mAR@50:0.781
2024-07-22 16:42:53 metrics/test.mAR@75:0.406
2024-07-22 16:42:53 Epoch 161/250 (lr=1e-05), train loss 0.37598
2024-07-22 16:43:02 Training for epoch 162 done, starting evaluation
2024-07-22 16:43:08 Epoch 162 performance:
2024-07-22 16:43:08 metrics/test.mAP@50:95:0.317
2024-07-22 16:43:08 metrics/test.mAP@50:0.663
2024-07-22 16:43:08 metrics/test.mAP@75:0.236
2024-07-22 16:43:08 metrics/test.mAR@50:95:0.421
2024-07-22 16:43:08 metrics/test.mAR@50:0.773
2024-07-22 16:43:08 metrics/test.mAR@75:0.387
2024-07-22 16:43:08 Epoch 162/250 (lr=1e-05), train loss 0.33063
2024-07-22 16:43:17 Training for epoch 163 done, starting evaluation
2024-07-22 16:43:23 Epoch 163 performance:
2024-07-22 16:43:23 metrics/test.mAP@50:95:0.321
2024-07-22 16:43:23 metrics/test.mAP@50:0.665
2024-07-22 16:43:23 metrics/test.mAP@75:0.263
2024-07-22 16:43:23 metrics/test.mAR@50:95:0.418
2024-07-22 16:43:23 metrics/test.mAR@50:0.773
2024-07-22 16:43:23 metrics/test.mAR@75:0.395
2024-07-22 16:43:23 Epoch 163/250 (lr=1e-05), train loss 0.32879
2024-07-22 16:43:32 Training for epoch 164 done, starting evaluation
2024-07-22 16:43:38 Epoch 164 performance:
2024-07-22 16:43:38 metrics/test.mAP@50:95:0.325
2024-07-22 16:43:38 metrics/test.mAP@50:0.663
2024-07-22 16:43:38 metrics/test.mAP@75:0.273
2024-07-22 16:43:38 metrics/test.mAR@50:95:0.425
2024-07-22 16:43:38 metrics/test.mAR@50:0.773
2024-07-22 16:43:38 metrics/test.mAR@75:0.418
2024-07-22 16:43:38 Epoch 164/250 (lr=1e-05), train loss 0.31705
2024-07-22 16:43:47 Training for epoch 165 done, starting evaluation
2024-07-22 16:43:54 Epoch 165 performance:
2024-07-22 16:43:54 metrics/test.mAP@50:95:0.328
2024-07-22 16:43:54 metrics/test.mAP@50:0.650
2024-07-22 16:43:54 metrics/test.mAP@75:0.270
2024-07-22 16:43:54 metrics/test.mAR@50:95:0.430
2024-07-22 16:43:54 metrics/test.mAR@50:0.766
2024-07-22 16:43:54 metrics/test.mAR@75:0.402
2024-07-22 16:43:54 Epoch 165/250 (lr=1e-05), train loss 0.33447
2024-07-22 16:44:02 Training for epoch 166 done, starting evaluation
2024-07-22 16:44:09 Epoch 166 performance:
2024-07-22 16:44:09 metrics/test.mAP@50:95:0.327
2024-07-22 16:44:09 metrics/test.mAP@50:0.657
2024-07-22 16:44:09 metrics/test.mAP@75:0.272
2024-07-22 16:44:09 metrics/test.mAR@50:95:0.428
2024-07-22 16:44:09 metrics/test.mAR@50:0.777
2024-07-22 16:44:09 metrics/test.mAR@75:0.398
2024-07-22 16:44:09 Epoch 166/250 (lr=1e-05), train loss 0.31932
2024-07-22 16:44:17 Training for epoch 167 done, starting evaluation
2024-07-22 16:44:23 Epoch 167 performance:
2024-07-22 16:44:23 metrics/test.mAP@50:95:0.331
2024-07-22 16:44:23 metrics/test.mAP@50:0.663
2024-07-22 16:44:23 metrics/test.mAP@75:0.281
2024-07-22 16:44:23 metrics/test.mAR@50:95:0.432
2024-07-22 16:44:23 metrics/test.mAR@50:0.777
2024-07-22 16:44:23 metrics/test.mAR@75:0.410
2024-07-22 16:44:23 Epoch 167/250 (lr=1e-05), train loss 0.32472
2024-07-22 16:44:31 Training for epoch 168 done, starting evaluation
2024-07-22 16:44:37 Epoch 168 performance:
2024-07-22 16:44:37 metrics/test.mAP@50:95:0.333
2024-07-22 16:44:37 metrics/test.mAP@50:0.666
2024-07-22 16:44:37 metrics/test.mAP@75:0.274
2024-07-22 16:44:37 metrics/test.mAR@50:95:0.438
2024-07-22 16:44:37 metrics/test.mAR@50:0.785
2024-07-22 16:44:37 metrics/test.mAR@75:0.410
2024-07-22 16:44:37 Epoch 168/250 (lr=1e-05), train loss 0.33201
2024-07-22 16:44:47 Training for epoch 169 done, starting evaluation
2024-07-22 16:44:53 Epoch 169 performance:
2024-07-22 16:44:53 metrics/test.mAP@50:95:0.329
2024-07-22 16:44:53 metrics/test.mAP@50:0.667
2024-07-22 16:44:53 metrics/test.mAP@75:0.263
2024-07-22 16:44:53 metrics/test.mAR@50:95:0.431
2024-07-22 16:44:53 metrics/test.mAR@50:0.777
2024-07-22 16:44:53 metrics/test.mAR@75:0.406
2024-07-22 16:44:53 Epoch 169/250 (lr=1e-05), train loss 0.34345
2024-07-22 16:45:03 Training for epoch 170 done, starting evaluation
2024-07-22 16:45:09 Epoch 170 performance:
2024-07-22 16:45:09 metrics/test.mAP@50:95:0.324
2024-07-22 16:45:09 metrics/test.mAP@50:0.667
2024-07-22 16:45:09 metrics/test.mAP@75:0.262
2024-07-22 16:45:09 metrics/test.mAR@50:95:0.426
2024-07-22 16:45:09 metrics/test.mAR@50:0.777
2024-07-22 16:45:09 metrics/test.mAR@75:0.398
2024-07-22 16:45:09 Epoch 170/250 (lr=1e-05), train loss 0.31521
2024-07-22 16:45:18 Training for epoch 171 done, starting evaluation
2024-07-22 16:45:25 Epoch 171 performance:
2024-07-22 16:45:25 metrics/test.mAP@50:95:0.322
2024-07-22 16:45:25 metrics/test.mAP@50:0.676
2024-07-22 16:45:25 metrics/test.mAP@75:0.253
2024-07-22 16:45:25 metrics/test.mAR@50:95:0.422
2024-07-22 16:45:25 metrics/test.mAR@50:0.781
2024-07-22 16:45:25 metrics/test.mAR@75:0.391
2024-07-22 16:45:25 Epoch 171/250 (lr=1e-05), train loss 0.34562
2024-07-22 16:45:34 Training for epoch 172 done, starting evaluation
2024-07-22 16:45:40 Epoch 172 performance:
2024-07-22 16:45:40 metrics/test.mAP@50:95:0.325
2024-07-22 16:45:40 metrics/test.mAP@50:0.668
2024-07-22 16:45:40 metrics/test.mAP@75:0.260
2024-07-22 16:45:40 metrics/test.mAR@50:95:0.425
2024-07-22 16:45:40 metrics/test.mAR@50:0.773
2024-07-22 16:45:40 metrics/test.mAR@75:0.391
2024-07-22 16:45:40 Epoch 172/250 (lr=1e-05), train loss 0.31241
2024-07-22 16:45:50 Training for epoch 173 done, starting evaluation
2024-07-22 16:45:56 Epoch 173 performance:
2024-07-22 16:45:56 metrics/test.mAP@50:95:0.327
2024-07-22 16:45:56 metrics/test.mAP@50:0.683
2024-07-22 16:45:56 metrics/test.mAP@75:0.258
2024-07-22 16:45:56 metrics/test.mAR@50:95:0.420
2024-07-22 16:45:56 metrics/test.mAR@50:0.773
2024-07-22 16:45:56 metrics/test.mAR@75:0.379
2024-07-22 16:45:56 Epoch 173/250 (lr=1e-05), train loss 0.34018
2024-07-22 16:46:05 Training for epoch 174 done, starting evaluation
2024-07-22 16:46:12 Epoch 174 performance:
2024-07-22 16:46:12 metrics/test.mAP@50:95:0.333
2024-07-22 16:46:12 metrics/test.mAP@50:0.685
2024-07-22 16:46:12 metrics/test.mAP@75:0.271
2024-07-22 16:46:12 metrics/test.mAR@50:95:0.423
2024-07-22 16:46:12 metrics/test.mAR@50:0.773
2024-07-22 16:46:12 metrics/test.mAR@75:0.402
2024-07-22 16:46:12 Epoch 174/250 (lr=1e-05), train loss 0.31992
2024-07-22 16:46:21 Training for epoch 175 done, starting evaluation
2024-07-22 16:46:27 Epoch 175 performance:
2024-07-22 16:46:27 metrics/test.mAP@50:95:0.324
2024-07-22 16:46:27 metrics/test.mAP@50:0.664
2024-07-22 16:46:27 metrics/test.mAP@75:0.269
2024-07-22 16:46:27 metrics/test.mAR@50:95:0.423
2024-07-22 16:46:27 metrics/test.mAR@50:0.766
2024-07-22 16:46:27 metrics/test.mAR@75:0.398
2024-07-22 16:46:27 Epoch 175/250 (lr=1e-05), train loss 0.32492
2024-07-22 16:46:36 Training for epoch 176 done, starting evaluation
2024-07-22 16:46:43 Epoch 176 performance:
2024-07-22 16:46:43 metrics/test.mAP@50:95:0.326
2024-07-22 16:46:43 metrics/test.mAP@50:0.661
2024-07-22 16:46:43 metrics/test.mAP@75:0.266
2024-07-22 16:46:43 metrics/test.mAR@50:95:0.421
2024-07-22 16:46:43 metrics/test.mAR@50:0.758
2024-07-22 16:46:43 metrics/test.mAR@75:0.391
2024-07-22 16:46:43 Epoch 176/250 (lr=1e-05), train loss 0.30912
2024-07-22 16:46:51 Training for epoch 177 done, starting evaluation
2024-07-22 16:46:58 Epoch 177 performance:
2024-07-22 16:46:58 metrics/test.mAP@50:95:0.323
2024-07-22 16:46:58 metrics/test.mAP@50:0.662
2024-07-22 16:46:58 metrics/test.mAP@75:0.270
2024-07-22 16:46:58 metrics/test.mAR@50:95:0.416
2024-07-22 16:46:58 metrics/test.mAR@50:0.754
2024-07-22 16:46:58 metrics/test.mAR@75:0.402
2024-07-22 16:46:58 Epoch 177/250 (lr=1e-05), train loss 0.32938
2024-07-22 16:47:07 Training for epoch 178 done, starting evaluation
2024-07-22 16:47:13 Epoch 178 performance:
2024-07-22 16:47:13 metrics/test.mAP@50:95:0.326
2024-07-22 16:47:13 metrics/test.mAP@50:0.672
2024-07-22 16:47:13 metrics/test.mAP@75:0.264
2024-07-22 16:47:13 metrics/test.mAR@50:95:0.418
2024-07-22 16:47:13 metrics/test.mAR@50:0.750
2024-07-22 16:47:13 metrics/test.mAR@75:0.398
2024-07-22 16:47:13 Epoch 178/250 (lr=1e-05), train loss 0.32451
2024-07-22 16:47:23 Training for epoch 179 done, starting evaluation
2024-07-22 16:47:29 Epoch 179 performance:
2024-07-22 16:47:29 metrics/test.mAP@50:95:0.327
2024-07-22 16:47:29 metrics/test.mAP@50:0.674
2024-07-22 16:47:29 metrics/test.mAP@75:0.267
2024-07-22 16:47:29 metrics/test.mAR@50:95:0.420
2024-07-22 16:47:29 metrics/test.mAR@50:0.766
2024-07-22 16:47:29 metrics/test.mAR@75:0.402
2024-07-22 16:47:29 Epoch 179/250 (lr=1e-05), train loss 0.33610
2024-07-22 16:47:38 Training for epoch 180 done, starting evaluation
2024-07-22 16:47:45 Epoch 180 performance:
2024-07-22 16:47:45 metrics/test.mAP@50:95:0.323
2024-07-22 16:47:45 metrics/test.mAP@50:0.657
2024-07-22 16:47:45 metrics/test.mAP@75:0.262
2024-07-22 16:47:45 metrics/test.mAR@50:95:0.419
2024-07-22 16:47:45 metrics/test.mAR@50:0.754
2024-07-22 16:47:45 metrics/test.mAR@75:0.398
2024-07-22 16:47:45 Epoch 180/250 (lr=1e-05), train loss 0.30645
2024-07-22 16:47:54 Training for epoch 181 done, starting evaluation
2024-07-22 16:48:00 Epoch 181 performance:
2024-07-22 16:48:00 metrics/test.mAP@50:95:0.326
2024-07-22 16:48:00 metrics/test.mAP@50:0.663
2024-07-22 16:48:00 metrics/test.mAP@75:0.258
2024-07-22 16:48:00 metrics/test.mAR@50:95:0.421
2024-07-22 16:48:00 metrics/test.mAR@50:0.758
2024-07-22 16:48:00 metrics/test.mAR@75:0.391
2024-07-22 16:48:00 Epoch 181/250 (lr=1e-05), train loss 0.29239
2024-07-22 16:48:09 Training for epoch 182 done, starting evaluation
2024-07-22 16:48:15 Epoch 182 performance:
2024-07-22 16:48:15 metrics/test.mAP@50:95:0.324
2024-07-22 16:48:15 metrics/test.mAP@50:0.672
2024-07-22 16:48:15 metrics/test.mAP@75:0.251
2024-07-22 16:48:15 metrics/test.mAR@50:95:0.421
2024-07-22 16:48:15 metrics/test.mAR@50:0.773
2024-07-22 16:48:15 metrics/test.mAR@75:0.379
2024-07-22 16:48:15 Epoch 182/250 (lr=1e-05), train loss 0.30347
2024-07-22 16:48:24 Training for epoch 183 done, starting evaluation
2024-07-22 16:48:31 Epoch 183 performance:
2024-07-22 16:48:31 metrics/test.mAP@50:95:0.325
2024-07-22 16:48:31 metrics/test.mAP@50:0.665
2024-07-22 16:48:31 metrics/test.mAP@75:0.259
2024-07-22 16:48:31 metrics/test.mAR@50:95:0.423
2024-07-22 16:48:31 metrics/test.mAR@50:0.770
2024-07-22 16:48:31 metrics/test.mAR@75:0.391
2024-07-22 16:48:31 Epoch 183/250 (lr=1e-05), train loss 0.29825
2024-07-22 16:48:39 Training for epoch 184 done, starting evaluation
2024-07-22 16:48:46 Epoch 184 performance:
2024-07-22 16:48:46 metrics/test.mAP@50:95:0.318
2024-07-22 16:48:46 metrics/test.mAP@50:0.662
2024-07-22 16:48:46 metrics/test.mAP@75:0.238
2024-07-22 16:48:46 metrics/test.mAR@50:95:0.413
2024-07-22 16:48:46 metrics/test.mAR@50:0.754
2024-07-22 16:48:46 metrics/test.mAR@75:0.375
2024-07-22 16:48:46 Epoch 184/250 (lr=1e-05), train loss 0.30874
2024-07-22 16:48:55 Training for epoch 185 done, starting evaluation
2024-07-22 16:49:01 Epoch 185 performance:
2024-07-22 16:49:01 metrics/test.mAP@50:95:0.325
2024-07-22 16:49:01 metrics/test.mAP@50:0.667
2024-07-22 16:49:01 metrics/test.mAP@75:0.250
2024-07-22 16:49:01 metrics/test.mAR@50:95:0.420
2024-07-22 16:49:01 metrics/test.mAR@50:0.762
2024-07-22 16:49:01 metrics/test.mAR@75:0.387
2024-07-22 16:49:01 Epoch 185/250 (lr=1e-05), train loss 0.32088
2024-07-22 16:49:11 Training for epoch 186 done, starting evaluation
2024-07-22 16:49:17 Epoch 186 performance:
2024-07-22 16:49:17 metrics/test.mAP@50:95:0.320
2024-07-22 16:49:17 metrics/test.mAP@50:0.655
2024-07-22 16:49:17 metrics/test.mAP@75:0.237
2024-07-22 16:49:17 metrics/test.mAR@50:95:0.421
2024-07-22 16:49:17 metrics/test.mAR@50:0.766
2024-07-22 16:49:17 metrics/test.mAR@75:0.379
2024-07-22 16:49:17 Epoch 186/250 (lr=1e-05), train loss 0.29165
2024-07-22 16:49:26 Training for epoch 187 done, starting evaluation
2024-07-22 16:49:32 Epoch 187 performance:
2024-07-22 16:49:32 metrics/test.mAP@50:95:0.321
2024-07-22 16:49:32 metrics/test.mAP@50:0.656
2024-07-22 16:49:32 metrics/test.mAP@75:0.247
2024-07-22 16:49:32 metrics/test.mAR@50:95:0.417
2024-07-22 16:49:32 metrics/test.mAR@50:0.758
2024-07-22 16:49:32 metrics/test.mAR@75:0.379
2024-07-22 16:49:32 Epoch 187/250 (lr=1e-05), train loss 0.29335
2024-07-22 16:49:41 Training for epoch 188 done, starting evaluation
2024-07-22 16:49:47 Epoch 188 performance:
2024-07-22 16:49:47 metrics/test.mAP@50:95:0.327
2024-07-22 16:49:47 metrics/test.mAP@50:0.672
2024-07-22 16:49:47 metrics/test.mAP@75:0.264
2024-07-22 16:49:47 metrics/test.mAR@50:95:0.424
2024-07-22 16:49:47 metrics/test.mAR@50:0.762
2024-07-22 16:49:47 metrics/test.mAR@75:0.402
2024-07-22 16:49:47 Epoch 188/250 (lr=1e-05), train loss 0.31997
2024-07-22 16:49:56 Training for epoch 189 done, starting evaluation
2024-07-22 16:50:02 Epoch 189 performance:
2024-07-22 16:50:02 metrics/test.mAP@50:95:0.324
2024-07-22 16:50:02 metrics/test.mAP@50:0.664
2024-07-22 16:50:02 metrics/test.mAP@75:0.247
2024-07-22 16:50:02 metrics/test.mAR@50:95:0.425
2024-07-22 16:50:02 metrics/test.mAR@50:0.766
2024-07-22 16:50:02 metrics/test.mAR@75:0.398
2024-07-22 16:50:02 Epoch 189/250 (lr=1e-05), train loss 0.32026
2024-07-22 16:50:10 Training for epoch 190 done, starting evaluation
2024-07-22 16:50:17 Epoch 190 performance:
2024-07-22 16:50:17 metrics/test.mAP@50:95:0.321
2024-07-22 16:50:17 metrics/test.mAP@50:0.666
2024-07-22 16:50:17 metrics/test.mAP@75:0.237
2024-07-22 16:50:17 metrics/test.mAR@50:95:0.416
2024-07-22 16:50:17 metrics/test.mAR@50:0.754
2024-07-22 16:50:17 metrics/test.mAR@75:0.371
2024-07-22 16:50:17 Epoch 190/250 (lr=1e-05), train loss 0.28402
2024-07-22 16:50:26 Training for epoch 191 done, starting evaluation
2024-07-22 16:50:32 Epoch 191 performance:
2024-07-22 16:50:32 metrics/test.mAP@50:95:0.328
2024-07-22 16:50:32 metrics/test.mAP@50:0.680
2024-07-22 16:50:32 metrics/test.mAP@75:0.259
2024-07-22 16:50:32 metrics/test.mAR@50:95:0.422
2024-07-22 16:50:32 metrics/test.mAR@50:0.762
2024-07-22 16:50:32 metrics/test.mAR@75:0.398
2024-07-22 16:50:32 Epoch 191/250 (lr=1e-05), train loss 0.32297
2024-07-22 16:50:41 Training for epoch 192 done, starting evaluation
2024-07-22 16:50:47 Epoch 192 performance:
2024-07-22 16:50:47 metrics/test.mAP@50:95:0.329
2024-07-22 16:50:47 metrics/test.mAP@50:0.683
2024-07-22 16:50:47 metrics/test.mAP@75:0.258
2024-07-22 16:50:47 metrics/test.mAR@50:95:0.423
2024-07-22 16:50:47 metrics/test.mAR@50:0.762
2024-07-22 16:50:47 metrics/test.mAR@75:0.402
2024-07-22 16:50:47 Epoch 192/250 (lr=1e-05), train loss 0.28886
2024-07-22 16:50:57 Training for epoch 193 done, starting evaluation
2024-07-22 16:51:04 Epoch 193 performance:
2024-07-22 16:51:04 metrics/test.mAP@50:95:0.328
2024-07-22 16:51:04 metrics/test.mAP@50:0.673
2024-07-22 16:51:04 metrics/test.mAP@75:0.260
2024-07-22 16:51:04 metrics/test.mAR@50:95:0.421
2024-07-22 16:51:04 metrics/test.mAR@50:0.754
2024-07-22 16:51:04 metrics/test.mAR@75:0.398
2024-07-22 16:51:04 Epoch 193/250 (lr=1e-05), train loss 0.28818
2024-07-22 16:51:12 Training for epoch 194 done, starting evaluation
2024-07-22 16:51:18 Epoch 194 performance:
2024-07-22 16:51:18 metrics/test.mAP@50:95:0.327
2024-07-22 16:51:18 metrics/test.mAP@50:0.686
2024-07-22 16:51:18 metrics/test.mAP@75:0.240
2024-07-22 16:51:18 metrics/test.mAR@50:95:0.426
2024-07-22 16:51:18 metrics/test.mAR@50:0.777
2024-07-22 16:51:18 metrics/test.mAR@75:0.383
2024-07-22 16:51:18 Epoch 194/250 (lr=1e-05), train loss 0.30733
2024-07-22 16:51:28 Training for epoch 195 done, starting evaluation
2024-07-22 16:51:35 Epoch 195 performance:
2024-07-22 16:51:35 metrics/test.mAP@50:95:0.325
2024-07-22 16:51:35 metrics/test.mAP@50:0.669
2024-07-22 16:51:35 metrics/test.mAP@75:0.256
2024-07-22 16:51:35 metrics/test.mAR@50:95:0.420
2024-07-22 16:51:35 metrics/test.mAR@50:0.750
2024-07-22 16:51:35 metrics/test.mAR@75:0.395
2024-07-22 16:51:35 Epoch 195/250 (lr=1e-05), train loss 0.31628
2024-07-22 16:51:43 Training for epoch 196 done, starting evaluation
2024-07-22 16:51:49 Epoch 196 performance:
2024-07-22 16:51:49 metrics/test.mAP@50:95:0.317
2024-07-22 16:51:49 metrics/test.mAP@50:0.660
2024-07-22 16:51:49 metrics/test.mAP@75:0.240
2024-07-22 16:51:49 metrics/test.mAR@50:95:0.417
2024-07-22 16:51:49 metrics/test.mAR@50:0.758
2024-07-22 16:51:49 metrics/test.mAR@75:0.383
2024-07-22 16:51:49 Epoch 196/250 (lr=1e-05), train loss 0.30513
2024-07-22 16:51:59 Training for epoch 197 done, starting evaluation
2024-07-22 16:52:06 Epoch 197 performance:
2024-07-22 16:52:06 metrics/test.mAP@50:95:0.325
2024-07-22 16:52:06 metrics/test.mAP@50:0.671
2024-07-22 16:52:06 metrics/test.mAP@75:0.262
2024-07-22 16:52:06 metrics/test.mAR@50:95:0.422
2024-07-22 16:52:06 metrics/test.mAR@50:0.762
2024-07-22 16:52:06 metrics/test.mAR@75:0.402
2024-07-22 16:52:06 Epoch 197/250 (lr=1e-05), train loss 0.29856
2024-07-22 16:52:14 Training for epoch 198 done, starting evaluation
2024-07-22 16:52:21 Epoch 198 performance:
2024-07-22 16:52:21 metrics/test.mAP@50:95:0.317
2024-07-22 16:52:21 metrics/test.mAP@50:0.655
2024-07-22 16:52:21 metrics/test.mAP@75:0.261
2024-07-22 16:52:21 metrics/test.mAR@50:95:0.416
2024-07-22 16:52:21 metrics/test.mAR@50:0.754
2024-07-22 16:52:21 metrics/test.mAR@75:0.402
2024-07-22 16:52:21 Epoch 198/250 (lr=1e-05), train loss 0.30055
2024-07-22 16:52:29 Training for epoch 199 done, starting evaluation
2024-07-22 16:52:36 Epoch 199 performance:
2024-07-22 16:52:36 metrics/test.mAP@50:95:0.318
2024-07-22 16:52:36 metrics/test.mAP@50:0.669
2024-07-22 16:52:36 metrics/test.mAP@75:0.239
2024-07-22 16:52:36 metrics/test.mAR@50:95:0.418
2024-07-22 16:52:36 metrics/test.mAR@50:0.762
2024-07-22 16:52:36 metrics/test.mAR@75:0.387
2024-07-22 16:52:36 Epoch 199/250 (lr=1e-05), train loss 0.30875
2024-07-22 16:52:45 Training for epoch 200 done, starting evaluation
2024-07-22 16:52:51 Epoch 200 performance:
2024-07-22 16:52:51 metrics/test.mAP@50:95:0.325
2024-07-22 16:52:51 metrics/test.mAP@50:0.654
2024-07-22 16:52:51 metrics/test.mAP@75:0.269
2024-07-22 16:52:51 metrics/test.mAR@50:95:0.424
2024-07-22 16:52:51 metrics/test.mAR@50:0.746
2024-07-22 16:52:51 metrics/test.mAR@75:0.418
2024-07-22 16:52:51 Epoch 200/250 (lr=1e-05), train loss 0.31868
2024-07-22 16:53:00 Training for epoch 201 done, starting evaluation
2024-07-22 16:53:07 Epoch 201 performance:
2024-07-22 16:53:07 metrics/test.mAP@50:95:0.317
2024-07-22 16:53:07 metrics/test.mAP@50:0.659
2024-07-22 16:53:07 metrics/test.mAP@75:0.247
2024-07-22 16:53:07 metrics/test.mAR@50:95:0.412
2024-07-22 16:53:07 metrics/test.mAR@50:0.754
2024-07-22 16:53:07 metrics/test.mAR@75:0.387
2024-07-22 16:53:07 Epoch 201/250 (lr=1e-05), train loss 0.27766
2024-07-22 16:53:15 Training for epoch 202 done, starting evaluation
2024-07-22 16:53:21 Epoch 202 performance:
2024-07-22 16:53:21 metrics/test.mAP@50:95:0.321
2024-07-22 16:53:21 metrics/test.mAP@50:0.670
2024-07-22 16:53:21 metrics/test.mAP@75:0.258
2024-07-22 16:53:21 metrics/test.mAR@50:95:0.418
2024-07-22 16:53:21 metrics/test.mAR@50:0.762
2024-07-22 16:53:21 metrics/test.mAR@75:0.398
2024-07-22 16:53:21 Epoch 202/250 (lr=1e-05), train loss 0.29361
2024-07-22 16:53:30 Training for epoch 203 done, starting evaluation
2024-07-22 16:53:36 Epoch 203 performance:
2024-07-22 16:53:36 metrics/test.mAP@50:95:0.313
2024-07-22 16:53:36 metrics/test.mAP@50:0.657
2024-07-22 16:53:36 metrics/test.mAP@75:0.230
2024-07-22 16:53:36 metrics/test.mAR@50:95:0.410
2024-07-22 16:53:36 metrics/test.mAR@50:0.758
2024-07-22 16:53:36 metrics/test.mAR@75:0.371
2024-07-22 16:53:36 Epoch 203/250 (lr=1e-05), train loss 0.28624
2024-07-22 16:53:46 Training for epoch 204 done, starting evaluation
2024-07-22 16:53:52 Epoch 204 performance:
2024-07-22 16:53:52 metrics/test.mAP@50:95:0.315
2024-07-22 16:53:52 metrics/test.mAP@50:0.656
2024-07-22 16:53:52 metrics/test.mAP@75:0.233
2024-07-22 16:53:52 metrics/test.mAR@50:95:0.415
2024-07-22 16:53:52 metrics/test.mAR@50:0.766
2024-07-22 16:53:52 metrics/test.mAR@75:0.375
2024-07-22 16:53:52 Epoch 204/250 (lr=1e-05), train loss 0.27590
2024-07-22 16:54:01 Training for epoch 205 done, starting evaluation
2024-07-22 16:54:07 Epoch 205 performance:
2024-07-22 16:54:07 metrics/test.mAP@50:95:0.316
2024-07-22 16:54:07 metrics/test.mAP@50:0.660
2024-07-22 16:54:07 metrics/test.mAP@75:0.227
2024-07-22 16:54:07 metrics/test.mAR@50:95:0.418
2024-07-22 16:54:07 metrics/test.mAR@50:0.762
2024-07-22 16:54:07 metrics/test.mAR@75:0.367
2024-07-22 16:54:07 Epoch 205/250 (lr=1e-05), train loss 0.26641
2024-07-22 16:54:16 Training for epoch 206 done, starting evaluation
2024-07-22 16:54:23 Epoch 206 performance:
2024-07-22 16:54:23 metrics/test.mAP@50:95:0.324
2024-07-22 16:54:23 metrics/test.mAP@50:0.665
2024-07-22 16:54:23 metrics/test.mAP@75:0.246
2024-07-22 16:54:23 metrics/test.mAR@50:95:0.424
2024-07-22 16:54:23 metrics/test.mAR@50:0.762
2024-07-22 16:54:23 metrics/test.mAR@75:0.391
2024-07-22 16:54:23 Epoch 206/250 (lr=1e-05), train loss 0.31203
2024-07-22 16:54:32 Training for epoch 207 done, starting evaluation
2024-07-22 16:54:38 Epoch 207 performance:
2024-07-22 16:54:38 metrics/test.mAP@50:95:0.336
2024-07-22 16:54:38 metrics/test.mAP@50:0.681
2024-07-22 16:54:38 metrics/test.mAP@75:0.258
2024-07-22 16:54:38 metrics/test.mAR@50:95:0.436
2024-07-22 16:54:38 metrics/test.mAR@50:0.781
2024-07-22 16:54:38 metrics/test.mAR@75:0.406
2024-07-22 16:54:38 Epoch 207/250 (lr=1e-05), train loss 0.29638
2024-07-22 16:54:46 Training for epoch 208 done, starting evaluation
2024-07-22 16:54:53 Epoch 208 performance:
2024-07-22 16:54:53 metrics/test.mAP@50:95:0.328
2024-07-22 16:54:53 metrics/test.mAP@50:0.671
2024-07-22 16:54:53 metrics/test.mAP@75:0.256
2024-07-22 16:54:53 metrics/test.mAR@50:95:0.424
2024-07-22 16:54:53 metrics/test.mAR@50:0.766
2024-07-22 16:54:53 metrics/test.mAR@75:0.395
2024-07-22 16:54:53 Epoch 208/250 (lr=1e-05), train loss 0.30206
2024-07-22 16:55:02 Training for epoch 209 done, starting evaluation
2024-07-22 16:55:08 Epoch 209 performance:
2024-07-22 16:55:08 metrics/test.mAP@50:95:0.326
2024-07-22 16:55:08 metrics/test.mAP@50:0.659
2024-07-22 16:55:08 metrics/test.mAP@75:0.248
2024-07-22 16:55:08 metrics/test.mAR@50:95:0.417
2024-07-22 16:55:08 metrics/test.mAR@50:0.742
2024-07-22 16:55:08 metrics/test.mAR@75:0.383
2024-07-22 16:55:08 Epoch 209/250 (lr=1e-05), train loss 0.32175
2024-07-22 16:55:17 Training for epoch 210 done, starting evaluation
2024-07-22 16:55:24 Epoch 210 performance:
2024-07-22 16:55:24 metrics/test.mAP@50:95:0.327
2024-07-22 16:55:24 metrics/test.mAP@50:0.673
2024-07-22 16:55:24 metrics/test.mAP@75:0.250
2024-07-22 16:55:24 metrics/test.mAR@50:95:0.417
2024-07-22 16:55:24 metrics/test.mAR@50:0.750
2024-07-22 16:55:24 metrics/test.mAR@75:0.387
2024-07-22 16:55:24 Epoch 210/250 (lr=1e-05), train loss 0.31952
2024-07-22 16:55:33 Training for epoch 211 done, starting evaluation
2024-07-22 16:55:39 Epoch 211 performance:
2024-07-22 16:55:39 metrics/test.mAP@50:95:0.326
2024-07-22 16:55:39 metrics/test.mAP@50:0.670
2024-07-22 16:55:39 metrics/test.mAP@75:0.250
2024-07-22 16:55:39 metrics/test.mAR@50:95:0.425
2024-07-22 16:55:39 metrics/test.mAR@50:0.766
2024-07-22 16:55:39 metrics/test.mAR@75:0.391
2024-07-22 16:55:39 Epoch 211/250 (lr=1e-05), train loss 0.31657
2024-07-22 16:55:48 Training for epoch 212 done, starting evaluation
2024-07-22 16:55:55 Epoch 212 performance:
2024-07-22 16:55:55 metrics/test.mAP@50:95:0.325
2024-07-22 16:55:55 metrics/test.mAP@50:0.663
2024-07-22 16:55:55 metrics/test.mAP@75:0.258
2024-07-22 16:55:55 metrics/test.mAR@50:95:0.423
2024-07-22 16:55:55 metrics/test.mAR@50:0.758
2024-07-22 16:55:55 metrics/test.mAR@75:0.398
2024-07-22 16:55:55 Epoch 212/250 (lr=1e-05), train loss 0.29883
2024-07-22 16:56:04 Training for epoch 213 done, starting evaluation
2024-07-22 16:56:11 Epoch 213 performance:
2024-07-22 16:56:11 metrics/test.mAP@50:95:0.328
2024-07-22 16:56:11 metrics/test.mAP@50:0.669
2024-07-22 16:56:11 metrics/test.mAP@75:0.257
2024-07-22 16:56:11 metrics/test.mAR@50:95:0.429
2024-07-22 16:56:11 metrics/test.mAR@50:0.770
2024-07-22 16:56:11 metrics/test.mAR@75:0.406
2024-07-22 16:56:11 Epoch 213/250 (lr=1e-05), train loss 0.28622
2024-07-22 16:56:20 Training for epoch 214 done, starting evaluation
2024-07-22 16:56:26 Epoch 214 performance:
2024-07-22 16:56:26 metrics/test.mAP@50:95:0.333
2024-07-22 16:56:26 metrics/test.mAP@50:0.676
2024-07-22 16:56:26 metrics/test.mAP@75:0.254
2024-07-22 16:56:26 metrics/test.mAR@50:95:0.434
2024-07-22 16:56:26 metrics/test.mAR@50:0.777
2024-07-22 16:56:26 metrics/test.mAR@75:0.398
2024-07-22 16:56:26 Epoch 214/250 (lr=1e-05), train loss 0.28993
2024-07-22 16:56:35 Training for epoch 215 done, starting evaluation
2024-07-22 16:56:42 Epoch 215 performance:
2024-07-22 16:56:42 metrics/test.mAP@50:95:0.328
2024-07-22 16:56:42 metrics/test.mAP@50:0.666
2024-07-22 16:56:42 metrics/test.mAP@75:0.246
2024-07-22 16:56:42 metrics/test.mAR@50:95:0.427
2024-07-22 16:56:42 metrics/test.mAR@50:0.766
2024-07-22 16:56:42 metrics/test.mAR@75:0.383
2024-07-22 16:56:42 Epoch 215/250 (lr=1e-05), train loss 0.27928
2024-07-22 16:56:51 Training for epoch 216 done, starting evaluation
2024-07-22 16:56:57 Epoch 216 performance:
2024-07-22 16:56:57 metrics/test.mAP@50:95:0.324
2024-07-22 16:56:57 metrics/test.mAP@50:0.670
2024-07-22 16:56:57 metrics/test.mAP@75:0.252
2024-07-22 16:56:57 metrics/test.mAR@50:95:0.420
2024-07-22 16:56:57 metrics/test.mAR@50:0.762
2024-07-22 16:56:57 metrics/test.mAR@75:0.402
2024-07-22 16:56:57 Epoch 216/250 (lr=1e-05), train loss 0.28855
2024-07-22 16:57:06 Training for epoch 217 done, starting evaluation
2024-07-22 16:57:12 Epoch 217 performance:
2024-07-22 16:57:12 metrics/test.mAP@50:95:0.322
2024-07-22 16:57:12 metrics/test.mAP@50:0.660
2024-07-22 16:57:12 metrics/test.mAP@75:0.250
2024-07-22 16:57:12 metrics/test.mAR@50:95:0.419
2024-07-22 16:57:12 metrics/test.mAR@50:0.750
2024-07-22 16:57:12 metrics/test.mAR@75:0.391
2024-07-22 16:57:12 Epoch 217/250 (lr=1e-05), train loss 0.33069
2024-07-22 16:57:22 Training for epoch 218 done, starting evaluation
2024-07-22 16:57:28 Epoch 218 performance:
2024-07-22 16:57:28 metrics/test.mAP@50:95:0.320
2024-07-22 16:57:28 metrics/test.mAP@50:0.656
2024-07-22 16:57:28 metrics/test.mAP@75:0.246
2024-07-22 16:57:28 metrics/test.mAR@50:95:0.416
2024-07-22 16:57:28 metrics/test.mAR@50:0.750
2024-07-22 16:57:28 metrics/test.mAR@75:0.387
2024-07-22 16:57:28 Epoch 218/250 (lr=1e-05), train loss 0.29555
2024-07-22 16:57:36 Training for epoch 219 done, starting evaluation
2024-07-22 16:57:43 Epoch 219 performance:
2024-07-22 16:57:43 metrics/test.mAP@50:95:0.325
2024-07-22 16:57:43 metrics/test.mAP@50:0.665
2024-07-22 16:57:43 metrics/test.mAP@75:0.244
2024-07-22 16:57:43 metrics/test.mAR@50:95:0.422
2024-07-22 16:57:43 metrics/test.mAR@50:0.762
2024-07-22 16:57:43 metrics/test.mAR@75:0.379
2024-07-22 16:57:43 Epoch 219/250 (lr=1e-05), train loss 0.28498
2024-07-22 16:57:52 Training for epoch 220 done, starting evaluation
2024-07-22 16:57:58 Epoch 220 performance:
2024-07-22 16:57:58 metrics/test.mAP@50:95:0.319
2024-07-22 16:57:58 metrics/test.mAP@50:0.658
2024-07-22 16:57:58 metrics/test.mAP@75:0.240
2024-07-22 16:57:58 metrics/test.mAR@50:95:0.415
2024-07-22 16:57:58 metrics/test.mAR@50:0.758
2024-07-22 16:57:58 metrics/test.mAR@75:0.379
2024-07-22 16:57:58 Epoch 220/250 (lr=1e-05), train loss 0.29080
2024-07-22 16:58:07 Training for epoch 221 done, starting evaluation
2024-07-22 16:58:14 Epoch 221 performance:
2024-07-22 16:58:14 metrics/test.mAP@50:95:0.322
2024-07-22 16:58:14 metrics/test.mAP@50:0.665
2024-07-22 16:58:14 metrics/test.mAP@75:0.254
2024-07-22 16:58:14 metrics/test.mAR@50:95:0.415
2024-07-22 16:58:14 metrics/test.mAR@50:0.758
2024-07-22 16:58:14 metrics/test.mAR@75:0.391
2024-07-22 16:58:14 Epoch 221/250 (lr=1e-05), train loss 0.27656
2024-07-22 16:58:23 Training for epoch 222 done, starting evaluation
2024-07-22 16:58:30 Epoch 222 performance:
2024-07-22 16:58:30 metrics/test.mAP@50:95:0.322
2024-07-22 16:58:30 metrics/test.mAP@50:0.668
2024-07-22 16:58:30 metrics/test.mAP@75:0.250
2024-07-22 16:58:30 metrics/test.mAR@50:95:0.417
2024-07-22 16:58:30 metrics/test.mAR@50:0.762
2024-07-22 16:58:30 metrics/test.mAR@75:0.391
2024-07-22 16:58:30 Epoch 222/250 (lr=1e-05), train loss 0.27447
2024-07-22 16:58:39 Training for epoch 223 done, starting evaluation
2024-07-22 16:58:45 Epoch 223 performance:
2024-07-22 16:58:45 metrics/test.mAP@50:95:0.320
2024-07-22 16:58:45 metrics/test.mAP@50:0.659
2024-07-22 16:58:45 metrics/test.mAP@75:0.243
2024-07-22 16:58:45 metrics/test.mAR@50:95:0.419
2024-07-22 16:58:45 metrics/test.mAR@50:0.758
2024-07-22 16:58:45 metrics/test.mAR@75:0.387
2024-07-22 16:58:45 Epoch 223/250 (lr=1e-05), train loss 0.31967
2024-07-22 16:58:54 Training for epoch 224 done, starting evaluation
2024-07-22 16:59:00 Epoch 224 performance:
2024-07-22 16:59:00 metrics/test.mAP@50:95:0.314
2024-07-22 16:59:00 metrics/test.mAP@50:0.658
2024-07-22 16:59:00 metrics/test.mAP@75:0.235
2024-07-22 16:59:00 metrics/test.mAR@50:95:0.414
2024-07-22 16:59:00 metrics/test.mAR@50:0.754
2024-07-22 16:59:00 metrics/test.mAR@75:0.375
2024-07-22 16:59:00 Epoch 224/250 (lr=1e-05), train loss 0.28737
2024-07-22 16:59:09 Training for epoch 225 done, starting evaluation
2024-07-22 16:59:15 Epoch 225 performance:
2024-07-22 16:59:15 metrics/test.mAP@50:95:0.315
2024-07-22 16:59:15 metrics/test.mAP@50:0.652
2024-07-22 16:59:15 metrics/test.mAP@75:0.242
2024-07-22 16:59:15 metrics/test.mAR@50:95:0.415
2024-07-22 16:59:15 metrics/test.mAR@50:0.758
2024-07-22 16:59:15 metrics/test.mAR@75:0.379
2024-07-22 16:59:16 Epoch 225/250 (lr=1e-05), train loss 0.30810
2024-07-22 16:59:25 Training for epoch 226 done, starting evaluation
2024-07-22 16:59:31 Epoch 226 performance:
2024-07-22 16:59:31 metrics/test.mAP@50:95:0.319
2024-07-22 16:59:31 metrics/test.mAP@50:0.662
2024-07-22 16:59:31 metrics/test.mAP@75:0.233
2024-07-22 16:59:31 metrics/test.mAR@50:95:0.417
2024-07-22 16:59:31 metrics/test.mAR@50:0.762
2024-07-22 16:59:31 metrics/test.mAR@75:0.371
2024-07-22 16:59:31 Epoch 226/250 (lr=1e-05), train loss 0.30747
2024-07-22 16:59:41 Training for epoch 227 done, starting evaluation
2024-07-22 16:59:47 Epoch 227 performance:
2024-07-22 16:59:47 metrics/test.mAP@50:95:0.320
2024-07-22 16:59:47 metrics/test.mAP@50:0.661
2024-07-22 16:59:47 metrics/test.mAP@75:0.238
2024-07-22 16:59:47 metrics/test.mAR@50:95:0.418
2024-07-22 16:59:47 metrics/test.mAR@50:0.758
2024-07-22 16:59:47 metrics/test.mAR@75:0.379
2024-07-22 16:59:47 Epoch 227/250 (lr=1e-05), train loss 0.32321
2024-07-22 16:59:56 Training for epoch 228 done, starting evaluation
2024-07-22 17:00:02 Epoch 228 performance:
2024-07-22 17:00:02 metrics/test.mAP@50:95:0.323
2024-07-22 17:00:02 metrics/test.mAP@50:0.672
2024-07-22 17:00:02 metrics/test.mAP@75:0.245
2024-07-22 17:00:02 metrics/test.mAR@50:95:0.425
2024-07-22 17:00:02 metrics/test.mAR@50:0.773
2024-07-22 17:00:02 metrics/test.mAR@75:0.387
2024-07-22 17:00:02 Epoch 228/250 (lr=1e-05), train loss 0.31368
2024-07-22 17:00:11 Training for epoch 229 done, starting evaluation
2024-07-22 17:00:18 Epoch 229 performance:
2024-07-22 17:00:18 metrics/test.mAP@50:95:0.321
2024-07-22 17:00:18 metrics/test.mAP@50:0.660
2024-07-22 17:00:18 metrics/test.mAP@75:0.243
2024-07-22 17:00:18 metrics/test.mAR@50:95:0.427
2024-07-22 17:00:18 metrics/test.mAR@50:0.770
2024-07-22 17:00:18 metrics/test.mAR@75:0.391
2024-07-22 17:00:18 Epoch 229/250 (lr=1e-05), train loss 0.30758
2024-07-22 17:00:26 Training for epoch 230 done, starting evaluation
2024-07-22 17:00:32 Epoch 230 performance:
2024-07-22 17:00:32 metrics/test.mAP@50:95:0.317
2024-07-22 17:00:32 metrics/test.mAP@50:0.657
2024-07-22 17:00:32 metrics/test.mAP@75:0.239
2024-07-22 17:00:32 metrics/test.mAR@50:95:0.416
2024-07-22 17:00:32 metrics/test.mAR@50:0.754
2024-07-22 17:00:32 metrics/test.mAR@75:0.387
2024-07-22 17:00:32 Epoch 230/250 (lr=1e-05), train loss 0.27932
2024-07-22 17:00:41 Training for epoch 231 done, starting evaluation
2024-07-22 17:00:47 Epoch 231 performance:
2024-07-22 17:00:47 metrics/test.mAP@50:95:0.314
2024-07-22 17:00:47 metrics/test.mAP@50:0.661
2024-07-22 17:00:47 metrics/test.mAP@75:0.227
2024-07-22 17:00:47 metrics/test.mAR@50:95:0.412
2024-07-22 17:00:47 metrics/test.mAR@50:0.762
2024-07-22 17:00:47 metrics/test.mAR@75:0.367
2024-07-22 17:00:47 Epoch 231/250 (lr=1e-05), train loss 0.28530
2024-07-22 17:00:57 Training for epoch 232 done, starting evaluation
2024-07-22 17:01:03 Epoch 232 performance:
2024-07-22 17:01:03 metrics/test.mAP@50:95:0.320
2024-07-22 17:01:03 metrics/test.mAP@50:0.658
2024-07-22 17:01:03 metrics/test.mAP@75:0.255
2024-07-22 17:01:03 metrics/test.mAR@50:95:0.421
2024-07-22 17:01:03 metrics/test.mAR@50:0.758
2024-07-22 17:01:03 metrics/test.mAR@75:0.398
2024-07-22 17:01:03 Epoch 232/250 (lr=1e-05), train loss 0.30844
2024-07-22 17:01:11 Training for epoch 233 done, starting evaluation
2024-07-22 17:01:18 Epoch 233 performance:
2024-07-22 17:01:18 metrics/test.mAP@50:95:0.319
2024-07-22 17:01:18 metrics/test.mAP@50:0.658
2024-07-22 17:01:18 metrics/test.mAP@75:0.248
2024-07-22 17:01:18 metrics/test.mAR@50:95:0.418
2024-07-22 17:01:18 metrics/test.mAR@50:0.758
2024-07-22 17:01:18 metrics/test.mAR@75:0.387
2024-07-22 17:01:18 Epoch 233/250 (lr=1e-05), train loss 0.26770
2024-07-22 17:01:26 Training for epoch 234 done, starting evaluation
2024-07-22 17:01:33 Epoch 234 performance:
2024-07-22 17:01:33 metrics/test.mAP@50:95:0.319
2024-07-22 17:01:33 metrics/test.mAP@50:0.664
2024-07-22 17:01:33 metrics/test.mAP@75:0.236
2024-07-22 17:01:33 metrics/test.mAR@50:95:0.417
2024-07-22 17:01:33 metrics/test.mAR@50:0.750
2024-07-22 17:01:33 metrics/test.mAR@75:0.379
2024-07-22 17:01:33 Epoch 234/250 (lr=1e-05), train loss 0.29953
2024-07-22 17:01:42 Training for epoch 235 done, starting evaluation
2024-07-22 17:01:48 Epoch 235 performance:
2024-07-22 17:01:48 metrics/test.mAP@50:95:0.324
2024-07-22 17:01:48 metrics/test.mAP@50:0.659
2024-07-22 17:01:48 metrics/test.mAP@75:0.251
2024-07-22 17:01:48 metrics/test.mAR@50:95:0.420
2024-07-22 17:01:48 metrics/test.mAR@50:0.746
2024-07-22 17:01:48 metrics/test.mAR@75:0.391
2024-07-22 17:01:48 Epoch 235/250 (lr=1e-05), train loss 0.30092
2024-07-22 17:01:57 Training for epoch 236 done, starting evaluation
2024-07-22 17:02:03 Epoch 236 performance:
2024-07-22 17:02:03 metrics/test.mAP@50:95:0.325
2024-07-22 17:02:03 metrics/test.mAP@50:0.659
2024-07-22 17:02:03 metrics/test.mAP@75:0.245
2024-07-22 17:02:03 metrics/test.mAR@50:95:0.420
2024-07-22 17:02:03 metrics/test.mAR@50:0.746
2024-07-22 17:02:03 metrics/test.mAR@75:0.383
2024-07-22 17:02:03 Epoch 236/250 (lr=1e-05), train loss 0.29843
2024-07-22 17:02:12 Training for epoch 237 done, starting evaluation
2024-07-22 17:02:18 Epoch 237 performance:
2024-07-22 17:02:18 metrics/test.mAP@50:95:0.321
2024-07-22 17:02:18 metrics/test.mAP@50:0.662
2024-07-22 17:02:18 metrics/test.mAP@75:0.232
2024-07-22 17:02:18 metrics/test.mAR@50:95:0.413
2024-07-22 17:02:18 metrics/test.mAR@50:0.746
2024-07-22 17:02:18 metrics/test.mAR@75:0.375
2024-07-22 17:02:18 Epoch 237/250 (lr=1e-05), train loss 0.31496
2024-07-22 17:02:27 Training for epoch 238 done, starting evaluation
2024-07-22 17:02:34 Epoch 238 performance:
2024-07-22 17:02:34 metrics/test.mAP@50:95:0.321
2024-07-22 17:02:34 metrics/test.mAP@50:0.671
2024-07-22 17:02:34 metrics/test.mAP@75:0.247
2024-07-22 17:02:34 metrics/test.mAR@50:95:0.414
2024-07-22 17:02:34 metrics/test.mAR@50:0.750
2024-07-22 17:02:34 metrics/test.mAR@75:0.383
2024-07-22 17:02:34 Epoch 238/250 (lr=1e-05), train loss 0.29099
2024-07-22 17:02:43 Training for epoch 239 done, starting evaluation
2024-07-22 17:02:49 Epoch 239 performance:
2024-07-22 17:02:49 metrics/test.mAP@50:95:0.314
2024-07-22 17:02:49 metrics/test.mAP@50:0.662
2024-07-22 17:02:49 metrics/test.mAP@75:0.226
2024-07-22 17:02:49 metrics/test.mAR@50:95:0.412
2024-07-22 17:02:49 metrics/test.mAR@50:0.754
2024-07-22 17:02:49 metrics/test.mAR@75:0.375
2024-07-22 17:02:49 Epoch 239/250 (lr=1e-05), train loss 0.32613
2024-07-22 17:02:57 Training for epoch 240 done, starting evaluation
2024-07-22 17:03:04 Epoch 240 performance:
2024-07-22 17:03:04 metrics/test.mAP@50:95:0.311
2024-07-22 17:03:04 metrics/test.mAP@50:0.658
2024-07-22 17:03:04 metrics/test.mAP@75:0.237
2024-07-22 17:03:04 metrics/test.mAR@50:95:0.411
2024-07-22 17:03:04 metrics/test.mAR@50:0.758
2024-07-22 17:03:04 metrics/test.mAR@75:0.391
2024-07-22 17:03:04 Epoch 240/250 (lr=1e-05), train loss 0.29956
2024-07-22 17:03:12 Training for epoch 241 done, starting evaluation
2024-07-22 17:03:19 Epoch 241 performance:
2024-07-22 17:03:19 metrics/test.mAP@50:95:0.316
2024-07-22 17:03:19 metrics/test.mAP@50:0.659
2024-07-22 17:03:19 metrics/test.mAP@75:0.243
2024-07-22 17:03:19 metrics/test.mAR@50:95:0.412
2024-07-22 17:03:19 metrics/test.mAR@50:0.750
2024-07-22 17:03:19 metrics/test.mAR@75:0.391
2024-07-22 17:03:19 Epoch 241/250 (lr=1e-05), train loss 0.26930
2024-07-22 17:03:27 Training for epoch 242 done, starting evaluation
2024-07-22 17:03:33 Epoch 242 performance:
2024-07-22 17:03:33 metrics/test.mAP@50:95:0.315
2024-07-22 17:03:33 metrics/test.mAP@50:0.658
2024-07-22 17:03:33 metrics/test.mAP@75:0.231
2024-07-22 17:03:33 metrics/test.mAR@50:95:0.409
2024-07-22 17:03:33 metrics/test.mAR@50:0.746
2024-07-22 17:03:33 metrics/test.mAR@75:0.371
2024-07-22 17:03:33 Epoch 242/250 (lr=1e-05), train loss 0.27438
2024-07-22 17:03:42 Training for epoch 243 done, starting evaluation
2024-07-22 17:03:48 Epoch 243 performance:
2024-07-22 17:03:48 metrics/test.mAP@50:95:0.323
2024-07-22 17:03:48 metrics/test.mAP@50:0.662
2024-07-22 17:03:48 metrics/test.mAP@75:0.254
2024-07-22 17:03:48 metrics/test.mAR@50:95:0.416
2024-07-22 17:03:48 metrics/test.mAR@50:0.746
2024-07-22 17:03:48 metrics/test.mAR@75:0.391
2024-07-22 17:03:48 Epoch 243/250 (lr=1e-05), train loss 0.26006
2024-07-22 17:03:57 Training for epoch 244 done, starting evaluation
2024-07-22 17:04:04 Epoch 244 performance:
2024-07-22 17:04:04 metrics/test.mAP@50:95:0.318
2024-07-22 17:04:04 metrics/test.mAP@50:0.652
2024-07-22 17:04:04 metrics/test.mAP@75:0.228
2024-07-22 17:04:04 metrics/test.mAR@50:95:0.414
2024-07-22 17:04:04 metrics/test.mAR@50:0.738
2024-07-22 17:04:04 metrics/test.mAR@75:0.371
2024-07-22 17:04:04 Epoch 244/250 (lr=1e-05), train loss 0.30008
2024-07-22 17:04:12 Training for epoch 245 done, starting evaluation
2024-07-22 17:04:19 Epoch 245 performance:
2024-07-22 17:04:19 metrics/test.mAP@50:95:0.318
2024-07-22 17:04:19 metrics/test.mAP@50:0.647
2024-07-22 17:04:19 metrics/test.mAP@75:0.238
2024-07-22 17:04:19 metrics/test.mAR@50:95:0.417
2024-07-22 17:04:19 metrics/test.mAR@50:0.738
2024-07-22 17:04:19 metrics/test.mAR@75:0.398
2024-07-22 17:04:19 Epoch 245/250 (lr=1e-05), train loss 0.28351
2024-07-22 17:04:27 Training for epoch 246 done, starting evaluation
2024-07-22 17:04:33 Epoch 246 performance:
2024-07-22 17:04:33 metrics/test.mAP@50:95:0.320
2024-07-22 17:04:33 metrics/test.mAP@50:0.666
2024-07-22 17:04:33 metrics/test.mAP@75:0.246
2024-07-22 17:04:33 metrics/test.mAR@50:95:0.420
2024-07-22 17:04:33 metrics/test.mAR@50:0.758
2024-07-22 17:04:33 metrics/test.mAR@75:0.398
2024-07-22 17:04:33 Epoch 246/250 (lr=1e-05), train loss 0.32677
2024-07-22 17:04:42 Training for epoch 247 done, starting evaluation
2024-07-22 17:04:49 Epoch 247 performance:
2024-07-22 17:04:49 metrics/test.mAP@50:95:0.319
2024-07-22 17:04:49 metrics/test.mAP@50:0.653
2024-07-22 17:04:49 metrics/test.mAP@75:0.246
2024-07-22 17:04:49 metrics/test.mAR@50:95:0.420
2024-07-22 17:04:49 metrics/test.mAR@50:0.746
2024-07-22 17:04:49 metrics/test.mAR@75:0.402
2024-07-22 17:04:49 Epoch 247/250 (lr=1e-05), train loss 0.28857
2024-07-22 17:04:57 Training for epoch 248 done, starting evaluation
2024-07-22 17:05:04 Epoch 248 performance:
2024-07-22 17:05:04 metrics/test.mAP@50:95:0.319
2024-07-22 17:05:04 metrics/test.mAP@50:0.658
2024-07-22 17:05:04 metrics/test.mAP@75:0.233
2024-07-22 17:05:04 metrics/test.mAR@50:95:0.420
2024-07-22 17:05:04 metrics/test.mAR@50:0.750
2024-07-22 17:05:04 metrics/test.mAR@75:0.379
2024-07-22 17:05:04 Epoch 248/250 (lr=1e-05), train loss 0.28172
2024-07-22 17:05:12 Training for epoch 249 done, starting evaluation
2024-07-22 17:05:19 Epoch 249 performance:
2024-07-22 17:05:19 metrics/test.mAP@50:95:0.319
2024-07-22 17:05:19 metrics/test.mAP@50:0.655
2024-07-22 17:05:19 metrics/test.mAP@75:0.237
2024-07-22 17:05:19 metrics/test.mAR@50:95:0.420
2024-07-22 17:05:19 metrics/test.mAR@50:0.750
2024-07-22 17:05:19 metrics/test.mAR@75:0.387
2024-07-22 17:05:19 Epoch 249/250 (lr=1e-05), train loss 0.25766
2024-07-22 17:05:27 Training for epoch 250 done, starting evaluation
2024-07-22 17:05:33 Epoch 250 performance:
2024-07-22 17:05:33 metrics/test.mAP@50:95:0.317
2024-07-22 17:05:33 metrics/test.mAP@50:0.660
2024-07-22 17:05:33 metrics/test.mAP@75:0.226
2024-07-22 17:05:33 metrics/test.mAR@50:95:0.416
2024-07-22 17:05:33 metrics/test.mAR@50:0.754
2024-07-22 17:05:33 metrics/test.mAR@75:0.375
2024-07-22 17:05:33 Epoch 250/250 (lr=1e-05), train loss 0.27162
2024-07-22 17:05:33 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2024-07-22 17:05:40 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2024-07-22 17:05:40 Data Transforms:
2024-07-22 17:05:40   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-07-22 17:05:40   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2024-07-22 17:05:40 
Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.
This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.
If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. 
This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).

2024-07-22 17:05:40 Using 414 images and 256 for testing
2024-07-22 17:05:40 
Starting pose model training...
--------------------------------------------------
2024-07-22 17:05:49 Training for epoch 1 done, starting evaluation
2024-07-22 17:05:55 Epoch 1 performance:
2024-07-22 17:05:55 metrics/test.rmse:  47.127
2024-07-22 17:05:55 metrics/test.rmse_pcutoff:20.078
2024-07-22 17:05:55 metrics/test.mAP:   3.952
2024-07-22 17:05:55 metrics/test.mAR:   30.742
2024-07-22 17:05:55 metrics/test.mAP_pcutoff:0.000
2024-07-22 17:05:55 metrics/test.mAR_pcutoff:0.000
2024-07-22 17:05:55 Epoch 1/200 (lr=0.0001), train loss 0.00541, valid loss 0.00441
2024-07-22 17:06:04 Training for epoch 2 done, starting evaluation
2024-07-22 17:06:11 Epoch 2 performance:
2024-07-22 17:06:11 metrics/test.rmse:  33.485
2024-07-22 17:06:11 metrics/test.rmse_pcutoff:12.968
2024-07-22 17:06:11 metrics/test.mAP:   7.907
2024-07-22 17:06:11 metrics/test.mAR:   48.711
2024-07-22 17:06:11 metrics/test.mAP_pcutoff:0.000
2024-07-22 17:06:11 metrics/test.mAR_pcutoff:0.000
2024-07-22 17:06:11 Epoch 2/200 (lr=0.0001), train loss 0.00429, valid loss 0.00375
2024-07-22 17:06:19 Training for epoch 3 done, starting evaluation
2024-07-22 17:06:26 Epoch 3 performance:
2024-07-22 17:06:26 metrics/test.rmse:  28.284
2024-07-22 17:06:26 metrics/test.rmse_pcutoff:13.416
2024-07-22 17:06:26 metrics/test.mAP:   9.161
2024-07-22 17:06:26 metrics/test.mAR:   56.133
2024-07-22 17:06:26 metrics/test.mAP_pcutoff:0.099
2024-07-22 17:06:26 metrics/test.mAR_pcutoff:0.078
2024-07-22 17:06:26 Epoch 3/200 (lr=0.0001), train loss 0.00372, valid loss 0.00335
2024-07-22 17:06:35 Training for epoch 4 done, starting evaluation
2024-07-22 17:06:42 Epoch 4 performance:
2024-07-22 17:06:42 metrics/test.rmse:  26.526
2024-07-22 17:06:42 metrics/test.rmse_pcutoff:13.451
2024-07-22 17:06:42 metrics/test.mAP:   9.499
2024-07-22 17:06:42 metrics/test.mAR:   58.750
2024-07-22 17:06:42 metrics/test.mAP_pcutoff:0.728
2024-07-22 17:06:42 metrics/test.mAR_pcutoff:0.859
2024-07-22 17:06:42 Epoch 4/200 (lr=0.0001), train loss 0.00335, valid loss 0.00310
2024-07-22 17:06:51 Training for epoch 5 done, starting evaluation
2024-07-22 17:06:58 Epoch 5 performance:
2024-07-22 17:06:58 metrics/test.rmse:  25.410
2024-07-22 17:06:58 metrics/test.rmse_pcutoff:13.455
2024-07-22 17:06:58 metrics/test.mAP:   9.971
2024-07-22 17:06:58 metrics/test.mAR:   60.000
2024-07-22 17:06:58 metrics/test.mAP_pcutoff:1.714
2024-07-22 17:06:58 metrics/test.mAR_pcutoff:2.070
2024-07-22 17:06:58 Epoch 5/200 (lr=0.0001), train loss 0.00314, valid loss 0.00295
2024-07-22 17:07:06 Training for epoch 6 done, starting evaluation
2024-07-22 17:07:13 Epoch 6 performance:
2024-07-22 17:07:13 metrics/test.rmse:  24.855
2024-07-22 17:07:13 metrics/test.rmse_pcutoff:13.677
2024-07-22 17:07:13 metrics/test.mAP:   10.660
2024-07-22 17:07:13 metrics/test.mAR:   61.758
2024-07-22 17:07:13 metrics/test.mAP_pcutoff:3.661
2024-07-22 17:07:13 metrics/test.mAR_pcutoff:4.180
2024-07-22 17:07:13 Epoch 6/200 (lr=0.0001), train loss 0.00292, valid loss 0.00286
2024-07-22 17:07:22 Training for epoch 7 done, starting evaluation
2024-07-22 17:07:29 Epoch 7 performance:
2024-07-22 17:07:29 metrics/test.rmse:  24.131
2024-07-22 17:07:29 metrics/test.rmse_pcutoff:13.974
2024-07-22 17:07:29 metrics/test.mAP:   10.795
2024-07-22 17:07:29 metrics/test.mAR:   62.461
2024-07-22 17:07:29 metrics/test.mAP_pcutoff:5.250
2024-07-22 17:07:29 metrics/test.mAR_pcutoff:6.406
2024-07-22 17:07:29 Epoch 7/200 (lr=0.0001), train loss 0.00278, valid loss 0.00278
2024-07-22 17:07:38 Training for epoch 8 done, starting evaluation
2024-07-22 17:07:45 Epoch 8 performance:
2024-07-22 17:07:45 metrics/test.rmse:  23.817
2024-07-22 17:07:45 metrics/test.rmse_pcutoff:13.895
2024-07-22 17:07:45 metrics/test.mAP:   11.269
2024-07-22 17:07:45 metrics/test.mAR:   63.555
2024-07-22 17:07:45 metrics/test.mAP_pcutoff:5.866
2024-07-22 17:07:45 metrics/test.mAR_pcutoff:7.109
2024-07-22 17:07:45 Epoch 8/200 (lr=0.0001), train loss 0.00264, valid loss 0.00274
2024-07-22 17:07:53 Training for epoch 9 done, starting evaluation
2024-07-22 17:08:01 Epoch 9 performance:
2024-07-22 17:08:01 metrics/test.rmse:  23.344
2024-07-22 17:08:01 metrics/test.rmse_pcutoff:13.887
2024-07-22 17:08:01 metrics/test.mAP:   11.522
2024-07-22 17:08:01 metrics/test.mAR:   64.180
2024-07-22 17:08:01 metrics/test.mAP_pcutoff:7.090
2024-07-22 17:08:01 metrics/test.mAR_pcutoff:8.711
2024-07-22 17:08:01 Epoch 9/200 (lr=0.0001), train loss 0.00255, valid loss 0.00272
2024-07-22 17:08:10 Training for epoch 10 done, starting evaluation
2024-07-22 17:08:17 Epoch 10 performance:
2024-07-22 17:08:17 metrics/test.rmse:  22.924
2024-07-22 17:08:17 metrics/test.rmse_pcutoff:13.419
2024-07-22 17:08:17 metrics/test.mAP:   11.090
2024-07-22 17:08:17 metrics/test.mAR:   64.297
2024-07-22 17:08:17 metrics/test.mAP_pcutoff:7.414
2024-07-22 17:08:17 metrics/test.mAR_pcutoff:9.102
2024-07-22 17:08:17 Epoch 10/200 (lr=0.0001), train loss 0.00239, valid loss 0.00269
2024-07-22 17:08:26 Training for epoch 11 done, starting evaluation
2024-07-22 17:08:34 Epoch 11 performance:
2024-07-22 17:08:34 metrics/test.rmse:  23.174
2024-07-22 17:08:34 metrics/test.rmse_pcutoff:14.244
2024-07-22 17:08:34 metrics/test.mAP:   11.608
2024-07-22 17:08:34 metrics/test.mAR:   64.922
2024-07-22 17:08:34 metrics/test.mAP_pcutoff:10.068
2024-07-22 17:08:34 metrics/test.mAR_pcutoff:12.109
2024-07-22 17:08:34 Epoch 11/200 (lr=0.0001), train loss 0.00230, valid loss 0.00269
2024-07-22 17:08:42 Training for epoch 12 done, starting evaluation
2024-07-22 17:08:49 Epoch 12 performance:
2024-07-22 17:08:49 metrics/test.rmse:  22.267
2024-07-22 17:08:49 metrics/test.rmse_pcutoff:14.101
2024-07-22 17:08:49 metrics/test.mAP:   11.355
2024-07-22 17:08:49 metrics/test.mAR:   65.156
2024-07-22 17:08:49 metrics/test.mAP_pcutoff:11.250
2024-07-22 17:08:49 metrics/test.mAR_pcutoff:13.086
2024-07-22 17:08:49 Epoch 12/200 (lr=0.0001), train loss 0.00223, valid loss 0.00266
2024-07-22 17:08:58 Training for epoch 13 done, starting evaluation
2024-07-22 17:09:05 Epoch 13 performance:
2024-07-22 17:09:05 metrics/test.rmse:  23.055
2024-07-22 17:09:05 metrics/test.rmse_pcutoff:14.151
2024-07-22 17:09:05 metrics/test.mAP:   11.497
2024-07-22 17:09:05 metrics/test.mAR:   65.039
2024-07-22 17:09:05 metrics/test.mAP_pcutoff:11.989
2024-07-22 17:09:05 metrics/test.mAR_pcutoff:13.906
2024-07-22 17:09:05 Epoch 13/200 (lr=0.0001), train loss 0.00213, valid loss 0.00267
2024-07-22 17:09:13 Training for epoch 14 done, starting evaluation
2024-07-22 17:09:21 Epoch 14 performance:
2024-07-22 17:09:21 metrics/test.rmse:  22.599
2024-07-22 17:09:21 metrics/test.rmse_pcutoff:14.227
2024-07-22 17:09:21 metrics/test.mAP:   11.730
2024-07-22 17:09:21 metrics/test.mAR:   65.234
2024-07-22 17:09:21 metrics/test.mAP_pcutoff:13.013
2024-07-22 17:09:21 metrics/test.mAR_pcutoff:15.078
2024-07-22 17:09:21 Epoch 14/200 (lr=0.0001), train loss 0.00204, valid loss 0.00265
2024-07-22 17:09:29 Training for epoch 15 done, starting evaluation
2024-07-22 17:09:36 Epoch 15 performance:
2024-07-22 17:09:36 metrics/test.rmse:  22.838
2024-07-22 17:09:36 metrics/test.rmse_pcutoff:13.965
2024-07-22 17:09:36 metrics/test.mAP:   11.311
2024-07-22 17:09:36 metrics/test.mAR:   65.117
2024-07-22 17:09:36 metrics/test.mAP_pcutoff:13.221
2024-07-22 17:09:36 metrics/test.mAR_pcutoff:15.313
2024-07-22 17:09:36 Epoch 15/200 (lr=0.0001), train loss 0.00196, valid loss 0.00264
2024-07-22 17:09:45 Training for epoch 16 done, starting evaluation
2024-07-22 17:09:52 Epoch 16 performance:
2024-07-22 17:09:52 metrics/test.rmse:  21.659
2024-07-22 17:09:52 metrics/test.rmse_pcutoff:14.464
2024-07-22 17:09:52 metrics/test.mAP:   12.323
2024-07-22 17:09:52 metrics/test.mAR:   66.680
2024-07-22 17:09:52 metrics/test.mAP_pcutoff:15.397
2024-07-22 17:09:52 metrics/test.mAR_pcutoff:17.773
2024-07-22 17:09:52 Epoch 16/200 (lr=0.0001), train loss 0.00188, valid loss 0.00264
2024-07-22 17:10:00 Training for epoch 17 done, starting evaluation
2024-07-22 17:10:07 Epoch 17 performance:
2024-07-22 17:10:07 metrics/test.rmse:  22.369
2024-07-22 17:10:07 metrics/test.rmse_pcutoff:14.262
2024-07-22 17:10:07 metrics/test.mAP:   11.935
2024-07-22 17:10:07 metrics/test.mAR:   65.859
2024-07-22 17:10:07 metrics/test.mAP_pcutoff:14.233
2024-07-22 17:10:07 metrics/test.mAR_pcutoff:16.719
2024-07-22 17:10:07 Epoch 17/200 (lr=0.0001), train loss 0.00180, valid loss 0.00264
2024-07-22 17:10:16 Training for epoch 18 done, starting evaluation
2024-07-22 17:10:24 Epoch 18 performance:
2024-07-22 17:10:24 metrics/test.rmse:  21.974
2024-07-22 17:10:24 metrics/test.rmse_pcutoff:13.960
2024-07-22 17:10:24 metrics/test.mAP:   12.006
2024-07-22 17:10:24 metrics/test.mAR:   66.211
2024-07-22 17:10:24 metrics/test.mAP_pcutoff:13.824
2024-07-22 17:10:24 metrics/test.mAR_pcutoff:15.859
2024-07-22 17:10:24 Epoch 18/200 (lr=0.0001), train loss 0.00172, valid loss 0.00263
2024-07-22 17:10:33 Training for epoch 19 done, starting evaluation
2024-07-22 17:10:40 Epoch 19 performance:
2024-07-22 17:10:40 metrics/test.rmse:  22.658
2024-07-22 17:10:40 metrics/test.rmse_pcutoff:14.489
2024-07-22 17:10:40 metrics/test.mAP:   11.954
2024-07-22 17:10:40 metrics/test.mAR:   65.859
2024-07-22 17:10:40 metrics/test.mAP_pcutoff:15.102
2024-07-22 17:10:40 metrics/test.mAR_pcutoff:17.578
2024-07-22 17:10:40 Epoch 19/200 (lr=0.0001), train loss 0.00166, valid loss 0.00267
2024-07-22 17:10:49 Training for epoch 20 done, starting evaluation
2024-07-22 17:10:57 Epoch 20 performance:
2024-07-22 17:10:57 metrics/test.rmse:  22.431
2024-07-22 17:10:57 metrics/test.rmse_pcutoff:14.284
2024-07-22 17:10:57 metrics/test.mAP:   12.271
2024-07-22 17:10:57 metrics/test.mAR:   65.781
2024-07-22 17:10:57 metrics/test.mAP_pcutoff:16.511
2024-07-22 17:10:57 metrics/test.mAR_pcutoff:18.867
2024-07-22 17:10:57 Epoch 20/200 (lr=0.0001), train loss 0.00157, valid loss 0.00264
2024-07-22 17:11:05 Training for epoch 21 done, starting evaluation
2024-07-22 17:11:12 Epoch 21 performance:
2024-07-22 17:11:12 metrics/test.rmse:  21.867
2024-07-22 17:11:12 metrics/test.rmse_pcutoff:14.623
2024-07-22 17:11:12 metrics/test.mAP:   12.358
2024-07-22 17:11:12 metrics/test.mAR:   66.172
2024-07-22 17:11:12 metrics/test.mAP_pcutoff:16.293
2024-07-22 17:11:12 metrics/test.mAR_pcutoff:19.297
2024-07-22 17:11:12 Epoch 21/200 (lr=0.0001), train loss 0.00149, valid loss 0.00267
2024-07-22 17:11:21 Training for epoch 22 done, starting evaluation
2024-07-22 17:11:28 Epoch 22 performance:
2024-07-22 17:11:28 metrics/test.rmse:  21.656
2024-07-22 17:11:28 metrics/test.rmse_pcutoff:14.520
2024-07-22 17:11:28 metrics/test.mAP:   12.205
2024-07-22 17:11:28 metrics/test.mAR:   65.859
2024-07-22 17:11:28 metrics/test.mAP_pcutoff:14.595
2024-07-22 17:11:28 metrics/test.mAR_pcutoff:17.148
2024-07-22 17:11:28 Epoch 22/200 (lr=0.0001), train loss 0.00145, valid loss 0.00265
2024-07-22 17:11:37 Training for epoch 23 done, starting evaluation
2024-07-22 17:11:44 Epoch 23 performance:
2024-07-22 17:11:44 metrics/test.rmse:  21.940
2024-07-22 17:11:44 metrics/test.rmse_pcutoff:14.328
2024-07-22 17:11:44 metrics/test.mAP:   12.183
2024-07-22 17:11:44 metrics/test.mAR:   66.289
2024-07-22 17:11:44 metrics/test.mAP_pcutoff:15.660
2024-07-22 17:11:44 metrics/test.mAR_pcutoff:18.086
2024-07-22 17:11:44 Epoch 23/200 (lr=0.0001), train loss 0.00142, valid loss 0.00263
2024-07-22 17:11:53 Training for epoch 24 done, starting evaluation
2024-07-22 17:12:00 Epoch 24 performance:
2024-07-22 17:12:00 metrics/test.rmse:  22.786
2024-07-22 17:12:00 metrics/test.rmse_pcutoff:15.381
2024-07-22 17:12:00 metrics/test.mAP:   11.841
2024-07-22 17:12:00 metrics/test.mAR:   65.859
2024-07-22 17:12:00 metrics/test.mAP_pcutoff:18.618
2024-07-22 17:12:00 metrics/test.mAR_pcutoff:21.133
2024-07-22 17:12:00 Epoch 24/200 (lr=0.0001), train loss 0.00135, valid loss 0.00268
2024-07-22 17:12:09 Training for epoch 25 done, starting evaluation
2024-07-22 17:12:16 Epoch 25 performance:
2024-07-22 17:12:16 metrics/test.rmse:  22.442
2024-07-22 17:12:16 metrics/test.rmse_pcutoff:14.482
2024-07-22 17:12:16 metrics/test.mAP:   12.040
2024-07-22 17:12:16 metrics/test.mAR:   65.938
2024-07-22 17:12:16 metrics/test.mAP_pcutoff:16.782
2024-07-22 17:12:16 metrics/test.mAR_pcutoff:19.219
2024-07-22 17:12:16 Epoch 25/200 (lr=0.0001), train loss 0.00128, valid loss 0.00267
2024-07-22 17:12:25 Training for epoch 26 done, starting evaluation
2024-07-22 17:12:33 Epoch 26 performance:
2024-07-22 17:12:33 metrics/test.rmse:  22.214
2024-07-22 17:12:33 metrics/test.rmse_pcutoff:14.560
2024-07-22 17:12:33 metrics/test.mAP:   12.004
2024-07-22 17:12:33 metrics/test.mAR:   65.977
2024-07-22 17:12:33 metrics/test.mAP_pcutoff:18.786
2024-07-22 17:12:33 metrics/test.mAR_pcutoff:21.367
2024-07-22 17:12:33 Epoch 26/200 (lr=0.0001), train loss 0.00121, valid loss 0.00268
2024-07-22 17:12:41 Training for epoch 27 done, starting evaluation
2024-07-22 17:12:48 Epoch 27 performance:
2024-07-22 17:12:48 metrics/test.rmse:  21.922
2024-07-22 17:12:48 metrics/test.rmse_pcutoff:15.886
2024-07-22 17:12:48 metrics/test.mAP:   12.951
2024-07-22 17:12:48 metrics/test.mAR:   66.680
2024-07-22 17:12:48 metrics/test.mAP_pcutoff:18.371
2024-07-22 17:12:48 metrics/test.mAR_pcutoff:21.133
2024-07-22 17:12:48 Epoch 27/200 (lr=0.0001), train loss 0.00119, valid loss 0.00267
2024-07-22 17:12:57 Training for epoch 28 done, starting evaluation
2024-07-22 17:13:04 Epoch 28 performance:
2024-07-22 17:13:04 metrics/test.rmse:  22.656
2024-07-22 17:13:04 metrics/test.rmse_pcutoff:15.411
2024-07-22 17:13:04 metrics/test.mAP:   11.878
2024-07-22 17:13:04 metrics/test.mAR:   65.234
2024-07-22 17:13:04 metrics/test.mAP_pcutoff:16.790
2024-07-22 17:13:04 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:13:04 Epoch 28/200 (lr=0.0001), train loss 0.00113, valid loss 0.00267
2024-07-22 17:13:13 Training for epoch 29 done, starting evaluation
2024-07-22 17:13:20 Epoch 29 performance:
2024-07-22 17:13:20 metrics/test.rmse:  21.775
2024-07-22 17:13:20 metrics/test.rmse_pcutoff:14.638
2024-07-22 17:13:20 metrics/test.mAP:   12.605
2024-07-22 17:13:20 metrics/test.mAR:   66.602
2024-07-22 17:13:20 metrics/test.mAP_pcutoff:18.581
2024-07-22 17:13:20 metrics/test.mAR_pcutoff:21.367
2024-07-22 17:13:20 Epoch 29/200 (lr=0.0001), train loss 0.00108, valid loss 0.00267
2024-07-22 17:13:29 Training for epoch 30 done, starting evaluation
2024-07-22 17:13:36 Epoch 30 performance:
2024-07-22 17:13:36 metrics/test.rmse:  22.162
2024-07-22 17:13:36 metrics/test.rmse_pcutoff:14.659
2024-07-22 17:13:36 metrics/test.mAP:   12.226
2024-07-22 17:13:36 metrics/test.mAR:   65.977
2024-07-22 17:13:36 metrics/test.mAP_pcutoff:16.065
2024-07-22 17:13:36 metrics/test.mAR_pcutoff:18.516
2024-07-22 17:13:36 Epoch 30/200 (lr=0.0001), train loss 0.00106, valid loss 0.00265
2024-07-22 17:13:45 Training for epoch 31 done, starting evaluation
2024-07-22 17:13:52 Epoch 31 performance:
2024-07-22 17:13:52 metrics/test.rmse:  22.307
2024-07-22 17:13:52 metrics/test.rmse_pcutoff:14.657
2024-07-22 17:13:52 metrics/test.mAP:   12.013
2024-07-22 17:13:52 metrics/test.mAR:   65.742
2024-07-22 17:13:52 metrics/test.mAP_pcutoff:18.341
2024-07-22 17:13:52 metrics/test.mAR_pcutoff:21.055
2024-07-22 17:13:52 Epoch 31/200 (lr=0.0001), train loss 0.00102, valid loss 0.00266
2024-07-22 17:14:00 Training for epoch 32 done, starting evaluation
2024-07-22 17:14:08 Epoch 32 performance:
2024-07-22 17:14:08 metrics/test.rmse:  22.135
2024-07-22 17:14:08 metrics/test.rmse_pcutoff:14.972
2024-07-22 17:14:08 metrics/test.mAP:   12.196
2024-07-22 17:14:08 metrics/test.mAR:   65.859
2024-07-22 17:14:08 metrics/test.mAP_pcutoff:19.052
2024-07-22 17:14:08 metrics/test.mAR_pcutoff:22.539
2024-07-22 17:14:08 Epoch 32/200 (lr=0.0001), train loss 0.00098, valid loss 0.00268
2024-07-22 17:14:16 Training for epoch 33 done, starting evaluation
2024-07-22 17:14:24 Epoch 33 performance:
2024-07-22 17:14:24 metrics/test.rmse:  22.409
2024-07-22 17:14:24 metrics/test.rmse_pcutoff:14.936
2024-07-22 17:14:24 metrics/test.mAP:   12.155
2024-07-22 17:14:24 metrics/test.mAR:   65.781
2024-07-22 17:14:24 metrics/test.mAP_pcutoff:17.430
2024-07-22 17:14:24 metrics/test.mAR_pcutoff:20.312
2024-07-22 17:14:24 Epoch 33/200 (lr=0.0001), train loss 0.00095, valid loss 0.00268
2024-07-22 17:14:32 Training for epoch 34 done, starting evaluation
2024-07-22 17:14:39 Epoch 34 performance:
2024-07-22 17:14:39 metrics/test.rmse:  21.646
2024-07-22 17:14:39 metrics/test.rmse_pcutoff:14.593
2024-07-22 17:14:39 metrics/test.mAP:   12.465
2024-07-22 17:14:39 metrics/test.mAR:   66.250
2024-07-22 17:14:39 metrics/test.mAP_pcutoff:17.160
2024-07-22 17:14:39 metrics/test.mAR_pcutoff:19.766
2024-07-22 17:14:39 Epoch 34/200 (lr=0.0001), train loss 0.00090, valid loss 0.00268
2024-07-22 17:14:47 Training for epoch 35 done, starting evaluation
2024-07-22 17:14:55 Epoch 35 performance:
2024-07-22 17:14:55 metrics/test.rmse:  22.202
2024-07-22 17:14:55 metrics/test.rmse_pcutoff:14.841
2024-07-22 17:14:55 metrics/test.mAP:   11.803
2024-07-22 17:14:55 metrics/test.mAR:   65.625
2024-07-22 17:14:55 metrics/test.mAP_pcutoff:16.469
2024-07-22 17:14:55 metrics/test.mAR_pcutoff:18.750
2024-07-22 17:14:55 Epoch 35/200 (lr=0.0001), train loss 0.00089, valid loss 0.00266
2024-07-22 17:15:03 Training for epoch 36 done, starting evaluation
2024-07-22 17:15:11 Epoch 36 performance:
2024-07-22 17:15:11 metrics/test.rmse:  22.015
2024-07-22 17:15:11 metrics/test.rmse_pcutoff:14.536
2024-07-22 17:15:11 metrics/test.mAP:   12.284
2024-07-22 17:15:11 metrics/test.mAR:   66.445
2024-07-22 17:15:11 metrics/test.mAP_pcutoff:17.089
2024-07-22 17:15:11 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:15:11 Epoch 36/200 (lr=0.0001), train loss 0.00087, valid loss 0.00266
2024-07-22 17:15:19 Training for epoch 37 done, starting evaluation
2024-07-22 17:15:27 Epoch 37 performance:
2024-07-22 17:15:27 metrics/test.rmse:  22.216
2024-07-22 17:15:27 metrics/test.rmse_pcutoff:14.658
2024-07-22 17:15:27 metrics/test.mAP:   12.072
2024-07-22 17:15:27 metrics/test.mAR:   65.781
2024-07-22 17:15:27 metrics/test.mAP_pcutoff:16.698
2024-07-22 17:15:27 metrics/test.mAR_pcutoff:20.078
2024-07-22 17:15:27 Epoch 37/200 (lr=0.0001), train loss 0.00078, valid loss 0.00266
2024-07-22 17:15:36 Training for epoch 38 done, starting evaluation
2024-07-22 17:15:43 Epoch 38 performance:
2024-07-22 17:15:43 metrics/test.rmse:  21.858
2024-07-22 17:15:43 metrics/test.rmse_pcutoff:14.603
2024-07-22 17:15:43 metrics/test.mAP:   12.157
2024-07-22 17:15:43 metrics/test.mAR:   66.055
2024-07-22 17:15:43 metrics/test.mAP_pcutoff:16.891
2024-07-22 17:15:43 metrics/test.mAR_pcutoff:19.414
2024-07-22 17:15:43 Epoch 38/200 (lr=0.0001), train loss 0.00082, valid loss 0.00263
2024-07-22 17:15:52 Training for epoch 39 done, starting evaluation
2024-07-22 17:15:59 Epoch 39 performance:
2024-07-22 17:15:59 metrics/test.rmse:  22.400
2024-07-22 17:15:59 metrics/test.rmse_pcutoff:14.721
2024-07-22 17:15:59 metrics/test.mAP:   11.475
2024-07-22 17:15:59 metrics/test.mAR:   65.352
2024-07-22 17:15:59 metrics/test.mAP_pcutoff:15.836
2024-07-22 17:15:59 metrics/test.mAR_pcutoff:18.516
2024-07-22 17:15:59 Epoch 39/200 (lr=0.0001), train loss 0.00076, valid loss 0.00265
2024-07-22 17:16:07 Training for epoch 40 done, starting evaluation
2024-07-22 17:16:15 Epoch 40 performance:
2024-07-22 17:16:15 metrics/test.rmse:  22.017
2024-07-22 17:16:15 metrics/test.rmse_pcutoff:14.617
2024-07-22 17:16:15 metrics/test.mAP:   12.150
2024-07-22 17:16:15 metrics/test.mAR:   65.859
2024-07-22 17:16:15 metrics/test.mAP_pcutoff:16.543
2024-07-22 17:16:15 metrics/test.mAR_pcutoff:19.102
2024-07-22 17:16:15 Epoch 40/200 (lr=0.0001), train loss 0.00072, valid loss 0.00263
2024-07-22 17:16:23 Training for epoch 41 done, starting evaluation
2024-07-22 17:16:31 Epoch 41 performance:
2024-07-22 17:16:31 metrics/test.rmse:  21.724
2024-07-22 17:16:31 metrics/test.rmse_pcutoff:14.661
2024-07-22 17:16:31 metrics/test.mAP:   12.379
2024-07-22 17:16:31 metrics/test.mAR:   66.289
2024-07-22 17:16:31 metrics/test.mAP_pcutoff:17.031
2024-07-22 17:16:31 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:16:31 Epoch 41/200 (lr=0.0001), train loss 0.00070, valid loss 0.00265
2024-07-22 17:16:40 Training for epoch 42 done, starting evaluation
2024-07-22 17:16:47 Epoch 42 performance:
2024-07-22 17:16:47 metrics/test.rmse:  22.317
2024-07-22 17:16:47 metrics/test.rmse_pcutoff:15.866
2024-07-22 17:16:47 metrics/test.mAP:   12.033
2024-07-22 17:16:47 metrics/test.mAR:   65.938
2024-07-22 17:16:47 metrics/test.mAP_pcutoff:17.903
2024-07-22 17:16:47 metrics/test.mAR_pcutoff:20.742
2024-07-22 17:16:47 Epoch 42/200 (lr=0.0001), train loss 0.00072, valid loss 0.00266
2024-07-22 17:16:56 Training for epoch 43 done, starting evaluation
2024-07-22 17:17:03 Epoch 43 performance:
2024-07-22 17:17:03 metrics/test.rmse:  22.235
2024-07-22 17:17:03 metrics/test.rmse_pcutoff:15.125
2024-07-22 17:17:03 metrics/test.mAP:   12.099
2024-07-22 17:17:03 metrics/test.mAR:   66.094
2024-07-22 17:17:03 metrics/test.mAP_pcutoff:16.739
2024-07-22 17:17:03 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:17:03 Epoch 43/200 (lr=0.0001), train loss 0.00067, valid loss 0.00265
2024-07-22 17:17:12 Training for epoch 44 done, starting evaluation
2024-07-22 17:17:19 Epoch 44 performance:
2024-07-22 17:17:19 metrics/test.rmse:  22.661
2024-07-22 17:17:19 metrics/test.rmse_pcutoff:15.095
2024-07-22 17:17:19 metrics/test.mAP:   12.137
2024-07-22 17:17:19 metrics/test.mAR:   66.055
2024-07-22 17:17:19 metrics/test.mAP_pcutoff:15.537
2024-07-22 17:17:19 metrics/test.mAR_pcutoff:18.672
2024-07-22 17:17:19 Epoch 44/200 (lr=0.0001), train loss 0.00066, valid loss 0.00263
2024-07-22 17:17:27 Training for epoch 45 done, starting evaluation
2024-07-22 17:17:35 Epoch 45 performance:
2024-07-22 17:17:35 metrics/test.rmse:  22.498
2024-07-22 17:17:35 metrics/test.rmse_pcutoff:15.553
2024-07-22 17:17:35 metrics/test.mAP:   12.313
2024-07-22 17:17:35 metrics/test.mAR:   65.742
2024-07-22 17:17:35 metrics/test.mAP_pcutoff:17.443
2024-07-22 17:17:35 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:17:35 Epoch 45/200 (lr=0.0001), train loss 0.00066, valid loss 0.00264
2024-07-22 17:17:43 Training for epoch 46 done, starting evaluation
2024-07-22 17:17:51 Epoch 46 performance:
2024-07-22 17:17:51 metrics/test.rmse:  21.998
2024-07-22 17:17:51 metrics/test.rmse_pcutoff:15.440
2024-07-22 17:17:51 metrics/test.mAP:   11.813
2024-07-22 17:17:51 metrics/test.mAR:   65.430
2024-07-22 17:17:51 metrics/test.mAP_pcutoff:16.694
2024-07-22 17:17:51 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:17:51 Epoch 46/200 (lr=0.0001), train loss 0.00062, valid loss 0.00263
2024-07-22 17:17:59 Training for epoch 47 done, starting evaluation
2024-07-22 17:18:06 Epoch 47 performance:
2024-07-22 17:18:06 metrics/test.rmse:  22.372
2024-07-22 17:18:06 metrics/test.rmse_pcutoff:15.613
2024-07-22 17:18:06 metrics/test.mAP:   11.865
2024-07-22 17:18:06 metrics/test.mAR:   65.352
2024-07-22 17:18:06 metrics/test.mAP_pcutoff:17.849
2024-07-22 17:18:06 metrics/test.mAR_pcutoff:21.016
2024-07-22 17:18:06 Epoch 47/200 (lr=0.0001), train loss 0.00058, valid loss 0.00264
2024-07-22 17:18:15 Training for epoch 48 done, starting evaluation
2024-07-22 17:18:23 Epoch 48 performance:
2024-07-22 17:18:23 metrics/test.rmse:  22.178
2024-07-22 17:18:23 metrics/test.rmse_pcutoff:15.153
2024-07-22 17:18:23 metrics/test.mAP:   11.755
2024-07-22 17:18:23 metrics/test.mAR:   65.391
2024-07-22 17:18:23 metrics/test.mAP_pcutoff:18.091
2024-07-22 17:18:23 metrics/test.mAR_pcutoff:21.406
2024-07-22 17:18:23 Epoch 48/200 (lr=0.0001), train loss 0.00057, valid loss 0.00263
2024-07-22 17:18:32 Training for epoch 49 done, starting evaluation
2024-07-22 17:18:39 Epoch 49 performance:
2024-07-22 17:18:39 metrics/test.rmse:  22.251
2024-07-22 17:18:39 metrics/test.rmse_pcutoff:15.942
2024-07-22 17:18:39 metrics/test.mAP:   11.733
2024-07-22 17:18:39 metrics/test.mAR:   65.508
2024-07-22 17:18:39 metrics/test.mAP_pcutoff:17.130
2024-07-22 17:18:39 metrics/test.mAR_pcutoff:20.156
2024-07-22 17:18:39 Epoch 49/200 (lr=0.0001), train loss 0.00056, valid loss 0.00263
2024-07-22 17:18:47 Training for epoch 50 done, starting evaluation
2024-07-22 17:18:55 Epoch 50 performance:
2024-07-22 17:18:55 metrics/test.rmse:  22.367
2024-07-22 17:18:55 metrics/test.rmse_pcutoff:15.732
2024-07-22 17:18:55 metrics/test.mAP:   12.029
2024-07-22 17:18:55 metrics/test.mAR:   65.625
2024-07-22 17:18:55 metrics/test.mAP_pcutoff:17.701
2024-07-22 17:18:55 metrics/test.mAR_pcutoff:20.469
2024-07-22 17:18:55 Epoch 50/200 (lr=0.0001), train loss 0.00057, valid loss 0.00264
2024-07-22 17:19:03 Training for epoch 51 done, starting evaluation
2024-07-22 17:19:11 Epoch 51 performance:
2024-07-22 17:19:11 metrics/test.rmse:  22.617
2024-07-22 17:19:11 metrics/test.rmse_pcutoff:15.112
2024-07-22 17:19:11 metrics/test.mAP:   12.254
2024-07-22 17:19:11 metrics/test.mAR:   66.016
2024-07-22 17:19:11 metrics/test.mAP_pcutoff:17.192
2024-07-22 17:19:11 metrics/test.mAR_pcutoff:20.195
2024-07-22 17:19:11 Epoch 51/200 (lr=0.0001), train loss 0.00051, valid loss 0.00264
2024-07-22 17:19:19 Training for epoch 52 done, starting evaluation
2024-07-22 17:19:27 Epoch 52 performance:
2024-07-22 17:19:27 metrics/test.rmse:  22.868
2024-07-22 17:19:27 metrics/test.rmse_pcutoff:15.392
2024-07-22 17:19:27 metrics/test.mAP:   11.990
2024-07-22 17:19:27 metrics/test.mAR:   65.391
2024-07-22 17:19:27 metrics/test.mAP_pcutoff:16.153
2024-07-22 17:19:27 metrics/test.mAR_pcutoff:19.141
2024-07-22 17:19:27 Epoch 52/200 (lr=0.0001), train loss 0.00054, valid loss 0.00263
2024-07-22 17:19:36 Training for epoch 53 done, starting evaluation
2024-07-22 17:19:44 Epoch 53 performance:
2024-07-22 17:19:44 metrics/test.rmse:  21.996
2024-07-22 17:19:44 metrics/test.rmse_pcutoff:15.742
2024-07-22 17:19:44 metrics/test.mAP:   12.490
2024-07-22 17:19:44 metrics/test.mAR:   66.328
2024-07-22 17:19:44 metrics/test.mAP_pcutoff:18.379
2024-07-22 17:19:44 metrics/test.mAR_pcutoff:21.445
2024-07-22 17:19:44 Epoch 53/200 (lr=0.0001), train loss 0.00053, valid loss 0.00262
2024-07-22 17:19:53 Training for epoch 54 done, starting evaluation
2024-07-22 17:20:00 Epoch 54 performance:
2024-07-22 17:20:00 metrics/test.rmse:  22.736
2024-07-22 17:20:00 metrics/test.rmse_pcutoff:15.582
2024-07-22 17:20:00 metrics/test.mAP:   11.748
2024-07-22 17:20:00 metrics/test.mAR:   64.961
2024-07-22 17:20:00 metrics/test.mAP_pcutoff:16.122
2024-07-22 17:20:00 metrics/test.mAR_pcutoff:19.023
2024-07-22 17:20:00 Epoch 54/200 (lr=0.0001), train loss 0.00055, valid loss 0.00262
2024-07-22 17:20:08 Training for epoch 55 done, starting evaluation
2024-07-22 17:20:16 Epoch 55 performance:
2024-07-22 17:20:16 metrics/test.rmse:  22.458
2024-07-22 17:20:16 metrics/test.rmse_pcutoff:15.667
2024-07-22 17:20:16 metrics/test.mAP:   11.542
2024-07-22 17:20:16 metrics/test.mAR:   65.273
2024-07-22 17:20:16 metrics/test.mAP_pcutoff:17.380
2024-07-22 17:20:16 metrics/test.mAR_pcutoff:20.781
2024-07-22 17:20:16 Epoch 55/200 (lr=0.0001), train loss 0.00047, valid loss 0.00263
2024-07-22 17:20:24 Training for epoch 56 done, starting evaluation
2024-07-22 17:20:32 Epoch 56 performance:
2024-07-22 17:20:32 metrics/test.rmse:  22.290
2024-07-22 17:20:32 metrics/test.rmse_pcutoff:15.608
2024-07-22 17:20:32 metrics/test.mAP:   11.585
2024-07-22 17:20:32 metrics/test.mAR:   65.547
2024-07-22 17:20:32 metrics/test.mAP_pcutoff:15.909
2024-07-22 17:20:32 metrics/test.mAR_pcutoff:19.297
2024-07-22 17:20:32 Epoch 56/200 (lr=0.0001), train loss 0.00050, valid loss 0.00262
2024-07-22 17:20:40 Training for epoch 57 done, starting evaluation
2024-07-22 17:20:48 Epoch 57 performance:
2024-07-22 17:20:48 metrics/test.rmse:  22.201
2024-07-22 17:20:48 metrics/test.rmse_pcutoff:15.596
2024-07-22 17:20:48 metrics/test.mAP:   11.569
2024-07-22 17:20:48 metrics/test.mAR:   65.664
2024-07-22 17:20:48 metrics/test.mAP_pcutoff:17.558
2024-07-22 17:20:48 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:20:48 Epoch 57/200 (lr=0.0001), train loss 0.00047, valid loss 0.00262
2024-07-22 17:20:56 Training for epoch 58 done, starting evaluation
2024-07-22 17:21:04 Epoch 58 performance:
2024-07-22 17:21:04 metrics/test.rmse:  22.236
2024-07-22 17:21:04 metrics/test.rmse_pcutoff:15.749
2024-07-22 17:21:04 metrics/test.mAP:   12.175
2024-07-22 17:21:04 metrics/test.mAR:   65.820
2024-07-22 17:21:04 metrics/test.mAP_pcutoff:17.639
2024-07-22 17:21:04 metrics/test.mAR_pcutoff:20.234
2024-07-22 17:21:04 Epoch 58/200 (lr=0.0001), train loss 0.00046, valid loss 0.00263
2024-07-22 17:21:12 Training for epoch 59 done, starting evaluation
2024-07-22 17:21:19 Epoch 59 performance:
2024-07-22 17:21:19 metrics/test.rmse:  22.548
2024-07-22 17:21:19 metrics/test.rmse_pcutoff:15.854
2024-07-22 17:21:19 metrics/test.mAP:   11.775
2024-07-22 17:21:19 metrics/test.mAR:   65.391
2024-07-22 17:21:19 metrics/test.mAP_pcutoff:16.930
2024-07-22 17:21:19 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:21:19 Epoch 59/200 (lr=0.0001), train loss 0.00051, valid loss 0.00262
2024-07-22 17:21:28 Training for epoch 60 done, starting evaluation
2024-07-22 17:21:36 Epoch 60 performance:
2024-07-22 17:21:36 metrics/test.rmse:  22.283
2024-07-22 17:21:36 metrics/test.rmse_pcutoff:15.655
2024-07-22 17:21:36 metrics/test.mAP:   12.410
2024-07-22 17:21:36 metrics/test.mAR:   66.523
2024-07-22 17:21:36 metrics/test.mAP_pcutoff:16.629
2024-07-22 17:21:36 metrics/test.mAR_pcutoff:19.531
2024-07-22 17:21:36 Epoch 60/200 (lr=0.0001), train loss 0.00048, valid loss 0.00261
2024-07-22 17:21:44 Training for epoch 61 done, starting evaluation
2024-07-22 17:21:52 Epoch 61 performance:
2024-07-22 17:21:52 metrics/test.rmse:  22.260
2024-07-22 17:21:52 metrics/test.rmse_pcutoff:15.480
2024-07-22 17:21:52 metrics/test.mAP:   12.166
2024-07-22 17:21:52 metrics/test.mAR:   65.664
2024-07-22 17:21:52 metrics/test.mAP_pcutoff:19.288
2024-07-22 17:21:52 metrics/test.mAR_pcutoff:22.227
2024-07-22 17:21:52 Epoch 61/200 (lr=0.0001), train loss 0.00043, valid loss 0.00260
2024-07-22 17:22:01 Training for epoch 62 done, starting evaluation
2024-07-22 17:22:08 Epoch 62 performance:
2024-07-22 17:22:08 metrics/test.rmse:  22.202
2024-07-22 17:22:08 metrics/test.rmse_pcutoff:15.749
2024-07-22 17:22:08 metrics/test.mAP:   11.814
2024-07-22 17:22:08 metrics/test.mAR:   65.586
2024-07-22 17:22:08 metrics/test.mAP_pcutoff:15.712
2024-07-22 17:22:08 metrics/test.mAR_pcutoff:18.828
2024-07-22 17:22:08 Epoch 62/200 (lr=0.0001), train loss 0.00045, valid loss 0.00260
2024-07-22 17:22:16 Training for epoch 63 done, starting evaluation
2024-07-22 17:22:23 Epoch 63 performance:
2024-07-22 17:22:24 metrics/test.rmse:  22.314
2024-07-22 17:22:24 metrics/test.rmse_pcutoff:15.534
2024-07-22 17:22:24 metrics/test.mAP:   11.860
2024-07-22 17:22:24 metrics/test.mAR:   65.156
2024-07-22 17:22:24 metrics/test.mAP_pcutoff:17.090
2024-07-22 17:22:24 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:22:24 Epoch 63/200 (lr=0.0001), train loss 0.00043, valid loss 0.00261
2024-07-22 17:22:32 Training for epoch 64 done, starting evaluation
2024-07-22 17:22:40 Epoch 64 performance:
2024-07-22 17:22:40 metrics/test.rmse:  22.621
2024-07-22 17:22:40 metrics/test.rmse_pcutoff:15.371
2024-07-22 17:22:40 metrics/test.mAP:   11.616
2024-07-22 17:22:40 metrics/test.mAR:   65.312
2024-07-22 17:22:40 metrics/test.mAP_pcutoff:16.914
2024-07-22 17:22:40 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:22:40 Epoch 64/200 (lr=0.0001), train loss 0.00042, valid loss 0.00261
2024-07-22 17:22:48 Training for epoch 65 done, starting evaluation
2024-07-22 17:22:56 Epoch 65 performance:
2024-07-22 17:22:56 metrics/test.rmse:  22.281
2024-07-22 17:22:56 metrics/test.rmse_pcutoff:15.738
2024-07-22 17:22:56 metrics/test.mAP:   12.024
2024-07-22 17:22:56 metrics/test.mAR:   65.586
2024-07-22 17:22:56 metrics/test.mAP_pcutoff:17.090
2024-07-22 17:22:56 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:22:56 Epoch 65/200 (lr=0.0001), train loss 0.00043, valid loss 0.00260
2024-07-22 17:23:04 Training for epoch 66 done, starting evaluation
2024-07-22 17:23:11 Epoch 66 performance:
2024-07-22 17:23:11 metrics/test.rmse:  22.413
2024-07-22 17:23:11 metrics/test.rmse_pcutoff:15.864
2024-07-22 17:23:11 metrics/test.mAP:   11.933
2024-07-22 17:23:11 metrics/test.mAR:   65.547
2024-07-22 17:23:11 metrics/test.mAP_pcutoff:18.301
2024-07-22 17:23:11 metrics/test.mAR_pcutoff:21.094
2024-07-22 17:23:11 Epoch 66/200 (lr=0.0001), train loss 0.00038, valid loss 0.00260
2024-07-22 17:23:20 Training for epoch 67 done, starting evaluation
2024-07-22 17:23:27 Epoch 67 performance:
2024-07-22 17:23:27 metrics/test.rmse:  22.310
2024-07-22 17:23:27 metrics/test.rmse_pcutoff:15.719
2024-07-22 17:23:27 metrics/test.mAP:   12.037
2024-07-22 17:23:27 metrics/test.mAR:   65.703
2024-07-22 17:23:27 metrics/test.mAP_pcutoff:17.490
2024-07-22 17:23:27 metrics/test.mAR_pcutoff:20.312
2024-07-22 17:23:27 Epoch 67/200 (lr=0.0001), train loss 0.00042, valid loss 0.00260
2024-07-22 17:23:36 Training for epoch 68 done, starting evaluation
2024-07-22 17:23:43 Epoch 68 performance:
2024-07-22 17:23:43 metrics/test.rmse:  22.110
2024-07-22 17:23:43 metrics/test.rmse_pcutoff:15.587
2024-07-22 17:23:43 metrics/test.mAP:   12.062
2024-07-22 17:23:43 metrics/test.mAR:   66.172
2024-07-22 17:23:43 metrics/test.mAP_pcutoff:17.891
2024-07-22 17:23:43 metrics/test.mAR_pcutoff:20.820
2024-07-22 17:23:43 Epoch 68/200 (lr=0.0001), train loss 0.00042, valid loss 0.00260
2024-07-22 17:23:52 Training for epoch 69 done, starting evaluation
2024-07-22 17:23:59 Epoch 69 performance:
2024-07-22 17:23:59 metrics/test.rmse:  22.329
2024-07-22 17:23:59 metrics/test.rmse_pcutoff:15.797
2024-07-22 17:23:59 metrics/test.mAP:   12.536
2024-07-22 17:23:59 metrics/test.mAR:   66.250
2024-07-22 17:23:59 metrics/test.mAP_pcutoff:18.097
2024-07-22 17:23:59 metrics/test.mAR_pcutoff:20.977
2024-07-22 17:23:59 Epoch 69/200 (lr=0.0001), train loss 0.00039, valid loss 0.00260
2024-07-22 17:24:08 Training for epoch 70 done, starting evaluation
2024-07-22 17:24:16 Epoch 70 performance:
2024-07-22 17:24:16 metrics/test.rmse:  22.252
2024-07-22 17:24:16 metrics/test.rmse_pcutoff:15.500
2024-07-22 17:24:16 metrics/test.mAP:   12.404
2024-07-22 17:24:16 metrics/test.mAR:   66.094
2024-07-22 17:24:16 metrics/test.mAP_pcutoff:16.251
2024-07-22 17:24:16 metrics/test.mAR_pcutoff:18.633
2024-07-22 17:24:16 Epoch 70/200 (lr=0.0001), train loss 0.00041, valid loss 0.00258
2024-07-22 17:24:24 Training for epoch 71 done, starting evaluation
2024-07-22 17:24:32 Epoch 71 performance:
2024-07-22 17:24:32 metrics/test.rmse:  22.509
2024-07-22 17:24:32 metrics/test.rmse_pcutoff:15.380
2024-07-22 17:24:32 metrics/test.mAP:   12.340
2024-07-22 17:24:32 metrics/test.mAR:   66.133
2024-07-22 17:24:32 metrics/test.mAP_pcutoff:17.996
2024-07-22 17:24:32 metrics/test.mAR_pcutoff:20.586
2024-07-22 17:24:32 Epoch 71/200 (lr=0.0001), train loss 0.00039, valid loss 0.00261
2024-07-22 17:24:40 Training for epoch 72 done, starting evaluation
2024-07-22 17:24:48 Epoch 72 performance:
2024-07-22 17:24:48 metrics/test.rmse:  22.465
2024-07-22 17:24:48 metrics/test.rmse_pcutoff:15.894
2024-07-22 17:24:48 metrics/test.mAP:   12.105
2024-07-22 17:24:48 metrics/test.mAR:   65.820
2024-07-22 17:24:48 metrics/test.mAP_pcutoff:17.905
2024-07-22 17:24:48 metrics/test.mAR_pcutoff:20.625
2024-07-22 17:24:48 Epoch 72/200 (lr=0.0001), train loss 0.00039, valid loss 0.00262
2024-07-22 17:24:56 Training for epoch 73 done, starting evaluation
2024-07-22 17:25:04 Epoch 73 performance:
2024-07-22 17:25:04 metrics/test.rmse:  22.116
2024-07-22 17:25:04 metrics/test.rmse_pcutoff:15.394
2024-07-22 17:25:04 metrics/test.mAP:   11.864
2024-07-22 17:25:04 metrics/test.mAR:   65.625
2024-07-22 17:25:04 metrics/test.mAP_pcutoff:18.850
2024-07-22 17:25:04 metrics/test.mAR_pcutoff:21.172
2024-07-22 17:25:04 Epoch 73/200 (lr=0.0001), train loss 0.00039, valid loss 0.00260
2024-07-22 17:25:12 Training for epoch 74 done, starting evaluation
2024-07-22 17:25:20 Epoch 74 performance:
2024-07-22 17:25:20 metrics/test.rmse:  22.436
2024-07-22 17:25:20 metrics/test.rmse_pcutoff:15.768
2024-07-22 17:25:20 metrics/test.mAP:   11.947
2024-07-22 17:25:20 metrics/test.mAR:   65.742
2024-07-22 17:25:20 metrics/test.mAP_pcutoff:17.006
2024-07-22 17:25:20 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:25:20 Epoch 74/200 (lr=0.0001), train loss 0.00037, valid loss 0.00259
2024-07-22 17:25:29 Training for epoch 75 done, starting evaluation
2024-07-22 17:25:36 Epoch 75 performance:
2024-07-22 17:25:36 metrics/test.rmse:  22.189
2024-07-22 17:25:36 metrics/test.rmse_pcutoff:14.900
2024-07-22 17:25:36 metrics/test.mAP:   11.643
2024-07-22 17:25:36 metrics/test.mAR:   65.391
2024-07-22 17:25:36 metrics/test.mAP_pcutoff:17.093
2024-07-22 17:25:36 metrics/test.mAR_pcutoff:19.648
2024-07-22 17:25:36 Epoch 75/200 (lr=0.0001), train loss 0.00034, valid loss 0.00258
2024-07-22 17:25:45 Training for epoch 76 done, starting evaluation
2024-07-22 17:25:53 Epoch 76 performance:
2024-07-22 17:25:53 metrics/test.rmse:  22.448
2024-07-22 17:25:53 metrics/test.rmse_pcutoff:15.413
2024-07-22 17:25:53 metrics/test.mAP:   12.200
2024-07-22 17:25:53 metrics/test.mAR:   65.742
2024-07-22 17:25:53 metrics/test.mAP_pcutoff:17.051
2024-07-22 17:25:53 metrics/test.mAR_pcutoff:19.219
2024-07-22 17:25:53 Epoch 76/200 (lr=0.0001), train loss 0.00034, valid loss 0.00259
2024-07-22 17:26:01 Training for epoch 77 done, starting evaluation
2024-07-22 17:26:08 Epoch 77 performance:
2024-07-22 17:26:08 metrics/test.rmse:  21.963
2024-07-22 17:26:08 metrics/test.rmse_pcutoff:15.469
2024-07-22 17:26:08 metrics/test.mAP:   12.169
2024-07-22 17:26:08 metrics/test.mAR:   66.172
2024-07-22 17:26:08 metrics/test.mAP_pcutoff:16.972
2024-07-22 17:26:08 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:26:08 Epoch 77/200 (lr=0.0001), train loss 0.00031, valid loss 0.00259
2024-07-22 17:26:17 Training for epoch 78 done, starting evaluation
2024-07-22 17:26:24 Epoch 78 performance:
2024-07-22 17:26:24 metrics/test.rmse:  21.822
2024-07-22 17:26:24 metrics/test.rmse_pcutoff:15.456
2024-07-22 17:26:24 metrics/test.mAP:   12.209
2024-07-22 17:26:24 metrics/test.mAR:   66.289
2024-07-22 17:26:24 metrics/test.mAP_pcutoff:16.375
2024-07-22 17:26:24 metrics/test.mAR_pcutoff:18.828
2024-07-22 17:26:24 Epoch 78/200 (lr=0.0001), train loss 0.00032, valid loss 0.00256
2024-07-22 17:26:32 Training for epoch 79 done, starting evaluation
2024-07-22 17:26:39 Epoch 79 performance:
2024-07-22 17:26:39 metrics/test.rmse:  21.940
2024-07-22 17:26:39 metrics/test.rmse_pcutoff:15.460
2024-07-22 17:26:39 metrics/test.mAP:   11.657
2024-07-22 17:26:39 metrics/test.mAR:   65.508
2024-07-22 17:26:39 metrics/test.mAP_pcutoff:18.554
2024-07-22 17:26:39 metrics/test.mAR_pcutoff:21.328
2024-07-22 17:26:40 Epoch 79/200 (lr=0.0001), train loss 0.00034, valid loss 0.00257
2024-07-22 17:26:47 Training for epoch 80 done, starting evaluation
2024-07-22 17:26:55 Epoch 80 performance:
2024-07-22 17:26:55 metrics/test.rmse:  22.320
2024-07-22 17:26:55 metrics/test.rmse_pcutoff:15.664
2024-07-22 17:26:55 metrics/test.mAP:   12.243
2024-07-22 17:26:55 metrics/test.mAR:   66.133
2024-07-22 17:26:55 metrics/test.mAP_pcutoff:16.324
2024-07-22 17:26:55 metrics/test.mAR_pcutoff:19.258
2024-07-22 17:26:55 Epoch 80/200 (lr=0.0001), train loss 0.00031, valid loss 0.00256
2024-07-22 17:27:04 Training for epoch 81 done, starting evaluation
2024-07-22 17:27:11 Epoch 81 performance:
2024-07-22 17:27:11 metrics/test.rmse:  22.348
2024-07-22 17:27:11 metrics/test.rmse_pcutoff:15.762
2024-07-22 17:27:11 metrics/test.mAP:   11.775
2024-07-22 17:27:11 metrics/test.mAR:   65.547
2024-07-22 17:27:11 metrics/test.mAP_pcutoff:17.421
2024-07-22 17:27:11 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:27:11 Epoch 81/200 (lr=0.0001), train loss 0.00030, valid loss 0.00256
2024-07-22 17:27:20 Training for epoch 82 done, starting evaluation
2024-07-22 17:27:28 Epoch 82 performance:
2024-07-22 17:27:28 metrics/test.rmse:  22.208
2024-07-22 17:27:28 metrics/test.rmse_pcutoff:15.500
2024-07-22 17:27:28 metrics/test.mAP:   11.873
2024-07-22 17:27:28 metrics/test.mAR:   66.055
2024-07-22 17:27:28 metrics/test.mAP_pcutoff:18.661
2024-07-22 17:27:28 metrics/test.mAR_pcutoff:21.367
2024-07-22 17:27:28 Epoch 82/200 (lr=0.0001), train loss 0.00030, valid loss 0.00257
2024-07-22 17:27:35 Training for epoch 83 done, starting evaluation
2024-07-22 17:27:42 Epoch 83 performance:
2024-07-22 17:27:42 metrics/test.rmse:  22.380
2024-07-22 17:27:42 metrics/test.rmse_pcutoff:15.797
2024-07-22 17:27:42 metrics/test.mAP:   11.513
2024-07-22 17:27:42 metrics/test.mAR:   65.703
2024-07-22 17:27:42 metrics/test.mAP_pcutoff:16.691
2024-07-22 17:27:42 metrics/test.mAR_pcutoff:19.219
2024-07-22 17:27:42 Epoch 83/200 (lr=0.0001), train loss 0.00032, valid loss 0.00257
2024-07-22 17:27:51 Training for epoch 84 done, starting evaluation
2024-07-22 17:27:58 Epoch 84 performance:
2024-07-22 17:27:58 metrics/test.rmse:  22.230
2024-07-22 17:27:58 metrics/test.rmse_pcutoff:15.597
2024-07-22 17:27:58 metrics/test.mAP:   11.766
2024-07-22 17:27:58 metrics/test.mAR:   65.664
2024-07-22 17:27:58 metrics/test.mAP_pcutoff:16.532
2024-07-22 17:27:58 metrics/test.mAR_pcutoff:19.570
2024-07-22 17:27:58 Epoch 84/200 (lr=0.0001), train loss 0.00030, valid loss 0.00258
2024-07-22 17:28:06 Training for epoch 85 done, starting evaluation
2024-07-22 17:28:14 Epoch 85 performance:
2024-07-22 17:28:14 metrics/test.rmse:  22.183
2024-07-22 17:28:14 metrics/test.rmse_pcutoff:15.139
2024-07-22 17:28:14 metrics/test.mAP:   12.138
2024-07-22 17:28:14 metrics/test.mAR:   65.742
2024-07-22 17:28:14 metrics/test.mAP_pcutoff:16.771
2024-07-22 17:28:14 metrics/test.mAR_pcutoff:19.453
2024-07-22 17:28:14 Epoch 85/200 (lr=0.0001), train loss 0.00030, valid loss 0.00258
2024-07-22 17:28:23 Training for epoch 86 done, starting evaluation
2024-07-22 17:28:30 Epoch 86 performance:
2024-07-22 17:28:30 metrics/test.rmse:  22.308
2024-07-22 17:28:30 metrics/test.rmse_pcutoff:15.566
2024-07-22 17:28:30 metrics/test.mAP:   11.902
2024-07-22 17:28:30 metrics/test.mAR:   65.664
2024-07-22 17:28:30 metrics/test.mAP_pcutoff:17.563
2024-07-22 17:28:30 metrics/test.mAR_pcutoff:19.961
2024-07-22 17:28:30 Epoch 86/200 (lr=0.0001), train loss 0.00029, valid loss 0.00257
2024-07-22 17:28:39 Training for epoch 87 done, starting evaluation
2024-07-22 17:28:46 Epoch 87 performance:
2024-07-22 17:28:46 metrics/test.rmse:  22.202
2024-07-22 17:28:46 metrics/test.rmse_pcutoff:15.251
2024-07-22 17:28:46 metrics/test.mAP:   11.591
2024-07-22 17:28:46 metrics/test.mAR:   65.430
2024-07-22 17:28:46 metrics/test.mAP_pcutoff:16.999
2024-07-22 17:28:46 metrics/test.mAR_pcutoff:19.570
2024-07-22 17:28:46 Epoch 87/200 (lr=0.0001), train loss 0.00027, valid loss 0.00257
2024-07-22 17:28:55 Training for epoch 88 done, starting evaluation
2024-07-22 17:29:02 Epoch 88 performance:
2024-07-22 17:29:02 metrics/test.rmse:  22.487
2024-07-22 17:29:02 metrics/test.rmse_pcutoff:15.409
2024-07-22 17:29:02 metrics/test.mAP:   11.729
2024-07-22 17:29:02 metrics/test.mAR:   65.508
2024-07-22 17:29:02 metrics/test.mAP_pcutoff:17.332
2024-07-22 17:29:02 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:29:02 Epoch 88/200 (lr=0.0001), train loss 0.00029, valid loss 0.00257
2024-07-22 17:29:11 Training for epoch 89 done, starting evaluation
2024-07-22 17:29:18 Epoch 89 performance:
2024-07-22 17:29:18 metrics/test.rmse:  22.279
2024-07-22 17:29:18 metrics/test.rmse_pcutoff:15.660
2024-07-22 17:29:18 metrics/test.mAP:   12.098
2024-07-22 17:29:18 metrics/test.mAR:   65.859
2024-07-22 17:29:18 metrics/test.mAP_pcutoff:15.716
2024-07-22 17:29:18 metrics/test.mAR_pcutoff:18.633
2024-07-22 17:29:18 Epoch 89/200 (lr=0.0001), train loss 0.00030, valid loss 0.00257
2024-07-22 17:29:26 Training for epoch 90 done, starting evaluation
2024-07-22 17:29:34 Epoch 90 performance:
2024-07-22 17:29:34 metrics/test.rmse:  22.463
2024-07-22 17:29:34 metrics/test.rmse_pcutoff:15.416
2024-07-22 17:29:34 metrics/test.mAP:   11.764
2024-07-22 17:29:34 metrics/test.mAR:   65.703
2024-07-22 17:29:34 metrics/test.mAP_pcutoff:16.943
2024-07-22 17:29:34 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:29:34 Epoch 90/200 (lr=0.0001), train loss 0.00026, valid loss 0.00255
2024-07-22 17:29:42 Training for epoch 91 done, starting evaluation
2024-07-22 17:29:49 Epoch 91 performance:
2024-07-22 17:29:49 metrics/test.rmse:  22.253
2024-07-22 17:29:49 metrics/test.rmse_pcutoff:15.783
2024-07-22 17:29:49 metrics/test.mAP:   11.845
2024-07-22 17:29:49 metrics/test.mAR:   65.664
2024-07-22 17:29:49 metrics/test.mAP_pcutoff:18.024
2024-07-22 17:29:49 metrics/test.mAR_pcutoff:20.312
2024-07-22 17:29:49 Epoch 91/200 (lr=0.0001), train loss 0.00027, valid loss 0.00258
2024-07-22 17:29:57 Training for epoch 92 done, starting evaluation
2024-07-22 17:30:05 Epoch 92 performance:
2024-07-22 17:30:05 metrics/test.rmse:  22.285
2024-07-22 17:30:05 metrics/test.rmse_pcutoff:15.497
2024-07-22 17:30:05 metrics/test.mAP:   11.922
2024-07-22 17:30:05 metrics/test.mAR:   66.133
2024-07-22 17:30:05 metrics/test.mAP_pcutoff:16.945
2024-07-22 17:30:05 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:30:05 Epoch 92/200 (lr=0.0001), train loss 0.00025, valid loss 0.00257
2024-07-22 17:30:13 Training for epoch 93 done, starting evaluation
2024-07-22 17:30:20 Epoch 93 performance:
2024-07-22 17:30:20 metrics/test.rmse:  22.406
2024-07-22 17:30:20 metrics/test.rmse_pcutoff:15.501
2024-07-22 17:30:20 metrics/test.mAP:   11.784
2024-07-22 17:30:20 metrics/test.mAR:   65.859
2024-07-22 17:30:20 metrics/test.mAP_pcutoff:16.353
2024-07-22 17:30:20 metrics/test.mAR_pcutoff:18.906
2024-07-22 17:30:20 Epoch 93/200 (lr=0.0001), train loss 0.00026, valid loss 0.00257
2024-07-22 17:30:29 Training for epoch 94 done, starting evaluation
2024-07-22 17:30:36 Epoch 94 performance:
2024-07-22 17:30:36 metrics/test.rmse:  22.629
2024-07-22 17:30:36 metrics/test.rmse_pcutoff:15.691
2024-07-22 17:30:36 metrics/test.mAP:   12.303
2024-07-22 17:30:36 metrics/test.mAR:   65.664
2024-07-22 17:30:36 metrics/test.mAP_pcutoff:16.750
2024-07-22 17:30:36 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:30:36 Epoch 94/200 (lr=0.0001), train loss 0.00024, valid loss 0.00256
2024-07-22 17:30:45 Training for epoch 95 done, starting evaluation
2024-07-22 17:30:53 Epoch 95 performance:
2024-07-22 17:30:53 metrics/test.rmse:  22.066
2024-07-22 17:30:53 metrics/test.rmse_pcutoff:15.820
2024-07-22 17:30:53 metrics/test.mAP:   12.007
2024-07-22 17:30:53 metrics/test.mAR:   66.016
2024-07-22 17:30:53 metrics/test.mAP_pcutoff:17.704
2024-07-22 17:30:53 metrics/test.mAR_pcutoff:20.195
2024-07-22 17:30:53 Epoch 95/200 (lr=0.0001), train loss 0.00026, valid loss 0.00256
2024-07-22 17:31:01 Training for epoch 96 done, starting evaluation
2024-07-22 17:31:08 Epoch 96 performance:
2024-07-22 17:31:08 metrics/test.rmse:  22.396
2024-07-22 17:31:08 metrics/test.rmse_pcutoff:15.497
2024-07-22 17:31:08 metrics/test.mAP:   12.064
2024-07-22 17:31:08 metrics/test.mAR:   66.055
2024-07-22 17:31:08 metrics/test.mAP_pcutoff:18.609
2024-07-22 17:31:08 metrics/test.mAR_pcutoff:21.094
2024-07-22 17:31:08 Epoch 96/200 (lr=0.0001), train loss 0.00025, valid loss 0.00255
2024-07-22 17:31:17 Training for epoch 97 done, starting evaluation
2024-07-22 17:31:25 Epoch 97 performance:
2024-07-22 17:31:25 metrics/test.rmse:  22.092
2024-07-22 17:31:25 metrics/test.rmse_pcutoff:15.527
2024-07-22 17:31:25 metrics/test.mAP:   12.127
2024-07-22 17:31:25 metrics/test.mAR:   66.172
2024-07-22 17:31:25 metrics/test.mAP_pcutoff:17.292
2024-07-22 17:31:25 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:31:25 Epoch 97/200 (lr=0.0001), train loss 0.00025, valid loss 0.00255
2024-07-22 17:31:34 Training for epoch 98 done, starting evaluation
2024-07-22 17:31:41 Epoch 98 performance:
2024-07-22 17:31:41 metrics/test.rmse:  22.569
2024-07-22 17:31:41 metrics/test.rmse_pcutoff:15.555
2024-07-22 17:31:41 metrics/test.mAP:   11.654
2024-07-22 17:31:41 metrics/test.mAR:   65.508
2024-07-22 17:31:41 metrics/test.mAP_pcutoff:17.005
2024-07-22 17:31:41 metrics/test.mAR_pcutoff:19.531
2024-07-22 17:31:41 Epoch 98/200 (lr=0.0001), train loss 0.00025, valid loss 0.00256
2024-07-22 17:31:50 Training for epoch 99 done, starting evaluation
2024-07-22 17:31:58 Epoch 99 performance:
2024-07-22 17:31:58 metrics/test.rmse:  22.363
2024-07-22 17:31:58 metrics/test.rmse_pcutoff:15.254
2024-07-22 17:31:58 metrics/test.mAP:   11.717
2024-07-22 17:31:58 metrics/test.mAR:   66.055
2024-07-22 17:31:58 metrics/test.mAP_pcutoff:16.800
2024-07-22 17:31:58 metrics/test.mAR_pcutoff:19.062
2024-07-22 17:31:58 Epoch 99/200 (lr=0.0001), train loss 0.00027, valid loss 0.00255
2024-07-22 17:32:07 Training for epoch 100 done, starting evaluation
2024-07-22 17:32:14 Epoch 100 performance:
2024-07-22 17:32:14 metrics/test.rmse:  22.648
2024-07-22 17:32:14 metrics/test.rmse_pcutoff:15.264
2024-07-22 17:32:14 metrics/test.mAP:   11.521
2024-07-22 17:32:14 metrics/test.mAR:   65.234
2024-07-22 17:32:14 metrics/test.mAP_pcutoff:15.158
2024-07-22 17:32:14 metrics/test.mAR_pcutoff:18.008
2024-07-22 17:32:14 Epoch 100/200 (lr=0.0001), train loss 0.00024, valid loss 0.00255
2024-07-22 17:32:23 Training for epoch 101 done, starting evaluation
2024-07-22 17:32:30 Epoch 101 performance:
2024-07-22 17:32:30 metrics/test.rmse:  22.211
2024-07-22 17:32:30 metrics/test.rmse_pcutoff:15.386
2024-07-22 17:32:30 metrics/test.mAP:   11.713
2024-07-22 17:32:30 metrics/test.mAR:   65.938
2024-07-22 17:32:30 metrics/test.mAP_pcutoff:18.433
2024-07-22 17:32:30 metrics/test.mAR_pcutoff:21.016
2024-07-22 17:32:30 Epoch 101/200 (lr=0.0001), train loss 0.00025, valid loss 0.00254
2024-07-22 17:32:39 Training for epoch 102 done, starting evaluation
2024-07-22 17:32:46 Epoch 102 performance:
2024-07-22 17:32:46 metrics/test.rmse:  22.140
2024-07-22 17:32:46 metrics/test.rmse_pcutoff:15.500
2024-07-22 17:32:46 metrics/test.mAP:   12.153
2024-07-22 17:32:46 metrics/test.mAR:   66.133
2024-07-22 17:32:46 metrics/test.mAP_pcutoff:17.668
2024-07-22 17:32:46 metrics/test.mAR_pcutoff:20.195
2024-07-22 17:32:46 Epoch 102/200 (lr=0.0001), train loss 0.00025, valid loss 0.00255
2024-07-22 17:32:55 Training for epoch 103 done, starting evaluation
2024-07-22 17:33:02 Epoch 103 performance:
2024-07-22 17:33:02 metrics/test.rmse:  22.260
2024-07-22 17:33:02 metrics/test.rmse_pcutoff:15.523
2024-07-22 17:33:02 metrics/test.mAP:   11.924
2024-07-22 17:33:02 metrics/test.mAR:   65.820
2024-07-22 17:33:02 metrics/test.mAP_pcutoff:17.310
2024-07-22 17:33:02 metrics/test.mAR_pcutoff:20.195
2024-07-22 17:33:02 Epoch 103/200 (lr=0.0001), train loss 0.00025, valid loss 0.00254
2024-07-22 17:33:11 Training for epoch 104 done, starting evaluation
2024-07-22 17:33:18 Epoch 104 performance:
2024-07-22 17:33:18 metrics/test.rmse:  22.149
2024-07-22 17:33:18 metrics/test.rmse_pcutoff:15.188
2024-07-22 17:33:18 metrics/test.mAP:   11.672
2024-07-22 17:33:18 metrics/test.mAR:   65.430
2024-07-22 17:33:18 metrics/test.mAP_pcutoff:16.909
2024-07-22 17:33:18 metrics/test.mAR_pcutoff:19.570
2024-07-22 17:33:18 Epoch 104/200 (lr=0.0001), train loss 0.00025, valid loss 0.00253
2024-07-22 17:33:27 Training for epoch 105 done, starting evaluation
2024-07-22 17:33:34 Epoch 105 performance:
2024-07-22 17:33:34 metrics/test.rmse:  22.241
2024-07-22 17:33:34 metrics/test.rmse_pcutoff:15.746
2024-07-22 17:33:34 metrics/test.mAP:   11.821
2024-07-22 17:33:34 metrics/test.mAR:   65.781
2024-07-22 17:33:34 metrics/test.mAP_pcutoff:16.987
2024-07-22 17:33:34 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:33:34 Epoch 105/200 (lr=0.0001), train loss 0.00023, valid loss 0.00253
2024-07-22 17:33:43 Training for epoch 106 done, starting evaluation
2024-07-22 17:33:50 Epoch 106 performance:
2024-07-22 17:33:50 metrics/test.rmse:  22.208
2024-07-22 17:33:50 metrics/test.rmse_pcutoff:15.203
2024-07-22 17:33:50 metrics/test.mAP:   11.785
2024-07-22 17:33:50 metrics/test.mAR:   65.625
2024-07-22 17:33:50 metrics/test.mAP_pcutoff:16.163
2024-07-22 17:33:50 metrics/test.mAR_pcutoff:18.789
2024-07-22 17:33:50 Epoch 106/200 (lr=0.0001), train loss 0.00023, valid loss 0.00253
2024-07-22 17:33:59 Training for epoch 107 done, starting evaluation
2024-07-22 17:34:06 Epoch 107 performance:
2024-07-22 17:34:06 metrics/test.rmse:  22.168
2024-07-22 17:34:06 metrics/test.rmse_pcutoff:15.975
2024-07-22 17:34:06 metrics/test.mAP:   11.657
2024-07-22 17:34:06 metrics/test.mAR:   65.625
2024-07-22 17:34:06 metrics/test.mAP_pcutoff:17.504
2024-07-22 17:34:06 metrics/test.mAR_pcutoff:20.391
2024-07-22 17:34:06 Epoch 107/200 (lr=0.0001), train loss 0.00023, valid loss 0.00255
2024-07-22 17:34:15 Training for epoch 108 done, starting evaluation
2024-07-22 17:34:22 Epoch 108 performance:
2024-07-22 17:34:22 metrics/test.rmse:  22.300
2024-07-22 17:34:22 metrics/test.rmse_pcutoff:15.978
2024-07-22 17:34:22 metrics/test.mAP:   11.676
2024-07-22 17:34:22 metrics/test.mAR:   65.430
2024-07-22 17:34:22 metrics/test.mAP_pcutoff:19.072
2024-07-22 17:34:22 metrics/test.mAR_pcutoff:21.484
2024-07-22 17:34:22 Epoch 108/200 (lr=0.0001), train loss 0.00023, valid loss 0.00254
2024-07-22 17:34:31 Training for epoch 109 done, starting evaluation
2024-07-22 17:34:38 Epoch 109 performance:
2024-07-22 17:34:38 metrics/test.rmse:  22.374
2024-07-22 17:34:38 metrics/test.rmse_pcutoff:15.686
2024-07-22 17:34:38 metrics/test.mAP:   12.125
2024-07-22 17:34:38 metrics/test.mAR:   65.977
2024-07-22 17:34:38 metrics/test.mAP_pcutoff:16.348
2024-07-22 17:34:38 metrics/test.mAR_pcutoff:18.906
2024-07-22 17:34:38 Epoch 109/200 (lr=0.0001), train loss 0.00023, valid loss 0.00254
2024-07-22 17:34:47 Training for epoch 110 done, starting evaluation
2024-07-22 17:34:54 Epoch 110 performance:
2024-07-22 17:34:54 metrics/test.rmse:  21.980
2024-07-22 17:34:54 metrics/test.rmse_pcutoff:15.327
2024-07-22 17:34:54 metrics/test.mAP:   11.801
2024-07-22 17:34:54 metrics/test.mAR:   66.094
2024-07-22 17:34:54 metrics/test.mAP_pcutoff:18.065
2024-07-22 17:34:54 metrics/test.mAR_pcutoff:20.586
2024-07-22 17:34:54 Epoch 110/200 (lr=0.0001), train loss 0.00023, valid loss 0.00254
2024-07-22 17:35:03 Training for epoch 111 done, starting evaluation
2024-07-22 17:35:11 Epoch 111 performance:
2024-07-22 17:35:11 metrics/test.rmse:  22.419
2024-07-22 17:35:11 metrics/test.rmse_pcutoff:15.362
2024-07-22 17:35:11 metrics/test.mAP:   12.277
2024-07-22 17:35:11 metrics/test.mAR:   65.820
2024-07-22 17:35:11 metrics/test.mAP_pcutoff:16.810
2024-07-22 17:35:11 metrics/test.mAR_pcutoff:19.023
2024-07-22 17:35:11 Epoch 111/200 (lr=0.0001), train loss 0.00022, valid loss 0.00254
2024-07-22 17:35:20 Training for epoch 112 done, starting evaluation
2024-07-22 17:35:27 Epoch 112 performance:
2024-07-22 17:35:27 metrics/test.rmse:  22.200
2024-07-22 17:35:27 metrics/test.rmse_pcutoff:15.716
2024-07-22 17:35:27 metrics/test.mAP:   11.775
2024-07-22 17:35:27 metrics/test.mAR:   65.391
2024-07-22 17:35:27 metrics/test.mAP_pcutoff:17.781
2024-07-22 17:35:27 metrics/test.mAR_pcutoff:20.703
2024-07-22 17:35:27 Epoch 112/200 (lr=0.0001), train loss 0.00021, valid loss 0.00253
2024-07-22 17:35:35 Training for epoch 113 done, starting evaluation
2024-07-22 17:35:43 Epoch 113 performance:
2024-07-22 17:35:43 metrics/test.rmse:  22.330
2024-07-22 17:35:43 metrics/test.rmse_pcutoff:15.841
2024-07-22 17:35:43 metrics/test.mAP:   11.775
2024-07-22 17:35:43 metrics/test.mAR:   65.781
2024-07-22 17:35:43 metrics/test.mAP_pcutoff:16.934
2024-07-22 17:35:43 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:35:43 Epoch 113/200 (lr=0.0001), train loss 0.00023, valid loss 0.00254
2024-07-22 17:35:51 Training for epoch 114 done, starting evaluation
2024-07-22 17:35:59 Epoch 114 performance:
2024-07-22 17:35:59 metrics/test.rmse:  22.369
2024-07-22 17:35:59 metrics/test.rmse_pcutoff:16.003
2024-07-22 17:35:59 metrics/test.mAP:   11.311
2024-07-22 17:35:59 metrics/test.mAR:   65.352
2024-07-22 17:35:59 metrics/test.mAP_pcutoff:17.847
2024-07-22 17:35:59 metrics/test.mAR_pcutoff:20.430
2024-07-22 17:35:59 Epoch 114/200 (lr=0.0001), train loss 0.00021, valid loss 0.00254
2024-07-22 17:36:07 Training for epoch 115 done, starting evaluation
2024-07-22 17:36:14 Epoch 115 performance:
2024-07-22 17:36:14 metrics/test.rmse:  22.238
2024-07-22 17:36:14 metrics/test.rmse_pcutoff:15.712
2024-07-22 17:36:14 metrics/test.mAP:   11.562
2024-07-22 17:36:14 metrics/test.mAR:   65.586
2024-07-22 17:36:14 metrics/test.mAP_pcutoff:19.186
2024-07-22 17:36:14 metrics/test.mAR_pcutoff:21.719
2024-07-22 17:36:14 Epoch 115/200 (lr=0.0001), train loss 0.00023, valid loss 0.00255
2024-07-22 17:36:23 Training for epoch 116 done, starting evaluation
2024-07-22 17:36:30 Epoch 116 performance:
2024-07-22 17:36:30 metrics/test.rmse:  22.257
2024-07-22 17:36:30 metrics/test.rmse_pcutoff:15.653
2024-07-22 17:36:30 metrics/test.mAP:   12.182
2024-07-22 17:36:30 metrics/test.mAR:   65.938
2024-07-22 17:36:30 metrics/test.mAP_pcutoff:17.026
2024-07-22 17:36:30 metrics/test.mAR_pcutoff:19.375
2024-07-22 17:36:30 Epoch 116/200 (lr=0.0001), train loss 0.00022, valid loss 0.00254
2024-07-22 17:36:38 Training for epoch 117 done, starting evaluation
2024-07-22 17:36:45 Epoch 117 performance:
2024-07-22 17:36:45 metrics/test.rmse:  22.551
2024-07-22 17:36:45 metrics/test.rmse_pcutoff:15.127
2024-07-22 17:36:45 metrics/test.mAP:   11.890
2024-07-22 17:36:45 metrics/test.mAR:   65.859
2024-07-22 17:36:45 metrics/test.mAP_pcutoff:16.721
2024-07-22 17:36:45 metrics/test.mAR_pcutoff:19.062
2024-07-22 17:36:45 Epoch 117/200 (lr=0.0001), train loss 0.00025, valid loss 0.00256
2024-07-22 17:36:54 Training for epoch 118 done, starting evaluation
2024-07-22 17:37:01 Epoch 118 performance:
2024-07-22 17:37:01 metrics/test.rmse:  22.153
2024-07-22 17:37:01 metrics/test.rmse_pcutoff:15.677
2024-07-22 17:37:01 metrics/test.mAP:   11.964
2024-07-22 17:37:01 metrics/test.mAR:   65.625
2024-07-22 17:37:01 metrics/test.mAP_pcutoff:16.487
2024-07-22 17:37:01 metrics/test.mAR_pcutoff:18.672
2024-07-22 17:37:01 Epoch 118/200 (lr=0.0001), train loss 0.00021, valid loss 0.00256
2024-07-22 17:37:10 Training for epoch 119 done, starting evaluation
2024-07-22 17:37:17 Epoch 119 performance:
2024-07-22 17:37:17 metrics/test.rmse:  22.263
2024-07-22 17:37:17 metrics/test.rmse_pcutoff:15.618
2024-07-22 17:37:17 metrics/test.mAP:   11.625
2024-07-22 17:37:17 metrics/test.mAR:   65.117
2024-07-22 17:37:17 metrics/test.mAP_pcutoff:18.899
2024-07-22 17:37:17 metrics/test.mAR_pcutoff:21.484
2024-07-22 17:37:18 Epoch 119/200 (lr=0.0001), train loss 0.00020, valid loss 0.00254
2024-07-22 17:37:26 Training for epoch 120 done, starting evaluation
2024-07-22 17:37:33 Epoch 120 performance:
2024-07-22 17:37:33 metrics/test.rmse:  22.507
2024-07-22 17:37:33 metrics/test.rmse_pcutoff:15.627
2024-07-22 17:37:33 metrics/test.mAP:   11.846
2024-07-22 17:37:33 metrics/test.mAR:   65.273
2024-07-22 17:37:33 metrics/test.mAP_pcutoff:17.715
2024-07-22 17:37:33 metrics/test.mAR_pcutoff:20.078
2024-07-22 17:37:33 Epoch 120/200 (lr=0.0001), train loss 0.00020, valid loss 0.00253
2024-07-22 17:37:41 Training for epoch 121 done, starting evaluation
2024-07-22 17:37:49 Epoch 121 performance:
2024-07-22 17:37:49 metrics/test.rmse:  22.061
2024-07-22 17:37:49 metrics/test.rmse_pcutoff:15.253
2024-07-22 17:37:49 metrics/test.mAP:   12.381
2024-07-22 17:37:49 metrics/test.mAR:   66.250
2024-07-22 17:37:49 metrics/test.mAP_pcutoff:18.521
2024-07-22 17:37:49 metrics/test.mAR_pcutoff:21.289
2024-07-22 17:37:49 Epoch 121/200 (lr=0.0001), train loss 0.00021, valid loss 0.00253
2024-07-22 17:37:57 Training for epoch 122 done, starting evaluation
2024-07-22 17:38:05 Epoch 122 performance:
2024-07-22 17:38:05 metrics/test.rmse:  22.199
2024-07-22 17:38:05 metrics/test.rmse_pcutoff:15.289
2024-07-22 17:38:05 metrics/test.mAP:   12.190
2024-07-22 17:38:05 metrics/test.mAR:   65.781
2024-07-22 17:38:05 metrics/test.mAP_pcutoff:18.609
2024-07-22 17:38:05 metrics/test.mAR_pcutoff:20.586
2024-07-22 17:38:05 Epoch 122/200 (lr=0.0001), train loss 0.00022, valid loss 0.00254
2024-07-22 17:38:13 Training for epoch 123 done, starting evaluation
2024-07-22 17:38:21 Epoch 123 performance:
2024-07-22 17:38:21 metrics/test.rmse:  22.228
2024-07-22 17:38:21 metrics/test.rmse_pcutoff:15.569
2024-07-22 17:38:21 metrics/test.mAP:   11.869
2024-07-22 17:38:21 metrics/test.mAR:   65.586
2024-07-22 17:38:21 metrics/test.mAP_pcutoff:18.641
2024-07-22 17:38:21 metrics/test.mAR_pcutoff:21.094
2024-07-22 17:38:21 Epoch 123/200 (lr=0.0001), train loss 0.00020, valid loss 0.00252
2024-07-22 17:38:29 Training for epoch 124 done, starting evaluation
2024-07-22 17:38:36 Epoch 124 performance:
2024-07-22 17:38:36 metrics/test.rmse:  22.333
2024-07-22 17:38:36 metrics/test.rmse_pcutoff:15.597
2024-07-22 17:38:36 metrics/test.mAP:   12.187
2024-07-22 17:38:36 metrics/test.mAR:   66.250
2024-07-22 17:38:36 metrics/test.mAP_pcutoff:18.175
2024-07-22 17:38:36 metrics/test.mAR_pcutoff:20.273
2024-07-22 17:38:36 Epoch 124/200 (lr=0.0001), train loss 0.00018, valid loss 0.00253
2024-07-22 17:38:45 Training for epoch 125 done, starting evaluation
2024-07-22 17:38:52 Epoch 125 performance:
2024-07-22 17:38:52 metrics/test.rmse:  22.343
2024-07-22 17:38:52 metrics/test.rmse_pcutoff:15.736
2024-07-22 17:38:52 metrics/test.mAP:   12.024
2024-07-22 17:38:52 metrics/test.mAR:   65.977
2024-07-22 17:38:52 metrics/test.mAP_pcutoff:16.360
2024-07-22 17:38:52 metrics/test.mAR_pcutoff:19.102
2024-07-22 17:38:52 Epoch 125/200 (lr=0.0001), train loss 0.00019, valid loss 0.00253
2024-07-22 17:39:01 Training for epoch 126 done, starting evaluation
2024-07-22 17:39:09 Epoch 126 performance:
2024-07-22 17:39:09 metrics/test.rmse:  22.032
2024-07-22 17:39:09 metrics/test.rmse_pcutoff:15.714
2024-07-22 17:39:09 metrics/test.mAP:   12.229
2024-07-22 17:39:09 metrics/test.mAR:   66.289
2024-07-22 17:39:09 metrics/test.mAP_pcutoff:16.766
2024-07-22 17:39:09 metrics/test.mAR_pcutoff:19.297
2024-07-22 17:39:09 Epoch 126/200 (lr=0.0001), train loss 0.00019, valid loss 0.00253
2024-07-22 17:39:17 Training for epoch 127 done, starting evaluation
2024-07-22 17:39:24 Epoch 127 performance:
2024-07-22 17:39:24 metrics/test.rmse:  22.321
2024-07-22 17:39:24 metrics/test.rmse_pcutoff:15.433
2024-07-22 17:39:24 metrics/test.mAP:   11.892
2024-07-22 17:39:24 metrics/test.mAR:   66.211
2024-07-22 17:39:24 metrics/test.mAP_pcutoff:17.961
2024-07-22 17:39:24 metrics/test.mAR_pcutoff:20.273
2024-07-22 17:39:24 Epoch 127/200 (lr=0.0001), train loss 0.00019, valid loss 0.00252
2024-07-22 17:39:33 Training for epoch 128 done, starting evaluation
2024-07-22 17:39:40 Epoch 128 performance:
2024-07-22 17:39:40 metrics/test.rmse:  22.571
2024-07-22 17:39:40 metrics/test.rmse_pcutoff:15.505
2024-07-22 17:39:40 metrics/test.mAP:   11.867
2024-07-22 17:39:40 metrics/test.mAR:   65.703
2024-07-22 17:39:40 metrics/test.mAP_pcutoff:15.202
2024-07-22 17:39:40 metrics/test.mAR_pcutoff:17.695
2024-07-22 17:39:40 Epoch 128/200 (lr=0.0001), train loss 0.00020, valid loss 0.00252
2024-07-22 17:39:48 Training for epoch 129 done, starting evaluation
2024-07-22 17:39:56 Epoch 129 performance:
2024-07-22 17:39:56 metrics/test.rmse:  22.253
2024-07-22 17:39:56 metrics/test.rmse_pcutoff:15.653
2024-07-22 17:39:56 metrics/test.mAP:   11.925
2024-07-22 17:39:56 metrics/test.mAR:   65.859
2024-07-22 17:39:56 metrics/test.mAP_pcutoff:16.966
2024-07-22 17:39:56 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:39:56 Epoch 129/200 (lr=0.0001), train loss 0.00018, valid loss 0.00252
2024-07-22 17:40:04 Training for epoch 130 done, starting evaluation
2024-07-22 17:40:11 Epoch 130 performance:
2024-07-22 17:40:11 metrics/test.rmse:  22.290
2024-07-22 17:40:11 metrics/test.rmse_pcutoff:15.510
2024-07-22 17:40:11 metrics/test.mAP:   12.074
2024-07-22 17:40:11 metrics/test.mAR:   65.977
2024-07-22 17:40:11 metrics/test.mAP_pcutoff:18.372
2024-07-22 17:40:11 metrics/test.mAR_pcutoff:20.547
2024-07-22 17:40:11 Epoch 130/200 (lr=0.0001), train loss 0.00018, valid loss 0.00254
2024-07-22 17:40:20 Training for epoch 131 done, starting evaluation
2024-07-22 17:40:27 Epoch 131 performance:
2024-07-22 17:40:27 metrics/test.rmse:  22.474
2024-07-22 17:40:27 metrics/test.rmse_pcutoff:15.676
2024-07-22 17:40:27 metrics/test.mAP:   11.563
2024-07-22 17:40:27 metrics/test.mAR:   65.586
2024-07-22 17:40:27 metrics/test.mAP_pcutoff:18.074
2024-07-22 17:40:27 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:40:27 Epoch 131/200 (lr=0.0001), train loss 0.00018, valid loss 0.00251
2024-07-22 17:40:35 Training for epoch 132 done, starting evaluation
2024-07-22 17:40:43 Epoch 132 performance:
2024-07-22 17:40:43 metrics/test.rmse:  22.729
2024-07-22 17:40:43 metrics/test.rmse_pcutoff:16.027
2024-07-22 17:40:43 metrics/test.mAP:   11.688
2024-07-22 17:40:43 metrics/test.mAR:   65.664
2024-07-22 17:40:43 metrics/test.mAP_pcutoff:18.312
2024-07-22 17:40:43 metrics/test.mAR_pcutoff:20.742
2024-07-22 17:40:43 Epoch 132/200 (lr=0.0001), train loss 0.00017, valid loss 0.00253
2024-07-22 17:40:51 Training for epoch 133 done, starting evaluation
2024-07-22 17:40:59 Epoch 133 performance:
2024-07-22 17:40:59 metrics/test.rmse:  22.312
2024-07-22 17:40:59 metrics/test.rmse_pcutoff:15.320
2024-07-22 17:40:59 metrics/test.mAP:   11.959
2024-07-22 17:40:59 metrics/test.mAR:   65.859
2024-07-22 17:40:59 metrics/test.mAP_pcutoff:17.206
2024-07-22 17:40:59 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:40:59 Epoch 133/200 (lr=0.0001), train loss 0.00019, valid loss 0.00252
2024-07-22 17:41:07 Training for epoch 134 done, starting evaluation
2024-07-22 17:41:15 Epoch 134 performance:
2024-07-22 17:41:15 metrics/test.rmse:  22.589
2024-07-22 17:41:15 metrics/test.rmse_pcutoff:15.753
2024-07-22 17:41:15 metrics/test.mAP:   11.853
2024-07-22 17:41:15 metrics/test.mAR:   65.859
2024-07-22 17:41:15 metrics/test.mAP_pcutoff:16.650
2024-07-22 17:41:15 metrics/test.mAR_pcutoff:19.102
2024-07-22 17:41:15 Epoch 134/200 (lr=0.0001), train loss 0.00018, valid loss 0.00253
2024-07-22 17:41:23 Training for epoch 135 done, starting evaluation
2024-07-22 17:41:31 Epoch 135 performance:
2024-07-22 17:41:31 metrics/test.rmse:  22.372
2024-07-22 17:41:31 metrics/test.rmse_pcutoff:15.861
2024-07-22 17:41:31 metrics/test.mAP:   11.708
2024-07-22 17:41:31 metrics/test.mAR:   65.781
2024-07-22 17:41:31 metrics/test.mAP_pcutoff:18.655
2024-07-22 17:41:31 metrics/test.mAR_pcutoff:20.859
2024-07-22 17:41:31 Epoch 135/200 (lr=0.0001), train loss 0.00016, valid loss 0.00252
2024-07-22 17:41:39 Training for epoch 136 done, starting evaluation
2024-07-22 17:41:46 Epoch 136 performance:
2024-07-22 17:41:46 metrics/test.rmse:  22.151
2024-07-22 17:41:46 metrics/test.rmse_pcutoff:15.713
2024-07-22 17:41:46 metrics/test.mAP:   12.134
2024-07-22 17:41:46 metrics/test.mAR:   66.445
2024-07-22 17:41:46 metrics/test.mAP_pcutoff:18.501
2024-07-22 17:41:46 metrics/test.mAR_pcutoff:21.016
2024-07-22 17:41:46 Epoch 136/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:41:55 Training for epoch 137 done, starting evaluation
2024-07-22 17:42:02 Epoch 137 performance:
2024-07-22 17:42:02 metrics/test.rmse:  22.338
2024-07-22 17:42:02 metrics/test.rmse_pcutoff:15.780
2024-07-22 17:42:02 metrics/test.mAP:   12.178
2024-07-22 17:42:02 metrics/test.mAR:   65.938
2024-07-22 17:42:02 metrics/test.mAP_pcutoff:18.045
2024-07-22 17:42:02 metrics/test.mAR_pcutoff:20.547
2024-07-22 17:42:02 Epoch 137/200 (lr=0.0001), train loss 0.00017, valid loss 0.00252
2024-07-22 17:42:11 Training for epoch 138 done, starting evaluation
2024-07-22 17:42:19 Epoch 138 performance:
2024-07-22 17:42:19 metrics/test.rmse:  22.189
2024-07-22 17:42:19 metrics/test.rmse_pcutoff:15.910
2024-07-22 17:42:19 metrics/test.mAP:   11.952
2024-07-22 17:42:19 metrics/test.mAR:   66.250
2024-07-22 17:42:19 metrics/test.mAP_pcutoff:18.517
2024-07-22 17:42:19 metrics/test.mAR_pcutoff:21.055
2024-07-22 17:42:19 Epoch 138/200 (lr=0.0001), train loss 0.00016, valid loss 0.00252
2024-07-22 17:42:27 Training for epoch 139 done, starting evaluation
2024-07-22 17:42:34 Epoch 139 performance:
2024-07-22 17:42:34 metrics/test.rmse:  22.669
2024-07-22 17:42:34 metrics/test.rmse_pcutoff:15.720
2024-07-22 17:42:34 metrics/test.mAP:   11.847
2024-07-22 17:42:34 metrics/test.mAR:   64.961
2024-07-22 17:42:34 metrics/test.mAP_pcutoff:17.108
2024-07-22 17:42:34 metrics/test.mAR_pcutoff:19.375
2024-07-22 17:42:34 Epoch 139/200 (lr=0.0001), train loss 0.00018, valid loss 0.00254
2024-07-22 17:42:44 Training for epoch 140 done, starting evaluation
2024-07-22 17:42:51 Epoch 140 performance:
2024-07-22 17:42:51 metrics/test.rmse:  22.271
2024-07-22 17:42:51 metrics/test.rmse_pcutoff:15.624
2024-07-22 17:42:51 metrics/test.mAP:   12.083
2024-07-22 17:42:51 metrics/test.mAR:   65.625
2024-07-22 17:42:51 metrics/test.mAP_pcutoff:18.169
2024-07-22 17:42:51 metrics/test.mAR_pcutoff:20.547
2024-07-22 17:42:51 Epoch 140/200 (lr=0.0001), train loss 0.00018, valid loss 0.00252
2024-07-22 17:43:00 Training for epoch 141 done, starting evaluation
2024-07-22 17:43:07 Epoch 141 performance:
2024-07-22 17:43:07 metrics/test.rmse:  22.117
2024-07-22 17:43:07 metrics/test.rmse_pcutoff:15.095
2024-07-22 17:43:07 metrics/test.mAP:   12.059
2024-07-22 17:43:07 metrics/test.mAR:   65.977
2024-07-22 17:43:07 metrics/test.mAP_pcutoff:18.687
2024-07-22 17:43:07 metrics/test.mAR_pcutoff:20.781
2024-07-22 17:43:07 Epoch 141/200 (lr=0.0001), train loss 0.00018, valid loss 0.00251
2024-07-22 17:43:16 Training for epoch 142 done, starting evaluation
2024-07-22 17:43:23 Epoch 142 performance:
2024-07-22 17:43:23 metrics/test.rmse:  22.431
2024-07-22 17:43:23 metrics/test.rmse_pcutoff:15.164
2024-07-22 17:43:23 metrics/test.mAP:   11.853
2024-07-22 17:43:23 metrics/test.mAR:   65.664
2024-07-22 17:43:23 metrics/test.mAP_pcutoff:17.998
2024-07-22 17:43:23 metrics/test.mAR_pcutoff:20.352
2024-07-22 17:43:23 Epoch 142/200 (lr=0.0001), train loss 0.00016, valid loss 0.00252
2024-07-22 17:43:32 Training for epoch 143 done, starting evaluation
2024-07-22 17:43:39 Epoch 143 performance:
2024-07-22 17:43:39 metrics/test.rmse:  22.265
2024-07-22 17:43:39 metrics/test.rmse_pcutoff:15.847
2024-07-22 17:43:39 metrics/test.mAP:   12.269
2024-07-22 17:43:39 metrics/test.mAR:   65.703
2024-07-22 17:43:39 metrics/test.mAP_pcutoff:17.934
2024-07-22 17:43:39 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:43:39 Epoch 143/200 (lr=0.0001), train loss 0.00017, valid loss 0.00251
2024-07-22 17:43:47 Training for epoch 144 done, starting evaluation
2024-07-22 17:43:55 Epoch 144 performance:
2024-07-22 17:43:55 metrics/test.rmse:  22.442
2024-07-22 17:43:55 metrics/test.rmse_pcutoff:15.206
2024-07-22 17:43:55 metrics/test.mAP:   11.716
2024-07-22 17:43:55 metrics/test.mAR:   65.742
2024-07-22 17:43:55 metrics/test.mAP_pcutoff:17.585
2024-07-22 17:43:55 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:43:55 Epoch 144/200 (lr=0.0001), train loss 0.00017, valid loss 0.00252
2024-07-22 17:44:03 Training for epoch 145 done, starting evaluation
2024-07-22 17:44:10 Epoch 145 performance:
2024-07-22 17:44:10 metrics/test.rmse:  22.441
2024-07-22 17:44:10 metrics/test.rmse_pcutoff:15.640
2024-07-22 17:44:10 metrics/test.mAP:   11.906
2024-07-22 17:44:10 metrics/test.mAR:   65.938
2024-07-22 17:44:10 metrics/test.mAP_pcutoff:17.713
2024-07-22 17:44:10 metrics/test.mAR_pcutoff:20.039
2024-07-22 17:44:10 Epoch 145/200 (lr=0.0001), train loss 0.00017, valid loss 0.00252
2024-07-22 17:44:19 Training for epoch 146 done, starting evaluation
2024-07-22 17:44:27 Epoch 146 performance:
2024-07-22 17:44:27 metrics/test.rmse:  22.241
2024-07-22 17:44:27 metrics/test.rmse_pcutoff:15.235
2024-07-22 17:44:27 metrics/test.mAP:   12.541
2024-07-22 17:44:27 metrics/test.mAR:   66.680
2024-07-22 17:44:27 metrics/test.mAP_pcutoff:18.555
2024-07-22 17:44:27 metrics/test.mAR_pcutoff:21.133
2024-07-22 17:44:27 Epoch 146/200 (lr=0.0001), train loss 0.00016, valid loss 0.00252
2024-07-22 17:44:35 Training for epoch 147 done, starting evaluation
2024-07-22 17:44:43 Epoch 147 performance:
2024-07-22 17:44:43 metrics/test.rmse:  22.286
2024-07-22 17:44:43 metrics/test.rmse_pcutoff:15.242
2024-07-22 17:44:43 metrics/test.mAP:   11.864
2024-07-22 17:44:43 metrics/test.mAR:   65.781
2024-07-22 17:44:43 metrics/test.mAP_pcutoff:16.238
2024-07-22 17:44:43 metrics/test.mAR_pcutoff:18.516
2024-07-22 17:44:43 Epoch 147/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:44:52 Training for epoch 148 done, starting evaluation
2024-07-22 17:44:59 Epoch 148 performance:
2024-07-22 17:44:59 metrics/test.rmse:  21.985
2024-07-22 17:44:59 metrics/test.rmse_pcutoff:15.275
2024-07-22 17:44:59 metrics/test.mAP:   11.860
2024-07-22 17:44:59 metrics/test.mAR:   66.055
2024-07-22 17:44:59 metrics/test.mAP_pcutoff:16.777
2024-07-22 17:44:59 metrics/test.mAR_pcutoff:19.102
2024-07-22 17:44:59 Epoch 148/200 (lr=0.0001), train loss 0.00016, valid loss 0.00252
2024-07-22 17:45:08 Training for epoch 149 done, starting evaluation
2024-07-22 17:45:15 Epoch 149 performance:
2024-07-22 17:45:15 metrics/test.rmse:  22.172
2024-07-22 17:45:15 metrics/test.rmse_pcutoff:15.252
2024-07-22 17:45:15 metrics/test.mAP:   12.483
2024-07-22 17:45:15 metrics/test.mAR:   66.758
2024-07-22 17:45:15 metrics/test.mAP_pcutoff:18.128
2024-07-22 17:45:15 metrics/test.mAR_pcutoff:20.391
2024-07-22 17:45:15 Epoch 149/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:45:23 Training for epoch 150 done, starting evaluation
2024-07-22 17:45:31 Epoch 150 performance:
2024-07-22 17:45:31 metrics/test.rmse:  22.407
2024-07-22 17:45:31 metrics/test.rmse_pcutoff:15.589
2024-07-22 17:45:31 metrics/test.mAP:   12.353
2024-07-22 17:45:31 metrics/test.mAR:   66.172
2024-07-22 17:45:31 metrics/test.mAP_pcutoff:18.875
2024-07-22 17:45:31 metrics/test.mAR_pcutoff:21.367
2024-07-22 17:45:31 Epoch 150/200 (lr=0.0001), train loss 0.00015, valid loss 0.00252
2024-07-22 17:45:39 Training for epoch 151 done, starting evaluation
2024-07-22 17:45:47 Epoch 151 performance:
2024-07-22 17:45:47 metrics/test.rmse:  22.285
2024-07-22 17:45:47 metrics/test.rmse_pcutoff:14.917
2024-07-22 17:45:47 metrics/test.mAP:   12.225
2024-07-22 17:45:47 metrics/test.mAR:   65.898
2024-07-22 17:45:47 metrics/test.mAP_pcutoff:16.331
2024-07-22 17:45:47 metrics/test.mAR_pcutoff:18.984
2024-07-22 17:45:47 Epoch 151/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:45:55 Training for epoch 152 done, starting evaluation
2024-07-22 17:46:02 Epoch 152 performance:
2024-07-22 17:46:02 metrics/test.rmse:  22.325
2024-07-22 17:46:02 metrics/test.rmse_pcutoff:14.946
2024-07-22 17:46:02 metrics/test.mAP:   11.855
2024-07-22 17:46:02 metrics/test.mAR:   65.938
2024-07-22 17:46:02 metrics/test.mAP_pcutoff:17.490
2024-07-22 17:46:02 metrics/test.mAR_pcutoff:19.453
2024-07-22 17:46:02 Epoch 152/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:46:11 Training for epoch 153 done, starting evaluation
2024-07-22 17:46:18 Epoch 153 performance:
2024-07-22 17:46:18 metrics/test.rmse:  22.456
2024-07-22 17:46:18 metrics/test.rmse_pcutoff:15.681
2024-07-22 17:46:18 metrics/test.mAP:   12.046
2024-07-22 17:46:18 metrics/test.mAR:   65.781
2024-07-22 17:46:18 metrics/test.mAP_pcutoff:17.727
2024-07-22 17:46:18 metrics/test.mAR_pcutoff:20.117
2024-07-22 17:46:18 Epoch 153/200 (lr=0.0001), train loss 0.00014, valid loss 0.00251
2024-07-22 17:46:26 Training for epoch 154 done, starting evaluation
2024-07-22 17:46:33 Epoch 154 performance:
2024-07-22 17:46:33 metrics/test.rmse:  22.006
2024-07-22 17:46:33 metrics/test.rmse_pcutoff:15.232
2024-07-22 17:46:33 metrics/test.mAP:   12.293
2024-07-22 17:46:33 metrics/test.mAR:   66.445
2024-07-22 17:46:33 metrics/test.mAP_pcutoff:17.296
2024-07-22 17:46:33 metrics/test.mAR_pcutoff:19.648
2024-07-22 17:46:33 Epoch 154/200 (lr=0.0001), train loss 0.00015, valid loss 0.00251
2024-07-22 17:46:42 Training for epoch 155 done, starting evaluation
2024-07-22 17:46:50 Epoch 155 performance:
2024-07-22 17:46:50 metrics/test.rmse:  21.863
2024-07-22 17:46:50 metrics/test.rmse_pcutoff:14.924
2024-07-22 17:46:50 metrics/test.mAP:   12.077
2024-07-22 17:46:50 metrics/test.mAR:   66.328
2024-07-22 17:46:50 metrics/test.mAP_pcutoff:16.212
2024-07-22 17:46:50 metrics/test.mAR_pcutoff:18.398
2024-07-22 17:46:50 Epoch 155/200 (lr=0.0001), train loss 0.00015, valid loss 0.00251
2024-07-22 17:46:58 Training for epoch 156 done, starting evaluation
2024-07-22 17:47:05 Epoch 156 performance:
2024-07-22 17:47:05 metrics/test.rmse:  22.056
2024-07-22 17:47:05 metrics/test.rmse_pcutoff:14.893
2024-07-22 17:47:05 metrics/test.mAP:   12.646
2024-07-22 17:47:05 metrics/test.mAR:   66.562
2024-07-22 17:47:05 metrics/test.mAP_pcutoff:17.945
2024-07-22 17:47:05 metrics/test.mAR_pcutoff:20.000
2024-07-22 17:47:05 Epoch 156/200 (lr=0.0001), train loss 0.00017, valid loss 0.00252
2024-07-22 17:47:14 Training for epoch 157 done, starting evaluation
2024-07-22 17:47:21 Epoch 157 performance:
2024-07-22 17:47:21 metrics/test.rmse:  22.545
2024-07-22 17:47:21 metrics/test.rmse_pcutoff:15.289
2024-07-22 17:47:21 metrics/test.mAP:   12.253
2024-07-22 17:47:21 metrics/test.mAR:   65.781
2024-07-22 17:47:21 metrics/test.mAP_pcutoff:16.599
2024-07-22 17:47:21 metrics/test.mAR_pcutoff:18.633
2024-07-22 17:47:21 Epoch 157/200 (lr=0.0001), train loss 0.00016, valid loss 0.00251
2024-07-22 17:47:30 Training for epoch 158 done, starting evaluation
2024-07-22 17:47:38 Epoch 158 performance:
2024-07-22 17:47:38 metrics/test.rmse:  22.084
2024-07-22 17:47:38 metrics/test.rmse_pcutoff:15.456
2024-07-22 17:47:38 metrics/test.mAP:   12.359
2024-07-22 17:47:38 metrics/test.mAR:   66.484
2024-07-22 17:47:38 metrics/test.mAP_pcutoff:18.322
2024-07-22 17:47:38 metrics/test.mAR_pcutoff:20.664
2024-07-22 17:47:38 Epoch 158/200 (lr=0.0001), train loss 0.00015, valid loss 0.00250
2024-07-22 17:47:46 Training for epoch 159 done, starting evaluation
2024-07-22 17:47:54 Epoch 159 performance:
2024-07-22 17:47:54 metrics/test.rmse:  22.077
2024-07-22 17:47:54 metrics/test.rmse_pcutoff:15.244
2024-07-22 17:47:54 metrics/test.mAP:   12.170
2024-07-22 17:47:54 metrics/test.mAR:   66.094
2024-07-22 17:47:54 metrics/test.mAP_pcutoff:16.772
2024-07-22 17:47:54 metrics/test.mAR_pcutoff:19.297
2024-07-22 17:47:54 Epoch 159/200 (lr=0.0001), train loss 0.00014, valid loss 0.00251
2024-07-22 17:48:03 Training for epoch 160 done, starting evaluation
2024-07-22 17:48:10 Epoch 160 performance:
2024-07-22 17:48:10 metrics/test.rmse:  22.886
2024-07-22 17:48:10 metrics/test.rmse_pcutoff:15.365
2024-07-22 17:48:10 metrics/test.mAP:   12.096
2024-07-22 17:48:10 metrics/test.mAR:   65.859
2024-07-22 17:48:10 metrics/test.mAP_pcutoff:17.974
2024-07-22 17:48:10 metrics/test.mAR_pcutoff:20.195
2024-07-22 17:48:10 Epoch 160/200 (lr=1e-05), train loss 0.00014, valid loss 0.00251
2024-07-22 17:48:18 Training for epoch 161 done, starting evaluation
2024-07-22 17:48:26 Epoch 161 performance:
2024-07-22 17:48:26 metrics/test.rmse:  22.919
2024-07-22 17:48:26 metrics/test.rmse_pcutoff:15.233
2024-07-22 17:48:26 metrics/test.mAP:   11.842
2024-07-22 17:48:26 metrics/test.mAR:   65.508
2024-07-22 17:48:26 metrics/test.mAP_pcutoff:17.937
2024-07-22 17:48:26 metrics/test.mAR_pcutoff:20.430
2024-07-22 17:48:26 Epoch 161/200 (lr=1e-05), train loss 0.00015, valid loss 0.00251
2024-07-22 17:48:34 Training for epoch 162 done, starting evaluation
2024-07-22 17:48:42 Epoch 162 performance:
2024-07-22 17:48:42 metrics/test.rmse:  22.561
2024-07-22 17:48:42 metrics/test.rmse_pcutoff:15.382
2024-07-22 17:48:42 metrics/test.mAP:   12.029
2024-07-22 17:48:42 metrics/test.mAR:   65.977
2024-07-22 17:48:42 metrics/test.mAP_pcutoff:17.764
2024-07-22 17:48:42 metrics/test.mAR_pcutoff:20.156
2024-07-22 17:48:42 Epoch 162/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:48:51 Training for epoch 163 done, starting evaluation
2024-07-22 17:48:58 Epoch 163 performance:
2024-07-22 17:48:58 metrics/test.rmse:  22.440
2024-07-22 17:48:58 metrics/test.rmse_pcutoff:15.147
2024-07-22 17:48:58 metrics/test.mAP:   12.015
2024-07-22 17:48:58 metrics/test.mAR:   66.133
2024-07-22 17:48:58 metrics/test.mAP_pcutoff:17.641
2024-07-22 17:48:58 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:48:58 Epoch 163/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:49:08 Training for epoch 164 done, starting evaluation
2024-07-22 17:49:15 Epoch 164 performance:
2024-07-22 17:49:15 metrics/test.rmse:  22.372
2024-07-22 17:49:15 metrics/test.rmse_pcutoff:15.230
2024-07-22 17:49:15 metrics/test.mAP:   12.043
2024-07-22 17:49:15 metrics/test.mAR:   66.172
2024-07-22 17:49:15 metrics/test.mAP_pcutoff:17.407
2024-07-22 17:49:15 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:49:15 Epoch 164/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:49:24 Training for epoch 165 done, starting evaluation
2024-07-22 17:49:31 Epoch 165 performance:
2024-07-22 17:49:31 metrics/test.rmse:  22.352
2024-07-22 17:49:31 metrics/test.rmse_pcutoff:15.128
2024-07-22 17:49:31 metrics/test.mAP:   12.136
2024-07-22 17:49:31 metrics/test.mAR:   66.367
2024-07-22 17:49:31 metrics/test.mAP_pcutoff:17.323
2024-07-22 17:49:31 metrics/test.mAR_pcutoff:19.648
2024-07-22 17:49:31 Epoch 165/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:49:39 Training for epoch 166 done, starting evaluation
2024-07-22 17:49:47 Epoch 166 performance:
2024-07-22 17:49:47 metrics/test.rmse:  22.463
2024-07-22 17:49:47 metrics/test.rmse_pcutoff:15.097
2024-07-22 17:49:47 metrics/test.mAP:   12.122
2024-07-22 17:49:47 metrics/test.mAR:   66.250
2024-07-22 17:49:47 metrics/test.mAP_pcutoff:18.172
2024-07-22 17:49:47 metrics/test.mAR_pcutoff:20.508
2024-07-22 17:49:47 Epoch 166/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:49:54 Training for epoch 167 done, starting evaluation
2024-07-22 17:50:02 Epoch 167 performance:
2024-07-22 17:50:02 metrics/test.rmse:  22.631
2024-07-22 17:50:02 metrics/test.rmse_pcutoff:15.161
2024-07-22 17:50:02 metrics/test.mAP:   11.884
2024-07-22 17:50:02 metrics/test.mAR:   65.820
2024-07-22 17:50:02 metrics/test.mAP_pcutoff:17.068
2024-07-22 17:50:02 metrics/test.mAR_pcutoff:19.336
2024-07-22 17:50:02 Epoch 167/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:50:10 Training for epoch 168 done, starting evaluation
2024-07-22 17:50:18 Epoch 168 performance:
2024-07-22 17:50:18 metrics/test.rmse:  22.494
2024-07-22 17:50:18 metrics/test.rmse_pcutoff:15.078
2024-07-22 17:50:18 metrics/test.mAP:   12.046
2024-07-22 17:50:18 metrics/test.mAR:   65.938
2024-07-22 17:50:18 metrics/test.mAP_pcutoff:17.453
2024-07-22 17:50:18 metrics/test.mAR_pcutoff:19.922
2024-07-22 17:50:18 Epoch 168/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:50:27 Training for epoch 169 done, starting evaluation
2024-07-22 17:50:34 Epoch 169 performance:
2024-07-22 17:50:34 metrics/test.rmse:  22.487
2024-07-22 17:50:34 metrics/test.rmse_pcutoff:15.197
2024-07-22 17:50:34 metrics/test.mAP:   11.988
2024-07-22 17:50:34 metrics/test.mAR:   66.016
2024-07-22 17:50:34 metrics/test.mAP_pcutoff:17.720
2024-07-22 17:50:34 metrics/test.mAR_pcutoff:19.961
2024-07-22 17:50:34 Epoch 169/200 (lr=1e-05), train loss 0.00013, valid loss 0.00250
2024-07-22 17:50:43 Training for epoch 170 done, starting evaluation
2024-07-22 17:50:50 Epoch 170 performance:
2024-07-22 17:50:50 metrics/test.rmse:  22.554
2024-07-22 17:50:50 metrics/test.rmse_pcutoff:15.185
2024-07-22 17:50:50 metrics/test.mAP:   11.933
2024-07-22 17:50:50 metrics/test.mAR:   65.820
2024-07-22 17:50:50 metrics/test.mAP_pcutoff:18.001
2024-07-22 17:50:50 metrics/test.mAR_pcutoff:20.312
2024-07-22 17:50:50 Epoch 170/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:50:59 Training for epoch 171 done, starting evaluation
2024-07-22 17:51:06 Epoch 171 performance:
2024-07-22 17:51:06 metrics/test.rmse:  22.507
2024-07-22 17:51:06 metrics/test.rmse_pcutoff:15.213
2024-07-22 17:51:06 metrics/test.mAP:   12.119
2024-07-22 17:51:06 metrics/test.mAR:   66.055
2024-07-22 17:51:06 metrics/test.mAP_pcutoff:17.982
2024-07-22 17:51:06 metrics/test.mAR_pcutoff:20.234
2024-07-22 17:51:06 Epoch 171/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:51:15 Training for epoch 172 done, starting evaluation
2024-07-22 17:51:22 Epoch 172 performance:
2024-07-22 17:51:22 metrics/test.rmse:  22.431
2024-07-22 17:51:22 metrics/test.rmse_pcutoff:15.201
2024-07-22 17:51:22 metrics/test.mAP:   12.099
2024-07-22 17:51:22 metrics/test.mAR:   66.172
2024-07-22 17:51:22 metrics/test.mAP_pcutoff:17.482
2024-07-22 17:51:22 metrics/test.mAR_pcutoff:19.844
2024-07-22 17:51:22 Epoch 172/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:51:31 Training for epoch 173 done, starting evaluation
2024-07-22 17:51:38 Epoch 173 performance:
2024-07-22 17:51:38 metrics/test.rmse:  22.422
2024-07-22 17:51:38 metrics/test.rmse_pcutoff:15.320
2024-07-22 17:51:38 metrics/test.mAP:   12.070
2024-07-22 17:51:38 metrics/test.mAR:   66.172
2024-07-22 17:51:38 metrics/test.mAP_pcutoff:17.973
2024-07-22 17:51:38 metrics/test.mAR_pcutoff:20.391
2024-07-22 17:51:38 Epoch 173/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:51:47 Training for epoch 174 done, starting evaluation
2024-07-22 17:51:54 Epoch 174 performance:
2024-07-22 17:51:54 metrics/test.rmse:  22.488
2024-07-22 17:51:54 metrics/test.rmse_pcutoff:15.336
2024-07-22 17:51:54 metrics/test.mAP:   11.977
2024-07-22 17:51:54 metrics/test.mAR:   65.977
2024-07-22 17:51:54 metrics/test.mAP_pcutoff:17.594
2024-07-22 17:51:54 metrics/test.mAR_pcutoff:20.000
2024-07-22 17:51:54 Epoch 174/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:52:03 Training for epoch 175 done, starting evaluation
2024-07-22 17:52:10 Epoch 175 performance:
2024-07-22 17:52:10 metrics/test.rmse:  22.423
2024-07-22 17:52:10 metrics/test.rmse_pcutoff:15.208
2024-07-22 17:52:10 metrics/test.mAP:   11.959
2024-07-22 17:52:10 metrics/test.mAR:   65.977
2024-07-22 17:52:10 metrics/test.mAP_pcutoff:17.052
2024-07-22 17:52:10 metrics/test.mAR_pcutoff:19.609
2024-07-22 17:52:10 Epoch 175/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:52:18 Training for epoch 176 done, starting evaluation
2024-07-22 17:52:26 Epoch 176 performance:
2024-07-22 17:52:26 metrics/test.rmse:  22.450
2024-07-22 17:52:26 metrics/test.rmse_pcutoff:15.258
2024-07-22 17:52:26 metrics/test.mAP:   12.011
2024-07-22 17:52:26 metrics/test.mAR:   65.977
2024-07-22 17:52:26 metrics/test.mAP_pcutoff:17.618
2024-07-22 17:52:26 metrics/test.mAR_pcutoff:20.078
2024-07-22 17:52:26 Epoch 176/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:52:35 Training for epoch 177 done, starting evaluation
2024-07-22 17:52:42 Epoch 177 performance:
2024-07-22 17:52:42 metrics/test.rmse:  22.440
2024-07-22 17:52:42 metrics/test.rmse_pcutoff:15.242
2024-07-22 17:52:42 metrics/test.mAP:   11.926
2024-07-22 17:52:42 metrics/test.mAR:   66.055
2024-07-22 17:52:42 metrics/test.mAP_pcutoff:17.000
2024-07-22 17:52:42 metrics/test.mAR_pcutoff:19.531
2024-07-22 17:52:42 Epoch 177/200 (lr=1e-05), train loss 0.00010, valid loss 0.00250
2024-07-22 17:52:51 Training for epoch 178 done, starting evaluation
2024-07-22 17:52:59 Epoch 178 performance:
2024-07-22 17:52:59 metrics/test.rmse:  22.435
2024-07-22 17:52:59 metrics/test.rmse_pcutoff:15.254
2024-07-22 17:52:59 metrics/test.mAP:   11.993
2024-07-22 17:52:59 metrics/test.mAR:   66.172
2024-07-22 17:52:59 metrics/test.mAP_pcutoff:16.849
2024-07-22 17:52:59 metrics/test.mAR_pcutoff:19.375
2024-07-22 17:52:59 Epoch 178/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:53:07 Training for epoch 179 done, starting evaluation
2024-07-22 17:53:14 Epoch 179 performance:
2024-07-22 17:53:14 metrics/test.rmse:  22.469
2024-07-22 17:53:14 metrics/test.rmse_pcutoff:15.157
2024-07-22 17:53:14 metrics/test.mAP:   11.952
2024-07-22 17:53:14 metrics/test.mAR:   66.016
2024-07-22 17:53:14 metrics/test.mAP_pcutoff:17.333
2024-07-22 17:53:14 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:53:14 Epoch 179/200 (lr=1e-05), train loss 0.00012, valid loss 0.00249
2024-07-22 17:53:22 Training for epoch 180 done, starting evaluation
2024-07-22 17:53:30 Epoch 180 performance:
2024-07-22 17:53:30 metrics/test.rmse:  22.536
2024-07-22 17:53:30 metrics/test.rmse_pcutoff:15.321
2024-07-22 17:53:30 metrics/test.mAP:   11.920
2024-07-22 17:53:30 metrics/test.mAR:   65.703
2024-07-22 17:53:30 metrics/test.mAP_pcutoff:17.220
2024-07-22 17:53:30 metrics/test.mAR_pcutoff:19.492
2024-07-22 17:53:30 Epoch 180/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:53:38 Training for epoch 181 done, starting evaluation
2024-07-22 17:53:45 Epoch 181 performance:
2024-07-22 17:53:45 metrics/test.rmse:  22.413
2024-07-22 17:53:45 metrics/test.rmse_pcutoff:15.189
2024-07-22 17:53:45 metrics/test.mAP:   11.965
2024-07-22 17:53:45 metrics/test.mAR:   65.938
2024-07-22 17:53:45 metrics/test.mAP_pcutoff:16.997
2024-07-22 17:53:45 metrics/test.mAR_pcutoff:19.414
2024-07-22 17:53:45 Epoch 181/200 (lr=1e-05), train loss 0.00011, valid loss 0.00249
2024-07-22 17:53:54 Training for epoch 182 done, starting evaluation
2024-07-22 17:54:01 Epoch 182 performance:
2024-07-22 17:54:01 metrics/test.rmse:  22.390
2024-07-22 17:54:01 metrics/test.rmse_pcutoff:15.173
2024-07-22 17:54:01 metrics/test.mAP:   11.902
2024-07-22 17:54:01 metrics/test.mAR:   65.938
2024-07-22 17:54:01 metrics/test.mAP_pcutoff:16.987
2024-07-22 17:54:01 metrics/test.mAR_pcutoff:19.414
2024-07-22 17:54:01 Epoch 182/200 (lr=1e-05), train loss 0.00011, valid loss 0.00249
2024-07-22 17:54:09 Training for epoch 183 done, starting evaluation
2024-07-22 17:54:17 Epoch 183 performance:
2024-07-22 17:54:17 metrics/test.rmse:  22.409
2024-07-22 17:54:17 metrics/test.rmse_pcutoff:15.204
2024-07-22 17:54:17 metrics/test.mAP:   11.919
2024-07-22 17:54:17 metrics/test.mAR:   65.898
2024-07-22 17:54:17 metrics/test.mAP_pcutoff:17.403
2024-07-22 17:54:17 metrics/test.mAR_pcutoff:19.766
2024-07-22 17:54:17 Epoch 183/200 (lr=1e-05), train loss 0.00011, valid loss 0.00249
2024-07-22 17:54:25 Training for epoch 184 done, starting evaluation
2024-07-22 17:54:32 Epoch 184 performance:
2024-07-22 17:54:32 metrics/test.rmse:  22.396
2024-07-22 17:54:32 metrics/test.rmse_pcutoff:15.101
2024-07-22 17:54:32 metrics/test.mAP:   11.890
2024-07-22 17:54:32 metrics/test.mAR:   65.898
2024-07-22 17:54:32 metrics/test.mAP_pcutoff:16.907
2024-07-22 17:54:32 metrics/test.mAR_pcutoff:19.297
2024-07-22 17:54:32 Epoch 184/200 (lr=1e-05), train loss 0.00011, valid loss 0.00249
2024-07-22 17:54:41 Training for epoch 185 done, starting evaluation
2024-07-22 17:54:48 Epoch 185 performance:
2024-07-22 17:54:48 metrics/test.rmse:  22.336
2024-07-22 17:54:48 metrics/test.rmse_pcutoff:15.326
2024-07-22 17:54:48 metrics/test.mAP:   11.972
2024-07-22 17:54:48 metrics/test.mAR:   66.094
2024-07-22 17:54:48 metrics/test.mAP_pcutoff:17.370
2024-07-22 17:54:48 metrics/test.mAR_pcutoff:19.727
2024-07-22 17:54:48 Epoch 185/200 (lr=1e-05), train loss 0.00010, valid loss 0.00250
2024-07-22 17:54:57 Training for epoch 186 done, starting evaluation
2024-07-22 17:55:04 Epoch 186 performance:
2024-07-22 17:55:04 metrics/test.rmse:  22.364
2024-07-22 17:55:04 metrics/test.rmse_pcutoff:15.191
2024-07-22 17:55:04 metrics/test.mAP:   11.939
2024-07-22 17:55:04 metrics/test.mAR:   66.055
2024-07-22 17:55:04 metrics/test.mAP_pcutoff:17.076
2024-07-22 17:55:04 metrics/test.mAR_pcutoff:19.570
2024-07-22 17:55:04 Epoch 186/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:55:13 Training for epoch 187 done, starting evaluation
2024-07-22 17:55:21 Epoch 187 performance:
2024-07-22 17:55:21 metrics/test.rmse:  22.445
2024-07-22 17:55:21 metrics/test.rmse_pcutoff:15.164
2024-07-22 17:55:21 metrics/test.mAP:   11.854
2024-07-22 17:55:21 metrics/test.mAR:   65.703
2024-07-22 17:55:21 metrics/test.mAP_pcutoff:17.145
2024-07-22 17:55:21 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:55:21 Epoch 187/200 (lr=1e-05), train loss 0.00011, valid loss 0.00250
2024-07-22 17:55:30 Training for epoch 188 done, starting evaluation
2024-07-22 17:55:37 Epoch 188 performance:
2024-07-22 17:55:37 metrics/test.rmse:  22.396
2024-07-22 17:55:37 metrics/test.rmse_pcutoff:15.165
2024-07-22 17:55:37 metrics/test.mAP:   11.910
2024-07-22 17:55:37 metrics/test.mAR:   65.938
2024-07-22 17:55:37 metrics/test.mAP_pcutoff:16.881
2024-07-22 17:55:37 metrics/test.mAR_pcutoff:19.375
2024-07-22 17:55:37 Epoch 188/200 (lr=1e-05), train loss 0.00012, valid loss 0.00250
2024-07-22 17:55:46 Training for epoch 189 done, starting evaluation
2024-07-22 17:55:53 Epoch 189 performance:
2024-07-22 17:55:53 metrics/test.rmse:  22.401
2024-07-22 17:55:53 metrics/test.rmse_pcutoff:15.212
2024-07-22 17:55:53 metrics/test.mAP:   11.943
2024-07-22 17:55:53 metrics/test.mAR:   66.094
2024-07-22 17:55:53 metrics/test.mAP_pcutoff:17.238
2024-07-22 17:55:53 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:55:53 Epoch 189/200 (lr=1e-05), train loss 0.00010, valid loss 0.00249
2024-07-22 17:56:02 Training for epoch 190 done, starting evaluation
2024-07-22 17:56:09 Epoch 190 performance:
2024-07-22 17:56:09 metrics/test.rmse:  22.466
2024-07-22 17:56:09 metrics/test.rmse_pcutoff:15.306
2024-07-22 17:56:09 metrics/test.mAP:   11.960
2024-07-22 17:56:09 metrics/test.mAR:   66.016
2024-07-22 17:56:09 metrics/test.mAP_pcutoff:16.969
2024-07-22 17:56:09 metrics/test.mAR_pcutoff:19.453
2024-07-22 17:56:09 Epoch 190/200 (lr=1e-06), train loss 0.00010, valid loss 0.00249
2024-07-22 17:56:18 Training for epoch 191 done, starting evaluation
2024-07-22 17:56:25 Epoch 191 performance:
2024-07-22 17:56:25 metrics/test.rmse:  22.433
2024-07-22 17:56:25 metrics/test.rmse_pcutoff:15.275
2024-07-22 17:56:25 metrics/test.mAP:   11.978
2024-07-22 17:56:25 metrics/test.mAR:   66.094
2024-07-22 17:56:25 metrics/test.mAP_pcutoff:16.960
2024-07-22 17:56:25 metrics/test.mAR_pcutoff:19.492
2024-07-22 17:56:25 Epoch 191/200 (lr=1e-06), train loss 0.00012, valid loss 0.00250
2024-07-22 17:56:34 Training for epoch 192 done, starting evaluation
2024-07-22 17:56:41 Epoch 192 performance:
2024-07-22 17:56:41 metrics/test.rmse:  22.407
2024-07-22 17:56:41 metrics/test.rmse_pcutoff:15.272
2024-07-22 17:56:41 metrics/test.mAP:   12.013
2024-07-22 17:56:41 metrics/test.mAR:   66.094
2024-07-22 17:56:41 metrics/test.mAP_pcutoff:17.205
2024-07-22 17:56:41 metrics/test.mAR_pcutoff:19.688
2024-07-22 17:56:41 Epoch 192/200 (lr=1e-06), train loss 0.00012, valid loss 0.00250
2024-07-22 17:56:50 Training for epoch 193 done, starting evaluation
2024-07-22 17:56:58 Epoch 193 performance:
2024-07-22 17:56:58 metrics/test.rmse:  22.398
2024-07-22 17:56:58 metrics/test.rmse_pcutoff:15.316
2024-07-22 17:56:58 metrics/test.mAP:   12.011
2024-07-22 17:56:58 metrics/test.mAR:   66.016
2024-07-22 17:56:58 metrics/test.mAP_pcutoff:17.118
2024-07-22 17:56:58 metrics/test.mAR_pcutoff:19.492
2024-07-22 17:56:58 Epoch 193/200 (lr=1e-06), train loss 0.00010, valid loss 0.00250
2024-07-22 17:57:07 Training for epoch 194 done, starting evaluation
2024-07-22 17:57:15 Epoch 194 performance:
2024-07-22 17:57:15 metrics/test.rmse:  22.408
2024-07-22 17:57:15 metrics/test.rmse_pcutoff:15.262
2024-07-22 17:57:15 metrics/test.mAP:   12.014
2024-07-22 17:57:15 metrics/test.mAR:   66.133
2024-07-22 17:57:15 metrics/test.mAP_pcutoff:17.002
2024-07-22 17:57:15 metrics/test.mAR_pcutoff:19.414
2024-07-22 17:57:15 Epoch 194/200 (lr=1e-06), train loss 0.00011, valid loss 0.00250
2024-07-22 17:57:23 Training for epoch 195 done, starting evaluation
2024-07-22 17:57:30 Epoch 195 performance:
2024-07-22 17:57:30 metrics/test.rmse:  22.413
2024-07-22 17:57:30 metrics/test.rmse_pcutoff:15.265
2024-07-22 17:57:30 metrics/test.mAP:   11.966
2024-07-22 17:57:30 metrics/test.mAR:   66.094
2024-07-22 17:57:30 metrics/test.mAP_pcutoff:16.800
2024-07-22 17:57:30 metrics/test.mAR_pcutoff:19.219
2024-07-22 17:57:30 Epoch 195/200 (lr=1e-06), train loss 0.00012, valid loss 0.00250
2024-07-22 17:57:38 Training for epoch 196 done, starting evaluation
2024-07-22 17:57:46 Epoch 196 performance:
2024-07-22 17:57:46 metrics/test.rmse:  22.427
2024-07-22 17:57:46 metrics/test.rmse_pcutoff:15.240
2024-07-22 17:57:46 metrics/test.mAP:   11.950
2024-07-22 17:57:46 metrics/test.mAR:   66.094
2024-07-22 17:57:46 metrics/test.mAP_pcutoff:16.844
2024-07-22 17:57:46 metrics/test.mAR_pcutoff:19.219
2024-07-22 17:57:46 Epoch 196/200 (lr=1e-06), train loss 0.00012, valid loss 0.00250
2024-07-22 17:57:54 Training for epoch 197 done, starting evaluation
2024-07-22 17:58:02 Epoch 197 performance:
2024-07-22 17:58:02 metrics/test.rmse:  22.374
2024-07-22 17:58:02 metrics/test.rmse_pcutoff:15.232
2024-07-22 17:58:02 metrics/test.mAP:   11.974
2024-07-22 17:58:02 metrics/test.mAR:   66.172
2024-07-22 17:58:02 metrics/test.mAP_pcutoff:16.922
2024-07-22 17:58:02 metrics/test.mAR_pcutoff:19.336
2024-07-22 17:58:02 Epoch 197/200 (lr=1e-06), train loss 0.00011, valid loss 0.00250
2024-07-22 17:58:10 Training for epoch 198 done, starting evaluation
2024-07-22 17:58:18 Epoch 198 performance:
2024-07-22 17:58:18 metrics/test.rmse:  22.361
2024-07-22 17:58:18 metrics/test.rmse_pcutoff:15.215
2024-07-22 17:58:18 metrics/test.mAP:   11.974
2024-07-22 17:58:18 metrics/test.mAR:   66.172
2024-07-22 17:58:18 metrics/test.mAP_pcutoff:16.920
2024-07-22 17:58:18 metrics/test.mAR_pcutoff:19.336
2024-07-22 17:58:18 Epoch 198/200 (lr=1e-06), train loss 0.00011, valid loss 0.00250
2024-07-22 17:58:26 Training for epoch 199 done, starting evaluation
2024-07-22 17:58:33 Epoch 199 performance:
2024-07-22 17:58:33 metrics/test.rmse:  22.368
2024-07-22 17:58:33 metrics/test.rmse_pcutoff:15.198
2024-07-22 17:58:33 metrics/test.mAP:   11.972
2024-07-22 17:58:33 metrics/test.mAR:   66.133
2024-07-22 17:58:33 metrics/test.mAP_pcutoff:16.851
2024-07-22 17:58:33 metrics/test.mAR_pcutoff:19.258
2024-07-22 17:58:33 Epoch 199/200 (lr=1e-06), train loss 0.00010, valid loss 0.00250
2024-07-22 17:58:41 Training for epoch 200 done, starting evaluation
2024-07-22 17:58:49 Epoch 200 performance:
2024-07-22 17:58:49 metrics/test.rmse:  22.368
2024-07-22 17:58:49 metrics/test.rmse_pcutoff:15.200
2024-07-22 17:58:49 metrics/test.mAP:   11.974
2024-07-22 17:58:49 metrics/test.mAR:   66.172
2024-07-22 17:58:49 metrics/test.mAP_pcutoff:16.847
2024-07-22 17:58:49 metrics/test.mAR_pcutoff:19.258
2024-07-22 17:58:49 Epoch 200/200 (lr=1e-06), train loss 0.00011, valid loss 0.00250
