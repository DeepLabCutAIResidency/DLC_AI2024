{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dlclive import DLCLive, Processor\n",
    "import dlclive\n",
    "from dlclive.display import Display\n",
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 296, 658)\n",
      "Loaded weights\n",
      "{'data': {'colormode': 'RGB', 'inference': {'normalize_images': True}, 'train': {'affine': {'p': 0.5, 'rotation': 30, 'scaling': [1.0, 1.0], 'translation': 0}, 'collate': {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}, 'covering': False, 'gaussian_noise': 12.75, 'hist_eq': False, 'motion_blur': False, 'normalize_images': True}}, 'device': 'auto', 'metadata': {'project_path': '/media1/data/anna/datasets/DLC_model_for_ventral_analysis', 'pose_config_path': '/media1/data/anna/datasets/DLC_model_for_ventral_analysis/dlc-models-pytorch/iteration-0/Anna1VideoAnalysisBottomFeb8-trainset95shuffle1003/train/pose_cfg.yaml', 'bodyparts': ['snout1', 'snout2', 'snout3', 'leftfrontpaw', 'rightfrontpaw', 'leftbackpaw', 'rightbackpaw', 'torsoleft', 'torsomiddle', 'torsoright', 'tail'], 'unique_bodyparts': [], 'individuals': ['animal'], 'with_identity': None}, 'method': 'bu', 'model': {'backbone': {'type': 'ResNet', 'model_name': 'resnet50_gn', 'output_stride': 16, 'freeze_bn_stats': True, 'freeze_bn_weights': False}, 'backbone_output_channels': 2048, 'heads': {'bodypart': {'type': 'HeatmapHead', 'weight_init': 'normal', 'predictor': {'type': 'HeatmapPredictor', 'apply_sigmoid': False, 'clip_scores': True, 'location_refinement': True, 'locref_std': 7.2801}, 'target_generator': {'type': 'HeatmapGaussianGenerator', 'num_heatmaps': 11, 'pos_dist_thresh': 17, 'heatmap_mode': 'KEYPOINT', 'generate_locref': True, 'locref_std': 7.2801}, 'criterion': {'heatmap': {'type': 'WeightedMSECriterion', 'weight': 1.0}, 'locref': {'type': 'WeightedHuberCriterion', 'weight': 0.05}}, 'heatmap_config': {'channels': [2048, 11], 'kernel_size': [3], 'strides': [2]}, 'locref_config': {'channels': [2048, 22], 'kernel_size': [3], 'strides': [2]}}}}, 'net_type': 'resnet_50', 'runner': {'type': 'PoseTrainingRunner', 'gpus': None, 'key_metric': 'test.mAP', 'key_metric_asc': True, 'eval_interval': 10, 'optimizer': {'type': 'AdamW', 'params': {'lr': 0.0001}}, 'scheduler': {'type': 'LRListScheduler', 'params': {'lr_list': [[1e-05], [1e-06]], 'milestones': [160, 190]}}, 'snapshots': {'max_snapshots': 5, 'save_epochs': 25, 'save_optimizer_state': False}}, 'train_settings': {'batch_size': 8, 'dataloader_workers': 0, 'dataloader_pin_memory': True, 'display_iters': 500, 'epochs': 263, 'seed': 42}, 'logger': {'type': 'WandbLogger', 'image_log_interval': 5, 'project_name': 'VentralGait', 'run_name': 'Resnet50_shuffle1003'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/dlclive/utils.py:102: DLCLiveWarning: Image has 4 dimensions. Must be 2 or 3 dimensions to convert to RGB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built pose model\n",
      "Loaded pretrained weights\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bodypart': {'poses': tensor([[[[154.2043, 161.3112,   0.8873],\n",
       "            [147.9084, 158.5554,   0.9155],\n",
       "            [150.8357, 149.1477,   0.8884],\n",
       "            [197.5319, 136.8985,   0.7463],\n",
       "            [207.2083, 172.4100,   0.7087],\n",
       "            [347.4321,  82.7715,   0.5223],\n",
       "            [325.0685, 151.2422,   0.7177],\n",
       "            [240.7299, 111.9966,   0.6632],\n",
       "            [260.4596, 127.7886,   0.6071],\n",
       "            [255.7202, 154.3601,   0.8126],\n",
       "            [385.4895, 112.8712,   0.7605]]]], grad_fn=<CopySlices>)}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc_proc = Processor()\n",
    "#Dikra\n",
    "#dlc_live = DLCLive(pytorch_cfg=\"/media1/data/dikra/fly-kevin\", processor=dlc_proc, snapshot='/media1/data/dikra/fly-kevin/snapshot-100.pt', model_type='onnx')\n",
    "#img = cv2.imread(\"/media1/data/dikra/fly-kevin/img001.png\")\n",
    "#img = img / 255.0\n",
    "#img = np.array(img, dtype=np.float32)\n",
    "#img = img.reshape(1, 3, 540, 682)\n",
    "\n",
    "# Anna\n",
    "\n",
    "#using PyTorch .pt files\n",
    "#dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "#using onnx\n",
    "dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt', model_type='pytorch') #change model type to 'pytorch' for raw .pt model\n",
    "img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/img0006.png\")\n",
    "\n",
    "#these should be adjusted to your image properties\n",
    "\n",
    "#normalization of color channels\n",
    "img = img / 255.0\n",
    "\n",
    "#convert to format float\n",
    "img = np.array(img, dtype=np.float32)\n",
    "\n",
    "#print(img)\n",
    "#print(img.shape)\n",
    "\n",
    "img = np.transpose(img,(2,0,1))\n",
    "img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n",
    "print(img.shape)\n",
    "\n",
    "pose = dlc_live.init_inference(frame=img)\n",
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.00095348, 0.00086121, 0.00089196, ..., 0.00092272,\n",
       "          0.00078431, 0.00078431],\n",
       "         [0.00096886, 0.00087659, 0.00089196, ..., 0.00101499,\n",
       "          0.00092272, 0.00092272],\n",
       "         [0.00081507, 0.00076894, 0.00079969, ..., 0.00124567,\n",
       "          0.00118416, 0.00118416],\n",
       "         ...,\n",
       "         [0.00089196, 0.00089196, 0.00084583, ..., 0.0009381 ,\n",
       "          0.00092272, 0.00090734],\n",
       "         [0.00090734, 0.00090734, 0.00087659, ..., 0.00083045,\n",
       "          0.00079969, 0.00078431],\n",
       "         [0.00090734, 0.00090734, 0.00087659, ..., 0.00079969,\n",
       "          0.00079969, 0.00078431]],\n",
       "\n",
       "        [[0.00116878, 0.00107651, 0.00110727, ..., 0.0011534 ,\n",
       "          0.00104575, 0.00104575],\n",
       "         [0.00118416, 0.00109189, 0.00110727, ..., 0.00124567,\n",
       "          0.00118416, 0.00118416],\n",
       "         [0.00099962, 0.00095348, 0.00101499, ..., 0.00152249,\n",
       "          0.00149173, 0.00149173],\n",
       "         ...,\n",
       "         [0.00112265, 0.00112265, 0.00110727, ..., 0.00104575,\n",
       "          0.00107651, 0.00106113],\n",
       "         [0.00113802, 0.00113802, 0.00113802, ..., 0.0009381 ,\n",
       "          0.00092272, 0.00090734],\n",
       "         [0.00113802, 0.00113802, 0.00113802, ..., 0.00090734,\n",
       "          0.00092272, 0.00090734]],\n",
       "\n",
       "        [[0.00096886, 0.00087659, 0.00090734, ..., 0.00079969,\n",
       "          0.00076894, 0.00076894],\n",
       "         [0.00098424, 0.00089196, 0.00090734, ..., 0.00089196,\n",
       "          0.00090734, 0.00090734],\n",
       "         [0.00079969, 0.00075356, 0.00081507, ..., 0.00113802,\n",
       "          0.00119954, 0.00119954],\n",
       "         ...,\n",
       "         [0.00084583, 0.00084583, 0.00083045, ..., 0.00083045,\n",
       "          0.00081507, 0.00079969],\n",
       "         [0.00086121, 0.00086121, 0.00086121, ..., 0.0007228 ,\n",
       "          0.00066128, 0.00064591],\n",
       "         [0.00086121, 0.00086121, 0.00086121, ..., 0.00069204,\n",
       "          0.00066128, 0.00064591]]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = (img /255.0)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodypart': {'poses': tensor([[[[154.2043, 161.3112,   0.8873],\n",
       "            [147.9084, 158.5554,   0.9155],\n",
       "            [150.8357, 149.1477,   0.8884],\n",
       "            [197.5319, 136.8985,   0.7463],\n",
       "            [207.2083, 172.4100,   0.7087],\n",
       "            [347.4321,  82.7715,   0.5223],\n",
       "            [325.0685, 151.2422,   0.7177],\n",
       "            [240.7299, 111.9966,   0.6632],\n",
       "            [260.4596, 127.7886,   0.6071],\n",
       "            [255.7202, 154.3601,   0.8126],\n",
       "            [385.4895, 112.8712,   0.7605]]]], grad_fn=<CopySlices>)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to allow it to run on CPU not just GPU, it transforms from a tensor to a plain np \n",
    "pose = pose['bodypart']['poses'].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = pose.reshape((-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/img0006.png\")\n",
    "\n",
    "display = Display()\n",
    "display.set_display(im_size=(img.shape[1],img.shape[2],img.shape[0]), bodyparts=11)\n",
    "display.display_frame(img, pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "display.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
