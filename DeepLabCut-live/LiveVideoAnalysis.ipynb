{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate model if it does not yet exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In case you do not have a .onnx model exported, use this cell to export your DLC3.0 snapshot\n",
    "\n",
    "# from dlclive import DLCLive\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# import time\n",
    "\n",
    "# from deeplabcut.pose_estimation_pytorch.config import read_config_as_dict\n",
    "# from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "# import torch\n",
    "# import onnxruntime as ort\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# #Anna\n",
    "# root = Path(\"/Users/annastuckert/Downloads/Hand-AnnaStuckert-2024-08-21/dlc-models-pytorch/iteration-0/HandAug21-trainset95shuffle101/train\")\n",
    "# model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "# weights_path = root / \"snapshot-200.pt\"\n",
    "\n",
    "# model = PoseModel.build(model_cfg[\"model\"])\n",
    "# weights = torch.load(weights_path, map_location=device)\n",
    "# model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "# dummy_input = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     dummy_input,\n",
    "#     \"/Users/annastuckert/Downloads/Hand-AnnaStuckert-2024-08-21/dlc-models-pytorch/iteration-0/HandAug21-trainset95shuffle101/train/resnet.onnx\",\n",
    "#     verbose=False,\n",
    "#     input_names=[\"input\"],\n",
    "#     dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}},\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run live video inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Adding stopping mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import colorcet as cc\n",
    "import cv2\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import ImageColor\n",
    "\n",
    "\n",
    "def analyze_live_video(\n",
    "    dlc_live,\n",
    "    camera: float = 0,\n",
    "    experiment_name: str = \"Test\",\n",
    "    pcutoff=0.5,\n",
    "    display_radius=5,\n",
    "    resize=None,\n",
    "    save_poses=False,\n",
    "    save_dir=\"model_predictions\",\n",
    "    draw_keypoint_names=False,\n",
    "    cmap=\"bmy\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze a video to track keypoints using an imported DeepLabCut model, visualize keypoints on the video, and optionally save the keypoint data and the labelled video.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dlc_live : DLCLive\n",
    "        An instance of the DLCLive class.\n",
    "    camera : float, deafult=0 (webcam)\n",
    "        The camera to record the live video from\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    pcutoff : float, optional, default=0.5\n",
    "        The probability cutoff value below which keypoints are not visualized.\n",
    "    display_radius : int, optional, default=5\n",
    "        The radius of the circles drawn to represent keypoints on the video frames.\n",
    "    resize : tuple of int (width, height) or None, optional, default=None\n",
    "        The size to which the frames should be resized. If None, the frames are not resized.\n",
    "    save_poses : bool, optional, default=False\n",
    "        Whether to save the detected poses to CSV and HDF5 files.\n",
    "    save_dir : str, optional, default=\"model_predictions\"\n",
    "        The directory where the output video and pose data will be saved.\n",
    "    draw_keypoint_names : bool, optional, default=False\n",
    "        Whether to draw the names of the keypoints on the video frames.\n",
    "    cmap : str, optional, default=\"bmy\"\n",
    "        The colormap from the colorcet library to use for keypoint visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "    \"\"\"\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(name=save_dir, exist_ok=True)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    # Start empty dict to save poses to for each frame\n",
    "    poses = []\n",
    "    # Create variable indicate current frame. Later in the code +1 is added to frame_index\n",
    "    frame_index = 0\n",
    "\n",
    "    # Load the DLC model\n",
    "    try:\n",
    "        pose_model = dlc_live.load_model()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load DLC model. Details: {e}\")\n",
    "        return\n",
    "\n",
    "    # Retrieve bodypart names and number of keypoints\n",
    "    bodyparts = dlc_live.cfg[\"metadata\"][\"bodyparts\"]\n",
    "    num_keypoints = len(bodyparts)\n",
    "\n",
    "    # Set colors and convert to RGB\n",
    "    cmap_colors = getattr(cc, cmap)\n",
    "    colors = [\n",
    "        ImageColor.getrgb(color)\n",
    "        for color in cmap_colors[:: int(len(cmap_colors) / num_keypoints)]\n",
    "    ]\n",
    "\n",
    "    # Define output video path\n",
    "    output_video_path = os.path.join(save_dir, f\"{experiment_name}_DLCLIVE_LABELLED.mp4\")\n",
    "\n",
    "    # Get video writer setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width, frame_height = (\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "    )\n",
    "\n",
    "    if resize:\n",
    "        frame_width, frame_height = resize\n",
    "    vwriter = cv2.VideoWriter(\n",
    "        filename=output_video_path,\n",
    "        fourcc=fourcc,\n",
    "        fps=fps,\n",
    "        frameSize=(frame_width, frame_height),\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            pose = dlc_live.get_pose(frame, pose_model=pose_model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing frame {frame_index}: {e}\")\n",
    "            continue\n",
    "\n",
    "        poses.append({\"frame\": frame_index, \"pose\": pose})\n",
    "\n",
    "        # Visualize keypoints\n",
    "        this_pose = pose[0][\"poses\"][0][0]\n",
    "        for j in range(this_pose.shape[0]):\n",
    "            if this_pose[j, 2] > pcutoff:\n",
    "                x, y = map(int, this_pose[j, :2])\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    center=(x, y),\n",
    "                    radius=display_radius,\n",
    "                    color=colors[j],\n",
    "                    thickness=-1,\n",
    "                )\n",
    "\n",
    "                if draw_keypoint_names:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text=bodyparts[j],\n",
    "                        org=(x + 10, y),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.5,\n",
    "                        color=colors[j],\n",
    "                        thickness=1,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "        if resize:\n",
    "            frame = cv2.resize(src=frame, dsize=resize)\n",
    "\n",
    "        vwriter.write(image=frame)\n",
    "        frame_index += 1\n",
    "\n",
    "    cap.release()\n",
    "    vwriter.release()\n",
    "\n",
    "    if save_poses:\n",
    "        save_poses_to_files(experiment_name, save_dir, bodyparts, poses)\n",
    "\n",
    "    return poses\n",
    "\n",
    "\n",
    "def save_poses_to_files(experiment_name, save_dir, bodyparts, poses):\n",
    "    \"\"\"\n",
    "    Save the keypoint poses detected in the video to CSV and HDF5 files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    save_dir : str\n",
    "        The directory where the pose data files will be saved.\n",
    "    bodyparts : list of str\n",
    "        A list of body part names corresponding to the keypoints.\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    base_filename = os.path.splitext(os.path.basename(experiment_name))[0]\n",
    "    csv_save_path = os.path.join(save_dir, f\"{base_filename}_poses.csv\")\n",
    "    h5_save_path = os.path.join(save_dir, f\"{base_filename}_poses.h5\")\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(csv_save_path, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        header = [\"frame\"] + [\n",
    "            f\"{bp}_{axis}\" for bp in bodyparts for axis in [\"x\", \"y\", \"confidence\"]\n",
    "        ]\n",
    "        writer.writerow(header)\n",
    "        for entry in poses:\n",
    "            frame_num = entry[\"frame\"]\n",
    "            pose = entry[\"pose\"][\"poses\"][0][0]\n",
    "            row = [frame_num] + [item for kp in pose for item in kp]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Save to HDF5\n",
    "    with h5py.File(h5_save_path, \"w\") as hf:\n",
    "        hf.create_dataset(name=\"frames\", data=[entry[\"frame\"] for entry in poses])\n",
    "        for i, bp in enumerate(bodyparts):\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_x\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 0].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_y\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 1].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_confidence\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 2].item() for entry in poses],\n",
    "            )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive\n",
    "\n",
    "dlc_live = DLCLive(\n",
    "    path=\"/Users/annastuckert/Downloads/Hand-AnnaStuckert-2024-08-21/dlc-models-pytorch/iteration-0/HandAug21-trainset95shuffle101/train\",\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cpu\",\n",
    "    display=True,\n",
    ")\n",
    "#short video\n",
    "#video_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/1_20cms_0degUP_first_1s.avi'\n",
    "#working_directory =\n",
    "#providing output directory\n",
    "poses = analyze_live_video(dlc_live=dlc_live, camera=0, save_poses=True, save_dir='output_directory', draw_keypoint_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it until you press Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import h5py\n",
    "import colorcet as cc\n",
    "import numpy as np\n",
    "from PIL import ImageColor\n",
    "\n",
    "\n",
    "def analyze_live_video(\n",
    "    dlc_live,\n",
    "    camera: float = 0,\n",
    "    experiment_name: str = \"Test\",\n",
    "    pcutoff=0.5,\n",
    "    display_radius=5,\n",
    "    resize=None,\n",
    "    save_poses=False,\n",
    "    save_dir=\"model_predictions\",\n",
    "    draw_keypoint_names=False,\n",
    "    cmap=\"bmy\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze a video to track keypoints using an imported DeepLabCut model, visualize keypoints on the video, and optionally save the keypoint data and the labelled video.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dlc_live : DLCLive\n",
    "        An instance of the DLCLive class.\n",
    "    camera : float, default=0 (webcam)\n",
    "        The camera to record the live video from\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    pcutoff : float, optional, default=0.5\n",
    "        The probability cutoff value below which keypoints are not visualized.\n",
    "    display_radius : int, optional, default=5\n",
    "        The radius of the circles drawn to represent keypoints on the video frames.\n",
    "    resize : tuple of int (width, height) or None, optional, default=None\n",
    "        The size to which the frames should be resized. If None, the frames are not resized.\n",
    "    save_poses : bool, optional, default=False\n",
    "        Whether to save the detected poses to CSV and HDF5 files.\n",
    "    save_dir : str, optional, default=\"model_predictions\"\n",
    "        The directory where the output video and pose data will be saved.\n",
    "    draw_keypoint_names : bool, optional, default=False\n",
    "        Whether to draw the names of the keypoints on the video frames.\n",
    "    cmap : str, optional, default=\"bmy\"\n",
    "        The colormap from the colorcet library to use for keypoint visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "    \"\"\"\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(name=save_dir, exist_ok=True)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video source {camera}\")\n",
    "        return\n",
    "\n",
    "    # Define output video path\n",
    "    output_video_path = os.path.join(save_dir, f\"{experiment_name}_DLCLIVE_LABELLED.mp4\")\n",
    "\n",
    "    # Get video writer setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width, frame_height = (\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "    )\n",
    "\n",
    "    if resize:\n",
    "        frame_width, frame_height = resize\n",
    "\n",
    "    vwriter = cv2.VideoWriter(\n",
    "        filename=output_video_path,\n",
    "        fourcc=fourcc,\n",
    "        fps=fps,\n",
    "        frameSize=(frame_width, frame_height),\n",
    "    )\n",
    "\n",
    "    # Load the DLC model\n",
    "    try:\n",
    "        pose_model = dlc_live.load_model()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load DLC model. Details: {e}\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Retrieve bodypart names and number of keypoints\n",
    "    bodyparts = dlc_live.cfg[\"metadata\"][\"bodyparts\"]\n",
    "    num_keypoints = len(bodyparts)\n",
    "\n",
    "    # Set colors and convert to RGB\n",
    "    cmap_colors = getattr(cc, cmap)\n",
    "    colors = [\n",
    "        ImageColor.getrgb(color)\n",
    "        for color in cmap_colors[:: int(len(cmap_colors) / num_keypoints)]\n",
    "    ]\n",
    "\n",
    "    poses = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            pose = dlc_live.get_pose(frame, pose_model=pose_model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing frame {len(poses)}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Log inference time\n",
    "        inference_time = time.time() - start_time\n",
    "        print(f\"Frame {len(poses)} processed in {inference_time:.2f} seconds.\")\n",
    "\n",
    "        poses.append({\"frame\": len(poses), \"pose\": pose})\n",
    "\n",
    "        # Visualize keypoints\n",
    "        this_pose = pose[0][\"poses\"][0][0]\n",
    "        for j in range(this_pose.shape[0]):\n",
    "            if this_pose[j, 2] > pcutoff:\n",
    "                x, y = map(int, this_pose[j, :2])\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    center=(x, y),\n",
    "                    radius=display_radius,\n",
    "                    color=colors[j],\n",
    "                    thickness=-1,\n",
    "                )\n",
    "\n",
    "                if draw_keypoint_names:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text=bodyparts[j],\n",
    "                        org=(x + 10, y),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.5,\n",
    "                        color=colors[j],\n",
    "                        thickness=1,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "        if resize:\n",
    "            frame = cv2.resize(src=frame, dsize=resize)\n",
    "\n",
    "        vwriter.write(image=frame)\n",
    "\n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('Live Inference', frame)\n",
    "\n",
    "        # Check if 'q' key was pressed to stop recording\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Video capture stopped by user.\")\n",
    "            break\n",
    "\n",
    "    # Release resources properly\n",
    "    cap.release()\n",
    "    vwriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if save_poses:\n",
    "        save_poses_to_files(experiment_name, save_dir, bodyparts, poses)\n",
    "\n",
    "    print(\"Analysis done.\")\n",
    "    return poses\n",
    "\n",
    "\n",
    "def save_poses_to_files(experiment_name, save_dir, bodyparts, poses):\n",
    "    \"\"\"\n",
    "    Save the keypoint poses detected in the video to CSV and HDF5 files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    save_dir : str\n",
    "        The directory where the pose data files will be saved.\n",
    "    bodyparts : list of str\n",
    "        A list of body part names corresponding to the keypoints.\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    base_filename = os.path.splitext(os.path.basename(experiment_name))[0]\n",
    "    csv_save_path = os.path.join(save_dir, f\"{base_filename}_poses.csv\")\n",
    "    h5_save_path = os.path.join(save_dir, f\"{base_filename}_poses.h5\")\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(csv_save_path, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        header = [\"frame\"] + [\n",
    "            f\"{bp}_{axis}\" for bp in bodyparts for axis in [\"x\", \"y\", \"confidence\"]\n",
    "        ]\n",
    "        writer.writerow(header)\n",
    "        for entry in poses:\n",
    "            frame_num = entry[\"frame\"]\n",
    "            pose = entry[\"pose\"][0][\"poses\"][0][0]\n",
    "            row = [frame_num] + [item for kp in pose for item in kp]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Save to HDF5\n",
    "    with h5py.File(h5_save_path, \"w\") as hf:\n",
    "        hf.create_dataset(name=\"frames\", data=[entry[\"frame\"] for entry in poses])\n",
    "        for i, bp in enumerate(bodyparts):\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_x\",\n",
    "                data=[entry[\"pose\"][0][\"poses\"][0][0][i, 0].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_y\",\n",
    "                data=[entry[\"pose\"][0][\"poses\"][0][0][i, 1].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_confidence\",\n",
    "                data=[entry[\"pose\"][0][\"poses\"][0][0][i, 2].item() for entry in poses],\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run it for 1 second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import h5py\n",
    "import colorcet as cc\n",
    "import numpy as np\n",
    "from PIL import ImageColor\n",
    "import cProfile\n",
    "import pstats\n",
    "from dlclive import DLCLive\n",
    "\n",
    "\n",
    "def analyze_live_video(\n",
    "    dlc_live,\n",
    "    camera: float = 0,\n",
    "    experiment_name: str = \"Test\",\n",
    "    pcutoff=0.5,\n",
    "    display_radius=5,\n",
    "    resize=None,\n",
    "    save_poses=False,\n",
    "    save_dir=\"model_predictions\",\n",
    "    draw_keypoint_names=False,\n",
    "    cmap=\"bmy\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze a video to track keypoints using an imported DeepLabCut model, visualize keypoints on the video, and optionally save the keypoint data and the labelled video.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dlc_live : DLCLive\n",
    "        An instance of the DLCLive class.\n",
    "    camera : float, default=0 (webcam)\n",
    "        The camera to record the live video from\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    pcutoff : float, optional, default=0.5\n",
    "        The probability cutoff value below which keypoints are not visualized.\n",
    "    display_radius : int, optional, default=5\n",
    "        The radius of the circles drawn to represent keypoints on the video frames.\n",
    "    resize : tuple of int (width, height) or None, optional, default=None\n",
    "        The size to which the frames should be resized. If None, the frames are not resized.\n",
    "    save_poses : bool, optional, default=False\n",
    "        Whether to save the detected poses to CSV and HDF5 files.\n",
    "    save_dir : str, optional, default=\"model_predictions\"\n",
    "        The directory where the output video and pose data will be saved.\n",
    "    draw_keypoint_names : bool, optional, default=False\n",
    "        Whether to draw the names of the keypoints on the video frames.\n",
    "    cmap : str, optional, default=\"bmy\"\n",
    "        The colormap from the colorcet library to use for keypoint visualization.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "    \"\"\"\n",
    "    # Ensure save directory exists\n",
    "    os.makedirs(name=save_dir, exist_ok=True)\n",
    "\n",
    "    # Load video\n",
    "    cap = cv2.VideoCapture(camera)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video source {camera}\")\n",
    "        return\n",
    "\n",
    "    # Define output video path\n",
    "    output_video_path = os.path.join(save_dir, f\"{experiment_name}_DLCLIVE_LABELLED.mp4\")\n",
    "\n",
    "    # Get video writer setup\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width, frame_height = (\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
    "    )\n",
    "\n",
    "    if resize:\n",
    "        frame_width, frame_height = resize\n",
    "\n",
    "    vwriter = cv2.VideoWriter(\n",
    "        filename=output_video_path,\n",
    "        fourcc=fourcc,\n",
    "        fps=fps,\n",
    "        frameSize=(frame_width, frame_height),\n",
    "    )\n",
    "\n",
    "    # Load the DLC model\n",
    "    try:\n",
    "        pose_model = dlc_live.load_model()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not load DLC model. Details: {e}\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    # Retrieve bodypart names and number of keypoints\n",
    "    bodyparts = dlc_live.cfg[\"metadata\"][\"bodyparts\"]\n",
    "    num_keypoints = len(bodyparts)\n",
    "\n",
    "    # Set colors and convert to RGB\n",
    "    cmap_colors = getattr(cc, cmap)\n",
    "    colors = [\n",
    "        ImageColor.getrgb(color)\n",
    "        for color in cmap_colors[:: int(len(cmap_colors) / num_keypoints)]\n",
    "    ]\n",
    "\n",
    "    poses = []\n",
    "    frames = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Capture the frame and store it\n",
    "        frames.append(frame.copy())\n",
    "\n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        if elapsed_time > 1.0:  # Stop capturing after 1 second\n",
    "            print(\"Recording stopped after 1 second.\")\n",
    "            break\n",
    "\n",
    "        # Display the frame (optional)\n",
    "        cv2.imshow('Recording...', frame)\n",
    "\n",
    "        # Check if 'q' key was pressed to stop recording early\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Video capture stopped by user.\")\n",
    "            break\n",
    "\n",
    "    # Release the video capture resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Start profiling the processing of frames\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "\n",
    "    # Process the captured frames\n",
    "    for i, frame in enumerate(frames):\n",
    "        try:\n",
    "            pose = dlc_live.get_pose(frame, pose_model=pose_model)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing frame {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "        poses.append({\"frame\": i, \"pose\": pose})\n",
    "\n",
    "        # Visualize keypoints\n",
    "        this_pose = pose[\"poses\"][0][0]\n",
    "        for j in range(this_pose.shape[0]):\n",
    "            if this_pose[j, 2] > pcutoff:\n",
    "                x, y = map(int, this_pose[j, :2])\n",
    "                cv2.circle(\n",
    "                    frame,\n",
    "                    center=(x, y),\n",
    "                    radius=display_radius,\n",
    "                    color=colors[j],\n",
    "                    thickness=-1,\n",
    "                )\n",
    "\n",
    "                if draw_keypoint_names:\n",
    "                    cv2.putText(\n",
    "                        frame,\n",
    "                        text=bodyparts[j],\n",
    "                        org=(x + 10, y),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=0.5,\n",
    "                        color=colors[j],\n",
    "                        thickness=1,\n",
    "                        lineType=cv2.LINE_AA,\n",
    "                    )\n",
    "\n",
    "        if resize:\n",
    "            frame = cv2.resize(src=frame, dsize=resize)\n",
    "\n",
    "        vwriter.write(image=frame)\n",
    "\n",
    "    # Stop profiling\n",
    "    profiler.disable()\n",
    "\n",
    "    # Release the video writer resources\n",
    "    vwriter.release()\n",
    "\n",
    "    if save_poses:\n",
    "        save_poses_to_files(experiment_name, save_dir, bodyparts, poses)\n",
    "\n",
    "    print(\"Analysis done.\")\n",
    "\n",
    "    # Print profiling results\n",
    "    profiler.print_stats(sort='cumtime')\n",
    "\n",
    "    return poses\n",
    "\n",
    "\n",
    "def save_poses_to_files(experiment_name, save_dir, bodyparts, poses):\n",
    "    \"\"\"\n",
    "    Save the keypoint poses detected in the video to CSV and HDF5 files.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    experiment_name : str, default = \"Test\"\n",
    "        Prefix to label generated pose and video files\n",
    "    save_dir : str\n",
    "        The directory where the pose data files will be saved.\n",
    "    bodyparts : list of str\n",
    "        A list of body part names corresponding to the keypoints.\n",
    "    poses : list of dict\n",
    "        A list of dictionaries where each dictionary contains the frame number and the corresponding pose data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    base_filename = os.path.splitext(os.path.basename(experiment_name))[0]\n",
    "    csv_save_path = os.path.join(save_dir, f\"{base_filename}_poses.csv\")\n",
    "    h5_save_path = os.path.join(save_dir, f\"{base_filename}_poses.h5\")\n",
    "\n",
    "    # Save to CSV\n",
    "    with open(csv_save_path, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        header = [\"frame\"] + [\n",
    "            f\"{bp}_{axis}\" for bp in bodyparts for axis in [\"x\", \"y\", \"confidence\"]\n",
    "        ]\n",
    "        writer.writerow(header)\n",
    "        for entry in poses:\n",
    "            frame_num = entry[\"frame\"]\n",
    "            pose = entry[\"pose\"][\"poses\"][0][0]\n",
    "            row = [frame_num] + [item for kp in pose for item in kp]\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Save to HDF5\n",
    "    with h5py.File(h5_save_path, \"w\") as hf:\n",
    "        hf.create_dataset(name=\"frames\", data=[entry[\"frame\"] for entry in poses])\n",
    "        for i, bp in enumerate(bodyparts):\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_x\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 0].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_y\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 1].item() for entry in poses],\n",
    "            )\n",
    "            hf.create_dataset(\n",
    "                name=f\"{bp}_confidence\",\n",
    "                data=[entry[\"pose\"][\"poses\"][0][0][i, 2].item() for entry in poses],\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<onnxruntime.capi.onnxruntime_inference_collection.InferenceSession object at 0x73cd92b08640>\n",
      "ONNX inference took 1.5418674945831299 sec\n",
      "ONNX postprocessing took 0.0056896209716796875 sec\n",
      "Frame 0 processed in 1.55 seconds.\n",
      "ONNX inference took 0.03749585151672363 sec\n",
      "ONNX postprocessing took 0.0007803440093994141 sec\n",
      "Frame 1 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03699326515197754 sec\n",
      "ONNX postprocessing took 0.0008795261383056641 sec\n",
      "Frame 2 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03663921356201172 sec\n",
      "ONNX postprocessing took 0.0009176731109619141 sec\n",
      "Frame 3 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03860664367675781 sec\n",
      "ONNX postprocessing took 0.0008058547973632812 sec\n",
      "Frame 4 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03636765480041504 sec\n",
      "ONNX postprocessing took 0.0007786750793457031 sec\n",
      "Frame 5 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03655385971069336 sec\n",
      "ONNX postprocessing took 0.0010945796966552734 sec\n",
      "Frame 6 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03727269172668457 sec\n",
      "ONNX postprocessing took 0.0011124610900878906 sec\n",
      "Frame 7 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0389857292175293 sec\n",
      "ONNX postprocessing took 0.00903630256652832 sec\n",
      "Frame 8 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04139065742492676 sec\n",
      "ONNX postprocessing took 0.007117509841918945 sec\n",
      "Frame 9 processed in 0.05 seconds.\n",
      "ONNX inference took 0.038477420806884766 sec\n",
      "ONNX postprocessing took 0.001127481460571289 sec\n",
      "Frame 10 processed in 0.04 seconds.\n",
      "ONNX inference took 0.038543701171875 sec\n",
      "ONNX postprocessing took 0.009186744689941406 sec\n",
      "Frame 11 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03843951225280762 sec\n",
      "ONNX postprocessing took 0.002106904983520508 sec\n",
      "Frame 12 processed in 0.04 seconds.\n",
      "ONNX inference took 0.047734737396240234 sec\n",
      "ONNX postprocessing took 0.0014307498931884766 sec\n",
      "Frame 13 processed in 0.06 seconds.\n",
      "ONNX inference took 0.04150986671447754 sec\n",
      "ONNX postprocessing took 0.009211301803588867 sec\n",
      "Frame 14 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039772987365722656 sec\n",
      "ONNX postprocessing took 0.006652355194091797 sec\n",
      "Frame 15 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04271864891052246 sec\n",
      "ONNX postprocessing took 0.008354902267456055 sec\n",
      "Frame 16 processed in 0.05 seconds.\n",
      "ONNX inference took 0.036524057388305664 sec\n",
      "ONNX postprocessing took 0.0013217926025390625 sec\n",
      "Frame 17 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03919410705566406 sec\n",
      "ONNX postprocessing took 0.0018908977508544922 sec\n",
      "Frame 18 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04114127159118652 sec\n",
      "ONNX postprocessing took 0.020348072052001953 sec\n",
      "Frame 19 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03945326805114746 sec\n",
      "ONNX postprocessing took 0.0011453628540039062 sec\n",
      "Frame 20 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03960394859313965 sec\n",
      "ONNX postprocessing took 0.007069826126098633 sec\n",
      "Frame 21 processed in 0.05 seconds.\n",
      "ONNX inference took 0.0372157096862793 sec\n",
      "ONNX postprocessing took 0.0010464191436767578 sec\n",
      "Frame 22 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03872227668762207 sec\n",
      "ONNX postprocessing took 0.004001140594482422 sec\n",
      "Frame 23 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040699005126953125 sec\n",
      "ONNX postprocessing took 0.0045506954193115234 sec\n",
      "Frame 24 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04034566879272461 sec\n",
      "ONNX postprocessing took 0.001226186752319336 sec\n",
      "Frame 25 processed in 0.04 seconds.\n",
      "ONNX inference took 0.038747549057006836 sec\n",
      "ONNX postprocessing took 0.002089977264404297 sec\n",
      "Frame 26 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03645133972167969 sec\n",
      "ONNX postprocessing took 0.0010709762573242188 sec\n",
      "Frame 27 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03779888153076172 sec\n",
      "ONNX postprocessing took 0.0030918121337890625 sec\n",
      "Frame 28 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040555477142333984 sec\n",
      "ONNX postprocessing took 0.004364967346191406 sec\n",
      "Frame 29 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04123377799987793 sec\n",
      "ONNX postprocessing took 0.003080129623413086 sec\n",
      "Frame 30 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040130615234375 sec\n",
      "ONNX postprocessing took 0.0014944076538085938 sec\n",
      "Frame 31 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04048800468444824 sec\n",
      "ONNX postprocessing took 0.004672527313232422 sec\n",
      "Frame 32 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03887033462524414 sec\n",
      "ONNX postprocessing took 0.0011463165283203125 sec\n",
      "Frame 33 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03887581825256348 sec\n",
      "ONNX postprocessing took 0.008913993835449219 sec\n",
      "Frame 34 processed in 0.05 seconds.\n",
      "ONNX inference took 0.038768768310546875 sec\n",
      "ONNX postprocessing took 0.0008561611175537109 sec\n",
      "Frame 35 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03727412223815918 sec\n",
      "ONNX postprocessing took 0.0014660358428955078 sec\n",
      "Frame 36 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0402684211730957 sec\n",
      "ONNX postprocessing took 0.003742694854736328 sec\n",
      "Frame 37 processed in 0.05 seconds.\n",
      "ONNX inference took 0.041466474533081055 sec\n",
      "ONNX postprocessing took 0.011270284652709961 sec\n",
      "Frame 38 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03664278984069824 sec\n",
      "ONNX postprocessing took 0.0013012886047363281 sec\n",
      "Frame 39 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03766202926635742 sec\n",
      "ONNX postprocessing took 0.0011849403381347656 sec\n",
      "Frame 40 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03783464431762695 sec\n",
      "ONNX postprocessing took 0.0020596981048583984 sec\n",
      "Frame 41 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04463505744934082 sec\n",
      "ONNX postprocessing took 0.00811624526977539 sec\n",
      "Frame 42 processed in 0.06 seconds.\n",
      "ONNX inference took 0.0401308536529541 sec\n",
      "ONNX postprocessing took 0.0025947093963623047 sec\n",
      "Frame 43 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040456295013427734 sec\n",
      "ONNX postprocessing took 0.008085966110229492 sec\n",
      "Frame 44 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03917503356933594 sec\n",
      "ONNX postprocessing took 0.0010676383972167969 sec\n",
      "Frame 45 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0398409366607666 sec\n",
      "ONNX postprocessing took 0.010558128356933594 sec\n",
      "Frame 46 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03669095039367676 sec\n",
      "ONNX postprocessing took 0.0012962818145751953 sec\n",
      "Frame 47 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03751635551452637 sec\n",
      "ONNX postprocessing took 0.001058816909790039 sec\n",
      "Frame 48 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03668403625488281 sec\n",
      "ONNX postprocessing took 0.0010905265808105469 sec\n",
      "Frame 49 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03853583335876465 sec\n",
      "ONNX postprocessing took 0.0020399093627929688 sec\n",
      "Frame 50 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040210723876953125 sec\n",
      "ONNX postprocessing took 0.009672164916992188 sec\n",
      "Frame 51 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04007291793823242 sec\n",
      "ONNX postprocessing took 0.0016515254974365234 sec\n",
      "Frame 52 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040224313735961914 sec\n",
      "ONNX postprocessing took 0.0008959770202636719 sec\n",
      "Frame 53 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03633546829223633 sec\n",
      "ONNX postprocessing took 0.0008912086486816406 sec\n",
      "Frame 54 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04076671600341797 sec\n",
      "ONNX postprocessing took 0.0027430057525634766 sec\n",
      "Frame 55 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04016757011413574 sec\n",
      "ONNX postprocessing took 0.008400201797485352 sec\n",
      "Frame 56 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03893327713012695 sec\n",
      "ONNX postprocessing took 0.004138469696044922 sec\n",
      "Frame 57 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04154372215270996 sec\n",
      "ONNX postprocessing took 0.0009083747863769531 sec\n",
      "Frame 58 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03728985786437988 sec\n",
      "ONNX postprocessing took 0.001336812973022461 sec\n",
      "Frame 59 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03900504112243652 sec\n",
      "ONNX postprocessing took 0.003116607666015625 sec\n",
      "Frame 60 processed in 0.04 seconds.\n",
      "ONNX inference took 0.041513681411743164 sec\n",
      "ONNX postprocessing took 0.0018661022186279297 sec\n",
      "Frame 61 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03674888610839844 sec\n",
      "ONNX postprocessing took 0.0010936260223388672 sec\n",
      "Frame 62 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03770732879638672 sec\n",
      "ONNX postprocessing took 0.0017311573028564453 sec\n",
      "Frame 63 processed in 0.04 seconds.\n",
      "ONNX inference took 0.039923667907714844 sec\n",
      "ONNX postprocessing took 0.010341167449951172 sec\n",
      "Frame 64 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04052114486694336 sec\n",
      "ONNX postprocessing took 0.0028383731842041016 sec\n",
      "Frame 65 processed in 0.05 seconds.\n",
      "ONNX inference took 0.037706613540649414 sec\n",
      "ONNX postprocessing took 0.001252889633178711 sec\n",
      "Frame 66 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03724312782287598 sec\n",
      "ONNX postprocessing took 0.0029168128967285156 sec\n",
      "Frame 67 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04060101509094238 sec\n",
      "ONNX postprocessing took 0.004233837127685547 sec\n",
      "Frame 68 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04012036323547363 sec\n",
      "ONNX postprocessing took 0.0019752979278564453 sec\n",
      "Frame 69 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03804373741149902 sec\n",
      "ONNX postprocessing took 0.0008490085601806641 sec\n",
      "Frame 70 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03729081153869629 sec\n",
      "ONNX postprocessing took 0.002031564712524414 sec\n",
      "Frame 71 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03896641731262207 sec\n",
      "ONNX postprocessing took 0.0037078857421875 sec\n",
      "Frame 72 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04137778282165527 sec\n",
      "ONNX postprocessing took 0.009582996368408203 sec\n",
      "Frame 73 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04172658920288086 sec\n",
      "ONNX postprocessing took 0.0035462379455566406 sec\n",
      "Frame 74 processed in 0.05 seconds.\n",
      "ONNX inference took 0.0379786491394043 sec\n",
      "ONNX postprocessing took 0.0012302398681640625 sec\n",
      "Frame 75 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03739666938781738 sec\n",
      "ONNX postprocessing took 0.0007989406585693359 sec\n",
      "Frame 76 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03738260269165039 sec\n",
      "ONNX postprocessing took 0.0009443759918212891 sec\n",
      "Frame 77 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0370783805847168 sec\n",
      "ONNX postprocessing took 0.0008492469787597656 sec\n",
      "Frame 78 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03724813461303711 sec\n",
      "ONNX postprocessing took 0.0008544921875 sec\n",
      "Frame 79 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03672623634338379 sec\n",
      "ONNX postprocessing took 0.0007953643798828125 sec\n",
      "Frame 80 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037853240966796875 sec\n",
      "ONNX postprocessing took 0.0009214878082275391 sec\n",
      "Frame 81 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03729724884033203 sec\n",
      "ONNX postprocessing took 0.0008559226989746094 sec\n",
      "Frame 82 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03665614128112793 sec\n",
      "ONNX postprocessing took 0.0008339881896972656 sec\n",
      "Frame 83 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03656435012817383 sec\n",
      "ONNX postprocessing took 0.00106048583984375 sec\n",
      "Frame 84 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03739476203918457 sec\n",
      "ONNX postprocessing took 0.0032405853271484375 sec\n",
      "Frame 85 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04015684127807617 sec\n",
      "ONNX postprocessing took 0.0017256736755371094 sec\n",
      "Frame 86 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04099130630493164 sec\n",
      "ONNX postprocessing took 0.004792690277099609 sec\n",
      "Frame 87 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04492473602294922 sec\n",
      "ONNX postprocessing took 0.0026400089263916016 sec\n",
      "Frame 88 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03736448287963867 sec\n",
      "ONNX postprocessing took 0.0010225772857666016 sec\n",
      "Frame 89 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03929924964904785 sec\n",
      "ONNX postprocessing took 0.0008320808410644531 sec\n",
      "Frame 90 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03695249557495117 sec\n",
      "ONNX postprocessing took 0.0009567737579345703 sec\n",
      "Frame 91 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0373992919921875 sec\n",
      "ONNX postprocessing took 0.0008463859558105469 sec\n",
      "Frame 92 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03760170936584473 sec\n",
      "ONNX postprocessing took 0.0008456707000732422 sec\n",
      "Frame 93 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036641597747802734 sec\n",
      "ONNX postprocessing took 0.0011119842529296875 sec\n",
      "Frame 94 processed in 0.04 seconds.\n",
      "ONNX inference took 0.039122819900512695 sec\n",
      "ONNX postprocessing took 0.0046596527099609375 sec\n",
      "Frame 95 processed in 0.05 seconds.\n",
      "ONNX inference took 0.048737287521362305 sec\n",
      "ONNX postprocessing took 0.012871503829956055 sec\n",
      "Frame 96 processed in 0.06 seconds.\n",
      "ONNX inference took 0.0393216609954834 sec\n",
      "ONNX postprocessing took 0.0014219284057617188 sec\n",
      "Frame 97 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040522098541259766 sec\n",
      "ONNX postprocessing took 0.004709720611572266 sec\n",
      "Frame 98 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04115581512451172 sec\n",
      "ONNX postprocessing took 0.0013396739959716797 sec\n",
      "Frame 99 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04010415077209473 sec\n",
      "ONNX postprocessing took 0.00817251205444336 sec\n",
      "Frame 100 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03667116165161133 sec\n",
      "ONNX postprocessing took 0.0013890266418457031 sec\n",
      "Frame 101 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03744816780090332 sec\n",
      "ONNX postprocessing took 0.0042765140533447266 sec\n",
      "Frame 102 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040994882583618164 sec\n",
      "ONNX postprocessing took 0.0049266815185546875 sec\n",
      "Frame 103 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04011344909667969 sec\n",
      "ONNX postprocessing took 0.00868082046508789 sec\n",
      "Frame 104 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03914833068847656 sec\n",
      "ONNX postprocessing took 0.0008552074432373047 sec\n",
      "Frame 105 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03659939765930176 sec\n",
      "ONNX postprocessing took 0.001065969467163086 sec\n",
      "Frame 106 processed in 0.04 seconds.\n",
      "ONNX inference took 0.039563655853271484 sec\n",
      "ONNX postprocessing took 0.008090734481811523 sec\n",
      "Frame 107 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04117107391357422 sec\n",
      "ONNX postprocessing took 0.0011167526245117188 sec\n",
      "Frame 108 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04038071632385254 sec\n",
      "ONNX postprocessing took 0.004317522048950195 sec\n",
      "Frame 109 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039168357849121094 sec\n",
      "ONNX postprocessing took 0.0010972023010253906 sec\n",
      "Frame 110 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036847829818725586 sec\n",
      "ONNX postprocessing took 0.0012059211730957031 sec\n",
      "Frame 111 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04006648063659668 sec\n",
      "ONNX postprocessing took 0.010642528533935547 sec\n",
      "Frame 112 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03944802284240723 sec\n",
      "ONNX postprocessing took 0.004030466079711914 sec\n",
      "Frame 113 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03795194625854492 sec\n",
      "ONNX postprocessing took 0.0016646385192871094 sec\n",
      "Frame 114 processed in 0.04 seconds.\n",
      "ONNX inference took 0.041513681411743164 sec\n",
      "ONNX postprocessing took 0.0026199817657470703 sec\n",
      "Frame 115 processed in 0.05 seconds.\n",
      "ONNX inference took 0.0368192195892334 sec\n",
      "ONNX postprocessing took 0.0013744831085205078 sec\n",
      "Frame 116 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03886604309082031 sec\n",
      "ONNX postprocessing took 0.011765003204345703 sec\n",
      "Frame 117 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04100942611694336 sec\n",
      "ONNX postprocessing took 0.008959054946899414 sec\n",
      "Frame 118 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03947162628173828 sec\n",
      "ONNX postprocessing took 0.0010666847229003906 sec\n",
      "Frame 119 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04054903984069824 sec\n",
      "ONNX postprocessing took 0.006969451904296875 sec\n",
      "Frame 120 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03960251808166504 sec\n",
      "ONNX postprocessing took 0.0014657974243164062 sec\n",
      "Frame 121 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0410158634185791 sec\n",
      "ONNX postprocessing took 0.0015931129455566406 sec\n",
      "Frame 122 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04074740409851074 sec\n",
      "ONNX postprocessing took 0.00960397720336914 sec\n",
      "Frame 123 processed in 0.06 seconds.\n",
      "ONNX inference took 0.0380859375 sec\n",
      "ONNX postprocessing took 0.0015511512756347656 sec\n",
      "Frame 124 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040632009506225586 sec\n",
      "ONNX postprocessing took 0.010184526443481445 sec\n",
      "Frame 125 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04562687873840332 sec\n",
      "ONNX postprocessing took 0.001325368881225586 sec\n",
      "Frame 126 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04026341438293457 sec\n",
      "ONNX postprocessing took 0.00854039192199707 sec\n",
      "Frame 127 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03911089897155762 sec\n",
      "ONNX postprocessing took 0.0014019012451171875 sec\n",
      "Frame 128 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0402679443359375 sec\n",
      "ONNX postprocessing took 0.010027647018432617 sec\n",
      "Frame 129 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03992199897766113 sec\n",
      "ONNX postprocessing took 0.00829768180847168 sec\n",
      "Frame 130 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04263019561767578 sec\n",
      "ONNX postprocessing took 0.0011415481567382812 sec\n",
      "Frame 131 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04055619239807129 sec\n",
      "ONNX postprocessing took 0.010303735733032227 sec\n",
      "Frame 132 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04005146026611328 sec\n",
      "ONNX postprocessing took 0.003995180130004883 sec\n",
      "Frame 133 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03983259201049805 sec\n",
      "ONNX postprocessing took 0.0009310245513916016 sec\n",
      "Frame 134 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03724360466003418 sec\n",
      "ONNX postprocessing took 0.0015482902526855469 sec\n",
      "Frame 135 processed in 0.04 seconds.\n",
      "ONNX inference took 0.043163299560546875 sec\n",
      "ONNX postprocessing took 0.012476682662963867 sec\n",
      "Frame 136 processed in 0.06 seconds.\n",
      "ONNX inference took 0.05127286911010742 sec\n",
      "ONNX postprocessing took 0.003007173538208008 sec\n",
      "Frame 137 processed in 0.06 seconds.\n",
      "ONNX inference took 0.038238525390625 sec\n",
      "ONNX postprocessing took 0.0017962455749511719 sec\n",
      "Frame 138 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04324221611022949 sec\n",
      "ONNX postprocessing took 0.0069653987884521484 sec\n",
      "Frame 139 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03771400451660156 sec\n",
      "ONNX postprocessing took 0.0012285709381103516 sec\n",
      "Frame 140 processed in 0.04 seconds.\n",
      "ONNX inference took 0.042234182357788086 sec\n",
      "ONNX postprocessing took 0.011711597442626953 sec\n",
      "Frame 141 processed in 0.06 seconds.\n",
      "ONNX inference took 0.047713518142700195 sec\n",
      "ONNX postprocessing took 0.010975837707519531 sec\n",
      "Frame 142 processed in 0.06 seconds.\n",
      "ONNX inference took 0.036721229553222656 sec\n",
      "ONNX postprocessing took 0.0011780261993408203 sec\n",
      "Frame 143 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03726959228515625 sec\n",
      "ONNX postprocessing took 0.002081155776977539 sec\n",
      "Frame 144 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04124283790588379 sec\n",
      "ONNX postprocessing took 0.008507966995239258 sec\n",
      "Frame 145 processed in 0.06 seconds.\n",
      "ONNX inference took 0.042023658752441406 sec\n",
      "ONNX postprocessing took 0.0012662410736083984 sec\n",
      "Frame 146 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03677725791931152 sec\n",
      "ONNX postprocessing took 0.0008585453033447266 sec\n",
      "Frame 147 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036496639251708984 sec\n",
      "ONNX postprocessing took 0.0008594989776611328 sec\n",
      "Frame 148 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03624081611633301 sec\n",
      "ONNX postprocessing took 0.0008783340454101562 sec\n",
      "Frame 149 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037363290786743164 sec\n",
      "ONNX postprocessing took 0.0012290477752685547 sec\n",
      "Frame 150 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0395045280456543 sec\n",
      "ONNX postprocessing took 0.005964040756225586 sec\n",
      "Frame 151 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04089784622192383 sec\n",
      "ONNX postprocessing took 0.006093025207519531 sec\n",
      "Frame 152 processed in 0.05 seconds.\n",
      "ONNX inference took 0.041261911392211914 sec\n",
      "ONNX postprocessing took 0.002109527587890625 sec\n",
      "Frame 153 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03696608543395996 sec\n",
      "ONNX postprocessing took 0.00109100341796875 sec\n",
      "Frame 154 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03928112983703613 sec\n",
      "ONNX postprocessing took 0.0018017292022705078 sec\n",
      "Frame 155 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040753841400146484 sec\n",
      "ONNX postprocessing took 0.009320735931396484 sec\n",
      "Frame 156 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03907418251037598 sec\n",
      "ONNX postprocessing took 0.0012290477752685547 sec\n",
      "Frame 157 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04011678695678711 sec\n",
      "ONNX postprocessing took 0.0050814151763916016 sec\n",
      "Frame 158 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04071664810180664 sec\n",
      "ONNX postprocessing took 0.011533260345458984 sec\n",
      "Frame 159 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03850269317626953 sec\n",
      "ONNX postprocessing took 0.001893758773803711 sec\n",
      "Frame 160 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03810882568359375 sec\n",
      "ONNX postprocessing took 0.0010752677917480469 sec\n",
      "Frame 161 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03983664512634277 sec\n",
      "ONNX postprocessing took 0.00866842269897461 sec\n",
      "Frame 162 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040198564529418945 sec\n",
      "ONNX postprocessing took 0.004717826843261719 sec\n",
      "Frame 163 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039353370666503906 sec\n",
      "ONNX postprocessing took 0.0012819766998291016 sec\n",
      "Frame 164 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04128551483154297 sec\n",
      "ONNX postprocessing took 0.005702495574951172 sec\n",
      "Frame 165 processed in 0.05 seconds.\n",
      "ONNX inference took 0.037096261978149414 sec\n",
      "ONNX postprocessing took 0.0012977123260498047 sec\n",
      "Frame 166 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03992962837219238 sec\n",
      "ONNX postprocessing took 0.007380247116088867 sec\n",
      "Frame 167 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04060840606689453 sec\n",
      "ONNX postprocessing took 0.005758762359619141 sec\n",
      "Frame 168 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040091753005981445 sec\n",
      "ONNX postprocessing took 0.0013093948364257812 sec\n",
      "Frame 169 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04132676124572754 sec\n",
      "ONNX postprocessing took 0.011373281478881836 sec\n",
      "Frame 170 processed in 0.06 seconds.\n",
      "ONNX inference took 0.04041337966918945 sec\n",
      "ONNX postprocessing took 0.0012354850769042969 sec\n",
      "Frame 171 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03650951385498047 sec\n",
      "ONNX postprocessing took 0.0009305477142333984 sec\n",
      "Frame 172 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03699326515197754 sec\n",
      "ONNX postprocessing took 0.0010819435119628906 sec\n",
      "Frame 173 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0370790958404541 sec\n",
      "ONNX postprocessing took 0.0014977455139160156 sec\n",
      "Frame 174 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03861498832702637 sec\n",
      "ONNX postprocessing took 0.00081634521484375 sec\n",
      "Frame 175 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036727190017700195 sec\n",
      "ONNX postprocessing took 0.0008795261383056641 sec\n",
      "Frame 176 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036397457122802734 sec\n",
      "ONNX postprocessing took 0.0008609294891357422 sec\n",
      "Frame 177 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03639364242553711 sec\n",
      "ONNX postprocessing took 0.0008478164672851562 sec\n",
      "Frame 178 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03668975830078125 sec\n",
      "ONNX postprocessing took 0.0013248920440673828 sec\n",
      "Frame 179 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03840279579162598 sec\n",
      "ONNX postprocessing took 0.0035009384155273438 sec\n",
      "Frame 180 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04048490524291992 sec\n",
      "ONNX postprocessing took 0.006693124771118164 sec\n",
      "Frame 181 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04075288772583008 sec\n",
      "ONNX postprocessing took 0.001672506332397461 sec\n",
      "Frame 182 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0370175838470459 sec\n",
      "ONNX postprocessing took 0.0011255741119384766 sec\n",
      "Frame 183 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03653454780578613 sec\n",
      "ONNX postprocessing took 0.0008389949798583984 sec\n",
      "Frame 184 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03654932975769043 sec\n",
      "ONNX postprocessing took 0.00081634521484375 sec\n",
      "Frame 185 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036635398864746094 sec\n",
      "ONNX postprocessing took 0.0009441375732421875 sec\n",
      "Frame 186 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03827786445617676 sec\n",
      "ONNX postprocessing took 0.0071680545806884766 sec\n",
      "Frame 187 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04288673400878906 sec\n",
      "ONNX postprocessing took 0.010689973831176758 sec\n",
      "Frame 188 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03679966926574707 sec\n",
      "ONNX postprocessing took 0.004971504211425781 sec\n",
      "Frame 189 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03992938995361328 sec\n",
      "ONNX postprocessing took 0.0034515857696533203 sec\n",
      "Frame 190 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03949546813964844 sec\n",
      "ONNX postprocessing took 0.0013282299041748047 sec\n",
      "Frame 191 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04004168510437012 sec\n",
      "ONNX postprocessing took 0.004616737365722656 sec\n",
      "Frame 192 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04157257080078125 sec\n",
      "ONNX postprocessing took 0.0019903182983398438 sec\n",
      "Frame 193 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03678464889526367 sec\n",
      "ONNX postprocessing took 0.00119781494140625 sec\n",
      "Frame 194 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04139399528503418 sec\n",
      "ONNX postprocessing took 0.01270604133605957 sec\n",
      "Frame 195 processed in 0.06 seconds.\n",
      "ONNX inference took 0.040770769119262695 sec\n",
      "ONNX postprocessing took 0.0031480789184570312 sec\n",
      "Frame 196 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03682684898376465 sec\n",
      "ONNX postprocessing took 0.0012805461883544922 sec\n",
      "Frame 197 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04001164436340332 sec\n",
      "ONNX postprocessing took 0.007852554321289062 sec\n",
      "Frame 198 processed in 0.05 seconds.\n",
      "ONNX inference took 0.046732425689697266 sec\n",
      "ONNX postprocessing took 0.004787921905517578 sec\n",
      "Frame 199 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04128861427307129 sec\n",
      "ONNX postprocessing took 0.011705160140991211 sec\n",
      "Frame 200 processed in 0.06 seconds.\n",
      "ONNX inference took 0.044714927673339844 sec\n",
      "ONNX postprocessing took 0.0008556842803955078 sec\n",
      "Frame 201 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03704953193664551 sec\n",
      "ONNX postprocessing took 0.0008521080017089844 sec\n",
      "Frame 202 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036511898040771484 sec\n",
      "ONNX postprocessing took 0.0009245872497558594 sec\n",
      "Frame 203 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037064552307128906 sec\n",
      "ONNX postprocessing took 0.0008141994476318359 sec\n",
      "Frame 204 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03685569763183594 sec\n",
      "ONNX postprocessing took 0.0008594989776611328 sec\n",
      "Frame 205 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036371469497680664 sec\n",
      "ONNX postprocessing took 0.0011069774627685547 sec\n",
      "Frame 206 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03904128074645996 sec\n",
      "ONNX postprocessing took 0.0008547306060791016 sec\n",
      "Frame 207 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03660416603088379 sec\n",
      "ONNX postprocessing took 0.0010585784912109375 sec\n",
      "Frame 208 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036611080169677734 sec\n",
      "ONNX postprocessing took 0.0008873939514160156 sec\n",
      "Frame 209 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03700375556945801 sec\n",
      "ONNX postprocessing took 0.0008339881896972656 sec\n",
      "Frame 210 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03726315498352051 sec\n",
      "ONNX postprocessing took 0.001096963882446289 sec\n",
      "Frame 211 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03760957717895508 sec\n",
      "ONNX postprocessing took 0.0018470287322998047 sec\n",
      "Frame 212 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040955543518066406 sec\n",
      "ONNX postprocessing took 0.00983738899230957 sec\n",
      "Frame 213 processed in 0.05 seconds.\n",
      "ONNX inference took 0.05372476577758789 sec\n",
      "ONNX postprocessing took 0.008596658706665039 sec\n",
      "Frame 214 processed in 0.07 seconds.\n",
      "ONNX inference took 0.03691601753234863 sec\n",
      "ONNX postprocessing took 0.0029947757720947266 sec\n",
      "Frame 215 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040082693099975586 sec\n",
      "ONNX postprocessing took 0.009169340133666992 sec\n",
      "Frame 216 processed in 0.05 seconds.\n",
      "ONNX inference took 0.041364431381225586 sec\n",
      "ONNX postprocessing took 0.0026471614837646484 sec\n",
      "Frame 217 processed in 0.05 seconds.\n",
      "ONNX inference took 0.041364431381225586 sec\n",
      "ONNX postprocessing took 0.011793851852416992 sec\n",
      "Frame 218 processed in 0.06 seconds.\n",
      "ONNX inference took 0.039969682693481445 sec\n",
      "ONNX postprocessing took 0.001352071762084961 sec\n",
      "Frame 219 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03692340850830078 sec\n",
      "ONNX postprocessing took 0.0030629634857177734 sec\n",
      "Frame 220 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0394139289855957 sec\n",
      "ONNX postprocessing took 0.007544517517089844 sec\n",
      "Frame 221 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03984236717224121 sec\n",
      "ONNX postprocessing took 0.006231546401977539 sec\n",
      "Frame 222 processed in 0.05 seconds.\n",
      "ONNX inference took 0.036664724349975586 sec\n",
      "ONNX postprocessing took 0.0011429786682128906 sec\n",
      "Frame 223 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03792572021484375 sec\n",
      "ONNX postprocessing took 0.0023343563079833984 sec\n",
      "Frame 224 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04232907295227051 sec\n",
      "ONNX postprocessing took 0.005213260650634766 sec\n",
      "Frame 225 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03806900978088379 sec\n",
      "ONNX postprocessing took 0.0016169548034667969 sec\n",
      "Frame 226 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03973555564880371 sec\n",
      "ONNX postprocessing took 0.011047601699829102 sec\n",
      "Frame 227 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04932832717895508 sec\n",
      "ONNX postprocessing took 0.004070758819580078 sec\n",
      "Frame 228 processed in 0.06 seconds.\n",
      "ONNX inference took 0.04005312919616699 sec\n",
      "ONNX postprocessing took 0.0011861324310302734 sec\n",
      "Frame 229 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03673434257507324 sec\n",
      "ONNX postprocessing took 0.0010602474212646484 sec\n",
      "Frame 230 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037941932678222656 sec\n",
      "ONNX postprocessing took 0.004019021987915039 sec\n",
      "Frame 231 processed in 0.04 seconds.\n",
      "ONNX inference took 0.0477144718170166 sec\n",
      "ONNX postprocessing took 0.012065649032592773 sec\n",
      "Frame 232 processed in 0.06 seconds.\n",
      "ONNX inference took 0.040503740310668945 sec\n",
      "ONNX postprocessing took 0.002025604248046875 sec\n",
      "Frame 233 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03987932205200195 sec\n",
      "ONNX postprocessing took 0.0014789104461669922 sec\n",
      "Frame 234 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03857612609863281 sec\n",
      "ONNX postprocessing took 0.0042874813079833984 sec\n",
      "Frame 235 processed in 0.05 seconds.\n",
      "ONNX inference took 0.036646366119384766 sec\n",
      "ONNX postprocessing took 0.0008106231689453125 sec\n",
      "Frame 236 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03661036491394043 sec\n",
      "ONNX postprocessing took 0.0009093284606933594 sec\n",
      "Frame 237 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037209510803222656 sec\n",
      "ONNX postprocessing took 0.001051187515258789 sec\n",
      "Frame 238 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03746151924133301 sec\n",
      "ONNX postprocessing took 0.004667043685913086 sec\n",
      "Frame 239 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04072165489196777 sec\n",
      "ONNX postprocessing took 0.010700702667236328 sec\n",
      "Frame 240 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04377150535583496 sec\n",
      "ONNX postprocessing took 0.0009529590606689453 sec\n",
      "Frame 241 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03754901885986328 sec\n",
      "ONNX postprocessing took 0.0013172626495361328 sec\n",
      "Frame 242 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04087638854980469 sec\n",
      "ONNX postprocessing took 0.004426002502441406 sec\n",
      "Frame 243 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04278087615966797 sec\n",
      "ONNX postprocessing took 0.012022018432617188 sec\n",
      "Frame 244 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03772687911987305 sec\n",
      "ONNX postprocessing took 0.0023643970489501953 sec\n",
      "Frame 245 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037688493728637695 sec\n",
      "ONNX postprocessing took 0.0015380382537841797 sec\n",
      "Frame 246 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04203915596008301 sec\n",
      "ONNX postprocessing took 0.011263370513916016 sec\n",
      "Frame 247 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03982806205749512 sec\n",
      "ONNX postprocessing took 0.010001659393310547 sec\n",
      "Frame 248 processed in 0.05 seconds.\n",
      "ONNX inference took 0.038831233978271484 sec\n",
      "ONNX postprocessing took 0.0014755725860595703 sec\n",
      "Frame 249 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040238142013549805 sec\n",
      "ONNX postprocessing took 0.007875680923461914 sec\n",
      "Frame 250 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04046368598937988 sec\n",
      "ONNX postprocessing took 0.007700443267822266 sec\n",
      "Frame 251 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03691411018371582 sec\n",
      "ONNX postprocessing took 0.0008332729339599609 sec\n",
      "Frame 252 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03729438781738281 sec\n",
      "ONNX postprocessing took 0.0013337135314941406 sec\n",
      "Frame 253 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03683280944824219 sec\n",
      "ONNX postprocessing took 0.0022568702697753906 sec\n",
      "Frame 254 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03872394561767578 sec\n",
      "ONNX postprocessing took 0.0012652873992919922 sec\n",
      "Frame 255 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03989911079406738 sec\n",
      "ONNX postprocessing took 0.00490570068359375 sec\n",
      "Frame 256 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04035353660583496 sec\n",
      "ONNX postprocessing took 0.004738569259643555 sec\n",
      "Frame 257 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03655600547790527 sec\n",
      "ONNX postprocessing took 0.0012319087982177734 sec\n",
      "Frame 258 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03720211982727051 sec\n",
      "ONNX postprocessing took 0.002755403518676758 sec\n",
      "Frame 259 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04053688049316406 sec\n",
      "ONNX postprocessing took 0.00421595573425293 sec\n",
      "Frame 260 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04266619682312012 sec\n",
      "ONNX postprocessing took 0.006789445877075195 sec\n",
      "Frame 261 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03913521766662598 sec\n",
      "ONNX postprocessing took 0.00196075439453125 sec\n",
      "Frame 262 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03745436668395996 sec\n",
      "ONNX postprocessing took 0.001096487045288086 sec\n",
      "Frame 263 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03882265090942383 sec\n",
      "ONNX postprocessing took 0.003046751022338867 sec\n",
      "Frame 264 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04310941696166992 sec\n",
      "ONNX postprocessing took 0.005689144134521484 sec\n",
      "Frame 265 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04442119598388672 sec\n",
      "ONNX postprocessing took 0.010141372680664062 sec\n",
      "Frame 266 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03946232795715332 sec\n",
      "ONNX postprocessing took 0.0011279582977294922 sec\n",
      "Frame 267 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03653073310852051 sec\n",
      "ONNX postprocessing took 0.0011167526245117188 sec\n",
      "Frame 268 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037055015563964844 sec\n",
      "ONNX postprocessing took 0.001058816909790039 sec\n",
      "Frame 269 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037072181701660156 sec\n",
      "ONNX postprocessing took 0.0020780563354492188 sec\n",
      "Frame 270 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04061579704284668 sec\n",
      "ONNX postprocessing took 0.008287906646728516 sec\n",
      "Frame 271 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03907299041748047 sec\n",
      "ONNX postprocessing took 0.001138448715209961 sec\n",
      "Frame 272 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03894925117492676 sec\n",
      "ONNX postprocessing took 0.002653360366821289 sec\n",
      "Frame 273 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04055166244506836 sec\n",
      "ONNX postprocessing took 0.004216909408569336 sec\n",
      "Frame 274 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04698753356933594 sec\n",
      "ONNX postprocessing took 0.004823923110961914 sec\n",
      "Frame 275 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03721022605895996 sec\n",
      "ONNX postprocessing took 0.0011010169982910156 sec\n",
      "Frame 276 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037259817123413086 sec\n",
      "ONNX postprocessing took 0.00153350830078125 sec\n",
      "Frame 277 processed in 0.04 seconds.\n",
      "ONNX inference took 0.040422677993774414 sec\n",
      "ONNX postprocessing took 0.011858224868774414 sec\n",
      "Frame 278 processed in 0.06 seconds.\n",
      "ONNX inference took 0.04691314697265625 sec\n",
      "ONNX postprocessing took 0.011513710021972656 sec\n",
      "Frame 279 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03687405586242676 sec\n",
      "ONNX postprocessing took 0.0012125968933105469 sec\n",
      "Frame 280 processed in 0.04 seconds.\n",
      "ONNX inference took 0.041863441467285156 sec\n",
      "ONNX postprocessing took 0.009292840957641602 sec\n",
      "Frame 281 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03887581825256348 sec\n",
      "ONNX postprocessing took 0.0028989315032958984 sec\n",
      "Frame 282 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04110074043273926 sec\n",
      "ONNX postprocessing took 0.0063190460205078125 sec\n",
      "Frame 283 processed in 0.05 seconds.\n",
      "ONNX inference took 0.038840532302856445 sec\n",
      "ONNX postprocessing took 0.0012772083282470703 sec\n",
      "Frame 284 processed in 0.04 seconds.\n",
      "ONNX inference took 0.038077592849731445 sec\n",
      "ONNX postprocessing took 0.0038950443267822266 sec\n",
      "Frame 285 processed in 0.04 seconds.\n",
      "ONNX inference took 0.039083003997802734 sec\n",
      "ONNX postprocessing took 0.00653076171875 sec\n",
      "Frame 286 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040097713470458984 sec\n",
      "ONNX postprocessing took 0.008864879608154297 sec\n",
      "Frame 287 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03994154930114746 sec\n",
      "ONNX postprocessing took 0.0013060569763183594 sec\n",
      "Frame 288 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03928828239440918 sec\n",
      "ONNX postprocessing took 0.0008671283721923828 sec\n",
      "Frame 289 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03725719451904297 sec\n",
      "ONNX postprocessing took 0.0009326934814453125 sec\n",
      "Frame 290 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036809682846069336 sec\n",
      "ONNX postprocessing took 0.0016238689422607422 sec\n",
      "Frame 291 processed in 0.04 seconds.\n",
      "ONNX inference took 0.036916494369506836 sec\n",
      "ONNX postprocessing took 0.0010578632354736328 sec\n",
      "Frame 292 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037390947341918945 sec\n",
      "ONNX postprocessing took 0.002711772918701172 sec\n",
      "Frame 293 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04014873504638672 sec\n",
      "ONNX postprocessing took 0.010645627975463867 sec\n",
      "Frame 294 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03961753845214844 sec\n",
      "ONNX postprocessing took 0.0024962425231933594 sec\n",
      "Frame 295 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04821920394897461 sec\n",
      "ONNX postprocessing took 0.009058952331542969 sec\n",
      "Frame 296 processed in 0.06 seconds.\n",
      "ONNX inference took 0.03925609588623047 sec\n",
      "ONNX postprocessing took 0.0027670860290527344 sec\n",
      "Frame 297 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04069375991821289 sec\n",
      "ONNX postprocessing took 0.01080942153930664 sec\n",
      "Frame 298 processed in 0.05 seconds.\n",
      "ONNX inference took 0.036844730377197266 sec\n",
      "ONNX postprocessing took 0.0011250972747802734 sec\n",
      "Frame 299 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03914284706115723 sec\n",
      "ONNX postprocessing took 0.0043354034423828125 sec\n",
      "Frame 300 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037563323974609375 sec\n",
      "ONNX postprocessing took 0.0010864734649658203 sec\n",
      "Frame 301 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03733658790588379 sec\n",
      "ONNX postprocessing took 0.0012602806091308594 sec\n",
      "Frame 302 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03739356994628906 sec\n",
      "ONNX postprocessing took 0.0016503334045410156 sec\n",
      "Frame 303 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03980231285095215 sec\n",
      "ONNX postprocessing took 0.0030694007873535156 sec\n",
      "Frame 304 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04037141799926758 sec\n",
      "ONNX postprocessing took 0.00914144515991211 sec\n",
      "Frame 305 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04013395309448242 sec\n",
      "ONNX postprocessing took 0.008521318435668945 sec\n",
      "Frame 306 processed in 0.05 seconds.\n",
      "ONNX inference took 0.036676883697509766 sec\n",
      "ONNX postprocessing took 0.0012965202331542969 sec\n",
      "Frame 307 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04004240036010742 sec\n",
      "ONNX postprocessing took 0.008746147155761719 sec\n",
      "Frame 308 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03868889808654785 sec\n",
      "ONNX postprocessing took 0.0013196468353271484 sec\n",
      "Frame 309 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04014730453491211 sec\n",
      "ONNX postprocessing took 0.007931947708129883 sec\n",
      "Frame 310 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03744053840637207 sec\n",
      "ONNX postprocessing took 0.0008575916290283203 sec\n",
      "Frame 311 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03709077835083008 sec\n",
      "ONNX postprocessing took 0.0013697147369384766 sec\n",
      "Frame 312 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03732776641845703 sec\n",
      "ONNX postprocessing took 0.0013189315795898438 sec\n",
      "Frame 313 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04115939140319824 sec\n",
      "ONNX postprocessing took 0.009469985961914062 sec\n",
      "Frame 314 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04067516326904297 sec\n",
      "ONNX postprocessing took 0.0012340545654296875 sec\n",
      "Frame 315 processed in 0.04 seconds.\n",
      "ONNX inference took 0.041152238845825195 sec\n",
      "ONNX postprocessing took 0.011113643646240234 sec\n",
      "Frame 316 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04126548767089844 sec\n",
      "ONNX postprocessing took 0.0011098384857177734 sec\n",
      "Frame 317 processed in 0.04 seconds.\n",
      "ONNX inference took 0.041025638580322266 sec\n",
      "ONNX postprocessing took 0.003212451934814453 sec\n",
      "Frame 318 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03639650344848633 sec\n",
      "ONNX postprocessing took 0.0008630752563476562 sec\n",
      "Frame 319 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03812456130981445 sec\n",
      "ONNX postprocessing took 0.002144336700439453 sec\n",
      "Frame 320 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03884601593017578 sec\n",
      "ONNX postprocessing took 0.002110004425048828 sec\n",
      "Frame 321 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04043722152709961 sec\n",
      "ONNX postprocessing took 0.011382102966308594 sec\n",
      "Frame 322 processed in 0.05 seconds.\n",
      "ONNX inference took 0.044174909591674805 sec\n",
      "ONNX postprocessing took 0.0021295547485351562 sec\n",
      "Frame 323 processed in 0.06 seconds.\n",
      "ONNX inference took 0.040459632873535156 sec\n",
      "ONNX postprocessing took 0.009975910186767578 sec\n",
      "Frame 324 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039879560470581055 sec\n",
      "ONNX postprocessing took 0.004003047943115234 sec\n",
      "Frame 325 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039999961853027344 sec\n",
      "ONNX postprocessing took 0.007178783416748047 sec\n",
      "Frame 326 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04033184051513672 sec\n",
      "ONNX postprocessing took 0.0008685588836669922 sec\n",
      "Frame 327 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03691911697387695 sec\n",
      "ONNX postprocessing took 0.001104593276977539 sec\n",
      "Frame 328 processed in 0.04 seconds.\n",
      "ONNX inference took 0.039537906646728516 sec\n",
      "ONNX postprocessing took 0.005872011184692383 sec\n",
      "Frame 329 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04113602638244629 sec\n",
      "ONNX postprocessing took 0.010136842727661133 sec\n",
      "Frame 330 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04175686836242676 sec\n",
      "ONNX postprocessing took 0.0010921955108642578 sec\n",
      "Frame 331 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03890228271484375 sec\n",
      "ONNX postprocessing took 0.004253387451171875 sec\n",
      "Frame 332 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04075026512145996 sec\n",
      "ONNX postprocessing took 0.0028154850006103516 sec\n",
      "Frame 333 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040851593017578125 sec\n",
      "ONNX postprocessing took 0.005596160888671875 sec\n",
      "Frame 334 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04029560089111328 sec\n",
      "ONNX postprocessing took 0.0012004375457763672 sec\n",
      "Frame 335 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03987860679626465 sec\n",
      "ONNX postprocessing took 0.011474847793579102 sec\n",
      "Frame 336 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04100942611694336 sec\n",
      "ONNX postprocessing took 0.0046539306640625 sec\n",
      "Frame 337 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040273427963256836 sec\n",
      "ONNX postprocessing took 0.0013926029205322266 sec\n",
      "Frame 338 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04057002067565918 sec\n",
      "ONNX postprocessing took 0.009894847869873047 sec\n",
      "Frame 339 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04550623893737793 sec\n",
      "ONNX postprocessing took 0.0014607906341552734 sec\n",
      "Frame 340 processed in 0.05 seconds.\n",
      "ONNX inference took 0.040160179138183594 sec\n",
      "ONNX postprocessing took 0.01677227020263672 sec\n",
      "Frame 341 processed in 0.06 seconds.\n",
      "ONNX inference took 0.04068922996520996 sec\n",
      "ONNX postprocessing took 0.0018329620361328125 sec\n",
      "Frame 342 processed in 0.05 seconds.\n",
      "ONNX inference took 0.04029107093811035 sec\n",
      "ONNX postprocessing took 0.010717391967773438 sec\n",
      "Frame 343 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03757023811340332 sec\n",
      "ONNX postprocessing took 0.0008919239044189453 sec\n",
      "Frame 344 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03806662559509277 sec\n",
      "ONNX postprocessing took 0.0008425712585449219 sec\n",
      "Frame 345 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037924766540527344 sec\n",
      "ONNX postprocessing took 0.001626729965209961 sec\n",
      "Frame 346 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03930497169494629 sec\n",
      "ONNX postprocessing took 0.001440286636352539 sec\n",
      "Frame 347 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04332995414733887 sec\n",
      "ONNX postprocessing took 0.0009107589721679688 sec\n",
      "Frame 348 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039647817611694336 sec\n",
      "ONNX postprocessing took 0.0013692378997802734 sec\n",
      "Frame 349 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03936433792114258 sec\n",
      "ONNX postprocessing took 0.0009770393371582031 sec\n",
      "Frame 350 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03738117218017578 sec\n",
      "ONNX postprocessing took 0.001321554183959961 sec\n",
      "Frame 351 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03984689712524414 sec\n",
      "ONNX postprocessing took 0.0015141963958740234 sec\n",
      "Frame 352 processed in 0.04 seconds.\n",
      "ONNX inference took 0.038690805435180664 sec\n",
      "ONNX postprocessing took 0.0008637905120849609 sec\n",
      "Frame 353 processed in 0.04 seconds.\n",
      "ONNX inference took 0.038063764572143555 sec\n",
      "ONNX postprocessing took 0.0009746551513671875 sec\n",
      "Frame 354 processed in 0.04 seconds.\n",
      "ONNX inference took 0.03752636909484863 sec\n",
      "ONNX postprocessing took 0.0008730888366699219 sec\n",
      "Frame 355 processed in 0.04 seconds.\n",
      "ONNX inference took 0.037123680114746094 sec\n",
      "ONNX postprocessing took 0.0011603832244873047 sec\n",
      "Frame 356 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04272294044494629 sec\n",
      "ONNX postprocessing took 0.003579378128051758 sec\n",
      "Frame 357 processed in 0.05 seconds.\n",
      "ONNX inference took 0.03983783721923828 sec\n",
      "ONNX postprocessing took 0.0015897750854492188 sec\n",
      "Frame 358 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04034829139709473 sec\n",
      "ONNX postprocessing took 0.0073702335357666016 sec\n",
      "Frame 359 processed in 0.05 seconds.\n",
      "ONNX inference took 0.039339542388916016 sec\n",
      "ONNX postprocessing took 0.001413583755493164 sec\n",
      "Frame 360 processed in 0.04 seconds.\n",
      "ONNX inference took 0.04004383087158203 sec\n",
      "ONNX postprocessing took 0.0013871192932128906 sec\n",
      "Frame 361 processed in 0.05 seconds.\n",
      "Video capture stopped by user.\n",
      "Analysis done.\n"
     ]
    }
   ],
   "source": [
    "from dlclive import DLCLive\n",
    "\n",
    "dlc_live = DLCLive(\n",
    "    # path=\"/Users/annastuckert/Downloads/Hand-AnnaStuckert-2024-08-21/dlc-models-pytorch/iteration-0/HandAug21-trainset95shuffle101/train\",\n",
    "    path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/hand-track\",\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",\n",
    "    display=False,\n",
    ")\n",
    "\n",
    "\n",
    "poses = analyze_live_video(\n",
    "    dlc_live=dlc_live,\n",
    "    camera=0,\n",
    "    save_poses=True,\n",
    "    save_dir='/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/hand-track/live_output/',\n",
    "    draw_keypoint_names=True)\n",
    "\n",
    "#OBS actually takes longer to run on resized than original videos!\n",
    "# resized_width = 320  # Desired width of the video\n",
    "# resized_height = 240  # Desired height of the video\n",
    "\n",
    "# poses = analyze_live_video(\n",
    "#     dlc_live=dlc_live,\n",
    "#     camera=0,\n",
    "#     save_poses=True,\n",
    "#     save_dir='output_directory',\n",
    "#     draw_keypoint_names=True,\n",
    "#     resize=(resized_width, resized_height)  # Resize parameter\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live.display.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplabcut3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
