{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PyTorch raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dlclive import DLCLive, Processor\n",
    "import dlclive\n",
    "from dlclive.display import Display\n",
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading model\n",
    "\n",
    "dlc_proc = Processor()\n",
    "#Dikra\n",
    "#dlc_live = DLCLive(pytorch_cfg=\"/media1/data/dikra/fly-kevin\", processor=dlc_proc, snapshot='/media1/data/dikra/fly-kevin/snapshot-100.pt', model_type='onnx')\n",
    "#img = cv2.imread(\"/media1/data/dikra/fly-kevin/img001.png\")\n",
    "#print(img.shape)\n",
    "\n",
    "# Anna\n",
    "dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights\n",
      "{'data': {'colormode': 'RGB', 'inference': {'normalize_images': True}, 'train': {'affine': {'p': 0.5, 'rotation': 30, 'scaling': [1.0, 1.0], 'translation': 0}, 'collate': {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}, 'covering': False, 'gaussian_noise': 12.75, 'hist_eq': False, 'motion_blur': False, 'normalize_images': True}}, 'device': 'auto', 'metadata': {'project_path': '/media1/data/anna/datasets/DLC_model_for_ventral_analysis', 'pose_config_path': '/media1/data/anna/datasets/DLC_model_for_ventral_analysis/dlc-models-pytorch/iteration-0/Anna1VideoAnalysisBottomFeb8-trainset95shuffle1003/train/pose_cfg.yaml', 'bodyparts': ['snout1', 'snout2', 'snout3', 'leftfrontpaw', 'rightfrontpaw', 'leftbackpaw', 'rightbackpaw', 'torsoleft', 'torsomiddle', 'torsoright', 'tail'], 'unique_bodyparts': [], 'individuals': ['animal'], 'with_identity': None}, 'method': 'bu', 'model': {'backbone': {'type': 'ResNet', 'model_name': 'resnet50_gn', 'output_stride': 16, 'freeze_bn_stats': True, 'freeze_bn_weights': False}, 'backbone_output_channels': 2048, 'heads': {'bodypart': {'type': 'HeatmapHead', 'weight_init': 'normal', 'predictor': {'type': 'HeatmapPredictor', 'apply_sigmoid': False, 'clip_scores': True, 'location_refinement': True, 'locref_std': 7.2801}, 'target_generator': {'type': 'HeatmapGaussianGenerator', 'num_heatmaps': 11, 'pos_dist_thresh': 17, 'heatmap_mode': 'KEYPOINT', 'generate_locref': True, 'locref_std': 7.2801}, 'criterion': {'heatmap': {'type': 'WeightedMSECriterion', 'weight': 1.0}, 'locref': {'type': 'WeightedHuberCriterion', 'weight': 0.05}}, 'heatmap_config': {'channels': [2048, 11], 'kernel_size': [3], 'strides': [2]}, 'locref_config': {'channels': [2048, 22], 'kernel_size': [3], 'strides': [2]}}}}, 'net_type': 'resnet_50', 'runner': {'type': 'PoseTrainingRunner', 'gpus': None, 'key_metric': 'test.mAP', 'key_metric_asc': True, 'eval_interval': 10, 'optimizer': {'type': 'AdamW', 'params': {'lr': 0.0001}}, 'scheduler': {'type': 'LRListScheduler', 'params': {'lr_list': [[1e-05], [1e-06]], 'milestones': [160, 190]}}, 'snapshots': {'max_snapshots': 5, 'save_epochs': 25, 'save_optimizer_state': False}}, 'train_settings': {'batch_size': 8, 'dataloader_workers': 0, 'dataloader_pin_memory': True, 'display_iters': 500, 'epochs': 263, 'seed': 42}, 'logger': {'type': 'WandbLogger', 'image_log_interval': 5, 'project_name': 'VentralGait', 'run_name': 'Resnet50_shuffle1003'}}\n",
      "Built pose model\n",
      "Loaded pretrained weights\n",
      "Inference of Pytorch model used 8.36922311782837 seconds\n",
      "{'bodypart': {'poses': tensor([[[[3.1484e+02, 3.1950e+02, 8.0711e-01],\n",
      "          [3.1133e+02, 3.1515e+02, 8.0013e-01],\n",
      "          [3.1377e+02, 3.1196e+02, 7.7319e-01],\n",
      "          [1.7764e+02, 8.3553e+01, 4.7866e-01],\n",
      "          [1.6815e+02, 3.3116e+02, 4.5507e-01],\n",
      "          [2.1613e+02, 8.3866e+01, 2.6758e-01],\n",
      "          [3.5618e+02, 3.3765e+02, 2.9820e-01],\n",
      "          [3.4312e+02, 3.0623e+02, 4.1945e-01],\n",
      "          [3.4367e+02, 3.1206e+02, 4.8124e-01],\n",
      "          [3.4792e+02, 3.2755e+02, 4.5332e-01],\n",
      "          [2.0984e+02, 9.3007e+01, 5.1895e-01]]]], grad_fn=<CopySlices>)}}\n"
     ]
    }
   ],
   "source": [
    "#timing inference\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pose = dlc_live.init_inference(frame=img)\n",
    "end = time.time()\n",
    "print(f\"Inference of Pytorch model used {end - start} seconds\")\n",
    "\n",
    "print(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input must be a list of dictionaries or a single numpy array for input 'input.1'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m dlc_live \u001b[38;5;241m=\u001b[39m DLCLive(pytorch_cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, processor\u001b[38;5;241m=\u001b[39mdlc_proc, snapshot\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m pose \u001b[38;5;241m=\u001b[39m \u001b[43mdlc_live\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:443\u001b[0m, in \u001b[0;36mDLCLive.init_inference\u001b[0;34m(self, frame, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# load model\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# if self.model_type == \"base\":\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# get pose of first frame (first inference is often very slow)\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     pose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:567\u001b[0m, in \u001b[0;36mDLCLive.get_pose\u001b[0;34m(self, frame, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m model_path \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpytorch_cfg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    565\u001b[0m ort_session \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mInferenceSession(model_path)\n\u001b[0;32m--> 567\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    571\u001b[0m outputs_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheatmap\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor(outputs[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocref\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor(outputs[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m    574\u001b[0m }\n\u001b[1;32m    575\u001b[0m predictor \u001b[38;5;241m=\u001b[39m HeatmapPredictor()\n",
      "File \u001b[0;32m~/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[0;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[1;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input must be a list of dictionaries or a single numpy array for input 'input.1'."
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from pathlib import Path\n",
    "\n",
    "dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt', model_type='onnx')\n",
    "\n",
    "img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "pose = dlc_live.init_inference(frame=img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pose = dlc_live.init_inference(frame=img)\n",
    "end = time.time()\n",
    "print(f\"Inference of Pytorch model used {end - start} seconds\")\n",
    "\n",
    "print(pose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplabcut3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
