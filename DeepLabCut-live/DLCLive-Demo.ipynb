{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Live PyTorch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from onnxruntime import quantization\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [\"fly-kevin\", \"hand-track\", \"superbird\", \"ventral-gait\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4604/1313231765.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(weights_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# In case you do not have a .onnx model exported, use this cell to export your DLC3.0 snapshot\n",
    "\n",
    "from deeplabcut.pose_estimation_pytorch.config import read_config_as_dict\n",
    "from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#Dikra\n",
    "root = Path(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3])\n",
    "model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "weights_path = root / \"snapshot-263.pt\"\n",
    "\n",
    "#Anna\n",
    "# root = Path(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\")\n",
    "# model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "# weights_path = root / \"snapshot-263.pt\"\n",
    "\n",
    "model = PoseModel.build(model_cfg[\"model\"])\n",
    "weights = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "dummy_input = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\",\n",
    "    verbose=False,\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quant ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP32 to FP16\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "onnx_fp32_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\"\n",
    "onnx_fp16_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet_fp16.onnx\"\n",
    "\n",
    "model_fp32 = onnx.load(onnx_fp32_model_path)\n",
    "model_fp16 = float16.convert_float_to_float16(model_fp32)\n",
    "onnx.save(model_fp16, onnx_fp16_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_fp32_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\"\n",
    "model_prep_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet_quant_prep.onnx\"\n",
    "\n",
    "# prep for quantisation\n",
    "quantization.shape_inference.quant_pre_process(onnx_fp32_model_path, model_prep_path, skip_symbolic_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test frame\n",
    "img = cv2.imread(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\"+ projects[3] +\"/img0006.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with ONNX exported DLC 3.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.09379959106445312 sec\n",
      "ONNX inference took 1.7872130870819092 sec\n",
      "ONNX postprocessing took 0.002176523208618164 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0182, 162.2244,   0.9150],\n",
       "            [146.8820, 158.9966,   0.9463],\n",
       "            [150.3497, 149.1153,   0.9092],\n",
       "            [196.7127, 137.2184,   0.8843],\n",
       "            [204.8954, 172.0166,   0.6792],\n",
       "            [342.8758,  81.4316,   0.6938],\n",
       "            [325.4095, 151.0748,   0.7803],\n",
       "            [240.2870, 110.5364,   0.6489],\n",
       "            [261.0193, 128.8380,   0.6074],\n",
       "            [254.8812, 154.8065,   0.8237],\n",
       "            [385.2753, 112.8754,   0.8096]]]])},\n",
       " 1.7872130870819092)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "onnx_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3],\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",\n",
    "    display=True,\n",
    "    precision=\"FP16\"\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# onnx_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# onnx_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "onnx_pose = onnx_dlc_live.init_inference(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot from 2024-08-20 14-29-53.png](./docs/assets/Screenshot%20from%202024-08-20%2014-36-00.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[162.2244, 158.9966, 149.1153, 137.2184, 172.0166,  81.4316, 151.0748,\n",
       "          110.5364, 128.8380, 154.8065, 112.8754]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected = (onnx_pose[0][\"poses\"][0][0][:, 2] > 0.9)\n",
    "print(torch.any(detected))\n",
    "x = onnx_pose[0][\"poses\"][0][0][detected, 0]\n",
    "y = onnx_pose[0][\"poses\"][0][0][detected, 1]\n",
    "onnx_pose[0][\"poses\"][:, :, :, 1][:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.0162506103515625 sec\n",
      "ONNX postprocessing took 0.0006670951843261719 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0218, 162.2289,   0.9150],\n",
       "            [146.8865, 158.9966,   0.9463],\n",
       "            [150.3515, 149.1109,   0.9092],\n",
       "            [196.7047, 137.2219,   0.8848],\n",
       "            [204.8865, 172.0128,   0.6797],\n",
       "            [342.8776,  81.4281,   0.6934],\n",
       "            [325.4157, 151.0748,   0.7803],\n",
       "            [240.2977, 110.5328,   0.6484],\n",
       "            [261.0255, 128.8380,   0.6074],\n",
       "            [254.8812, 154.8029,   0.8237],\n",
       "            [385.2806, 112.8754,   0.8101]]]])},\n",
       " 0.0162506103515625)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pose = onnx_dlc_live.get_pose(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with snaptshot of DLC 3.0 model (.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikra/MyHub/Code/DLC24_Hub/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:257: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_path, map_location=torch.device(self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.4676992893218994 sec\n",
      "PyTorch inference took 0.034587860107421875 sec\n",
      "PyTorch postprocessing took 0.0018115043640136719 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0203, 162.2280,   0.9152],\n",
       "            [146.8848, 158.9930,   0.9459],\n",
       "            [150.3487, 149.1102,   0.9093],\n",
       "            [196.7133, 137.2184,   0.8843],\n",
       "            [204.8920, 172.0188,   0.6791],\n",
       "            [342.8778,  81.4373,   0.6930],\n",
       "            [325.4101, 151.0759,   0.7803],\n",
       "            [240.2807, 110.5330,   0.6488],\n",
       "            [261.0057, 128.8403,   0.6076],\n",
       "            [254.8730, 154.8122,   0.8238],\n",
       "            [385.2763, 112.8773,   0.8098]]]])},\n",
       " 0.034587860107421875)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "pytorch_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    snapshot=\"snapshot-263.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# pytorch_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# pytorch_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "pytorch_pose = pytorch_dlc_live.init_inference(frame=img)\n",
    "pytorch_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PyTorch model inference](./docs/assets/Screenshot%20from%202024-08-20%2014-29-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "root = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\"\n",
    "test_images = glob.glob(os.path.normpath(root + \"/*.png\"))\n",
    "\n",
    "\n",
    "def mean_time_inference(dlc_live, images):\n",
    "    times = []\n",
    "    for i, img_p in enumerate(images):\n",
    "        img = cv2.imread(img_p)\n",
    "\n",
    "        if i == 0:\n",
    "            start = time.time()\n",
    "            dlc_live.init_inference(img)\n",
    "            end = time.time()\n",
    "        else:\n",
    "            start = time.time()\n",
    "            dlc_live.get_pose(img)\n",
    "            end = time.time()\n",
    "        times.append(end - start)\n",
    "    print(times)\n",
    "\n",
    "    return np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.4884378910064697 sec\n",
      "ONNX inference took 2.5211031436920166 sec\n",
      "ONNX postprocessing took 0.0028717517852783203 sec\n",
      "[3.2065136432647705]\n",
      "TOTAL Inference of ONNX model took on average 3.2065136432647705 seconds for 1 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"TOTAL Inference of ONNX model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\"\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images) \n",
    "print(f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 4.69077205657959 sec\n",
      "ONNX inference took 49.87957811355591 sec\n",
      "ONNX postprocessing took 0.0015039443969726562 sec\n",
      "[54.57309126853943]\n",
      "Inference of PyTorch model took on average 54.57309126853943 seconds for 1 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3],\n",
    "    device=\"tensorrt\",\n",
    "    model_type=\"onnx\"\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images) \n",
    "print(f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.02220296859741211 sec\n",
      "ONNX postprocessing took 0.0027968883514404297 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dlc_live.get_pose(img)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "Currently the benchmark_pytorch.py script serves to provide a function for analyzing a preexisting video to test PyTorch for running video inference in DLC-Live. Code for running video inference on a live video feed is WIP.\n",
    "\n",
    "For true benchmarking purposes, we aim to add feature for recording the time it takes to analyze each frame / how many frames can be analyzed per second. Discuss what measure to use and consult the DLC Live paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 45.56147336959839 sec\n",
      "ONNX postprocessing took 0.0014200210571289062 sec\n",
      "ONNX inference took 0.012729883193969727 sec\n",
      "ONNX postprocessing took 0.002814054489135742 sec\n",
      "ONNX inference took 0.013358116149902344 sec\n",
      "ONNX postprocessing took 0.0033102035522460938 sec\n",
      "ONNX inference took 0.013541460037231445 sec\n",
      "ONNX postprocessing took 0.0030677318572998047 sec\n",
      "ONNX inference took 0.01412057876586914 sec\n",
      "ONNX postprocessing took 0.0031762123107910156 sec\n",
      "ONNX inference took 0.014404535293579102 sec\n",
      "ONNX postprocessing took 0.004117488861083984 sec\n",
      "ONNX inference took 0.014124870300292969 sec\n",
      "ONNX postprocessing took 0.0033724308013916016 sec\n",
      "ONNX inference took 0.013591766357421875 sec\n",
      "ONNX postprocessing took 0.002768278121948242 sec\n",
      "ONNX inference took 0.013484477996826172 sec\n",
      "ONNX postprocessing took 0.0033674240112304688 sec\n",
      "ONNX inference took 0.01388406753540039 sec\n",
      "ONNX postprocessing took 0.0026786327362060547 sec\n",
      "ONNX inference took 0.013867855072021484 sec\n",
      "ONNX postprocessing took 0.004326581954956055 sec\n",
      "ONNX inference took 0.013368606567382812 sec\n",
      "ONNX postprocessing took 0.0030260086059570312 sec\n",
      "ONNX inference took 0.013878822326660156 sec\n",
      "ONNX postprocessing took 0.0023293495178222656 sec\n",
      "ONNX inference took 0.014385223388671875 sec\n",
      "ONNX postprocessing took 0.0038442611694335938 sec\n",
      "ONNX inference took 0.013648509979248047 sec\n",
      "ONNX postprocessing took 0.0024156570434570312 sec\n",
      "ONNX inference took 0.013150691986083984 sec\n",
      "ONNX postprocessing took 0.004536867141723633 sec\n",
      "ONNX inference took 0.013747692108154297 sec\n",
      "ONNX postprocessing took 0.0023717880249023438 sec\n",
      "ONNX inference took 0.013940811157226562 sec\n",
      "ONNX postprocessing took 0.0018537044525146484 sec\n",
      "ONNX inference took 0.014015436172485352 sec\n",
      "ONNX postprocessing took 0.0033435821533203125 sec\n",
      "ONNX inference took 0.01317286491394043 sec\n",
      "ONNX postprocessing took 0.0036673545837402344 sec\n",
      "ONNX inference took 0.013327836990356445 sec\n",
      "ONNX postprocessing took 0.0029463768005371094 sec\n",
      "ONNX inference took 0.013864517211914062 sec\n",
      "ONNX postprocessing took 0.0025191307067871094 sec\n",
      "ONNX inference took 0.013581991195678711 sec\n",
      "ONNX postprocessing took 0.002882719039916992 sec\n",
      "ONNX inference took 0.013495206832885742 sec\n",
      "ONNX postprocessing took 0.003175020217895508 sec\n",
      "ONNX inference took 0.014394998550415039 sec\n",
      "ONNX postprocessing took 0.002660512924194336 sec\n",
      "ONNX inference took 0.013504743576049805 sec\n",
      "ONNX postprocessing took 0.0028924942016601562 sec\n",
      "ONNX inference took 0.014069318771362305 sec\n",
      "ONNX postprocessing took 0.002897024154663086 sec\n",
      "ONNX inference took 0.013922452926635742 sec\n",
      "ONNX postprocessing took 0.0029783248901367188 sec\n",
      "ONNX inference took 0.01326441764831543 sec\n",
      "ONNX postprocessing took 0.0020542144775390625 sec\n",
      "ONNX inference took 0.014159917831420898 sec\n",
      "ONNX postprocessing took 0.004492282867431641 sec\n",
      "ONNX inference took 0.013276100158691406 sec\n",
      "ONNX postprocessing took 0.0017290115356445312 sec\n",
      "ONNX inference took 0.01427006721496582 sec\n",
      "ONNX postprocessing took 0.0022649765014648438 sec\n",
      "ONNX inference took 0.01423954963684082 sec\n",
      "ONNX postprocessing took 0.0032122135162353516 sec\n",
      "ONNX inference took 0.013362646102905273 sec\n",
      "ONNX postprocessing took 0.0033066272735595703 sec\n",
      "ONNX inference took 0.013953685760498047 sec\n",
      "ONNX postprocessing took 0.002496004104614258 sec\n",
      "ONNX inference took 0.013521671295166016 sec\n",
      "ONNX postprocessing took 0.003064393997192383 sec\n",
      "ONNX inference took 0.013378381729125977 sec\n",
      "ONNX postprocessing took 0.0033702850341796875 sec\n",
      "ONNX inference took 0.013223648071289062 sec\n",
      "ONNX postprocessing took 0.002933025360107422 sec\n",
      "ONNX inference took 0.014266014099121094 sec\n",
      "ONNX postprocessing took 0.0028684139251708984 sec\n",
      "ONNX inference took 0.013972282409667969 sec\n",
      "ONNX postprocessing took 0.0029239654541015625 sec\n",
      "ONNX inference took 0.014368295669555664 sec\n",
      "ONNX postprocessing took 0.002369403839111328 sec\n",
      "ONNX inference took 0.013623237609863281 sec\n",
      "ONNX postprocessing took 0.004305601119995117 sec\n",
      "ONNX inference took 0.013467073440551758 sec\n",
      "ONNX postprocessing took 0.00266265869140625 sec\n",
      "ONNX inference took 0.013317346572875977 sec\n",
      "ONNX postprocessing took 0.0029435157775878906 sec\n",
      "ONNX inference took 0.013332843780517578 sec\n",
      "ONNX postprocessing took 0.0033774375915527344 sec\n",
      "ONNX inference took 0.013887405395507812 sec\n",
      "ONNX postprocessing took 0.003142118453979492 sec\n",
      "ONNX inference took 0.013728618621826172 sec\n",
      "ONNX postprocessing took 0.003686666488647461 sec\n",
      "ONNX inference took 0.013536214828491211 sec\n",
      "ONNX postprocessing took 0.004569053649902344 sec\n",
      "ONNX inference took 0.013503789901733398 sec\n",
      "ONNX postprocessing took 0.002747774124145508 sec\n",
      "ONNX inference took 0.013347864151000977 sec\n",
      "ONNX postprocessing took 0.0024662017822265625 sec\n",
      "ONNX inference took 0.013537168502807617 sec\n",
      "ONNX postprocessing took 0.002784252166748047 sec\n",
      "ONNX inference took 0.014144182205200195 sec\n",
      "ONNX postprocessing took 0.002467632293701172 sec\n",
      "ONNX inference took 0.013960838317871094 sec\n",
      "ONNX postprocessing took 0.0032312870025634766 sec\n",
      "ONNX inference took 0.013747930526733398 sec\n",
      "ONNX postprocessing took 0.0028829574584960938 sec\n",
      "ONNX inference took 0.013420581817626953 sec\n",
      "ONNX postprocessing took 0.00506901741027832 sec\n",
      "ONNX inference took 0.01343989372253418 sec\n",
      "ONNX postprocessing took 0.002787351608276367 sec\n",
      "ONNX inference took 0.013721942901611328 sec\n",
      "ONNX postprocessing took 0.0031511783599853516 sec\n",
      "ONNX inference took 0.013645172119140625 sec\n",
      "ONNX postprocessing took 0.0026154518127441406 sec\n",
      "ONNX inference took 0.013812541961669922 sec\n",
      "ONNX postprocessing took 0.003740549087524414 sec\n",
      "ONNX inference took 0.01352548599243164 sec\n",
      "ONNX postprocessing took 0.003044605255126953 sec\n",
      "ONNX inference took 0.013370990753173828 sec\n",
      "ONNX postprocessing took 0.0028264522552490234 sec\n",
      "ONNX inference took 0.013570785522460938 sec\n",
      "ONNX postprocessing took 0.0028073787689208984 sec\n",
      "ONNX inference took 0.01399540901184082 sec\n",
      "ONNX postprocessing took 0.0026314258575439453 sec\n",
      "ONNX inference took 0.013534307479858398 sec\n",
      "ONNX postprocessing took 0.002979278564453125 sec\n",
      "ONNX inference took 0.013633489608764648 sec\n",
      "ONNX postprocessing took 0.0029897689819335938 sec\n",
      "ONNX inference took 0.013429880142211914 sec\n",
      "ONNX postprocessing took 0.003473997116088867 sec\n",
      "ONNX inference took 0.014117717742919922 sec\n",
      "ONNX postprocessing took 0.0031976699829101562 sec\n",
      "ONNX inference took 0.013609886169433594 sec\n",
      "ONNX postprocessing took 0.0035512447357177734 sec\n",
      "ONNX inference took 0.013957500457763672 sec\n",
      "ONNX postprocessing took 0.004584789276123047 sec\n",
      "ONNX inference took 0.013870716094970703 sec\n",
      "ONNX postprocessing took 0.0029592514038085938 sec\n",
      "ONNX inference took 0.013120651245117188 sec\n",
      "ONNX postprocessing took 0.004204988479614258 sec\n",
      "ONNX inference took 0.01354360580444336 sec\n",
      "ONNX postprocessing took 0.005279064178466797 sec\n",
      "ONNX inference took 0.01372218132019043 sec\n",
      "ONNX postprocessing took 0.0027060508728027344 sec\n",
      "ONNX inference took 0.013750791549682617 sec\n",
      "ONNX postprocessing took 0.0031232833862304688 sec\n",
      "ONNX inference took 0.013533592224121094 sec\n",
      "ONNX postprocessing took 0.0023491382598876953 sec\n",
      "ONNX inference took 0.013521671295166016 sec\n",
      "ONNX postprocessing took 0.005446910858154297 sec\n",
      "ONNX inference took 0.013206005096435547 sec\n",
      "ONNX postprocessing took 0.0021209716796875 sec\n",
      "ONNX inference took 0.013622522354125977 sec\n",
      "ONNX postprocessing took 0.002888202667236328 sec\n",
      "ONNX inference took 0.013700485229492188 sec\n",
      "ONNX postprocessing took 0.002665281295776367 sec\n",
      "ONNX inference took 0.013514518737792969 sec\n",
      "ONNX postprocessing took 0.004068613052368164 sec\n",
      "ONNX inference took 0.014019489288330078 sec\n",
      "ONNX postprocessing took 0.0035979747772216797 sec\n",
      "ONNX inference took 0.013714790344238281 sec\n",
      "ONNX postprocessing took 0.003047943115234375 sec\n",
      "ONNX inference took 0.01348114013671875 sec\n",
      "ONNX postprocessing took 0.0029914379119873047 sec\n",
      "ONNX inference took 0.013584136962890625 sec\n",
      "ONNX postprocessing took 0.0032029151916503906 sec\n",
      "ONNX inference took 0.013254642486572266 sec\n",
      "ONNX postprocessing took 0.003976583480834961 sec\n",
      "ONNX inference took 0.01361227035522461 sec\n",
      "ONNX postprocessing took 0.0019936561584472656 sec\n",
      "ONNX inference took 0.013479232788085938 sec\n",
      "ONNX postprocessing took 0.0024406909942626953 sec\n",
      "ONNX inference took 0.013507366180419922 sec\n",
      "ONNX postprocessing took 0.0015861988067626953 sec\n",
      "ONNX inference took 0.014577150344848633 sec\n",
      "ONNX postprocessing took 0.003818035125732422 sec\n",
      "ONNX inference took 0.01364898681640625 sec\n",
      "ONNX postprocessing took 0.0018458366394042969 sec\n",
      "ONNX inference took 0.01381683349609375 sec\n",
      "ONNX postprocessing took 0.003320932388305664 sec\n",
      "ONNX inference took 0.014004707336425781 sec\n",
      "ONNX postprocessing took 0.0033025741577148438 sec\n",
      "ONNX inference took 0.013971328735351562 sec\n",
      "ONNX postprocessing took 0.004462480545043945 sec\n",
      "ONNX inference took 0.013176679611206055 sec\n",
      "ONNX postprocessing took 0.002315044403076172 sec\n",
      "ONNX inference took 0.013369560241699219 sec\n",
      "ONNX postprocessing took 0.0042724609375 sec\n",
      "ONNX inference took 0.013458490371704102 sec\n",
      "ONNX postprocessing took 0.0034651756286621094 sec\n",
      "ONNX inference took 0.01363372802734375 sec\n",
      "ONNX postprocessing took 0.002767324447631836 sec\n",
      "ONNX inference took 0.013364076614379883 sec\n",
      "ONNX postprocessing took 0.0015285015106201172 sec\n",
      "ONNX inference took 0.014298677444458008 sec\n",
      "ONNX postprocessing took 0.0028007030487060547 sec\n",
      "ONNX inference took 0.01369929313659668 sec\n",
      "ONNX postprocessing took 0.002629995346069336 sec\n",
      "ONNX inference took 0.013572931289672852 sec\n",
      "ONNX postprocessing took 0.002870798110961914 sec\n",
      "ONNX inference took 0.014349937438964844 sec\n",
      "ONNX postprocessing took 0.0034782886505126953 sec\n",
      "ONNX inference took 0.013759613037109375 sec\n",
      "ONNX postprocessing took 0.0026764869689941406 sec\n",
      "ONNX inference took 0.013489484786987305 sec\n",
      "ONNX postprocessing took 0.002436399459838867 sec\n",
      "ONNX inference took 0.014197587966918945 sec\n",
      "ONNX postprocessing took 0.0024847984313964844 sec\n",
      "ONNX inference took 0.013375043869018555 sec\n",
      "ONNX postprocessing took 0.001865386962890625 sec\n",
      "ONNX inference took 0.013696432113647461 sec\n",
      "ONNX postprocessing took 0.0052318572998046875 sec\n",
      "ONNX inference took 0.013878107070922852 sec\n",
      "ONNX postprocessing took 0.002927541732788086 sec\n",
      "ONNX inference took 0.013767242431640625 sec\n",
      "ONNX postprocessing took 0.0030961036682128906 sec\n",
      "ONNX inference took 0.01324772834777832 sec\n",
      "ONNX postprocessing took 0.002178668975830078 sec\n",
      "ONNX inference took 0.014364480972290039 sec\n",
      "ONNX postprocessing took 0.0035452842712402344 sec\n",
      "ONNX inference took 0.013530731201171875 sec\n",
      "ONNX postprocessing took 0.0026454925537109375 sec\n",
      "ONNX inference took 0.013917922973632812 sec\n",
      "ONNX postprocessing took 0.001825571060180664 sec\n",
      "ONNX inference took 0.013971328735351562 sec\n",
      "ONNX postprocessing took 0.0022084712982177734 sec\n",
      "ONNX inference took 0.014383077621459961 sec\n",
      "ONNX postprocessing took 0.004527091979980469 sec\n",
      "ONNX inference took 0.013353347778320312 sec\n",
      "ONNX postprocessing took 0.004693746566772461 sec\n",
      "ONNX inference took 0.013030290603637695 sec\n",
      "ONNX postprocessing took 0.002826690673828125 sec\n",
      "ONNX inference took 0.014229774475097656 sec\n",
      "ONNX postprocessing took 0.0024535655975341797 sec\n",
      "ONNX inference took 0.01411581039428711 sec\n",
      "ONNX postprocessing took 0.0024607181549072266 sec\n",
      "ONNX inference took 0.013470172882080078 sec\n",
      "ONNX postprocessing took 0.003162860870361328 sec\n",
      "ONNX inference took 0.014127969741821289 sec\n",
      "ONNX postprocessing took 0.002974271774291992 sec\n",
      "ONNX inference took 0.013574600219726562 sec\n",
      "ONNX postprocessing took 0.003199338912963867 sec\n",
      "ONNX inference took 0.013394355773925781 sec\n",
      "ONNX postprocessing took 0.0032858848571777344 sec\n",
      "ONNX inference took 0.013230562210083008 sec\n",
      "ONNX postprocessing took 0.004536151885986328 sec\n",
      "ONNX inference took 0.013427734375 sec\n",
      "ONNX postprocessing took 0.002992868423461914 sec\n",
      "ONNX inference took 0.014064311981201172 sec\n",
      "ONNX postprocessing took 0.003373861312866211 sec\n",
      "ONNX inference took 0.013742208480834961 sec\n",
      "ONNX postprocessing took 0.0018382072448730469 sec\n",
      "ONNX inference took 0.013348817825317383 sec\n",
      "ONNX postprocessing took 0.0023076534271240234 sec\n",
      "ONNX inference took 0.014125585556030273 sec\n",
      "ONNX postprocessing took 0.0030333995819091797 sec\n",
      "ONNX inference took 0.014325380325317383 sec\n",
      "ONNX postprocessing took 0.003169536590576172 sec\n",
      "ONNX inference took 0.014107465744018555 sec\n",
      "ONNX postprocessing took 0.0026035308837890625 sec\n",
      "ONNX inference took 0.013351202011108398 sec\n",
      "ONNX postprocessing took 0.0017611980438232422 sec\n",
      "ONNX inference took 0.014103889465332031 sec\n",
      "ONNX postprocessing took 0.0030269622802734375 sec\n",
      "ONNX inference took 0.013471841812133789 sec\n",
      "ONNX postprocessing took 0.002220630645751953 sec\n",
      "ONNX inference took 0.01421809196472168 sec\n",
      "ONNX postprocessing took 0.0025773048400878906 sec\n",
      "ONNX inference took 0.014094114303588867 sec\n",
      "ONNX postprocessing took 0.0026128292083740234 sec\n",
      "ONNX inference took 0.013434171676635742 sec\n",
      "ONNX postprocessing took 0.002906322479248047 sec\n",
      "ONNX inference took 0.013183355331420898 sec\n",
      "ONNX postprocessing took 0.003168344497680664 sec\n",
      "ONNX inference took 0.01403665542602539 sec\n",
      "ONNX postprocessing took 0.0030558109283447266 sec\n",
      "ONNX inference took 0.014209508895874023 sec\n",
      "ONNX postprocessing took 0.003528118133544922 sec\n",
      "ONNX inference took 0.013154268264770508 sec\n",
      "ONNX postprocessing took 0.002931833267211914 sec\n",
      "ONNX inference took 0.014195680618286133 sec\n",
      "ONNX postprocessing took 0.0029370784759521484 sec\n",
      "ONNX inference took 0.013837814331054688 sec\n",
      "ONNX postprocessing took 0.00451350212097168 sec\n",
      "ONNX inference took 0.013794422149658203 sec\n",
      "ONNX postprocessing took 0.0027213096618652344 sec\n",
      "ONNX inference took 0.013965606689453125 sec\n",
      "ONNX postprocessing took 0.0026857852935791016 sec\n",
      "ONNX inference took 0.013395309448242188 sec\n",
      "ONNX postprocessing took 0.002871274948120117 sec\n",
      "ONNX inference took 0.013479232788085938 sec\n",
      "ONNX postprocessing took 0.002325773239135742 sec\n",
      "ONNX inference took 0.014102935791015625 sec\n",
      "ONNX postprocessing took 0.0030431747436523438 sec\n",
      "ONNX inference took 0.014068603515625 sec\n",
      "ONNX postprocessing took 0.0028488636016845703 sec\n",
      "ONNX inference took 0.013723134994506836 sec\n",
      "ONNX postprocessing took 0.0027742385864257812 sec\n",
      "ONNX inference took 0.014356136322021484 sec\n",
      "ONNX postprocessing took 0.003916740417480469 sec\n",
      "ONNX inference took 0.01328420639038086 sec\n",
      "ONNX postprocessing took 0.0019505023956298828 sec\n",
      "ONNX inference took 0.015295743942260742 sec\n",
      "ONNX postprocessing took 0.0062487125396728516 sec\n",
      "ONNX inference took 0.01359868049621582 sec\n",
      "ONNX postprocessing took 0.004665851593017578 sec\n",
      "ONNX inference took 0.013166666030883789 sec\n",
      "ONNX postprocessing took 0.0031654834747314453 sec\n",
      "ONNX inference took 0.014084100723266602 sec\n",
      "ONNX postprocessing took 0.003175497055053711 sec\n",
      "ONNX inference took 0.014089107513427734 sec\n",
      "ONNX postprocessing took 0.0026636123657226562 sec\n",
      "ONNX inference took 0.01316213607788086 sec\n",
      "ONNX postprocessing took 0.00813436508178711 sec\n",
      "ONNX inference took 0.013528108596801758 sec\n",
      "ONNX postprocessing took 0.002127408981323242 sec\n",
      "ONNX inference took 0.014565229415893555 sec\n",
      "ONNX postprocessing took 0.0038635730743408203 sec\n",
      "ONNX inference took 0.01338505744934082 sec\n",
      "ONNX postprocessing took 0.002048492431640625 sec\n",
      "ONNX inference took 0.013393402099609375 sec\n",
      "ONNX postprocessing took 0.005093812942504883 sec\n",
      "ONNX inference took 0.014251947402954102 sec\n",
      "ONNX postprocessing took 0.004795551300048828 sec\n",
      "ONNX inference took 0.014441251754760742 sec\n",
      "ONNX postprocessing took 0.00407862663269043 sec\n",
      "ONNX inference took 0.013946294784545898 sec\n",
      "ONNX postprocessing took 0.004937887191772461 sec\n",
      "ONNX inference took 0.01415395736694336 sec\n",
      "ONNX postprocessing took 0.0023369789123535156 sec\n",
      "ONNX inference took 0.013038873672485352 sec\n",
      "ONNX postprocessing took 0.0047376155853271484 sec\n",
      "ONNX inference took 0.013121366500854492 sec\n",
      "ONNX postprocessing took 0.0028371810913085938 sec\n",
      "ONNX inference took 0.014477729797363281 sec\n",
      "ONNX postprocessing took 0.00348663330078125 sec\n",
      "ONNX inference took 0.01372075080871582 sec\n",
      "ONNX postprocessing took 0.003958463668823242 sec\n",
      "ONNX inference took 0.013660669326782227 sec\n",
      "ONNX postprocessing took 0.0026018619537353516 sec\n",
      "ONNX inference took 0.014284849166870117 sec\n",
      "ONNX postprocessing took 0.0039713382720947266 sec\n",
      "ONNX inference took 0.013498067855834961 sec\n",
      "ONNX postprocessing took 0.005660295486450195 sec\n",
      "ONNX inference took 0.013500452041625977 sec\n",
      "ONNX postprocessing took 0.002426624298095703 sec\n",
      "ONNX inference took 0.013579368591308594 sec\n",
      "ONNX postprocessing took 0.0032722949981689453 sec\n",
      "ONNX inference took 0.013558626174926758 sec\n",
      "ONNX postprocessing took 0.002202749252319336 sec\n",
      "ONNX inference took 0.013544797897338867 sec\n",
      "ONNX postprocessing took 0.0025272369384765625 sec\n",
      "ONNX inference took 0.014003992080688477 sec\n",
      "ONNX postprocessing took 0.002835988998413086 sec\n",
      "ONNX inference took 0.014038801193237305 sec\n",
      "ONNX postprocessing took 0.003162384033203125 sec\n",
      "ONNX inference took 0.013695001602172852 sec\n",
      "ONNX postprocessing took 0.0023107528686523438 sec\n",
      "ONNX inference took 0.01330709457397461 sec\n",
      "ONNX postprocessing took 0.004704713821411133 sec\n",
      "ONNX inference took 0.01360774040222168 sec\n",
      "ONNX postprocessing took 0.0028510093688964844 sec\n",
      "ONNX inference took 0.013895273208618164 sec\n",
      "ONNX postprocessing took 0.00435948371887207 sec\n",
      "ONNX inference took 0.013520956039428711 sec\n",
      "ONNX postprocessing took 0.0038347244262695312 sec\n",
      "ONNX inference took 0.013537883758544922 sec\n",
      "ONNX postprocessing took 0.0023763179779052734 sec\n",
      "ONNX inference took 0.01402735710144043 sec\n",
      "ONNX postprocessing took 0.0029277801513671875 sec\n",
      "ONNX inference took 0.013346672058105469 sec\n",
      "ONNX postprocessing took 0.0020737648010253906 sec\n",
      "ONNX inference took 0.014489889144897461 sec\n",
      "ONNX postprocessing took 0.003964900970458984 sec\n",
      "ONNX inference took 0.013982057571411133 sec\n",
      "ONNX postprocessing took 0.0019202232360839844 sec\n",
      "ONNX inference took 0.014050483703613281 sec\n",
      "ONNX postprocessing took 0.0029306411743164062 sec\n",
      "ONNX inference took 0.014441251754760742 sec\n",
      "ONNX postprocessing took 0.003206968307495117 sec\n",
      "ONNX inference took 0.014169931411743164 sec\n",
      "ONNX postprocessing took 0.0020182132720947266 sec\n",
      "ONNX inference took 0.013186216354370117 sec\n",
      "ONNX postprocessing took 0.00888204574584961 sec\n",
      "ONNX inference took 0.012299776077270508 sec\n",
      "ONNX postprocessing took 0.0031800270080566406 sec\n",
      "ONNX inference took 0.013722658157348633 sec\n",
      "ONNX postprocessing took 0.0038912296295166016 sec\n",
      "ONNX inference took 0.013872623443603516 sec\n",
      "ONNX postprocessing took 0.002645730972290039 sec\n",
      "ONNX inference took 0.01393270492553711 sec\n",
      "ONNX postprocessing took 0.002926349639892578 sec\n",
      "ONNX inference took 0.01351618766784668 sec\n",
      "ONNX postprocessing took 0.002092599868774414 sec\n",
      "ONNX inference took 0.013653993606567383 sec\n",
      "ONNX postprocessing took 0.001951456069946289 sec\n",
      "ONNX inference took 0.013800859451293945 sec\n",
      "ONNX postprocessing took 0.0030231475830078125 sec\n",
      "ONNX inference took 0.013600349426269531 sec\n",
      "ONNX postprocessing took 0.0023984909057617188 sec\n",
      "ONNX inference took 0.013829469680786133 sec\n",
      "ONNX postprocessing took 0.005772590637207031 sec\n",
      "ONNX inference took 0.013864517211914062 sec\n",
      "ONNX postprocessing took 0.002643108367919922 sec\n",
      "ONNX inference took 0.013570547103881836 sec\n",
      "ONNX postprocessing took 0.002057790756225586 sec\n",
      "ONNX inference took 0.013483762741088867 sec\n",
      "ONNX postprocessing took 0.0028166770935058594 sec\n",
      "ONNX inference took 0.013509511947631836 sec\n",
      "ONNX postprocessing took 0.0034983158111572266 sec\n",
      "ONNX inference took 0.013251781463623047 sec\n",
      "ONNX postprocessing took 0.004519224166870117 sec\n",
      "ONNX inference took 0.013713359832763672 sec\n",
      "ONNX postprocessing took 0.002874135971069336 sec\n",
      "ONNX inference took 0.014771223068237305 sec\n",
      "ONNX postprocessing took 0.003357410430908203 sec\n",
      "ONNX inference took 0.013643503189086914 sec\n",
      "ONNX postprocessing took 0.0026400089263916016 sec\n",
      "ONNX inference took 0.013831615447998047 sec\n",
      "ONNX postprocessing took 0.0027306079864501953 sec\n",
      "ONNX inference took 0.014292001724243164 sec\n",
      "ONNX postprocessing took 0.0030841827392578125 sec\n",
      "ONNX inference took 0.013493061065673828 sec\n",
      "ONNX postprocessing took 0.002523183822631836 sec\n",
      "ONNX inference took 0.014197111129760742 sec\n",
      "ONNX postprocessing took 0.003061532974243164 sec\n",
      "ONNX inference took 0.013781547546386719 sec\n",
      "ONNX postprocessing took 0.002695798873901367 sec\n",
      "ONNX inference took 0.013975143432617188 sec\n",
      "ONNX postprocessing took 0.0021562576293945312 sec\n",
      "ONNX inference took 0.013871908187866211 sec\n",
      "ONNX postprocessing took 0.0031173229217529297 sec\n",
      "ONNX inference took 0.013606786727905273 sec\n",
      "ONNX postprocessing took 0.0024094581604003906 sec\n",
      "ONNX inference took 0.013061761856079102 sec\n",
      "ONNX postprocessing took 0.0032761096954345703 sec\n",
      "ONNX inference took 0.013528585433959961 sec\n",
      "ONNX postprocessing took 0.0029473304748535156 sec\n",
      "ONNX inference took 0.01357412338256836 sec\n",
      "ONNX postprocessing took 0.0027005672454833984 sec\n",
      "ONNX inference took 0.013642549514770508 sec\n",
      "ONNX postprocessing took 0.002434253692626953 sec\n",
      "ONNX inference took 0.013512849807739258 sec\n",
      "ONNX postprocessing took 0.004438161849975586 sec\n",
      "ONNX inference took 0.013347387313842773 sec\n",
      "ONNX postprocessing took 0.003145456314086914 sec\n",
      "ONNX inference took 0.013430118560791016 sec\n",
      "ONNX postprocessing took 0.0028285980224609375 sec\n",
      "ONNX inference took 0.013478994369506836 sec\n",
      "ONNX postprocessing took 0.004394054412841797 sec\n",
      "ONNX inference took 0.013352394104003906 sec\n",
      "ONNX postprocessing took 0.0032868385314941406 sec\n",
      "ONNX inference took 0.013844490051269531 sec\n",
      "ONNX postprocessing took 0.0029239654541015625 sec\n",
      "ONNX inference took 0.013671875 sec\n",
      "ONNX postprocessing took 0.0032792091369628906 sec\n",
      "ONNX inference took 0.013184547424316406 sec\n",
      "ONNX postprocessing took 0.001737833023071289 sec\n",
      "ONNX inference took 0.013854026794433594 sec\n",
      "ONNX postprocessing took 0.0025281906127929688 sec\n",
      "ONNX inference took 0.013618946075439453 sec\n",
      "ONNX postprocessing took 0.006285905838012695 sec\n",
      "ONNX inference took 0.014031171798706055 sec\n",
      "ONNX postprocessing took 0.0027403831481933594 sec\n",
      "ONNX inference took 0.01423788070678711 sec\n",
      "ONNX postprocessing took 0.008712530136108398 sec\n",
      "ONNX inference took 0.013293743133544922 sec\n",
      "ONNX postprocessing took 0.0029082298278808594 sec\n",
      "ONNX inference took 0.013844490051269531 sec\n",
      "ONNX postprocessing took 0.0030405521392822266 sec\n",
      "ONNX inference took 0.013527870178222656 sec\n",
      "ONNX postprocessing took 0.002507448196411133 sec\n",
      "ONNX inference took 0.013501644134521484 sec\n",
      "ONNX postprocessing took 0.003145456314086914 sec\n",
      "ONNX inference took 0.013213396072387695 sec\n",
      "ONNX postprocessing took 0.0030372142791748047 sec\n",
      "ONNX inference took 0.01421976089477539 sec\n",
      "ONNX postprocessing took 0.004339456558227539 sec\n",
      "ONNX inference took 0.013448953628540039 sec\n",
      "ONNX postprocessing took 0.003661632537841797 sec\n",
      "ONNX inference took 0.013745307922363281 sec\n",
      "ONNX postprocessing took 0.003175020217895508 sec\n",
      "ONNX inference took 0.0142822265625 sec\n",
      "ONNX postprocessing took 0.002924680709838867 sec\n",
      "ONNX inference took 0.013904571533203125 sec\n",
      "ONNX postprocessing took 0.002958059310913086 sec\n",
      "ONNX inference took 0.01352381706237793 sec\n",
      "ONNX postprocessing took 0.001621246337890625 sec\n",
      "ONNX inference took 0.01533055305480957 sec\n",
      "ONNX postprocessing took 0.005093812942504883 sec\n",
      "ONNX inference took 0.013555765151977539 sec\n",
      "ONNX postprocessing took 0.002721071243286133 sec\n",
      "ONNX inference took 0.013889789581298828 sec\n",
      "ONNX postprocessing took 0.004561901092529297 sec\n",
      "ONNX inference took 0.013179779052734375 sec\n",
      "ONNX postprocessing took 0.002901792526245117 sec\n",
      "ONNX inference took 0.013845443725585938 sec\n",
      "ONNX postprocessing took 0.0023984909057617188 sec\n",
      "ONNX inference took 0.013120651245117188 sec\n",
      "ONNX postprocessing took 0.0023889541625976562 sec\n",
      "ONNX inference took 0.014106988906860352 sec\n",
      "ONNX postprocessing took 0.003003358840942383 sec\n",
      "ONNX inference took 0.013051509857177734 sec\n",
      "ONNX postprocessing took 0.0018880367279052734 sec\n",
      "ONNX inference took 0.01408076286315918 sec\n",
      "ONNX postprocessing took 0.004227638244628906 sec\n",
      "ONNX inference took 0.01318359375 sec\n",
      "ONNX postprocessing took 0.0015528202056884766 sec\n",
      "ONNX inference took 0.01335000991821289 sec\n",
      "ONNX postprocessing took 0.0030362606048583984 sec\n",
      "ONNX inference took 0.014309883117675781 sec\n",
      "ONNX postprocessing took 0.0034627914428710938 sec\n",
      "ONNX inference took 0.014120817184448242 sec\n",
      "ONNX postprocessing took 0.0031824111938476562 sec\n",
      "ONNX inference took 0.013266563415527344 sec\n",
      "ONNX postprocessing took 0.002796173095703125 sec\n",
      "ONNX inference took 0.013277053833007812 sec\n",
      "ONNX postprocessing took 0.003289937973022461 sec\n",
      "ONNX inference took 0.014425039291381836 sec\n",
      "ONNX postprocessing took 0.002023935317993164 sec\n",
      "ONNX inference took 0.013320446014404297 sec\n",
      "ONNX postprocessing took 0.0022301673889160156 sec\n",
      "ONNX inference took 0.013407230377197266 sec\n",
      "ONNX postprocessing took 0.003521442413330078 sec\n",
      "ONNX inference took 0.013875007629394531 sec\n",
      "ONNX postprocessing took 0.00418853759765625 sec\n",
      "ONNX inference took 0.013628959655761719 sec\n",
      "ONNX postprocessing took 0.002079486846923828 sec\n",
      "ONNX inference took 0.013586044311523438 sec\n",
      "ONNX postprocessing took 0.0023949146270751953 sec\n",
      "ONNX inference took 0.013234376907348633 sec\n",
      "ONNX postprocessing took 0.002714872360229492 sec\n",
      "ONNX inference took 0.014086723327636719 sec\n",
      "ONNX postprocessing took 0.0028967857360839844 sec\n",
      "ONNX inference took 0.013566255569458008 sec\n",
      "ONNX postprocessing took 0.002291440963745117 sec\n",
      "ONNX inference took 0.014050960540771484 sec\n",
      "ONNX postprocessing took 0.0027892589569091797 sec\n",
      "ONNX inference took 0.013736724853515625 sec\n",
      "ONNX postprocessing took 0.004048347473144531 sec\n",
      "ONNX inference took 0.013301849365234375 sec\n",
      "ONNX postprocessing took 0.00504612922668457 sec\n",
      "ONNX inference took 0.014037847518920898 sec\n",
      "ONNX postprocessing took 0.0031096935272216797 sec\n",
      "ONNX inference took 0.013455390930175781 sec\n",
      "ONNX postprocessing took 0.002931833267211914 sec\n",
      "ONNX inference took 0.014022350311279297 sec\n",
      "ONNX postprocessing took 0.00334930419921875 sec\n",
      "ONNX inference took 0.014668703079223633 sec\n",
      "ONNX postprocessing took 0.003526449203491211 sec\n",
      "ONNX inference took 0.014126300811767578 sec\n",
      "ONNX postprocessing took 0.0038084983825683594 sec\n",
      "ONNX inference took 0.013903617858886719 sec\n",
      "ONNX postprocessing took 0.0063588619232177734 sec\n",
      "ONNX inference took 0.01335763931274414 sec\n",
      "ONNX postprocessing took 0.0023071765899658203 sec\n",
      "ONNX inference took 0.013207674026489258 sec\n",
      "ONNX postprocessing took 0.004456758499145508 sec\n",
      "ONNX inference took 0.013348817825317383 sec\n",
      "ONNX postprocessing took 0.0034470558166503906 sec\n",
      "ONNX inference took 0.014135360717773438 sec\n",
      "ONNX postprocessing took 0.0031723976135253906 sec\n",
      "ONNX inference took 0.014003753662109375 sec\n",
      "ONNX postprocessing took 0.0031785964965820312 sec\n",
      "ONNX inference took 0.013234376907348633 sec\n",
      "ONNX postprocessing took 0.0025615692138671875 sec\n",
      "ONNX inference took 0.013442516326904297 sec\n",
      "ONNX postprocessing took 0.0015785694122314453 sec\n",
      "ONNX inference took 0.014050960540771484 sec\n",
      "ONNX postprocessing took 0.0031280517578125 sec\n",
      "ONNX inference took 0.013618946075439453 sec\n",
      "ONNX postprocessing took 0.0018811225891113281 sec\n",
      "ONNX inference took 0.013733386993408203 sec\n",
      "ONNX postprocessing took 0.0031642913818359375 sec\n",
      "ONNX inference took 0.013586759567260742 sec\n",
      "ONNX postprocessing took 0.002377748489379883 sec\n",
      "ONNX inference took 0.013972282409667969 sec\n",
      "ONNX postprocessing took 0.0032498836517333984 sec\n",
      "ONNX inference took 0.013342142105102539 sec\n",
      "ONNX postprocessing took 0.003214597702026367 sec\n",
      "ONNX inference took 0.012935638427734375 sec\n",
      "ONNX postprocessing took 0.0023751258850097656 sec\n",
      "ONNX inference took 0.013233423233032227 sec\n",
      "ONNX postprocessing took 0.0022182464599609375 sec\n",
      "ONNX inference took 0.013615131378173828 sec\n",
      "ONNX postprocessing took 0.004589080810546875 sec\n",
      "ONNX inference took 0.013504981994628906 sec\n",
      "ONNX postprocessing took 0.0032205581665039062 sec\n",
      "ONNX inference took 0.014218807220458984 sec\n",
      "ONNX postprocessing took 0.0031850337982177734 sec\n",
      "ONNX inference took 0.01303243637084961 sec\n",
      "ONNX postprocessing took 0.00139617919921875 sec\n",
      "ONNX inference took 0.01462244987487793 sec\n",
      "ONNX postprocessing took 0.004780769348144531 sec\n",
      "ONNX inference took 0.013940811157226562 sec\n",
      "ONNX postprocessing took 0.0032346248626708984 sec\n",
      "ONNX inference took 0.013645410537719727 sec\n",
      "ONNX postprocessing took 0.005388498306274414 sec\n",
      "ONNX inference took 0.013669967651367188 sec\n",
      "ONNX postprocessing took 0.002958536148071289 sec\n",
      "ONNX inference took 0.013889074325561523 sec\n",
      "ONNX postprocessing took 0.0027832984924316406 sec\n",
      "ONNX inference took 0.01341104507446289 sec\n",
      "ONNX postprocessing took 0.0030710697174072266 sec\n",
      "ONNX inference took 0.014062643051147461 sec\n",
      "ONNX postprocessing took 0.004471302032470703 sec\n",
      "ONNX inference took 0.013703584671020508 sec\n",
      "ONNX postprocessing took 0.003509998321533203 sec\n",
      "ONNX inference took 0.013827085494995117 sec\n",
      "ONNX postprocessing took 0.0029230117797851562 sec\n",
      "ONNX inference took 0.014000654220581055 sec\n",
      "ONNX postprocessing took 0.0029032230377197266 sec\n",
      "ONNX inference took 0.013770818710327148 sec\n",
      "ONNX postprocessing took 0.0028734207153320312 sec\n",
      "ONNX inference took 0.014097929000854492 sec\n",
      "ONNX postprocessing took 0.0024700164794921875 sec\n",
      "ONNX inference took 0.014223814010620117 sec\n",
      "ONNX postprocessing took 0.003044605255126953 sec\n",
      "ONNX inference took 0.014141082763671875 sec\n",
      "ONNX postprocessing took 0.0030868053436279297 sec\n",
      "ONNX inference took 0.014322280883789062 sec\n",
      "ONNX postprocessing took 0.0032379627227783203 sec\n",
      "ONNX inference took 0.013144969940185547 sec\n",
      "ONNX postprocessing took 0.002861499786376953 sec\n",
      "ONNX inference took 0.013648509979248047 sec\n",
      "ONNX postprocessing took 0.003214120864868164 sec\n",
      "ONNX inference took 0.013788223266601562 sec\n",
      "ONNX postprocessing took 0.003190755844116211 sec\n",
      "ONNX inference took 0.014440774917602539 sec\n",
      "ONNX postprocessing took 0.0027587413787841797 sec\n",
      "ONNX inference took 0.013481616973876953 sec\n",
      "ONNX postprocessing took 0.002801179885864258 sec\n",
      "ONNX inference took 0.014377593994140625 sec\n",
      "ONNX postprocessing took 0.004776716232299805 sec\n",
      "ONNX inference took 0.013655662536621094 sec\n",
      "ONNX postprocessing took 0.0034863948822021484 sec\n",
      "ONNX inference took 0.013742685317993164 sec\n",
      "ONNX postprocessing took 0.0031206607818603516 sec\n",
      "ONNX inference took 0.014230728149414062 sec\n",
      "ONNX postprocessing took 0.002910614013671875 sec\n",
      "ONNX inference took 0.013063192367553711 sec\n",
      "ONNX postprocessing took 0.002098560333251953 sec\n",
      "ONNX inference took 0.01404261589050293 sec\n",
      "ONNX postprocessing took 0.0023653507232666016 sec\n",
      "ONNX inference took 0.01321268081665039 sec\n",
      "ONNX postprocessing took 0.003300905227661133 sec\n",
      "ONNX inference took 0.014470338821411133 sec\n",
      "ONNX postprocessing took 0.0031206607818603516 sec\n",
      "ONNX inference took 0.013594627380371094 sec\n",
      "ONNX postprocessing took 0.002947092056274414 sec\n",
      "ONNX inference took 0.013527393341064453 sec\n",
      "ONNX postprocessing took 0.003222942352294922 sec\n",
      "ONNX inference took 0.013105630874633789 sec\n",
      "ONNX postprocessing took 0.00379180908203125 sec\n",
      "ONNX inference took 0.013488531112670898 sec\n",
      "ONNX postprocessing took 0.0029578208923339844 sec\n",
      "ONNX inference took 0.013483524322509766 sec\n",
      "ONNX postprocessing took 0.002088785171508789 sec\n",
      "ONNX inference took 0.013982057571411133 sec\n",
      "ONNX postprocessing took 0.002436399459838867 sec\n",
      "ONNX inference took 0.013906478881835938 sec\n",
      "ONNX postprocessing took 0.002079010009765625 sec\n",
      "ONNX inference took 0.014194965362548828 sec\n",
      "ONNX postprocessing took 0.003993988037109375 sec\n",
      "ONNX inference took 0.013822317123413086 sec\n",
      "ONNX postprocessing took 0.0014522075653076172 sec\n",
      "ONNX inference took 0.013478517532348633 sec\n",
      "ONNX postprocessing took 0.0026001930236816406 sec\n",
      "ONNX inference took 0.013772010803222656 sec\n",
      "ONNX postprocessing took 0.0019559860229492188 sec\n",
      "ONNX inference took 0.01359248161315918 sec\n",
      "ONNX postprocessing took 0.002138376235961914 sec\n",
      "ONNX inference took 0.014841556549072266 sec\n",
      "ONNX postprocessing took 0.005767345428466797 sec\n",
      "ONNX inference took 0.014298200607299805 sec\n",
      "ONNX postprocessing took 0.0024051666259765625 sec\n",
      "ONNX inference took 0.013681888580322266 sec\n",
      "ONNX postprocessing took 0.002057313919067383 sec\n",
      "ONNX inference took 0.014158964157104492 sec\n",
      "ONNX postprocessing took 0.0029401779174804688 sec\n",
      "ONNX inference took 0.014915227890014648 sec\n",
      "ONNX postprocessing took 0.005312442779541016 sec\n",
      "ONNX inference took 0.013703584671020508 sec\n",
      "ONNX postprocessing took 0.0031011104583740234 sec\n",
      "ONNX inference took 0.014198780059814453 sec\n",
      "ONNX postprocessing took 0.0030794143676757812 sec\n",
      "ONNX inference took 0.013906478881835938 sec\n",
      "ONNX postprocessing took 0.002464771270751953 sec\n",
      "ONNX inference took 0.014212846755981445 sec\n",
      "ONNX postprocessing took 0.0028603076934814453 sec\n",
      "ONNX inference took 0.013345003128051758 sec\n",
      "ONNX postprocessing took 0.0025794506072998047 sec\n",
      "ONNX inference took 0.014147281646728516 sec\n",
      "ONNX postprocessing took 0.0032231807708740234 sec\n",
      "ONNX inference took 0.013912200927734375 sec\n",
      "ONNX postprocessing took 0.004401445388793945 sec\n",
      "ONNX inference took 0.013842344284057617 sec\n",
      "ONNX postprocessing took 0.0017294883728027344 sec\n",
      "ONNX inference took 0.014381647109985352 sec\n",
      "ONNX postprocessing took 0.005392551422119141 sec\n",
      "ONNX inference took 0.013660907745361328 sec\n",
      "ONNX postprocessing took 0.004210710525512695 sec\n",
      "ONNX inference took 0.014043092727661133 sec\n",
      "ONNX postprocessing took 0.0035419464111328125 sec\n",
      "ONNX inference took 0.013539791107177734 sec\n",
      "ONNX postprocessing took 0.0036215782165527344 sec\n",
      "ONNX inference took 0.013754844665527344 sec\n",
      "ONNX postprocessing took 0.003078460693359375 sec\n",
      "ONNX inference took 0.013340950012207031 sec\n",
      "ONNX postprocessing took 0.0030570030212402344 sec\n",
      "ONNX inference took 0.013629913330078125 sec\n",
      "ONNX postprocessing took 0.0026404857635498047 sec\n",
      "ONNX inference took 0.013409137725830078 sec\n",
      "ONNX postprocessing took 0.0014417171478271484 sec\n",
      "ONNX inference took 0.014022588729858398 sec\n",
      "ONNX postprocessing took 0.002015829086303711 sec\n",
      "ONNX inference took 0.014222145080566406 sec\n",
      "ONNX postprocessing took 0.0029180049896240234 sec\n",
      "ONNX inference took 0.013860464096069336 sec\n",
      "ONNX postprocessing took 0.004205465316772461 sec\n",
      "ONNX inference took 0.014226675033569336 sec\n",
      "ONNX postprocessing took 0.003974437713623047 sec\n",
      "ONNX inference took 0.013318061828613281 sec\n",
      "ONNX postprocessing took 0.004521369934082031 sec\n",
      "ONNX inference took 0.013912439346313477 sec\n",
      "ONNX postprocessing took 0.0069370269775390625 sec\n",
      "ONNX inference took 0.013726949691772461 sec\n",
      "ONNX postprocessing took 0.0028984546661376953 sec\n",
      "ONNX inference took 0.013711929321289062 sec\n",
      "ONNX postprocessing took 0.002965688705444336 sec\n",
      "ONNX inference took 0.013705730438232422 sec\n",
      "ONNX postprocessing took 0.0021402835845947266 sec\n",
      "ONNX inference took 0.013889312744140625 sec\n",
      "ONNX postprocessing took 0.002485513687133789 sec\n",
      "ONNX inference took 0.013491392135620117 sec\n",
      "ONNX postprocessing took 0.001790761947631836 sec\n",
      "ONNX inference took 0.013593673706054688 sec\n",
      "ONNX postprocessing took 0.0030167102813720703 sec\n",
      "ONNX inference took 0.01348733901977539 sec\n",
      "ONNX postprocessing took 0.004442453384399414 sec\n",
      "ONNX inference took 0.01348733901977539 sec\n",
      "ONNX postprocessing took 0.0038988590240478516 sec\n",
      "ONNX inference took 0.013815641403198242 sec\n",
      "ONNX postprocessing took 0.00292205810546875 sec\n",
      "ONNX inference took 0.013997077941894531 sec\n",
      "ONNX postprocessing took 0.002331972122192383 sec\n",
      "ONNX inference took 0.01324462890625 sec\n",
      "ONNX postprocessing took 0.003926515579223633 sec\n",
      "ONNX inference took 0.013693094253540039 sec\n",
      "ONNX postprocessing took 0.0028455257415771484 sec\n",
      "ONNX inference took 0.014158010482788086 sec\n",
      "ONNX postprocessing took 0.0021119117736816406 sec\n",
      "ONNX inference took 0.014177322387695312 sec\n",
      "ONNX postprocessing took 0.00529932975769043 sec\n",
      "ONNX inference took 0.014010906219482422 sec\n",
      "ONNX postprocessing took 0.0020008087158203125 sec\n",
      "ONNX inference took 0.013891458511352539 sec\n",
      "ONNX postprocessing took 0.0044553279876708984 sec\n",
      "ONNX inference took 0.01353311538696289 sec\n",
      "ONNX postprocessing took 0.002443075180053711 sec\n",
      "ONNX inference took 0.014219284057617188 sec\n",
      "ONNX postprocessing took 0.003922224044799805 sec\n",
      "ONNX inference took 0.013638496398925781 sec\n",
      "ONNX postprocessing took 0.005025625228881836 sec\n",
      "ONNX inference took 0.013603448867797852 sec\n",
      "ONNX postprocessing took 0.0025441646575927734 sec\n",
      "ONNX inference took 0.013627767562866211 sec\n",
      "ONNX postprocessing took 0.002883434295654297 sec\n",
      "ONNX inference took 0.013861656188964844 sec\n",
      "ONNX postprocessing took 0.0027947425842285156 sec\n",
      "ONNX inference took 0.01437687873840332 sec\n",
      "ONNX postprocessing took 0.0029191970825195312 sec\n",
      "ONNX inference took 0.01358342170715332 sec\n",
      "ONNX postprocessing took 0.0038919448852539062 sec\n",
      "ONNX inference took 0.013670921325683594 sec\n",
      "ONNX postprocessing took 0.003026723861694336 sec\n",
      "ONNX inference took 0.014579296112060547 sec\n",
      "ONNX postprocessing took 0.005432844161987305 sec\n",
      "ONNX inference took 0.013836860656738281 sec\n",
      "ONNX postprocessing took 0.0032007694244384766 sec\n",
      "ONNX inference took 0.012919187545776367 sec\n",
      "ONNX postprocessing took 0.004196882247924805 sec\n",
      "ONNX inference took 0.01363062858581543 sec\n",
      "ONNX postprocessing took 0.0036711692810058594 sec\n",
      "ONNX inference took 0.013581991195678711 sec\n",
      "ONNX postprocessing took 0.0028085708618164062 sec\n",
      "ONNX inference took 0.013786554336547852 sec\n",
      "ONNX postprocessing took 0.0025358200073242188 sec\n",
      "ONNX inference took 0.013492345809936523 sec\n",
      "ONNX postprocessing took 0.0045435428619384766 sec\n",
      "ONNX inference took 0.013689279556274414 sec\n",
      "ONNX postprocessing took 0.004922151565551758 sec\n",
      "ONNX inference took 0.01397395133972168 sec\n",
      "ONNX postprocessing took 0.0048847198486328125 sec\n",
      "ONNX inference took 0.013913869857788086 sec\n",
      "ONNX postprocessing took 0.002639293670654297 sec\n",
      "ONNX inference took 0.013641834259033203 sec\n",
      "ONNX postprocessing took 0.002491474151611328 sec\n",
      "ONNX inference took 0.014817237854003906 sec\n",
      "ONNX postprocessing took 0.0027408599853515625 sec\n",
      "ONNX inference took 0.01442098617553711 sec\n",
      "ONNX postprocessing took 0.005055904388427734 sec\n",
      "ONNX inference took 0.014140605926513672 sec\n",
      "ONNX postprocessing took 0.002888202667236328 sec\n",
      "ONNX inference took 0.013606548309326172 sec\n",
      "ONNX postprocessing took 0.002599000930786133 sec\n",
      "ONNX inference took 0.015053272247314453 sec\n",
      "ONNX postprocessing took 0.003512144088745117 sec\n",
      "ONNX inference took 0.013669967651367188 sec\n",
      "ONNX postprocessing took 0.002919912338256836 sec\n",
      "ONNX inference took 0.013976097106933594 sec\n",
      "ONNX postprocessing took 0.003021717071533203 sec\n",
      "ONNX inference took 0.01403045654296875 sec\n",
      "ONNX postprocessing took 0.002877473831176758 sec\n",
      "ONNX inference took 0.013532161712646484 sec\n",
      "ONNX postprocessing took 0.0018362998962402344 sec\n",
      "ONNX inference took 0.014220237731933594 sec\n",
      "ONNX postprocessing took 0.002893209457397461 sec\n",
      "ONNX inference took 0.013598442077636719 sec\n",
      "ONNX postprocessing took 0.005235195159912109 sec\n",
      "ONNX inference took 0.013635635375976562 sec\n",
      "ONNX postprocessing took 0.0027942657470703125 sec\n",
      "ONNX inference took 0.013950824737548828 sec\n",
      "ONNX postprocessing took 0.004555702209472656 sec\n",
      "ONNX inference took 0.014774084091186523 sec\n",
      "ONNX postprocessing took 0.0029442310333251953 sec\n",
      "ONNX inference took 0.013775110244750977 sec\n",
      "ONNX postprocessing took 0.0020377635955810547 sec\n",
      "ONNX inference took 0.01379084587097168 sec\n",
      "ONNX postprocessing took 0.015819072723388672 sec\n",
      "ONNX inference took 0.013318777084350586 sec\n",
      "ONNX postprocessing took 0.0029685497283935547 sec\n",
      "ONNX inference took 0.013152599334716797 sec\n",
      "ONNX postprocessing took 0.002292633056640625 sec\n",
      "ONNX inference took 0.014578104019165039 sec\n",
      "ONNX postprocessing took 0.006515979766845703 sec\n",
      "ONNX inference took 0.014180898666381836 sec\n",
      "ONNX postprocessing took 0.002007007598876953 sec\n",
      "ONNX inference took 0.013515233993530273 sec\n",
      "ONNX postprocessing took 0.003065824508666992 sec\n",
      "ONNX inference took 0.013035774230957031 sec\n",
      "ONNX postprocessing took 0.0019040107727050781 sec\n",
      "ONNX inference took 0.013263225555419922 sec\n",
      "ONNX postprocessing took 0.00325775146484375 sec\n",
      "ONNX inference took 0.013826370239257812 sec\n",
      "ONNX postprocessing took 0.001978158950805664 sec\n",
      "ONNX inference took 0.013753175735473633 sec\n",
      "ONNX postprocessing took 0.0028543472290039062 sec\n",
      "ONNX inference took 0.013857603073120117 sec\n",
      "ONNX postprocessing took 0.004909515380859375 sec\n",
      "ONNX inference took 0.0140228271484375 sec\n",
      "ONNX postprocessing took 0.0027451515197753906 sec\n",
      "ONNX inference took 0.013099193572998047 sec\n",
      "ONNX postprocessing took 0.00435328483581543 sec\n",
      "ONNX inference took 0.013827800750732422 sec\n",
      "ONNX postprocessing took 0.003287792205810547 sec\n",
      "ONNX inference took 0.01336050033569336 sec\n",
      "ONNX postprocessing took 0.0021533966064453125 sec\n",
      "ONNX inference took 0.014172792434692383 sec\n",
      "ONNX postprocessing took 0.004544734954833984 sec\n",
      "ONNX inference took 0.014862537384033203 sec\n",
      "ONNX postprocessing took 0.0026252269744873047 sec\n",
      "ONNX inference took 0.014165163040161133 sec\n",
      "ONNX postprocessing took 0.003696441650390625 sec\n",
      "ONNX inference took 0.013737916946411133 sec\n",
      "ONNX postprocessing took 0.002798795700073242 sec\n",
      "ONNX inference took 0.013479232788085938 sec\n",
      "ONNX postprocessing took 0.001722097396850586 sec\n",
      "ONNX inference took 0.013459205627441406 sec\n",
      "ONNX postprocessing took 0.00295257568359375 sec\n",
      "ONNX inference took 0.015112161636352539 sec\n",
      "ONNX postprocessing took 0.003713369369506836 sec\n",
      "ONNX inference took 0.01422262191772461 sec\n",
      "ONNX postprocessing took 0.0029959678649902344 sec\n",
      "ONNX inference took 0.013800621032714844 sec\n",
      "ONNX postprocessing took 0.0029964447021484375 sec\n",
      "ONNX inference took 0.013885736465454102 sec\n",
      "ONNX postprocessing took 0.0025119781494140625 sec\n",
      "ONNX inference took 0.013758182525634766 sec\n",
      "ONNX postprocessing took 0.0028269290924072266 sec\n",
      "ONNX inference took 0.013458728790283203 sec\n",
      "ONNX postprocessing took 0.0021495819091796875 sec\n",
      "ONNX inference took 0.014408349990844727 sec\n",
      "ONNX postprocessing took 0.003526449203491211 sec\n",
      "ONNX inference took 0.014096736907958984 sec\n",
      "ONNX postprocessing took 0.0029888153076171875 sec\n",
      "ONNX inference took 0.014163970947265625 sec\n",
      "ONNX postprocessing took 0.0023925304412841797 sec\n",
      "ONNX inference took 0.0147857666015625 sec\n",
      "ONNX postprocessing took 0.002975940704345703 sec\n",
      "ONNX inference took 0.013735771179199219 sec\n",
      "ONNX postprocessing took 0.0036249160766601562 sec\n",
      "ONNX inference took 0.013657093048095703 sec\n",
      "ONNX postprocessing took 0.0026056766510009766 sec\n",
      "ONNX inference took 0.013471364974975586 sec\n",
      "ONNX postprocessing took 0.0023033618927001953 sec\n",
      "ONNX inference took 0.014042377471923828 sec\n",
      "ONNX postprocessing took 0.00350189208984375 sec\n",
      "ONNX inference took 0.013527393341064453 sec\n",
      "ONNX postprocessing took 0.0035271644592285156 sec\n",
      "ONNX inference took 0.013846158981323242 sec\n",
      "ONNX postprocessing took 0.002058267593383789 sec\n",
      "ONNX inference took 0.013549327850341797 sec\n",
      "ONNX postprocessing took 0.0030333995819091797 sec\n",
      "ONNX inference took 0.014604568481445312 sec\n",
      "ONNX postprocessing took 0.003461122512817383 sec\n",
      "ONNX inference took 0.0142974853515625 sec\n",
      "ONNX postprocessing took 0.003000497817993164 sec\n",
      "ONNX inference took 0.014247894287109375 sec\n",
      "ONNX postprocessing took 0.005086183547973633 sec\n",
      "ONNX inference took 0.01416468620300293 sec\n",
      "ONNX postprocessing took 0.0019025802612304688 sec\n",
      "ONNX inference took 0.013500452041625977 sec\n",
      "ONNX postprocessing took 0.003066539764404297 sec\n",
      "ONNX inference took 0.014229774475097656 sec\n",
      "ONNX postprocessing took 0.0028765201568603516 sec\n",
      "ONNX inference took 0.013814687728881836 sec\n",
      "ONNX postprocessing took 0.0017154216766357422 sec\n",
      "ONNX inference took 0.014780759811401367 sec\n",
      "ONNX postprocessing took 0.0034101009368896484 sec\n",
      "ONNX inference took 0.013162612915039062 sec\n",
      "ONNX postprocessing took 0.0031561851501464844 sec\n",
      "ONNX inference took 0.013732433319091797 sec\n",
      "ONNX postprocessing took 0.002667665481567383 sec\n",
      "ONNX inference took 0.013714075088500977 sec\n",
      "ONNX postprocessing took 0.002154111862182617 sec\n",
      "ONNX inference took 0.013660907745361328 sec\n",
      "ONNX postprocessing took 0.004109859466552734 sec\n",
      "ONNX inference took 0.013490915298461914 sec\n",
      "ONNX postprocessing took 0.002849578857421875 sec\n",
      "ONNX inference took 0.01398468017578125 sec\n",
      "ONNX postprocessing took 0.002627849578857422 sec\n",
      "ONNX inference took 0.014102935791015625 sec\n",
      "ONNX postprocessing took 0.0030460357666015625 sec\n",
      "ONNX inference took 0.014458179473876953 sec\n",
      "ONNX postprocessing took 0.002622365951538086 sec\n",
      "ONNX inference took 0.013293027877807617 sec\n",
      "ONNX postprocessing took 0.0030126571655273438 sec\n",
      "ONNX inference took 0.014394283294677734 sec\n",
      "ONNX postprocessing took 0.003055572509765625 sec\n",
      "ONNX inference took 0.013907194137573242 sec\n",
      "ONNX postprocessing took 0.005087137222290039 sec\n",
      "ONNX inference took 0.013462066650390625 sec\n",
      "ONNX postprocessing took 0.0049059391021728516 sec\n",
      "ONNX inference took 0.012885570526123047 sec\n",
      "ONNX postprocessing took 0.002283334732055664 sec\n",
      "ONNX inference took 0.013789892196655273 sec\n",
      "ONNX postprocessing took 0.005036592483520508 sec\n",
      "ONNX inference took 0.013689041137695312 sec\n",
      "ONNX postprocessing took 0.002297639846801758 sec\n",
      "ONNX inference took 0.01398468017578125 sec\n",
      "ONNX postprocessing took 0.0016376972198486328 sec\n",
      "ONNX inference took 0.013899087905883789 sec\n",
      "ONNX postprocessing took 0.0025980472564697266 sec\n",
      "ONNX inference took 0.013803720474243164 sec\n",
      "ONNX postprocessing took 0.0030128955841064453 sec\n",
      "ONNX inference took 0.013241052627563477 sec\n",
      "ONNX postprocessing took 0.004472255706787109 sec\n",
      "ONNX inference took 0.013641595840454102 sec\n",
      "ONNX postprocessing took 0.004429340362548828 sec\n",
      "ONNX inference took 0.013413667678833008 sec\n",
      "ONNX postprocessing took 0.004651308059692383 sec\n",
      "ONNX inference took 0.014249086380004883 sec\n",
      "ONNX postprocessing took 0.006141185760498047 sec\n",
      "ONNX inference took 0.013116121292114258 sec\n",
      "ONNX postprocessing took 0.0032491683959960938 sec\n",
      "ONNX inference took 0.012283086776733398 sec\n",
      "ONNX postprocessing took 0.0014145374298095703 sec\n",
      "ONNX inference took 0.013299703598022461 sec\n",
      "ONNX postprocessing took 0.0012688636779785156 sec\n",
      "ONNX inference took 0.013150930404663086 sec\n",
      "ONNX postprocessing took 0.0011444091796875 sec\n",
      "ONNX inference took 0.014824867248535156 sec\n",
      "ONNX postprocessing took 0.0035774707794189453 sec\n",
      "ONNX inference took 0.013868570327758789 sec\n",
      "ONNX postprocessing took 0.002529144287109375 sec\n",
      "ONNX inference took 0.014191627502441406 sec\n",
      "ONNX postprocessing took 0.0028128623962402344 sec\n",
      "ONNX inference took 0.013467550277709961 sec\n",
      "ONNX postprocessing took 0.004723548889160156 sec\n",
      "ONNX inference took 0.013225078582763672 sec\n",
      "ONNX postprocessing took 0.003658294677734375 sec\n",
      "ONNX inference took 0.012824296951293945 sec\n",
      "ONNX postprocessing took 0.00231170654296875 sec\n",
      "ONNX inference took 0.014323711395263672 sec\n",
      "ONNX postprocessing took 0.0031900405883789062 sec\n",
      "ONNX inference took 0.013668298721313477 sec\n",
      "ONNX postprocessing took 0.002057790756225586 sec\n",
      "ONNX inference took 0.013572454452514648 sec\n",
      "ONNX postprocessing took 0.004950046539306641 sec\n",
      "ONNX inference took 0.013558626174926758 sec\n",
      "ONNX postprocessing took 0.0021996498107910156 sec\n",
      "ONNX inference took 0.013412952423095703 sec\n",
      "ONNX postprocessing took 0.001993417739868164 sec\n",
      "ONNX inference took 0.014292001724243164 sec\n",
      "ONNX postprocessing took 0.0022678375244140625 sec\n",
      "ONNX inference took 0.014468669891357422 sec\n",
      "ONNX postprocessing took 0.004520416259765625 sec\n",
      "ONNX inference took 0.013328313827514648 sec\n",
      "ONNX postprocessing took 0.0028710365295410156 sec\n",
      "ONNX inference took 0.014320135116577148 sec\n",
      "ONNX postprocessing took 0.0027091503143310547 sec\n",
      "ONNX inference took 0.014700889587402344 sec\n",
      "ONNX postprocessing took 0.004533529281616211 sec\n",
      "ONNX inference took 0.013405084609985352 sec\n",
      "ONNX postprocessing took 0.0032188892364501953 sec\n",
      "ONNX inference took 0.013454437255859375 sec\n",
      "ONNX postprocessing took 0.0035789012908935547 sec\n",
      "ONNX inference took 0.013357400894165039 sec\n",
      "ONNX postprocessing took 0.004281044006347656 sec\n",
      "ONNX inference took 0.013293266296386719 sec\n",
      "ONNX postprocessing took 0.002132415771484375 sec\n",
      "ONNX inference took 0.013688802719116211 sec\n",
      "ONNX postprocessing took 0.0055866241455078125 sec\n",
      "ONNX inference took 0.013400077819824219 sec\n",
      "ONNX postprocessing took 0.0027468204498291016 sec\n",
      "ONNX inference took 0.014260292053222656 sec\n",
      "ONNX postprocessing took 0.002508401870727539 sec\n",
      "ONNX inference took 0.013407230377197266 sec\n",
      "ONNX postprocessing took 0.004009723663330078 sec\n",
      "ONNX inference took 0.013162851333618164 sec\n",
      "ONNX postprocessing took 0.001954793930053711 sec\n",
      "ONNX inference took 0.014124631881713867 sec\n",
      "ONNX postprocessing took 0.0031881332397460938 sec\n",
      "ONNX inference took 0.014590024948120117 sec\n",
      "ONNX postprocessing took 0.004209995269775391 sec\n",
      "ONNX inference took 0.01395106315612793 sec\n",
      "ONNX postprocessing took 0.002547025680541992 sec\n",
      "ONNX inference took 0.014912128448486328 sec\n",
      "ONNX postprocessing took 0.0031681060791015625 sec\n",
      "ONNX inference took 0.013740777969360352 sec\n",
      "ONNX postprocessing took 0.003311634063720703 sec\n",
      "ONNX inference took 0.013261079788208008 sec\n",
      "ONNX postprocessing took 0.0022673606872558594 sec\n",
      "ONNX inference took 0.013837337493896484 sec\n",
      "ONNX postprocessing took 0.0025038719177246094 sec\n",
      "ONNX inference took 0.014016151428222656 sec\n",
      "ONNX postprocessing took 0.0021233558654785156 sec\n",
      "ONNX inference took 0.01428985595703125 sec\n",
      "ONNX postprocessing took 0.0025014877319335938 sec\n",
      "ONNX inference took 0.014295339584350586 sec\n",
      "ONNX postprocessing took 0.003406524658203125 sec\n",
      "ONNX inference took 0.013617277145385742 sec\n",
      "ONNX postprocessing took 0.0025081634521484375 sec\n",
      "ONNX inference took 0.014064788818359375 sec\n",
      "ONNX postprocessing took 0.0025627613067626953 sec\n",
      "ONNX inference took 0.014330387115478516 sec\n",
      "ONNX postprocessing took 0.004233121871948242 sec\n",
      "ONNX inference took 0.013959884643554688 sec\n",
      "ONNX postprocessing took 0.0020172595977783203 sec\n",
      "ONNX inference took 0.013645648956298828 sec\n",
      "ONNX postprocessing took 0.0023720264434814453 sec\n",
      "ONNX inference took 0.014099836349487305 sec\n",
      "ONNX postprocessing took 0.002104520797729492 sec\n",
      "ONNX inference took 0.01371312141418457 sec\n",
      "ONNX postprocessing took 0.0017440319061279297 sec\n",
      "ONNX inference took 0.014614582061767578 sec\n",
      "ONNX postprocessing took 0.0039021968841552734 sec\n",
      "ONNX inference took 0.013689994812011719 sec\n",
      "ONNX postprocessing took 0.004522085189819336 sec\n",
      "ONNX inference took 0.01336669921875 sec\n",
      "ONNX postprocessing took 0.00177764892578125 sec\n",
      "ONNX inference took 0.013840913772583008 sec\n",
      "ONNX postprocessing took 0.003966331481933594 sec\n",
      "ONNX inference took 0.013618946075439453 sec\n",
      "ONNX postprocessing took 0.0025925636291503906 sec\n",
      "ONNX inference took 0.014257192611694336 sec\n",
      "ONNX postprocessing took 0.001836538314819336 sec\n",
      "ONNX inference took 0.01384425163269043 sec\n",
      "ONNX postprocessing took 0.0033409595489501953 sec\n",
      "ONNX inference took 0.014001607894897461 sec\n",
      "ONNX postprocessing took 0.0029113292694091797 sec\n",
      "ONNX inference took 0.013777017593383789 sec\n",
      "ONNX postprocessing took 0.0024957656860351562 sec\n",
      "ONNX inference took 0.014255762100219727 sec\n",
      "ONNX postprocessing took 0.0018000602722167969 sec\n",
      "ONNX inference took 0.013920307159423828 sec\n",
      "ONNX postprocessing took 0.0027811527252197266 sec\n",
      "ONNX inference took 0.01344442367553711 sec\n",
      "ONNX postprocessing took 0.006048440933227539 sec\n",
      "ONNX inference took 0.013411760330200195 sec\n",
      "ONNX postprocessing took 0.002180814743041992 sec\n",
      "ONNX inference took 0.01400446891784668 sec\n",
      "ONNX postprocessing took 0.0032196044921875 sec\n",
      "ONNX inference took 0.014889955520629883 sec\n",
      "ONNX postprocessing took 0.005115509033203125 sec\n",
      "ONNX inference took 0.013351678848266602 sec\n",
      "ONNX postprocessing took 0.004348278045654297 sec\n",
      "ONNX inference took 0.013060808181762695 sec\n",
      "ONNX postprocessing took 0.00164794921875 sec\n",
      "ONNX inference took 0.01608109474182129 sec\n",
      "ONNX postprocessing took 0.002693653106689453 sec\n",
      "ONNX inference took 0.014494895935058594 sec\n",
      "ONNX postprocessing took 0.0035200119018554688 sec\n",
      "ONNX inference took 0.014356851577758789 sec\n",
      "ONNX postprocessing took 0.0029075145721435547 sec\n",
      "ONNX inference took 0.013062000274658203 sec\n",
      "ONNX postprocessing took 0.0020432472229003906 sec\n",
      "ONNX inference took 0.013788700103759766 sec\n",
      "ONNX postprocessing took 0.003049612045288086 sec\n",
      "ONNX inference took 0.013843297958374023 sec\n",
      "ONNX postprocessing took 0.0029938220977783203 sec\n",
      "ONNX inference took 0.013826131820678711 sec\n",
      "ONNX postprocessing took 0.001918792724609375 sec\n",
      "ONNX inference took 0.014655828475952148 sec\n",
      "ONNX postprocessing took 0.005052089691162109 sec\n",
      "ONNX inference took 0.013519763946533203 sec\n",
      "ONNX postprocessing took 0.0021750926971435547 sec\n",
      "ONNX inference took 0.014681100845336914 sec\n",
      "ONNX postprocessing took 0.005423307418823242 sec\n",
      "ONNX inference took 0.012700557708740234 sec\n",
      "ONNX postprocessing took 0.002399444580078125 sec\n",
      "ONNX inference took 0.014113664627075195 sec\n",
      "ONNX postprocessing took 0.00262451171875 sec\n",
      "ONNX inference took 0.014188766479492188 sec\n",
      "ONNX postprocessing took 0.0020666122436523438 sec\n",
      "ONNX inference took 0.014659881591796875 sec\n",
      "ONNX postprocessing took 0.004082918167114258 sec\n",
      "ONNX inference took 0.013917684555053711 sec\n",
      "ONNX postprocessing took 0.0035524368286132812 sec\n",
      "ONNX inference took 0.013590812683105469 sec\n",
      "ONNX postprocessing took 0.002652883529663086 sec\n",
      "ONNX inference took 0.013904571533203125 sec\n",
      "ONNX postprocessing took 0.003161907196044922 sec\n",
      "ONNX inference took 0.013414859771728516 sec\n",
      "ONNX postprocessing took 0.003228425979614258 sec\n",
      "ONNX inference took 0.013406753540039062 sec\n",
      "ONNX postprocessing took 0.0015950202941894531 sec\n",
      "ONNX inference took 0.014144659042358398 sec\n",
      "ONNX postprocessing took 0.0023386478424072266 sec\n",
      "ONNX inference took 0.014599800109863281 sec\n",
      "ONNX postprocessing took 0.0029706954956054688 sec\n",
      "ONNX inference took 0.013527393341064453 sec\n",
      "ONNX postprocessing took 0.0024945735931396484 sec\n",
      "ONNX inference took 0.014098644256591797 sec\n",
      "ONNX postprocessing took 0.0031981468200683594 sec\n",
      "ONNX inference took 0.013733148574829102 sec\n",
      "ONNX postprocessing took 0.00191497802734375 sec\n",
      "ONNX inference took 0.013950586318969727 sec\n",
      "ONNX postprocessing took 0.003196239471435547 sec\n",
      "ONNX inference took 0.013901948928833008 sec\n",
      "ONNX postprocessing took 0.0033860206604003906 sec\n",
      "ONNX inference took 0.0142364501953125 sec\n",
      "ONNX postprocessing took 0.0045166015625 sec\n",
      "ONNX inference took 0.013724327087402344 sec\n",
      "ONNX postprocessing took 0.0024607181549072266 sec\n",
      "ONNX inference took 0.013232231140136719 sec\n",
      "ONNX postprocessing took 0.002897500991821289 sec\n",
      "ONNX inference took 0.0144195556640625 sec\n",
      "ONNX postprocessing took 0.004556894302368164 sec\n",
      "ONNX inference took 0.013753652572631836 sec\n",
      "ONNX postprocessing took 0.0020384788513183594 sec\n",
      "ONNX inference took 0.01427769660949707 sec\n",
      "ONNX postprocessing took 0.0030205249786376953 sec\n",
      "ONNX inference took 0.013392210006713867 sec\n",
      "ONNX postprocessing took 0.002524852752685547 sec\n",
      "ONNX inference took 0.013924121856689453 sec\n",
      "ONNX postprocessing took 0.004617452621459961 sec\n",
      "ONNX inference took 0.013646364212036133 sec\n",
      "ONNX postprocessing took 0.0024182796478271484 sec\n",
      "ONNX inference took 0.013892650604248047 sec\n",
      "ONNX postprocessing took 0.003000497817993164 sec\n",
      "ONNX inference took 0.013511419296264648 sec\n",
      "ONNX postprocessing took 0.002942323684692383 sec\n",
      "ONNX inference took 0.015037775039672852 sec\n",
      "ONNX postprocessing took 0.0038213729858398438 sec\n",
      "ONNX inference took 0.014008760452270508 sec\n",
      "ONNX postprocessing took 0.0029325485229492188 sec\n",
      "ONNX inference took 0.013417720794677734 sec\n",
      "ONNX postprocessing took 0.002924680709838867 sec\n",
      "ONNX inference took 0.013468265533447266 sec\n",
      "ONNX postprocessing took 0.0029680728912353516 sec\n",
      "ONNX inference took 0.013722896575927734 sec\n",
      "ONNX postprocessing took 0.0016202926635742188 sec\n",
      "ONNX inference took 0.013406753540039062 sec\n",
      "ONNX postprocessing took 0.0047321319580078125 sec\n",
      "ONNX inference took 0.013700485229492188 sec\n",
      "ONNX postprocessing took 0.003414630889892578 sec\n",
      "ONNX inference took 0.014045476913452148 sec\n",
      "ONNX postprocessing took 0.0025424957275390625 sec\n",
      "ONNX inference took 0.012270689010620117 sec\n",
      "ONNX postprocessing took 0.0009889602661132812 sec\n",
      "ONNX inference took 0.014003992080688477 sec\n",
      "ONNX postprocessing took 0.004573822021484375 sec\n",
      "ONNX inference took 0.013664007186889648 sec\n",
      "ONNX postprocessing took 0.006237983703613281 sec\n",
      "ONNX inference took 0.013226509094238281 sec\n",
      "ONNX postprocessing took 0.0017778873443603516 sec\n",
      "ONNX inference took 0.013570785522460938 sec\n",
      "ONNX postprocessing took 0.002815723419189453 sec\n",
      "ONNX inference took 0.014608383178710938 sec\n",
      "ONNX postprocessing took 0.003690481185913086 sec\n",
      "ONNX inference took 0.013581991195678711 sec\n",
      "ONNX postprocessing took 0.002773761749267578 sec\n",
      "ONNX inference took 0.013472557067871094 sec\n",
      "ONNX postprocessing took 0.0031387805938720703 sec\n",
      "ONNX inference took 0.014247417449951172 sec\n",
      "ONNX postprocessing took 0.004377841949462891 sec\n",
      "ONNX inference took 0.014727592468261719 sec\n",
      "ONNX postprocessing took 0.002413034439086914 sec\n",
      "ONNX inference took 0.013640403747558594 sec\n",
      "ONNX postprocessing took 0.003924131393432617 sec\n",
      "ONNX inference took 0.013311386108398438 sec\n",
      "ONNX postprocessing took 0.002828359603881836 sec\n",
      "ONNX inference took 0.014019012451171875 sec\n",
      "ONNX postprocessing took 0.0021762847900390625 sec\n",
      "ONNX inference took 0.013552427291870117 sec\n",
      "ONNX postprocessing took 0.0030219554901123047 sec\n",
      "ONNX inference took 0.014200448989868164 sec\n",
      "ONNX postprocessing took 0.0046617984771728516 sec\n",
      "ONNX inference took 0.01365804672241211 sec\n",
      "ONNX postprocessing took 0.0026657581329345703 sec\n",
      "ONNX inference took 0.014597177505493164 sec\n",
      "ONNX postprocessing took 0.002536773681640625 sec\n",
      "ONNX inference took 0.013754844665527344 sec\n",
      "ONNX postprocessing took 0.0022695064544677734 sec\n",
      "ONNX inference took 0.014152050018310547 sec\n",
      "ONNX postprocessing took 0.0032291412353515625 sec\n",
      "ONNX inference took 0.014805078506469727 sec\n",
      "ONNX postprocessing took 0.0028967857360839844 sec\n",
      "ONNX inference took 0.014103174209594727 sec\n",
      "ONNX postprocessing took 0.002602100372314453 sec\n",
      "ONNX inference took 0.012996435165405273 sec\n",
      "ONNX postprocessing took 0.002105712890625 sec\n",
      "ONNX inference took 0.014001607894897461 sec\n",
      "ONNX postprocessing took 0.002944469451904297 sec\n",
      "ONNX inference took 0.013406038284301758 sec\n",
      "ONNX postprocessing took 0.005166292190551758 sec\n",
      "ONNX inference took 0.01400899887084961 sec\n",
      "ONNX postprocessing took 0.004189491271972656 sec\n",
      "ONNX inference took 0.014042139053344727 sec\n",
      "ONNX postprocessing took 0.0026397705078125 sec\n",
      "ONNX inference took 0.01399993896484375 sec\n",
      "ONNX postprocessing took 0.002916574478149414 sec\n",
      "ONNX inference took 0.013787984848022461 sec\n",
      "ONNX postprocessing took 0.005038738250732422 sec\n",
      "ONNX inference took 0.014119386672973633 sec\n",
      "ONNX postprocessing took 0.0020465850830078125 sec\n",
      "ONNX inference took 0.014324665069580078 sec\n",
      "ONNX postprocessing took 0.0052967071533203125 sec\n",
      "ONNX inference took 0.013544797897338867 sec\n",
      "ONNX postprocessing took 0.005468130111694336 sec\n",
      "ONNX inference took 0.013881444931030273 sec\n",
      "ONNX postprocessing took 0.003968715667724609 sec\n",
      "ONNX inference took 0.013437986373901367 sec\n",
      "ONNX postprocessing took 0.002013683319091797 sec\n",
      "ONNX inference took 0.014117240905761719 sec\n",
      "ONNX postprocessing took 0.0043146610260009766 sec\n",
      "ONNX inference took 0.013655424118041992 sec\n",
      "ONNX postprocessing took 0.006963014602661133 sec\n",
      "ONNX inference took 0.013835430145263672 sec\n",
      "ONNX postprocessing took 0.006003379821777344 sec\n",
      "ONNX inference took 0.014354467391967773 sec\n",
      "ONNX postprocessing took 0.0022923946380615234 sec\n",
      "ONNX inference took 0.014133930206298828 sec\n",
      "ONNX postprocessing took 0.0031540393829345703 sec\n",
      "ONNX inference took 0.013720035552978516 sec\n",
      "ONNX postprocessing took 0.0023267269134521484 sec\n",
      "ONNX inference took 0.013497114181518555 sec\n",
      "ONNX postprocessing took 0.0025069713592529297 sec\n",
      "ONNX inference took 0.013460397720336914 sec\n",
      "ONNX postprocessing took 0.0030977725982666016 sec\n",
      "ONNX inference took 0.01409006118774414 sec\n",
      "ONNX postprocessing took 0.0032799243927001953 sec\n",
      "ONNX inference took 0.014100790023803711 sec\n",
      "ONNX postprocessing took 0.003984689712524414 sec\n",
      "ONNX inference took 0.01338052749633789 sec\n",
      "ONNX postprocessing took 0.00209808349609375 sec\n",
      "ONNX inference took 0.014716148376464844 sec\n",
      "ONNX postprocessing took 0.005587100982666016 sec\n",
      "ONNX inference took 0.014288902282714844 sec\n",
      "ONNX postprocessing took 0.004436969757080078 sec\n",
      "ONNX inference took 0.013370513916015625 sec\n",
      "ONNX postprocessing took 0.003217458724975586 sec\n",
      "ONNX inference took 0.014647960662841797 sec\n",
      "ONNX postprocessing took 0.010282039642333984 sec\n",
      "ONNX inference took 0.013904094696044922 sec\n",
      "ONNX postprocessing took 0.002664327621459961 sec\n",
      "ONNX inference took 0.014432907104492188 sec\n",
      "ONNX postprocessing took 0.007400035858154297 sec\n",
      "ONNX inference took 0.014546632766723633 sec\n",
      "ONNX postprocessing took 0.0022683143615722656 sec\n",
      "ONNX inference took 0.013655424118041992 sec\n",
      "ONNX postprocessing took 0.0026674270629882812 sec\n",
      "ONNX inference took 0.014003515243530273 sec\n",
      "ONNX postprocessing took 0.004381418228149414 sec\n",
      "ONNX inference took 0.01403188705444336 sec\n",
      "ONNX postprocessing took 0.003309011459350586 sec\n",
      "ONNX inference took 0.014238595962524414 sec\n",
      "ONNX postprocessing took 0.002865314483642578 sec\n",
      "ONNX inference took 0.013394832611083984 sec\n",
      "ONNX postprocessing took 0.004288196563720703 sec\n",
      "ONNX inference took 0.013838529586791992 sec\n",
      "ONNX postprocessing took 0.002956390380859375 sec\n",
      "ONNX inference took 0.014162540435791016 sec\n",
      "ONNX postprocessing took 0.003020048141479492 sec\n",
      "ONNX inference took 0.013725519180297852 sec\n",
      "ONNX postprocessing took 0.006022214889526367 sec\n",
      "ONNX inference took 0.013277769088745117 sec\n",
      "ONNX postprocessing took 0.003238677978515625 sec\n",
      "ONNX inference took 0.013356685638427734 sec\n",
      "ONNX postprocessing took 0.004441499710083008 sec\n",
      "ONNX inference took 0.01375126838684082 sec\n",
      "ONNX postprocessing took 0.0029494762420654297 sec\n",
      "ONNX inference took 0.01351308822631836 sec\n",
      "ONNX postprocessing took 0.005094051361083984 sec\n",
      "ONNX inference took 0.013277053833007812 sec\n",
      "ONNX postprocessing took 0.0027899742126464844 sec\n",
      "ONNX inference took 0.01378941535949707 sec\n",
      "ONNX postprocessing took 0.003628969192504883 sec\n",
      "ONNX inference took 0.014043569564819336 sec\n",
      "ONNX postprocessing took 0.0030879974365234375 sec\n",
      "ONNX inference took 0.013556718826293945 sec\n",
      "ONNX postprocessing took 0.005364179611206055 sec\n",
      "ONNX inference took 0.013895034790039062 sec\n",
      "ONNX postprocessing took 0.003926277160644531 sec\n",
      "ONNX inference took 0.014132022857666016 sec\n",
      "ONNX postprocessing took 0.0056552886962890625 sec\n",
      "ONNX inference took 0.014142513275146484 sec\n",
      "ONNX postprocessing took 0.003875255584716797 sec\n",
      "ONNX inference took 0.013709545135498047 sec\n",
      "ONNX postprocessing took 0.005221128463745117 sec\n",
      "ONNX inference took 0.014253616333007812 sec\n",
      "ONNX postprocessing took 0.004782676696777344 sec\n",
      "ONNX inference took 0.013623237609863281 sec\n",
      "ONNX postprocessing took 0.003231525421142578 sec\n",
      "ONNX inference took 0.014535903930664062 sec\n",
      "ONNX postprocessing took 0.005961418151855469 sec\n",
      "ONNX inference took 0.013164520263671875 sec\n",
      "ONNX postprocessing took 0.0018601417541503906 sec\n",
      "ONNX inference took 0.013592004776000977 sec\n",
      "ONNX postprocessing took 0.0012216567993164062 sec\n",
      "ONNX inference took 0.015162944793701172 sec\n",
      "ONNX postprocessing took 0.003582000732421875 sec\n",
      "ONNX inference took 0.01421666145324707 sec\n",
      "ONNX postprocessing took 0.003309488296508789 sec\n",
      "ONNX inference took 0.014496803283691406 sec\n",
      "ONNX postprocessing took 0.00444483757019043 sec\n",
      "ONNX inference took 0.013583660125732422 sec\n",
      "ONNX postprocessing took 0.0037250518798828125 sec\n",
      "ONNX inference took 0.013280630111694336 sec\n",
      "ONNX postprocessing took 0.005317211151123047 sec\n",
      "ONNX inference took 0.013506889343261719 sec\n",
      "ONNX postprocessing took 0.0026493072509765625 sec\n",
      "ONNX inference took 0.013170480728149414 sec\n",
      "ONNX postprocessing took 0.004190921783447266 sec\n",
      "ONNX inference took 0.01352548599243164 sec\n",
      "ONNX postprocessing took 0.0035364627838134766 sec\n",
      "ONNX inference took 0.01347208023071289 sec\n",
      "ONNX postprocessing took 0.0032625198364257812 sec\n",
      "ONNX inference took 0.013155937194824219 sec\n",
      "ONNX postprocessing took 0.002505064010620117 sec\n",
      "ONNX inference took 0.014041662216186523 sec\n",
      "ONNX postprocessing took 0.0034203529357910156 sec\n",
      "ONNX inference took 0.013835668563842773 sec\n",
      "ONNX postprocessing took 0.006247043609619141 sec\n",
      "ONNX inference took 0.013777732849121094 sec\n",
      "ONNX postprocessing took 0.0032491683959960938 sec\n",
      "ONNX inference took 0.013096809387207031 sec\n",
      "ONNX postprocessing took 0.001459360122680664 sec\n",
      "ONNX inference took 0.012867212295532227 sec\n",
      "ONNX postprocessing took 0.0017504692077636719 sec\n",
      "ONNX inference took 0.013374090194702148 sec\n",
      "ONNX postprocessing took 0.0015652179718017578 sec\n",
      "ONNX inference took 0.013258218765258789 sec\n",
      "ONNX postprocessing took 0.001001119613647461 sec\n",
      "ONNX inference took 0.013602018356323242 sec\n",
      "ONNX postprocessing took 0.0027413368225097656 sec\n",
      "ONNX inference took 0.012662887573242188 sec\n",
      "ONNX postprocessing took 0.0014786720275878906 sec\n",
      "ONNX inference took 0.012875556945800781 sec\n",
      "ONNX postprocessing took 0.001383066177368164 sec\n",
      "ONNX inference took 0.013451337814331055 sec\n",
      "ONNX postprocessing took 0.001451730728149414 sec\n",
      "ONNX inference took 0.01302647590637207 sec\n",
      "ONNX postprocessing took 0.0021762847900390625 sec\n",
      "ONNX inference took 0.013736248016357422 sec\n",
      "ONNX postprocessing took 0.003892183303833008 sec\n",
      "ONNX inference took 0.014518260955810547 sec\n",
      "ONNX postprocessing took 0.007097005844116211 sec\n",
      "ONNX inference took 0.01426839828491211 sec\n",
      "ONNX postprocessing took 0.003634214401245117 sec\n",
      "ONNX inference took 0.013184785842895508 sec\n",
      "ONNX postprocessing took 0.004439115524291992 sec\n",
      "ONNX inference took 0.013774633407592773 sec\n",
      "ONNX postprocessing took 0.003180980682373047 sec\n",
      "ONNX inference took 0.014495849609375 sec\n",
      "ONNX postprocessing took 0.0069005489349365234 sec\n",
      "ONNX inference took 0.013721704483032227 sec\n",
      "ONNX postprocessing took 0.002750873565673828 sec\n",
      "ONNX inference took 0.014145135879516602 sec\n",
      "ONNX postprocessing took 0.0034618377685546875 sec\n",
      "ONNX inference took 0.013288497924804688 sec\n",
      "ONNX postprocessing took 0.002162933349609375 sec\n",
      "ONNX inference took 0.013986349105834961 sec\n",
      "ONNX postprocessing took 0.003095865249633789 sec\n",
      "ONNX inference took 0.013512372970581055 sec\n",
      "ONNX postprocessing took 0.0021903514862060547 sec\n",
      "ONNX inference took 0.013666152954101562 sec\n",
      "ONNX postprocessing took 0.0026445388793945312 sec\n",
      "ONNX inference took 0.014340400695800781 sec\n",
      "ONNX postprocessing took 0.0020837783813476562 sec\n",
      "ONNX inference took 0.013984918594360352 sec\n",
      "ONNX postprocessing took 0.0051915645599365234 sec\n",
      "ONNX inference took 0.013419866561889648 sec\n",
      "ONNX postprocessing took 0.0023424625396728516 sec\n",
      "ONNX inference took 0.013567924499511719 sec\n",
      "ONNX postprocessing took 0.001651763916015625 sec\n",
      "ONNX inference took 0.013955354690551758 sec\n",
      "ONNX postprocessing took 0.002019166946411133 sec\n",
      "ONNX inference took 0.013544321060180664 sec\n",
      "ONNX postprocessing took 0.002836465835571289 sec\n",
      "ONNX inference took 0.014515399932861328 sec\n",
      "ONNX postprocessing took 0.0029206275939941406 sec\n",
      "ONNX inference took 0.013819694519042969 sec\n",
      "ONNX postprocessing took 0.004914283752441406 sec\n",
      "ONNX inference took 0.014300346374511719 sec\n",
      "ONNX postprocessing took 0.0026068687438964844 sec\n",
      "ONNX inference took 0.014385223388671875 sec\n",
      "ONNX postprocessing took 0.0037376880645751953 sec\n",
      "ONNX inference took 0.014402151107788086 sec\n",
      "ONNX postprocessing took 0.003843545913696289 sec\n",
      "ONNX inference took 0.013061285018920898 sec\n",
      "ONNX postprocessing took 0.002301931381225586 sec\n",
      "ONNX inference took 0.014458894729614258 sec\n",
      "ONNX postprocessing took 0.004689216613769531 sec\n",
      "ONNX inference took 0.014192819595336914 sec\n",
      "ONNX postprocessing took 0.002824544906616211 sec\n",
      "ONNX inference took 0.013396501541137695 sec\n",
      "ONNX postprocessing took 0.002192974090576172 sec\n",
      "ONNX inference took 0.014387130737304688 sec\n",
      "ONNX postprocessing took 0.0032732486724853516 sec\n",
      "ONNX inference took 0.01468348503112793 sec\n",
      "ONNX postprocessing took 0.0044939517974853516 sec\n",
      "ONNX inference took 0.014980077743530273 sec\n",
      "ONNX postprocessing took 0.0026481151580810547 sec\n",
      "ONNX inference took 0.013843059539794922 sec\n",
      "ONNX postprocessing took 0.003018617630004883 sec\n",
      "ONNX inference took 0.013446331024169922 sec\n",
      "ONNX postprocessing took 0.0018677711486816406 sec\n",
      "ONNX inference took 0.014372587203979492 sec\n",
      "ONNX postprocessing took 0.003366708755493164 sec\n",
      "ONNX inference took 0.013806819915771484 sec\n",
      "ONNX postprocessing took 0.002796173095703125 sec\n",
      "ONNX inference took 0.013313055038452148 sec\n",
      "ONNX postprocessing took 0.004690408706665039 sec\n",
      "ONNX inference took 0.013319730758666992 sec\n",
      "ONNX postprocessing took 0.0014357566833496094 sec\n",
      "ONNX inference took 0.014421701431274414 sec\n",
      "ONNX postprocessing took 0.003387451171875 sec\n",
      "ONNX inference took 0.014372587203979492 sec\n",
      "ONNX postprocessing took 0.0020363330841064453 sec\n",
      "ONNX inference took 0.014705181121826172 sec\n",
      "ONNX postprocessing took 0.0035552978515625 sec\n",
      "ONNX inference took 0.014304876327514648 sec\n",
      "ONNX postprocessing took 0.0031507015228271484 sec\n",
      "ONNX inference took 0.013766050338745117 sec\n",
      "ONNX postprocessing took 0.0037424564361572266 sec\n",
      "ONNX inference took 0.013641595840454102 sec\n",
      "ONNX postprocessing took 0.002559661865234375 sec\n",
      "ONNX inference took 0.01400136947631836 sec\n",
      "ONNX postprocessing took 0.0048182010650634766 sec\n",
      "ONNX inference took 0.013839244842529297 sec\n",
      "ONNX postprocessing took 0.0027184486389160156 sec\n",
      "ONNX inference took 0.014469385147094727 sec\n",
      "ONNX postprocessing took 0.0035636425018310547 sec\n",
      "ONNX inference took 0.015219449996948242 sec\n",
      "ONNX postprocessing took 0.0031135082244873047 sec\n",
      "ONNX inference took 0.013690471649169922 sec\n",
      "ONNX postprocessing took 0.0027174949645996094 sec\n",
      "ONNX inference took 0.013594865798950195 sec\n",
      "ONNX postprocessing took 0.0025360584259033203 sec\n",
      "ONNX inference took 0.014857053756713867 sec\n",
      "ONNX postprocessing took 0.0039234161376953125 sec\n",
      "ONNX inference took 0.014062166213989258 sec\n",
      "ONNX postprocessing took 0.0044062137603759766 sec\n",
      "ONNX inference took 0.013762950897216797 sec\n",
      "ONNX postprocessing took 0.004641294479370117 sec\n",
      "ONNX inference took 0.01385354995727539 sec\n",
      "ONNX postprocessing took 0.0020422935485839844 sec\n",
      "ONNX inference took 0.014115571975708008 sec\n",
      "ONNX postprocessing took 0.0045392513275146484 sec\n",
      "ONNX inference took 0.013519048690795898 sec\n",
      "ONNX postprocessing took 0.003770589828491211 sec\n",
      "ONNX inference took 0.013940095901489258 sec\n",
      "ONNX postprocessing took 0.0031921863555908203 sec\n",
      "ONNX inference took 0.01360464096069336 sec\n",
      "ONNX postprocessing took 0.0030672550201416016 sec\n",
      "ONNX inference took 0.014093875885009766 sec\n",
      "ONNX postprocessing took 0.0021152496337890625 sec\n",
      "ONNX inference took 0.01422119140625 sec\n",
      "ONNX postprocessing took 0.002848386764526367 sec\n",
      "ONNX inference took 0.014435052871704102 sec\n",
      "ONNX postprocessing took 0.002016782760620117 sec\n",
      "ONNX inference took 0.013642072677612305 sec\n",
      "ONNX postprocessing took 0.002104043960571289 sec\n",
      "ONNX inference took 0.014545440673828125 sec\n",
      "ONNX postprocessing took 0.003177165985107422 sec\n",
      "ONNX inference took 0.013702630996704102 sec\n",
      "ONNX postprocessing took 0.0029604434967041016 sec\n",
      "ONNX inference took 0.014200210571289062 sec\n",
      "ONNX postprocessing took 0.002956867218017578 sec\n",
      "ONNX inference took 0.013344764709472656 sec\n",
      "ONNX postprocessing took 0.0024483203887939453 sec\n",
      "ONNX inference took 0.013606786727905273 sec\n",
      "ONNX postprocessing took 0.006402015686035156 sec\n",
      "ONNX inference took 0.013180017471313477 sec\n",
      "ONNX postprocessing took 0.0013165473937988281 sec\n",
      "ONNX inference took 0.013825416564941406 sec\n",
      "ONNX postprocessing took 0.0028128623962402344 sec\n",
      "ONNX inference took 0.015079975128173828 sec\n",
      "ONNX postprocessing took 0.005918025970458984 sec\n",
      "ONNX inference took 0.013673782348632812 sec\n",
      "ONNX postprocessing took 0.00508570671081543 sec\n",
      "ONNX inference took 0.013356924057006836 sec\n",
      "ONNX postprocessing took 0.004703998565673828 sec\n",
      "ONNX inference took 0.013910770416259766 sec\n",
      "ONNX postprocessing took 0.0031991004943847656 sec\n",
      "ONNX inference took 0.013916015625 sec\n",
      "ONNX postprocessing took 0.0033893585205078125 sec\n",
      "ONNX inference took 0.014511585235595703 sec\n",
      "ONNX postprocessing took 0.002924203872680664 sec\n",
      "ONNX inference took 0.013711929321289062 sec\n",
      "ONNX postprocessing took 0.0015621185302734375 sec\n",
      "ONNX inference took 0.012769937515258789 sec\n",
      "ONNX postprocessing took 0.002082347869873047 sec\n",
      "ONNX inference took 0.0129547119140625 sec\n",
      "ONNX postprocessing took 0.0023953914642333984 sec\n",
      "ONNX inference took 0.015363693237304688 sec\n",
      "ONNX postprocessing took 0.00438690185546875 sec\n",
      "ONNX inference took 0.01412653923034668 sec\n",
      "ONNX postprocessing took 0.002568483352661133 sec\n",
      "ONNX inference took 0.014107465744018555 sec\n",
      "ONNX postprocessing took 0.002810955047607422 sec\n",
      "ONNX inference took 0.014348030090332031 sec\n",
      "ONNX postprocessing took 0.002782106399536133 sec\n",
      "ONNX inference took 0.01337575912475586 sec\n",
      "ONNX postprocessing took 0.0020341873168945312 sec\n",
      "ONNX inference took 0.013381719589233398 sec\n",
      "ONNX postprocessing took 0.005322933197021484 sec\n",
      "ONNX inference took 0.013638496398925781 sec\n",
      "ONNX postprocessing took 0.004655599594116211 sec\n",
      "ONNX inference took 0.013578176498413086 sec\n",
      "ONNX postprocessing took 0.0028357505798339844 sec\n",
      "ONNX inference took 0.014413118362426758 sec\n",
      "ONNX postprocessing took 0.003578662872314453 sec\n",
      "ONNX inference took 0.014354944229125977 sec\n",
      "ONNX postprocessing took 0.003216981887817383 sec\n",
      "ONNX inference took 0.014194011688232422 sec\n",
      "ONNX postprocessing took 0.0030913352966308594 sec\n",
      "ONNX inference took 0.013310909271240234 sec\n",
      "ONNX postprocessing took 0.0024535655975341797 sec\n",
      "ONNX inference took 0.013402223587036133 sec\n",
      "ONNX postprocessing took 0.003091573715209961 sec\n",
      "ONNX inference took 0.013764381408691406 sec\n",
      "ONNX postprocessing took 0.0033206939697265625 sec\n",
      "ONNX inference took 0.013658285140991211 sec\n",
      "ONNX postprocessing took 0.004758119583129883 sec\n",
      "ONNX inference took 0.014210700988769531 sec\n",
      "ONNX postprocessing took 0.002737283706665039 sec\n",
      "ONNX inference took 0.013496875762939453 sec\n",
      "ONNX postprocessing took 0.004842519760131836 sec\n",
      "ONNX inference took 0.014057397842407227 sec\n",
      "ONNX postprocessing took 0.004358768463134766 sec\n",
      "ONNX inference took 0.013761281967163086 sec\n",
      "ONNX postprocessing took 0.0029647350311279297 sec\n",
      "ONNX inference took 0.01379251480102539 sec\n",
      "ONNX postprocessing took 0.004208564758300781 sec\n",
      "ONNX inference took 0.013763189315795898 sec\n",
      "ONNX postprocessing took 0.0026433467864990234 sec\n",
      "ONNX inference took 0.014208555221557617 sec\n",
      "ONNX postprocessing took 0.0032999515533447266 sec\n",
      "ONNX inference took 0.013675928115844727 sec\n",
      "ONNX postprocessing took 0.0024225711822509766 sec\n",
      "ONNX inference took 0.014156103134155273 sec\n",
      "ONNX postprocessing took 0.004164695739746094 sec\n",
      "ONNX inference took 0.014239072799682617 sec\n",
      "ONNX postprocessing took 0.002216815948486328 sec\n",
      "ONNX inference took 0.01431131362915039 sec\n",
      "ONNX postprocessing took 0.003366231918334961 sec\n",
      "ONNX inference took 0.013663291931152344 sec\n",
      "ONNX postprocessing took 0.001962900161743164 sec\n",
      "ONNX inference took 0.013523578643798828 sec\n",
      "ONNX postprocessing took 0.0028502941131591797 sec\n",
      "ONNX inference took 0.014912843704223633 sec\n",
      "ONNX postprocessing took 0.002695798873901367 sec\n",
      "ONNX inference took 0.013895273208618164 sec\n",
      "ONNX postprocessing took 0.0025899410247802734 sec\n",
      "ONNX inference took 0.014487981796264648 sec\n",
      "ONNX postprocessing took 0.003236532211303711 sec\n",
      "ONNX inference took 0.013643741607666016 sec\n",
      "ONNX postprocessing took 0.0026705265045166016 sec\n",
      "ONNX inference took 0.013917922973632812 sec\n",
      "ONNX postprocessing took 0.0026979446411132812 sec\n",
      "ONNX inference took 0.014349699020385742 sec\n",
      "ONNX postprocessing took 0.002869844436645508 sec\n",
      "ONNX inference took 0.01387643814086914 sec\n",
      "ONNX postprocessing took 0.0047762393951416016 sec\n",
      "ONNX inference took 0.013676643371582031 sec\n",
      "ONNX postprocessing took 0.0030236244201660156 sec\n",
      "ONNX inference took 0.01340031623840332 sec\n",
      "ONNX postprocessing took 0.001516103744506836 sec\n",
      "ONNX inference took 0.013780832290649414 sec\n",
      "ONNX postprocessing took 0.0036242008209228516 sec\n",
      "ONNX inference took 0.013715267181396484 sec\n",
      "ONNX postprocessing took 0.0014488697052001953 sec\n",
      "ONNX inference took 0.014068126678466797 sec\n",
      "ONNX postprocessing took 0.0026421546936035156 sec\n",
      "ONNX inference took 0.01356196403503418 sec\n",
      "ONNX postprocessing took 0.0020427703857421875 sec\n",
      "ONNX inference took 0.014824867248535156 sec\n",
      "ONNX postprocessing took 0.0040357112884521484 sec\n",
      "ONNX inference took 0.013183116912841797 sec\n",
      "ONNX postprocessing took 0.0029993057250976562 sec\n",
      "ONNX inference took 0.013470888137817383 sec\n",
      "ONNX postprocessing took 0.002337932586669922 sec\n",
      "ONNX inference took 0.013872385025024414 sec\n",
      "ONNX postprocessing took 0.0021839141845703125 sec\n",
      "ONNX inference took 0.013991594314575195 sec\n",
      "ONNX postprocessing took 0.0029642581939697266 sec\n",
      "ONNX inference took 0.013449430465698242 sec\n",
      "ONNX postprocessing took 0.002251148223876953 sec\n",
      "ONNX inference took 0.015272378921508789 sec\n",
      "ONNX postprocessing took 0.0055866241455078125 sec\n",
      "ONNX inference took 0.014036893844604492 sec\n",
      "ONNX postprocessing took 0.011575460433959961 sec\n",
      "ONNX inference took 0.014847993850708008 sec\n",
      "ONNX postprocessing took 0.002866983413696289 sec\n",
      "ONNX inference took 0.013879537582397461 sec\n",
      "ONNX postprocessing took 0.002694368362426758 sec\n",
      "ONNX inference took 0.013947010040283203 sec\n",
      "ONNX postprocessing took 0.0029942989349365234 sec\n",
      "ONNX inference took 0.014412879943847656 sec\n",
      "ONNX postprocessing took 0.003000497817993164 sec\n",
      "ONNX inference took 0.014128446578979492 sec\n",
      "ONNX postprocessing took 0.00401759147644043 sec\n",
      "ONNX inference took 0.013995170593261719 sec\n",
      "ONNX postprocessing took 0.002771139144897461 sec\n",
      "ONNX inference took 0.014060258865356445 sec\n",
      "ONNX postprocessing took 0.003510713577270508 sec\n",
      "ONNX inference took 0.013566255569458008 sec\n",
      "ONNX postprocessing took 0.0033409595489501953 sec\n",
      "ONNX inference took 0.014404058456420898 sec\n",
      "ONNX postprocessing took 0.003313779830932617 sec\n",
      "ONNX inference took 0.012514114379882812 sec\n",
      "ONNX postprocessing took 0.0015180110931396484 sec\n",
      "ONNX inference took 0.012975454330444336 sec\n",
      "ONNX postprocessing took 0.002175569534301758 sec\n",
      "ONNX inference took 0.01389312744140625 sec\n",
      "ONNX postprocessing took 0.002918243408203125 sec\n",
      "ONNX inference took 0.014261484146118164 sec\n",
      "ONNX postprocessing took 0.0030777454376220703 sec\n",
      "ONNX inference took 0.013539552688598633 sec\n",
      "ONNX postprocessing took 0.001990079879760742 sec\n",
      "ONNX inference took 0.013219356536865234 sec\n",
      "ONNX postprocessing took 0.003030538558959961 sec\n",
      "ONNX inference took 0.013492822647094727 sec\n",
      "ONNX postprocessing took 0.0036041736602783203 sec\n",
      "ONNX inference took 0.013367652893066406 sec\n",
      "ONNX postprocessing took 0.0044367313385009766 sec\n",
      "ONNX inference took 0.01354837417602539 sec\n",
      "ONNX postprocessing took 0.004316568374633789 sec\n",
      "ONNX inference took 0.013641357421875 sec\n",
      "ONNX postprocessing took 0.004048585891723633 sec\n",
      "ONNX inference took 0.013627767562866211 sec\n",
      "ONNX postprocessing took 0.003556489944458008 sec\n",
      "ONNX inference took 0.014001607894897461 sec\n",
      "ONNX postprocessing took 0.0019080638885498047 sec\n",
      "ONNX inference took 0.01427316665649414 sec\n",
      "ONNX postprocessing took 0.002619504928588867 sec\n",
      "ONNX inference took 0.013304471969604492 sec\n",
      "ONNX postprocessing took 0.003634214401245117 sec\n",
      "ONNX inference took 0.013495445251464844 sec\n",
      "ONNX postprocessing took 0.003452777862548828 sec\n",
      "ONNX inference took 0.014800071716308594 sec\n",
      "ONNX postprocessing took 0.0019218921661376953 sec\n",
      "ONNX inference took 0.013176202774047852 sec\n",
      "ONNX postprocessing took 0.0016317367553710938 sec\n",
      "ONNX inference took 0.013131856918334961 sec\n",
      "ONNX postprocessing took 0.0028765201568603516 sec\n",
      "ONNX inference took 0.013921260833740234 sec\n",
      "ONNX postprocessing took 0.0028274059295654297 sec\n",
      "ONNX inference took 0.0142059326171875 sec\n",
      "ONNX postprocessing took 0.0047533512115478516 sec\n",
      "ONNX inference took 0.012982368469238281 sec\n",
      "ONNX postprocessing took 0.0035555362701416016 sec\n",
      "ONNX inference took 0.014833688735961914 sec\n",
      "ONNX postprocessing took 0.004454612731933594 sec\n",
      "ONNX inference took 0.014399051666259766 sec\n",
      "ONNX postprocessing took 0.005281925201416016 sec\n",
      "ONNX inference took 0.013939380645751953 sec\n",
      "ONNX postprocessing took 0.002972841262817383 sec\n",
      "ONNX inference took 0.01383066177368164 sec\n",
      "ONNX postprocessing took 0.003859996795654297 sec\n",
      "ONNX inference took 0.014909029006958008 sec\n",
      "ONNX postprocessing took 0.002519369125366211 sec\n",
      "ONNX inference took 0.013675928115844727 sec\n",
      "ONNX postprocessing took 0.002470731735229492 sec\n",
      "ONNX inference took 0.014458179473876953 sec\n",
      "ONNX postprocessing took 0.0026884078979492188 sec\n",
      "ONNX inference took 0.013712406158447266 sec\n",
      "ONNX postprocessing took 0.0025739669799804688 sec\n",
      "ONNX inference took 0.013896703720092773 sec\n",
      "ONNX postprocessing took 0.0016493797302246094 sec\n",
      "ONNX inference took 0.01381373405456543 sec\n",
      "ONNX postprocessing took 0.002766132354736328 sec\n",
      "ONNX inference took 0.01430201530456543 sec\n",
      "ONNX postprocessing took 0.0029048919677734375 sec\n",
      "ONNX inference took 0.013718128204345703 sec\n",
      "ONNX postprocessing took 0.0027534961700439453 sec\n",
      "ONNX inference took 0.013848304748535156 sec\n",
      "ONNX postprocessing took 0.0037305355072021484 sec\n",
      "ONNX inference took 0.013558387756347656 sec\n",
      "ONNX postprocessing took 0.0024597644805908203 sec\n",
      "ONNX inference took 0.013832807540893555 sec\n",
      "ONNX postprocessing took 0.0020170211791992188 sec\n",
      "ONNX inference took 0.013342618942260742 sec\n",
      "ONNX postprocessing took 0.0025975704193115234 sec\n",
      "ONNX inference took 0.014416933059692383 sec\n",
      "ONNX postprocessing took 0.002134084701538086 sec\n",
      "ONNX inference took 0.013779878616333008 sec\n",
      "ONNX postprocessing took 0.002682924270629883 sec\n",
      "ONNX inference took 0.013885259628295898 sec\n",
      "ONNX postprocessing took 0.002975940704345703 sec\n",
      "ONNX inference took 0.013698816299438477 sec\n",
      "ONNX postprocessing took 0.0030603408813476562 sec\n",
      "ONNX inference took 0.013495683670043945 sec\n",
      "ONNX postprocessing took 0.0029954910278320312 sec\n",
      "ONNX inference took 0.01341700553894043 sec\n",
      "ONNX postprocessing took 0.0022001266479492188 sec\n",
      "ONNX inference took 0.013891458511352539 sec\n",
      "ONNX postprocessing took 0.0033292770385742188 sec\n",
      "ONNX inference took 0.013210058212280273 sec\n",
      "ONNX postprocessing took 0.001997709274291992 sec\n",
      "ONNX inference took 0.014720916748046875 sec\n",
      "ONNX postprocessing took 0.002766132354736328 sec\n",
      "ONNX inference took 0.013062238693237305 sec\n",
      "ONNX postprocessing took 0.0028476715087890625 sec\n",
      "ONNX inference took 0.01355600357055664 sec\n",
      "ONNX postprocessing took 0.0031447410583496094 sec\n",
      "ONNX inference took 0.013509511947631836 sec\n",
      "ONNX postprocessing took 0.0030853748321533203 sec\n",
      "ONNX inference took 0.013943195343017578 sec\n",
      "ONNX postprocessing took 0.002890348434448242 sec\n",
      "ONNX inference took 0.013719320297241211 sec\n",
      "ONNX postprocessing took 0.0024938583374023438 sec\n",
      "ONNX inference took 0.013326644897460938 sec\n",
      "ONNX postprocessing took 0.002054452896118164 sec\n",
      "ONNX inference took 0.01368403434753418 sec\n",
      "ONNX postprocessing took 0.002748250961303711 sec\n",
      "ONNX inference took 0.013909578323364258 sec\n",
      "ONNX postprocessing took 0.0027773380279541016 sec\n",
      "ONNX inference took 0.013962030410766602 sec\n",
      "ONNX postprocessing took 0.002007007598876953 sec\n",
      "ONNX inference took 0.014343976974487305 sec\n",
      "ONNX postprocessing took 0.0022406578063964844 sec\n",
      "ONNX inference took 0.01417088508605957 sec\n",
      "ONNX postprocessing took 0.004734516143798828 sec\n",
      "ONNX inference took 0.014030218124389648 sec\n",
      "ONNX postprocessing took 0.0029060840606689453 sec\n",
      "ONNX inference took 0.013387918472290039 sec\n",
      "ONNX postprocessing took 0.003239870071411133 sec\n",
      "ONNX inference took 0.014395952224731445 sec\n",
      "ONNX postprocessing took 0.0029478073120117188 sec\n",
      "ONNX inference took 0.013955116271972656 sec\n",
      "ONNX postprocessing took 0.003801107406616211 sec\n",
      "ONNX inference took 0.01441192626953125 sec\n",
      "ONNX postprocessing took 0.0030617713928222656 sec\n",
      "ONNX inference took 0.014089107513427734 sec\n",
      "ONNX postprocessing took 0.002956867218017578 sec\n",
      "ONNX inference took 0.013889312744140625 sec\n",
      "ONNX postprocessing took 0.0024232864379882812 sec\n",
      "ONNX inference took 0.014209747314453125 sec\n",
      "ONNX postprocessing took 0.003020763397216797 sec\n",
      "ONNX inference took 0.013649225234985352 sec\n",
      "ONNX postprocessing took 0.005099773406982422 sec\n",
      "ONNX inference took 0.013390302658081055 sec\n",
      "ONNX postprocessing took 0.0025382041931152344 sec\n",
      "ONNX inference took 0.013897418975830078 sec\n",
      "ONNX postprocessing took 0.0034160614013671875 sec\n",
      "ONNX inference took 0.013323307037353516 sec\n",
      "ONNX postprocessing took 0.0014908313751220703 sec\n",
      "ONNX inference took 0.01310276985168457 sec\n",
      "ONNX postprocessing took 0.0018253326416015625 sec\n",
      "ONNX inference took 0.012889623641967773 sec\n",
      "ONNX postprocessing took 0.002931356430053711 sec\n",
      "ONNX inference took 0.01268911361694336 sec\n",
      "ONNX postprocessing took 0.0033426284790039062 sec\n",
      "ONNX inference took 0.012894392013549805 sec\n",
      "ONNX postprocessing took 0.0028328895568847656 sec\n",
      "ONNX inference took 0.01462554931640625 sec\n",
      "ONNX postprocessing took 0.004880666732788086 sec\n",
      "ONNX inference took 0.014580965042114258 sec\n",
      "ONNX postprocessing took 0.0027616024017333984 sec\n",
      "ONNX inference took 0.014241456985473633 sec\n",
      "ONNX postprocessing took 0.004868507385253906 sec\n",
      "ONNX inference took 0.013593912124633789 sec\n",
      "ONNX postprocessing took 0.004221200942993164 sec\n",
      "ONNX inference took 0.01288294792175293 sec\n",
      "ONNX postprocessing took 0.004313230514526367 sec\n",
      "ONNX inference took 0.013748884201049805 sec\n",
      "ONNX postprocessing took 0.0026242733001708984 sec\n",
      "ONNX inference took 0.014001846313476562 sec\n",
      "ONNX postprocessing took 0.005194664001464844 sec\n",
      "ONNX inference took 0.014056682586669922 sec\n",
      "ONNX postprocessing took 0.00316619873046875 sec\n",
      "ONNX inference took 0.014979839324951172 sec\n",
      "ONNX postprocessing took 0.002760648727416992 sec\n",
      "ONNX inference took 0.013277530670166016 sec\n",
      "ONNX postprocessing took 0.004714250564575195 sec\n",
      "ONNX inference took 0.013857364654541016 sec\n",
      "ONNX postprocessing took 0.002982616424560547 sec\n",
      "ONNX inference took 0.013280391693115234 sec\n",
      "ONNX postprocessing took 0.00471949577331543 sec\n",
      "ONNX inference took 0.014255523681640625 sec\n",
      "ONNX postprocessing took 0.0037584304809570312 sec\n",
      "ONNX inference took 0.01397562026977539 sec\n",
      "ONNX postprocessing took 0.0024428367614746094 sec\n",
      "ONNX inference took 0.013703107833862305 sec\n",
      "ONNX postprocessing took 0.002561330795288086 sec\n",
      "ONNX inference took 0.013764142990112305 sec\n",
      "ONNX postprocessing took 0.0028183460235595703 sec\n",
      "ONNX inference took 0.014009237289428711 sec\n",
      "ONNX postprocessing took 0.004322528839111328 sec\n",
      "ONNX inference took 0.013881683349609375 sec\n",
      "ONNX postprocessing took 0.00284576416015625 sec\n",
      "ONNX inference took 0.014297723770141602 sec\n",
      "ONNX postprocessing took 0.005487680435180664 sec\n",
      "ONNX inference took 0.013931751251220703 sec\n",
      "ONNX postprocessing took 0.0029604434967041016 sec\n",
      "ONNX inference took 0.013823270797729492 sec\n",
      "ONNX postprocessing took 0.0032193660736083984 sec\n",
      "ONNX inference took 0.013519525527954102 sec\n",
      "ONNX postprocessing took 0.0037717819213867188 sec\n",
      "ONNX inference took 0.013354063034057617 sec\n",
      "ONNX postprocessing took 0.0028476715087890625 sec\n",
      "ONNX inference took 0.014518022537231445 sec\n",
      "ONNX postprocessing took 0.0026366710662841797 sec\n",
      "ONNX inference took 0.014125347137451172 sec\n",
      "ONNX postprocessing took 0.0052852630615234375 sec\n",
      "ONNX inference took 0.014107227325439453 sec\n",
      "ONNX postprocessing took 0.0032830238342285156 sec\n",
      "ONNX inference took 0.014582633972167969 sec\n",
      "ONNX postprocessing took 0.002019166946411133 sec\n",
      "ONNX inference took 0.013528823852539062 sec\n",
      "ONNX postprocessing took 0.002362489700317383 sec\n",
      "ONNX inference took 0.014655590057373047 sec\n",
      "ONNX postprocessing took 0.0031740665435791016 sec\n",
      "ONNX inference took 0.01450037956237793 sec\n",
      "ONNX postprocessing took 0.0023446083068847656 sec\n",
      "ONNX inference took 0.014432668685913086 sec\n",
      "ONNX postprocessing took 0.002986431121826172 sec\n",
      "ONNX inference took 0.013554573059082031 sec\n",
      "ONNX postprocessing took 0.0030350685119628906 sec\n",
      "ONNX inference took 0.014665603637695312 sec\n",
      "ONNX postprocessing took 0.0032472610473632812 sec\n",
      "ONNX inference took 0.013545989990234375 sec\n",
      "ONNX postprocessing took 0.002098560333251953 sec\n",
      "ONNX inference took 0.014451265335083008 sec\n",
      "ONNX postprocessing took 0.002814054489135742 sec\n",
      "ONNX inference took 0.013643503189086914 sec\n",
      "ONNX postprocessing took 0.004006862640380859 sec\n",
      "ONNX inference took 0.01400303840637207 sec\n",
      "ONNX postprocessing took 0.0018458366394042969 sec\n",
      "ONNX inference took 0.014068841934204102 sec\n",
      "ONNX postprocessing took 0.0023627281188964844 sec\n",
      "ONNX inference took 0.013724803924560547 sec\n",
      "ONNX postprocessing took 0.003331899642944336 sec\n",
      "ONNX inference took 0.013836860656738281 sec\n",
      "ONNX postprocessing took 0.0028944015502929688 sec\n",
      "ONNX inference took 0.013904094696044922 sec\n",
      "ONNX postprocessing took 0.004849672317504883 sec\n",
      "ONNX inference took 0.01377558708190918 sec\n",
      "ONNX postprocessing took 0.0017011165618896484 sec\n",
      "ONNX inference took 0.013945817947387695 sec\n",
      "ONNX postprocessing took 0.0031740665435791016 sec\n",
      "ONNX inference took 0.013983726501464844 sec\n",
      "ONNX postprocessing took 0.0030138492584228516 sec\n",
      "ONNX inference took 0.014389514923095703 sec\n",
      "ONNX postprocessing took 0.0029947757720947266 sec\n",
      "ONNX inference took 0.01440882682800293 sec\n",
      "ONNX postprocessing took 0.002057313919067383 sec\n",
      "ONNX inference took 0.013965606689453125 sec\n",
      "ONNX postprocessing took 0.0030128955841064453 sec\n",
      "ONNX inference took 0.013740062713623047 sec\n",
      "ONNX postprocessing took 0.0027532577514648438 sec\n",
      "ONNX inference took 0.01412653923034668 sec\n",
      "ONNX postprocessing took 0.002691030502319336 sec\n",
      "ONNX inference took 0.014580965042114258 sec\n",
      "ONNX postprocessing took 0.00709080696105957 sec\n",
      "ONNX inference took 0.01339268684387207 sec\n",
      "ONNX postprocessing took 0.002914905548095703 sec\n",
      "ONNX inference took 0.014738082885742188 sec\n",
      "ONNX postprocessing took 0.0023365020751953125 sec\n",
      "ONNX inference took 0.01442265510559082 sec\n",
      "ONNX postprocessing took 0.003371715545654297 sec\n",
      "ONNX inference took 0.014565706253051758 sec\n",
      "ONNX postprocessing took 0.0027549266815185547 sec\n",
      "ONNX inference took 0.0139923095703125 sec\n",
      "ONNX postprocessing took 0.0024433135986328125 sec\n",
      "ONNX inference took 0.014026880264282227 sec\n",
      "ONNX postprocessing took 0.002159595489501953 sec\n",
      "ONNX inference took 0.014046430587768555 sec\n",
      "ONNX postprocessing took 0.004596710205078125 sec\n",
      "ONNX inference took 0.01345062255859375 sec\n",
      "ONNX postprocessing took 0.0020384788513183594 sec\n",
      "ONNX inference took 0.01377105712890625 sec\n",
      "ONNX postprocessing took 0.002323150634765625 sec\n",
      "ONNX inference took 0.014872312545776367 sec\n",
      "ONNX postprocessing took 0.0046765804290771484 sec\n",
      "ONNX inference took 0.013377904891967773 sec\n",
      "ONNX postprocessing took 0.0034148693084716797 sec\n",
      "ONNX inference took 0.014061212539672852 sec\n",
      "ONNX postprocessing took 0.0028738975524902344 sec\n",
      "ONNX inference took 0.014274120330810547 sec\n",
      "ONNX postprocessing took 0.0029752254486083984 sec\n",
      "ONNX inference took 0.013441324234008789 sec\n",
      "ONNX postprocessing took 0.004630565643310547 sec\n",
      "ONNX inference took 0.014389753341674805 sec\n",
      "ONNX postprocessing took 0.004822492599487305 sec\n",
      "ONNX inference took 0.01419520378112793 sec\n",
      "ONNX postprocessing took 0.0031998157501220703 sec\n",
      "ONNX inference took 0.014165163040161133 sec\n",
      "ONNX postprocessing took 0.004339694976806641 sec\n",
      "ONNX inference took 0.013220787048339844 sec\n",
      "ONNX postprocessing took 0.0021653175354003906 sec\n",
      "ONNX inference took 0.013530254364013672 sec\n",
      "ONNX postprocessing took 0.0031518936157226562 sec\n",
      "ONNX inference took 0.013170003890991211 sec\n",
      "ONNX postprocessing took 0.002830028533935547 sec\n",
      "ONNX inference took 0.013817071914672852 sec\n",
      "ONNX postprocessing took 0.00409388542175293 sec\n",
      "ONNX inference took 0.013628959655761719 sec\n",
      "ONNX postprocessing took 0.002088785171508789 sec\n",
      "ONNX inference took 0.013481616973876953 sec\n",
      "ONNX postprocessing took 0.0019354820251464844 sec\n",
      "ONNX inference took 0.014465093612670898 sec\n",
      "ONNX postprocessing took 0.0022122859954833984 sec\n",
      "ONNX inference took 0.01439356803894043 sec\n",
      "ONNX postprocessing took 0.0026941299438476562 sec\n",
      "ONNX inference took 0.013712406158447266 sec\n",
      "ONNX postprocessing took 0.003913402557373047 sec\n",
      "ONNX inference took 0.013811111450195312 sec\n",
      "ONNX postprocessing took 0.0019583702087402344 sec\n",
      "ONNX inference took 0.013775110244750977 sec\n",
      "ONNX postprocessing took 0.004156589508056641 sec\n",
      "ONNX inference took 0.013689756393432617 sec\n",
      "ONNX postprocessing took 0.002234220504760742 sec\n",
      "ONNX inference took 0.013568878173828125 sec\n",
      "ONNX postprocessing took 0.002325296401977539 sec\n",
      "ONNX inference took 0.013618230819702148 sec\n",
      "ONNX postprocessing took 0.005598783493041992 sec\n",
      "ONNX inference took 0.014202356338500977 sec\n",
      "ONNX postprocessing took 0.003925323486328125 sec\n",
      "ONNX inference took 0.01344919204711914 sec\n",
      "ONNX postprocessing took 0.004055500030517578 sec\n",
      "ONNX inference took 0.01366567611694336 sec\n",
      "ONNX postprocessing took 0.0029044151306152344 sec\n",
      "ONNX inference took 0.01366424560546875 sec\n",
      "ONNX postprocessing took 0.003154277801513672 sec\n",
      "ONNX inference took 0.014000415802001953 sec\n",
      "ONNX postprocessing took 0.007017850875854492 sec\n",
      "ONNX inference took 0.014089107513427734 sec\n",
      "ONNX postprocessing took 0.003510713577270508 sec\n",
      "ONNX inference took 0.014388561248779297 sec\n",
      "ONNX postprocessing took 0.0032110214233398438 sec\n",
      "ONNX inference took 0.014267206192016602 sec\n",
      "ONNX postprocessing took 0.0031468868255615234 sec\n",
      "ONNX inference took 0.013821840286254883 sec\n",
      "ONNX postprocessing took 0.0034253597259521484 sec\n",
      "ONNX inference took 0.014733314514160156 sec\n",
      "ONNX postprocessing took 0.005183219909667969 sec\n",
      "ONNX inference took 0.013666868209838867 sec\n",
      "ONNX postprocessing took 0.0029354095458984375 sec\n",
      "ONNX inference took 0.014435291290283203 sec\n",
      "ONNX postprocessing took 0.0071430206298828125 sec\n",
      "ONNX inference took 0.013221979141235352 sec\n",
      "ONNX postprocessing took 0.002912282943725586 sec\n",
      "ONNX inference took 0.015827655792236328 sec\n",
      "ONNX postprocessing took 0.0050029754638671875 sec\n",
      "ONNX inference took 0.012326717376708984 sec\n",
      "ONNX postprocessing took 0.0014524459838867188 sec\n",
      "ONNX inference took 0.013970375061035156 sec\n",
      "ONNX postprocessing took 0.0031690597534179688 sec\n",
      "ONNX inference took 0.014186620712280273 sec\n",
      "ONNX postprocessing took 0.004354953765869141 sec\n",
      "ONNX inference took 0.01395559310913086 sec\n",
      "ONNX postprocessing took 0.00416111946105957 sec\n",
      "ONNX inference took 0.013697147369384766 sec\n",
      "ONNX postprocessing took 0.0046749114990234375 sec\n",
      "ONNX inference took 0.014202117919921875 sec\n",
      "ONNX postprocessing took 0.0032379627227783203 sec\n",
      "ONNX inference took 0.014670372009277344 sec\n",
      "ONNX postprocessing took 0.002796649932861328 sec\n",
      "ONNX inference took 0.01377105712890625 sec\n",
      "ONNX postprocessing took 0.002921581268310547 sec\n",
      "ONNX inference took 0.014133930206298828 sec\n",
      "ONNX postprocessing took 0.002830028533935547 sec\n",
      "ONNX inference took 0.013434886932373047 sec\n",
      "ONNX postprocessing took 0.002802133560180664 sec\n",
      "ONNX inference took 0.014078378677368164 sec\n",
      "ONNX postprocessing took 0.003271341323852539 sec\n",
      "ONNX inference took 0.014719009399414062 sec\n",
      "ONNX postprocessing took 0.003163576126098633 sec\n",
      "ONNX inference took 0.014200448989868164 sec\n",
      "ONNX postprocessing took 0.004425764083862305 sec\n",
      "ONNX inference took 0.014300823211669922 sec\n",
      "ONNX postprocessing took 0.00516510009765625 sec\n",
      "ONNX inference took 0.013138294219970703 sec\n",
      "ONNX postprocessing took 0.0029227733612060547 sec\n",
      "ONNX inference took 0.014381885528564453 sec\n",
      "ONNX postprocessing took 0.006728410720825195 sec\n",
      "ONNX inference took 0.014817237854003906 sec\n",
      "ONNX postprocessing took 0.005106687545776367 sec\n",
      "ONNX inference took 0.014474153518676758 sec\n",
      "ONNX postprocessing took 0.017104148864746094 sec\n",
      "ONNX inference took 0.01307058334350586 sec\n",
      "ONNX postprocessing took 0.0016705989837646484 sec\n",
      "ONNX inference took 0.013093709945678711 sec\n",
      "ONNX postprocessing took 0.0015995502471923828 sec\n",
      "ONNX inference took 0.013048887252807617 sec\n",
      "ONNX postprocessing took 0.00212860107421875 sec\n",
      "ONNX inference took 0.013006925582885742 sec\n",
      "ONNX postprocessing took 0.0035648345947265625 sec\n",
      "ONNX inference took 0.013408184051513672 sec\n",
      "ONNX postprocessing took 0.004220485687255859 sec\n",
      "ONNX inference took 0.013913631439208984 sec\n",
      "ONNX postprocessing took 0.002745389938354492 sec\n",
      "ONNX inference took 0.013890743255615234 sec\n",
      "ONNX postprocessing took 0.0038557052612304688 sec\n",
      "ONNX inference took 0.014102935791015625 sec\n",
      "ONNX postprocessing took 0.0026388168334960938 sec\n",
      "ONNX inference took 0.01360630989074707 sec\n",
      "ONNX postprocessing took 0.004984617233276367 sec\n",
      "ONNX inference took 0.013365030288696289 sec\n",
      "ONNX postprocessing took 0.002900838851928711 sec\n",
      "ONNX inference took 0.014415740966796875 sec\n",
      "ONNX postprocessing took 0.0020089149475097656 sec\n",
      "ONNX inference took 0.01410222053527832 sec\n",
      "ONNX postprocessing took 0.0018353462219238281 sec\n",
      "ONNX inference took 0.014175891876220703 sec\n",
      "ONNX postprocessing took 0.00222015380859375 sec\n",
      "ONNX inference took 0.013921976089477539 sec\n",
      "ONNX postprocessing took 0.0021562576293945312 sec\n",
      "ONNX inference took 0.013662099838256836 sec\n",
      "ONNX postprocessing took 0.002226591110229492 sec\n",
      "ONNX inference took 0.013751029968261719 sec\n",
      "ONNX postprocessing took 0.0018427371978759766 sec\n",
      "ONNX inference took 0.01446843147277832 sec\n",
      "ONNX postprocessing took 0.0032470226287841797 sec\n",
      "ONNX inference took 0.014117002487182617 sec\n",
      "ONNX postprocessing took 0.001767873764038086 sec\n",
      "ONNX inference took 0.014125585556030273 sec\n",
      "ONNX postprocessing took 0.005095720291137695 sec\n",
      "ONNX inference took 0.01408529281616211 sec\n",
      "ONNX postprocessing took 0.0021545886993408203 sec\n",
      "ONNX inference took 0.014379262924194336 sec\n",
      "ONNX postprocessing took 0.00421452522277832 sec\n",
      "ONNX inference took 0.014258623123168945 sec\n",
      "ONNX postprocessing took 0.003137350082397461 sec\n",
      "ONNX inference took 0.013391733169555664 sec\n",
      "ONNX postprocessing took 0.004462003707885742 sec\n",
      "ONNX inference took 0.014484643936157227 sec\n",
      "ONNX postprocessing took 0.0034813880920410156 sec\n",
      "ONNX inference took 0.014085054397583008 sec\n",
      "ONNX postprocessing took 0.004274845123291016 sec\n",
      "ONNX inference took 0.013639211654663086 sec\n",
      "ONNX postprocessing took 0.002453327178955078 sec\n",
      "ONNX inference took 0.013647079467773438 sec\n",
      "ONNX postprocessing took 0.002300739288330078 sec\n",
      "ONNX inference took 0.01334381103515625 sec\n",
      "ONNX postprocessing took 0.0013849735260009766 sec\n",
      "ONNX inference took 0.01369929313659668 sec\n",
      "ONNX postprocessing took 0.004120588302612305 sec\n",
      "ONNX inference took 0.014246940612792969 sec\n",
      "ONNX postprocessing took 0.003351926803588867 sec\n",
      "ONNX inference took 0.01414799690246582 sec\n",
      "ONNX postprocessing took 0.0031583309173583984 sec\n",
      "ONNX inference took 0.01359415054321289 sec\n",
      "ONNX postprocessing took 0.002834320068359375 sec\n",
      "ONNX inference took 0.014106512069702148 sec\n",
      "ONNX postprocessing took 0.002047300338745117 sec\n",
      "ONNX inference took 0.01351022720336914 sec\n",
      "ONNX postprocessing took 0.003760814666748047 sec\n",
      "ONNX inference took 0.01343989372253418 sec\n",
      "ONNX postprocessing took 0.001397848129272461 sec\n",
      "ONNX inference took 0.014155864715576172 sec\n",
      "ONNX postprocessing took 0.0028378963470458984 sec\n",
      "ONNX inference took 0.013794898986816406 sec\n",
      "ONNX postprocessing took 0.0028083324432373047 sec\n",
      "ONNX inference took 0.013922691345214844 sec\n",
      "ONNX postprocessing took 0.0034193992614746094 sec\n",
      "ONNX inference took 0.013336896896362305 sec\n",
      "ONNX postprocessing took 0.0039403438568115234 sec\n",
      "ONNX inference took 0.013381719589233398 sec\n",
      "ONNX postprocessing took 0.0022411346435546875 sec\n",
      "ONNX inference took 0.014883756637573242 sec\n",
      "ONNX postprocessing took 0.0027666091918945312 sec\n",
      "ONNX inference took 0.014351129531860352 sec\n",
      "ONNX postprocessing took 0.0050580501556396484 sec\n",
      "ONNX inference took 0.013567447662353516 sec\n",
      "ONNX postprocessing took 0.0051727294921875 sec\n",
      "ONNX inference took 0.014139652252197266 sec\n",
      "ONNX postprocessing took 0.0029845237731933594 sec\n",
      "ONNX inference took 0.014929771423339844 sec\n",
      "ONNX postprocessing took 0.0098724365234375 sec\n",
      "ONNX inference took 0.013674736022949219 sec\n",
      "ONNX postprocessing took 0.0023648738861083984 sec\n",
      "ONNX inference took 0.014318227767944336 sec\n",
      "ONNX postprocessing took 0.004500865936279297 sec\n",
      "ONNX inference took 0.012999534606933594 sec\n",
      "ONNX postprocessing took 0.002284526824951172 sec\n",
      "ONNX inference took 0.013697624206542969 sec\n",
      "ONNX postprocessing took 0.002844095230102539 sec\n",
      "ONNX inference took 0.013811111450195312 sec\n",
      "ONNX postprocessing took 0.0043675899505615234 sec\n",
      "ONNX inference took 0.014078617095947266 sec\n",
      "ONNX postprocessing took 0.002925395965576172 sec\n",
      "ONNX inference took 0.014340639114379883 sec\n",
      "ONNX postprocessing took 0.003094196319580078 sec\n",
      "ONNX inference took 0.013809442520141602 sec\n",
      "ONNX postprocessing took 0.002919435501098633 sec\n",
      "ONNX inference took 0.013531684875488281 sec\n",
      "ONNX postprocessing took 0.0025932788848876953 sec\n",
      "ONNX inference took 0.014261007308959961 sec\n",
      "ONNX postprocessing took 0.0029554367065429688 sec\n",
      "ONNX inference took 0.013779640197753906 sec\n",
      "ONNX postprocessing took 0.002828836441040039 sec\n",
      "ONNX inference took 0.014155864715576172 sec\n",
      "ONNX postprocessing took 0.0029158592224121094 sec\n",
      "ONNX inference took 0.013355016708374023 sec\n",
      "ONNX postprocessing took 0.002233266830444336 sec\n",
      "ONNX inference took 0.013835668563842773 sec\n",
      "ONNX postprocessing took 0.0022258758544921875 sec\n",
      "ONNX inference took 0.014101505279541016 sec\n",
      "ONNX postprocessing took 0.00225067138671875 sec\n",
      "ONNX inference took 0.01404118537902832 sec\n",
      "ONNX postprocessing took 0.00273895263671875 sec\n",
      "ONNX inference took 0.013363838195800781 sec\n",
      "ONNX postprocessing took 0.0021152496337890625 sec\n",
      "ONNX inference took 0.014172554016113281 sec\n",
      "ONNX postprocessing took 0.0029251575469970703 sec\n",
      "ONNX inference took 0.014806509017944336 sec\n",
      "ONNX postprocessing took 0.004349231719970703 sec\n",
      "ONNX inference took 0.014122486114501953 sec\n",
      "ONNX postprocessing took 0.002663135528564453 sec\n",
      "ONNX inference took 0.013460636138916016 sec\n",
      "ONNX postprocessing took 0.002157449722290039 sec\n",
      "ONNX inference took 0.014106512069702148 sec\n",
      "ONNX postprocessing took 0.0022029876708984375 sec\n",
      "ONNX inference took 0.013807535171508789 sec\n",
      "ONNX postprocessing took 0.0025963783264160156 sec\n",
      "ONNX inference took 0.013496875762939453 sec\n",
      "ONNX postprocessing took 0.0036406517028808594 sec\n",
      "ONNX inference took 0.013564825057983398 sec\n",
      "ONNX postprocessing took 0.00264739990234375 sec\n",
      "ONNX inference took 0.014348030090332031 sec\n",
      "ONNX postprocessing took 0.00599360466003418 sec\n",
      "ONNX inference took 0.01337122917175293 sec\n",
      "ONNX postprocessing took 0.0025594234466552734 sec\n",
      "ONNX inference took 0.01379847526550293 sec\n",
      "ONNX postprocessing took 0.002310037612915039 sec\n",
      "ONNX inference took 0.014308452606201172 sec\n",
      "ONNX postprocessing took 0.002835988998413086 sec\n",
      "ONNX inference took 0.015002012252807617 sec\n",
      "ONNX postprocessing took 0.0028505325317382812 sec\n",
      "ONNX inference took 0.01351618766784668 sec\n",
      "ONNX postprocessing took 0.0028238296508789062 sec\n",
      "ONNX inference took 0.01437997817993164 sec\n",
      "ONNX postprocessing took 0.0031142234802246094 sec\n",
      "ONNX inference took 0.013807058334350586 sec\n",
      "ONNX postprocessing took 0.002310514450073242 sec\n",
      "ONNX inference took 0.014254331588745117 sec\n",
      "ONNX postprocessing took 0.002711772918701172 sec\n",
      "ONNX inference took 0.013795614242553711 sec\n",
      "ONNX postprocessing took 0.0023462772369384766 sec\n",
      "ONNX inference took 0.01456141471862793 sec\n",
      "ONNX postprocessing took 0.0031080245971679688 sec\n",
      "ONNX inference took 0.013466596603393555 sec\n",
      "ONNX postprocessing took 0.0036940574645996094 sec\n",
      "ONNX inference took 0.013742923736572266 sec\n",
      "ONNX postprocessing took 0.002845287322998047 sec\n",
      "ONNX inference took 0.013650894165039062 sec\n",
      "ONNX postprocessing took 0.0015075206756591797 sec\n",
      "ONNX inference took 0.014191627502441406 sec\n",
      "ONNX postprocessing took 0.00498509407043457 sec\n",
      "ONNX inference took 0.013423681259155273 sec\n",
      "ONNX postprocessing took 0.0020568370819091797 sec\n",
      "ONNX inference took 0.013813257217407227 sec\n",
      "ONNX postprocessing took 0.00423884391784668 sec\n",
      "ONNX inference took 0.01334834098815918 sec\n",
      "ONNX postprocessing took 0.0029828548431396484 sec\n",
      "ONNX inference took 0.014241695404052734 sec\n",
      "ONNX postprocessing took 0.003682374954223633 sec\n",
      "ONNX inference took 0.01361703872680664 sec\n",
      "ONNX postprocessing took 0.002493619918823242 sec\n",
      "ONNX inference took 0.013801097869873047 sec\n",
      "ONNX postprocessing took 0.006321907043457031 sec\n",
      "ONNX inference took 0.01327371597290039 sec\n",
      "ONNX postprocessing took 0.0028078556060791016 sec\n",
      "ONNX inference took 0.013260126113891602 sec\n",
      "ONNX postprocessing took 0.005545854568481445 sec\n",
      "ONNX inference took 0.013500452041625977 sec\n",
      "ONNX postprocessing took 0.003314495086669922 sec\n",
      "ONNX inference took 0.014061450958251953 sec\n",
      "ONNX postprocessing took 0.004281759262084961 sec\n",
      "ONNX inference took 0.013509035110473633 sec\n",
      "ONNX postprocessing took 0.0033152103424072266 sec\n",
      "ONNX inference took 0.013359546661376953 sec\n",
      "ONNX postprocessing took 0.002898693084716797 sec\n",
      "ONNX inference took 0.013516664505004883 sec\n",
      "ONNX postprocessing took 0.002989530563354492 sec\n",
      "ONNX inference took 0.014422893524169922 sec\n",
      "ONNX postprocessing took 0.0032660961151123047 sec\n",
      "ONNX inference took 0.013428688049316406 sec\n",
      "ONNX postprocessing took 0.002841472625732422 sec\n",
      "ONNX inference took 0.01459503173828125 sec\n",
      "ONNX postprocessing took 0.002752065658569336 sec\n",
      "ONNX inference took 0.013072967529296875 sec\n",
      "ONNX postprocessing took 0.002656698226928711 sec\n",
      "ONNX inference took 0.014032602310180664 sec\n",
      "ONNX postprocessing took 0.003529787063598633 sec\n",
      "ONNX inference took 0.013399839401245117 sec\n",
      "ONNX postprocessing took 0.002561330795288086 sec\n",
      "ONNX inference took 0.014281988143920898 sec\n",
      "ONNX postprocessing took 0.0028641223907470703 sec\n",
      "ONNX inference took 0.013611555099487305 sec\n",
      "ONNX postprocessing took 0.0029172897338867188 sec\n",
      "ONNX inference took 0.013727664947509766 sec\n",
      "ONNX postprocessing took 0.004293680191040039 sec\n",
      "ONNX inference took 0.013545513153076172 sec\n",
      "ONNX postprocessing took 0.002616405487060547 sec\n",
      "ONNX inference took 0.014020681381225586 sec\n",
      "ONNX postprocessing took 0.002196788787841797 sec\n",
      "ONNX inference took 0.013499975204467773 sec\n",
      "ONNX postprocessing took 0.0019326210021972656 sec\n",
      "ONNX inference took 0.014239788055419922 sec\n",
      "ONNX postprocessing took 0.0029942989349365234 sec\n",
      "ONNX inference took 0.014370441436767578 sec\n",
      "ONNX postprocessing took 0.0036118030548095703 sec\n",
      "ONNX inference took 0.013653993606567383 sec\n",
      "ONNX postprocessing took 0.003309488296508789 sec\n",
      "ONNX inference took 0.015470504760742188 sec\n",
      "ONNX postprocessing took 0.005023002624511719 sec\n",
      "ONNX inference took 0.013640165328979492 sec\n",
      "ONNX postprocessing took 0.002300739288330078 sec\n",
      "ONNX inference took 0.013467550277709961 sec\n",
      "ONNX postprocessing took 0.002367258071899414 sec\n",
      "ONNX inference took 0.01455378532409668 sec\n",
      "ONNX postprocessing took 0.003499269485473633 sec\n",
      "ONNX inference took 0.013481378555297852 sec\n",
      "ONNX postprocessing took 0.0020689964294433594 sec\n",
      "ONNX inference took 0.01329350471496582 sec\n",
      "ONNX postprocessing took 0.0022411346435546875 sec\n",
      "ONNX inference took 0.01375269889831543 sec\n",
      "ONNX postprocessing took 0.0021162033081054688 sec\n",
      "ONNX inference took 0.013460874557495117 sec\n",
      "ONNX postprocessing took 0.0023627281188964844 sec\n",
      "ONNX inference took 0.013829946517944336 sec\n",
      "ONNX postprocessing took 0.0022919178009033203 sec\n",
      "ONNX inference took 0.013902902603149414 sec\n",
      "ONNX postprocessing took 0.0030269622802734375 sec\n",
      "ONNX inference took 0.013686418533325195 sec\n",
      "ONNX postprocessing took 0.0020422935485839844 sec\n",
      "ONNX inference took 0.013136148452758789 sec\n",
      "ONNX postprocessing took 0.0017437934875488281 sec\n",
      "ONNX inference took 0.013110876083374023 sec\n",
      "ONNX postprocessing took 0.002457141876220703 sec\n",
      "ONNX inference took 0.01355433464050293 sec\n",
      "ONNX postprocessing took 0.003220796585083008 sec\n",
      "ONNX inference took 0.012466192245483398 sec\n",
      "ONNX postprocessing took 0.0015921592712402344 sec\n",
      "ONNX inference took 0.013371467590332031 sec\n",
      "ONNX postprocessing took 0.004678487777709961 sec\n",
      "ONNX inference took 0.013387441635131836 sec\n",
      "ONNX postprocessing took 0.0019195079803466797 sec\n",
      "ONNX inference took 0.014178037643432617 sec\n",
      "ONNX postprocessing took 0.0030193328857421875 sec\n",
      "ONNX inference took 0.014462471008300781 sec\n",
      "ONNX postprocessing took 0.003184795379638672 sec\n",
      "ONNX inference took 0.013651132583618164 sec\n",
      "ONNX postprocessing took 0.006226301193237305 sec\n",
      "ONNX inference took 0.013318300247192383 sec\n",
      "ONNX postprocessing took 0.002936840057373047 sec\n",
      "ONNX inference took 0.012651920318603516 sec\n",
      "ONNX postprocessing took 0.001489400863647461 sec\n",
      "ONNX inference took 0.012935400009155273 sec\n",
      "ONNX postprocessing took 0.0012309551239013672 sec\n",
      "ONNX inference took 0.013571500778198242 sec\n",
      "ONNX postprocessing took 0.0031211376190185547 sec\n",
      "ONNX inference took 0.01373744010925293 sec\n",
      "ONNX postprocessing took 0.0024025440216064453 sec\n",
      "ONNX inference took 0.014135122299194336 sec\n",
      "ONNX postprocessing took 0.003284454345703125 sec\n",
      "ONNX inference took 0.01357126235961914 sec\n",
      "ONNX postprocessing took 0.003248929977416992 sec\n",
      "ONNX inference took 0.014288902282714844 sec\n",
      "ONNX postprocessing took 0.004082202911376953 sec\n",
      "ONNX inference took 0.013352155685424805 sec\n",
      "ONNX postprocessing took 0.0023648738861083984 sec\n",
      "ONNX inference took 0.014122486114501953 sec\n",
      "ONNX postprocessing took 0.0025665760040283203 sec\n",
      "ONNX inference took 0.01330113410949707 sec\n",
      "ONNX postprocessing took 0.0028421878814697266 sec\n",
      "ONNX inference took 0.013549089431762695 sec\n",
      "ONNX postprocessing took 0.0044252872467041016 sec\n",
      "ONNX inference took 0.013350248336791992 sec\n",
      "ONNX postprocessing took 0.0033888816833496094 sec\n",
      "ONNX inference took 0.013846874237060547 sec\n",
      "ONNX postprocessing took 0.002805471420288086 sec\n",
      "ONNX inference took 0.013410091400146484 sec\n",
      "ONNX postprocessing took 0.002941131591796875 sec\n",
      "ONNX inference took 0.014556169509887695 sec\n",
      "ONNX postprocessing took 0.003673553466796875 sec\n",
      "ONNX inference took 0.01339864730834961 sec\n",
      "ONNX postprocessing took 0.0021789073944091797 sec\n",
      "ONNX inference took 0.014255762100219727 sec\n",
      "ONNX postprocessing took 0.0029327869415283203 sec\n",
      "ONNX inference took 0.013328075408935547 sec\n",
      "ONNX postprocessing took 0.002252817153930664 sec\n",
      "ONNX inference took 0.013913393020629883 sec\n",
      "ONNX postprocessing took 0.002635955810546875 sec\n",
      "ONNX inference took 0.014411449432373047 sec\n",
      "ONNX postprocessing took 0.0027976036071777344 sec\n",
      "ONNX inference took 0.01403498649597168 sec\n",
      "ONNX postprocessing took 0.003162384033203125 sec\n",
      "ONNX inference took 0.013419628143310547 sec\n",
      "ONNX postprocessing took 0.002994537353515625 sec\n",
      "ONNX inference took 0.014000892639160156 sec\n",
      "ONNX postprocessing took 0.0033707618713378906 sec\n",
      "ONNX inference took 0.013854265213012695 sec\n",
      "ONNX postprocessing took 0.002604961395263672 sec\n",
      "ONNX inference took 0.013872623443603516 sec\n",
      "ONNX postprocessing took 0.0035130977630615234 sec\n",
      "ONNX inference took 0.013385295867919922 sec\n",
      "ONNX postprocessing took 0.0022330284118652344 sec\n",
      "ONNX inference took 0.013848543167114258 sec\n",
      "ONNX postprocessing took 0.004323720932006836 sec\n",
      "ONNX inference took 0.012961864471435547 sec\n",
      "ONNX postprocessing took 0.0026535987854003906 sec\n",
      "ONNX inference took 0.013393640518188477 sec\n",
      "ONNX postprocessing took 0.003147125244140625 sec\n",
      "ONNX inference took 0.013653278350830078 sec\n",
      "ONNX postprocessing took 0.002535581588745117 sec\n",
      "ONNX inference took 0.013670921325683594 sec\n",
      "ONNX postprocessing took 0.003288745880126953 sec\n",
      "ONNX inference took 0.01399540901184082 sec\n",
      "ONNX postprocessing took 0.0016629695892333984 sec\n",
      "ONNX inference took 0.014565467834472656 sec\n",
      "ONNX postprocessing took 0.0036563873291015625 sec\n",
      "ONNX inference took 0.013739824295043945 sec\n",
      "ONNX postprocessing took 0.0023009777069091797 sec\n",
      "ONNX inference took 0.013623237609863281 sec\n",
      "ONNX postprocessing took 0.002897500991821289 sec\n",
      "ONNX inference took 0.013601064682006836 sec\n",
      "ONNX postprocessing took 0.003099203109741211 sec\n",
      "ONNX inference took 0.015537738800048828 sec\n",
      "ONNX postprocessing took 0.005067348480224609 sec\n",
      "ONNX inference took 0.014466285705566406 sec\n",
      "ONNX postprocessing took 0.0029380321502685547 sec\n",
      "ONNX inference took 0.014167070388793945 sec\n",
      "ONNX postprocessing took 0.002637624740600586 sec\n",
      "ONNX inference took 0.013948440551757812 sec\n",
      "ONNX postprocessing took 0.001971721649169922 sec\n",
      "ONNX inference took 0.014003276824951172 sec\n",
      "ONNX postprocessing took 0.0024907588958740234 sec\n",
      "ONNX inference took 0.013565301895141602 sec\n",
      "ONNX postprocessing took 0.002046823501586914 sec\n",
      "ONNX inference took 0.014121532440185547 sec\n",
      "ONNX postprocessing took 0.00422978401184082 sec\n",
      "ONNX inference took 0.013769388198852539 sec\n",
      "ONNX postprocessing took 0.004571437835693359 sec\n",
      "ONNX inference took 0.0133819580078125 sec\n",
      "ONNX postprocessing took 0.002685070037841797 sec\n",
      "ONNX inference took 0.013949155807495117 sec\n",
      "ONNX postprocessing took 0.0032579898834228516 sec\n",
      "ONNX inference took 0.014201164245605469 sec\n",
      "ONNX postprocessing took 0.0033228397369384766 sec\n",
      "ONNX inference took 0.013500452041625977 sec\n",
      "ONNX postprocessing took 0.002836942672729492 sec\n",
      "ONNX inference took 0.01395726203918457 sec\n",
      "ONNX postprocessing took 0.004414558410644531 sec\n",
      "ONNX inference took 0.014130353927612305 sec\n",
      "ONNX postprocessing took 0.0029778480529785156 sec\n",
      "ONNX inference took 0.014081478118896484 sec\n",
      "ONNX postprocessing took 0.004770994186401367 sec\n",
      "ONNX inference took 0.01416015625 sec\n",
      "ONNX postprocessing took 0.00448918342590332 sec\n",
      "ONNX inference took 0.013368844985961914 sec\n",
      "ONNX postprocessing took 0.0019211769104003906 sec\n",
      "ONNX inference took 0.014287710189819336 sec\n",
      "ONNX postprocessing took 0.002901315689086914 sec\n",
      "ONNX inference took 0.013971328735351562 sec\n",
      "ONNX postprocessing took 0.0017981529235839844 sec\n",
      "ONNX inference took 0.017206430435180664 sec\n",
      "ONNX postprocessing took 0.004998922348022461 sec\n",
      "ONNX inference took 0.013931512832641602 sec\n",
      "ONNX postprocessing took 0.002164602279663086 sec\n",
      "ONNX inference took 0.014250755310058594 sec\n",
      "ONNX postprocessing took 0.0022192001342773438 sec\n",
      "ONNX inference took 0.013843297958374023 sec\n",
      "ONNX postprocessing took 0.002848386764526367 sec\n",
      "ONNX inference took 0.013837575912475586 sec\n",
      "ONNX postprocessing took 0.003051280975341797 sec\n",
      "ONNX inference took 0.013944149017333984 sec\n",
      "ONNX postprocessing took 0.002036571502685547 sec\n",
      "ONNX inference took 0.01383829116821289 sec\n",
      "ONNX postprocessing took 0.0022706985473632812 sec\n",
      "ONNX inference took 0.014794111251831055 sec\n",
      "ONNX postprocessing took 0.0046198368072509766 sec\n",
      "ONNX inference took 0.013216733932495117 sec\n",
      "ONNX postprocessing took 0.0026755332946777344 sec\n",
      "ONNX inference took 0.013692378997802734 sec\n",
      "ONNX postprocessing took 0.002380847930908203 sec\n",
      "ONNX inference took 0.01401209831237793 sec\n",
      "ONNX postprocessing took 0.005204200744628906 sec\n",
      "ONNX inference took 0.013831377029418945 sec\n",
      "ONNX postprocessing took 0.0027015209197998047 sec\n",
      "ONNX inference took 0.013950586318969727 sec\n",
      "ONNX postprocessing took 0.003365755081176758 sec\n",
      "ONNX inference took 0.014309883117675781 sec\n",
      "ONNX postprocessing took 0.003367185592651367 sec\n",
      "ONNX inference took 0.014818906784057617 sec\n",
      "ONNX postprocessing took 0.0027899742126464844 sec\n",
      "ONNX inference took 0.014041900634765625 sec\n",
      "ONNX postprocessing took 0.006824016571044922 sec\n",
      "ONNX inference took 0.018116474151611328 sec\n",
      "ONNX postprocessing took 0.004282712936401367 sec\n",
      "ONNX inference took 0.013751506805419922 sec\n",
      "ONNX postprocessing took 0.002173185348510742 sec\n",
      "ONNX inference took 0.01416635513305664 sec\n",
      "ONNX postprocessing took 0.006183624267578125 sec\n",
      "ONNX inference took 0.013590812683105469 sec\n",
      "ONNX postprocessing took 0.00538182258605957 sec\n",
      "ONNX inference took 0.01429891586303711 sec\n",
      "ONNX postprocessing took 0.004714488983154297 sec\n",
      "ONNX inference took 0.013612031936645508 sec\n",
      "ONNX postprocessing took 0.004273176193237305 sec\n",
      "ONNX inference took 0.014636754989624023 sec\n",
      "ONNX postprocessing took 0.004559040069580078 sec\n",
      "ONNX inference took 0.013763666152954102 sec\n",
      "ONNX postprocessing took 0.005591630935668945 sec\n",
      "ONNX inference took 0.013076066970825195 sec\n",
      "ONNX postprocessing took 0.001710653305053711 sec\n",
      "ONNX inference took 0.01373147964477539 sec\n",
      "ONNX postprocessing took 0.003805398941040039 sec\n",
      "ONNX inference took 0.014646053314208984 sec\n",
      "ONNX postprocessing took 0.017542123794555664 sec\n",
      "ONNX inference took 0.013346672058105469 sec\n",
      "ONNX postprocessing took 0.0037817955017089844 sec\n",
      "ONNX inference took 0.013419866561889648 sec\n",
      "ONNX postprocessing took 0.0022971630096435547 sec\n",
      "ONNX inference took 0.013790369033813477 sec\n",
      "ONNX postprocessing took 0.006023406982421875 sec\n",
      "ONNX inference took 0.013591766357421875 sec\n",
      "ONNX postprocessing took 0.0033905506134033203 sec\n",
      "ONNX inference took 0.014065265655517578 sec\n",
      "ONNX postprocessing took 0.0035305023193359375 sec\n",
      "ONNX inference took 0.013812780380249023 sec\n",
      "ONNX postprocessing took 0.0034389495849609375 sec\n",
      "ONNX inference took 0.013808488845825195 sec\n",
      "ONNX postprocessing took 0.0029375553131103516 sec\n",
      "ONNX inference took 0.014618635177612305 sec\n",
      "ONNX postprocessing took 0.004170656204223633 sec\n",
      "ONNX inference took 0.014201164245605469 sec\n",
      "ONNX postprocessing took 0.0027170181274414062 sec\n",
      "ONNX inference took 0.01433420181274414 sec\n",
      "ONNX postprocessing took 0.003195047378540039 sec\n",
      "ONNX inference took 0.013167381286621094 sec\n",
      "ONNX postprocessing took 0.0017910003662109375 sec\n",
      "ONNX inference took 0.013905763626098633 sec\n",
      "ONNX postprocessing took 0.0059130191802978516 sec\n",
      "ONNX inference took 0.01372981071472168 sec\n",
      "ONNX postprocessing took 0.0025746822357177734 sec\n",
      "ONNX inference took 0.013642072677612305 sec\n",
      "ONNX postprocessing took 0.004443168640136719 sec\n",
      "ONNX inference took 0.013678312301635742 sec\n",
      "ONNX postprocessing took 0.001455545425415039 sec\n",
      "ONNX inference took 0.014456748962402344 sec\n",
      "ONNX postprocessing took 0.003336191177368164 sec\n",
      "ONNX inference took 0.01427769660949707 sec\n",
      "ONNX postprocessing took 0.003212451934814453 sec\n",
      "ONNX inference took 0.013916254043579102 sec\n",
      "ONNX postprocessing took 0.0028460025787353516 sec\n",
      "ONNX inference took 0.014209747314453125 sec\n",
      "ONNX postprocessing took 0.003386259078979492 sec\n",
      "ONNX inference took 0.014040231704711914 sec\n",
      "ONNX postprocessing took 0.0030832290649414062 sec\n",
      "ONNX inference took 0.013318538665771484 sec\n",
      "ONNX postprocessing took 0.0038983821868896484 sec\n",
      "ONNX inference took 0.01276707649230957 sec\n",
      "ONNX postprocessing took 0.0015406608581542969 sec\n",
      "ONNX inference took 0.014188289642333984 sec\n",
      "ONNX postprocessing took 0.0051386356353759766 sec\n",
      "ONNX inference took 0.014082193374633789 sec\n",
      "ONNX postprocessing took 0.0033655166625976562 sec\n",
      "ONNX inference took 0.013471126556396484 sec\n",
      "ONNX postprocessing took 0.00427556037902832 sec\n",
      "ONNX inference took 0.012287378311157227 sec\n",
      "ONNX postprocessing took 0.0009560585021972656 sec\n",
      "ONNX inference took 0.013746023178100586 sec\n",
      "ONNX postprocessing took 0.0017442703247070312 sec\n",
      "ONNX inference took 0.013100385665893555 sec\n",
      "ONNX postprocessing took 0.0025343894958496094 sec\n",
      "ONNX inference took 0.014491081237792969 sec\n",
      "ONNX postprocessing took 0.005255937576293945 sec\n",
      "ONNX inference took 0.014242410659790039 sec\n",
      "ONNX postprocessing took 0.0049517154693603516 sec\n",
      "ONNX inference took 0.014914751052856445 sec\n",
      "ONNX postprocessing took 0.003016948699951172 sec\n",
      "ONNX inference took 0.014053821563720703 sec\n",
      "ONNX postprocessing took 0.004275083541870117 sec\n",
      "ONNX inference took 0.013449907302856445 sec\n",
      "ONNX postprocessing took 0.002870321273803711 sec\n",
      "ONNX inference took 0.014352798461914062 sec\n",
      "ONNX postprocessing took 0.003203153610229492 sec\n",
      "ONNX inference took 0.013416528701782227 sec\n",
      "ONNX postprocessing took 0.0027735233306884766 sec\n",
      "ONNX inference took 0.01445770263671875 sec\n",
      "ONNX postprocessing took 0.0038895606994628906 sec\n",
      "ONNX inference took 0.01379704475402832 sec\n",
      "ONNX postprocessing took 0.0027000904083251953 sec\n",
      "ONNX inference took 0.013588666915893555 sec\n",
      "ONNX postprocessing took 0.004681825637817383 sec\n",
      "ONNX inference took 0.013571500778198242 sec\n",
      "ONNX postprocessing took 0.003277301788330078 sec\n",
      "ONNX inference took 0.013366222381591797 sec\n",
      "ONNX postprocessing took 0.00408172607421875 sec\n",
      "ONNX inference took 0.013463973999023438 sec\n",
      "ONNX postprocessing took 0.004077911376953125 sec\n",
      "ONNX inference took 0.014399290084838867 sec\n",
      "ONNX postprocessing took 0.0021848678588867188 sec\n",
      "ONNX inference took 0.014701366424560547 sec\n",
      "ONNX postprocessing took 0.0031287670135498047 sec\n",
      "ONNX inference took 0.013977527618408203 sec\n",
      "ONNX postprocessing took 0.0029151439666748047 sec\n",
      "ONNX inference took 0.014253616333007812 sec\n",
      "ONNX postprocessing took 0.002907991409301758 sec\n",
      "ONNX inference took 0.014053106307983398 sec\n",
      "ONNX postprocessing took 0.0027637481689453125 sec\n",
      "ONNX inference took 0.013913393020629883 sec\n",
      "ONNX postprocessing took 0.004375457763671875 sec\n",
      "ONNX inference took 0.013476848602294922 sec\n",
      "ONNX postprocessing took 0.0024831295013427734 sec\n",
      "ONNX inference took 0.01398468017578125 sec\n",
      "ONNX postprocessing took 0.002872943878173828 sec\n",
      "ONNX inference took 0.014841079711914062 sec\n",
      "ONNX postprocessing took 0.003050088882446289 sec\n",
      "ONNX inference took 0.015050888061523438 sec\n",
      "ONNX postprocessing took 0.008292675018310547 sec\n",
      "ONNX inference took 0.01343679428100586 sec\n",
      "ONNX postprocessing took 0.00263214111328125 sec\n",
      "ONNX inference took 0.013410091400146484 sec\n",
      "ONNX postprocessing took 0.003007650375366211 sec\n",
      "ONNX inference took 0.013231515884399414 sec\n",
      "ONNX postprocessing took 0.00414586067199707 sec\n",
      "ONNX inference took 0.01347804069519043 sec\n",
      "ONNX postprocessing took 0.0016944408416748047 sec\n",
      "ONNX inference took 0.01421046257019043 sec\n",
      "ONNX postprocessing took 0.002423524856567383 sec\n",
      "ONNX inference took 0.013983488082885742 sec\n",
      "ONNX postprocessing took 0.0030591487884521484 sec\n",
      "ONNX inference took 0.013571023941040039 sec\n",
      "ONNX postprocessing took 0.0021851062774658203 sec\n",
      "ONNX inference took 0.014031410217285156 sec\n",
      "ONNX postprocessing took 0.0038585662841796875 sec\n",
      "ONNX inference took 0.01401829719543457 sec\n",
      "ONNX postprocessing took 0.001829385757446289 sec\n",
      "ONNX inference took 0.014468669891357422 sec\n",
      "ONNX postprocessing took 0.003129243850708008 sec\n",
      "ONNX inference took 0.01394510269165039 sec\n",
      "ONNX postprocessing took 0.0038170814514160156 sec\n",
      "ONNX inference took 0.013656139373779297 sec\n",
      "ONNX postprocessing took 0.002135038375854492 sec\n",
      "ONNX inference took 0.014106035232543945 sec\n",
      "ONNX postprocessing took 0.0026633739471435547 sec\n",
      "ONNX inference took 0.014660120010375977 sec\n",
      "ONNX postprocessing took 0.003313302993774414 sec\n",
      "ONNX inference took 0.014148473739624023 sec\n",
      "ONNX postprocessing took 0.002996206283569336 sec\n",
      "ONNX inference took 0.014313459396362305 sec\n",
      "ONNX postprocessing took 0.002963542938232422 sec\n",
      "ONNX inference took 0.013319015502929688 sec\n",
      "ONNX postprocessing took 0.0027985572814941406 sec\n",
      "ONNX inference took 0.01426839828491211 sec\n",
      "ONNX postprocessing took 0.004303932189941406 sec\n",
      "ONNX inference took 0.013712406158447266 sec\n",
      "ONNX postprocessing took 0.004248380661010742 sec\n",
      "ONNX inference took 0.014312028884887695 sec\n",
      "ONNX postprocessing took 0.0056514739990234375 sec\n",
      "ONNX inference took 0.013406038284301758 sec\n",
      "ONNX postprocessing took 0.002042531967163086 sec\n",
      "ONNX inference took 0.014076948165893555 sec\n",
      "ONNX postprocessing took 0.0031425952911376953 sec\n",
      "ONNX inference took 0.01411747932434082 sec\n",
      "ONNX postprocessing took 0.002922534942626953 sec\n",
      "ONNX inference took 0.013599872589111328 sec\n",
      "ONNX postprocessing took 0.002956867218017578 sec\n",
      "ONNX inference took 0.014459371566772461 sec\n",
      "ONNX postprocessing took 0.0039556026458740234 sec\n",
      "ONNX inference took 0.014437675476074219 sec\n",
      "ONNX postprocessing took 0.002618074417114258 sec\n",
      "ONNX inference took 0.013763666152954102 sec\n",
      "ONNX postprocessing took 0.0044269561767578125 sec\n",
      "ONNX inference took 0.013359785079956055 sec\n",
      "ONNX postprocessing took 0.002872467041015625 sec\n",
      "ONNX inference took 0.014518499374389648 sec\n",
      "ONNX postprocessing took 0.004529237747192383 sec\n",
      "ONNX inference took 0.014209747314453125 sec\n",
      "ONNX postprocessing took 0.002843141555786133 sec\n",
      "ONNX inference took 0.01352834701538086 sec\n",
      "ONNX postprocessing took 0.005337715148925781 sec\n",
      "ONNX inference took 0.013461112976074219 sec\n",
      "ONNX postprocessing took 0.004834413528442383 sec\n",
      "ONNX inference took 0.01374673843383789 sec\n",
      "ONNX postprocessing took 0.002034425735473633 sec\n",
      "ONNX inference took 0.013527154922485352 sec\n",
      "ONNX postprocessing took 0.003015756607055664 sec\n",
      "ONNX inference took 0.01388692855834961 sec\n",
      "ONNX postprocessing took 0.003930330276489258 sec\n",
      "ONNX inference took 0.014174938201904297 sec\n",
      "ONNX postprocessing took 0.0052411556243896484 sec\n",
      "ONNX inference took 0.01345968246459961 sec\n",
      "ONNX postprocessing took 0.0029914379119873047 sec\n",
      "ONNX inference took 0.014689445495605469 sec\n",
      "ONNX postprocessing took 0.004488229751586914 sec\n",
      "ONNX inference took 0.014370918273925781 sec\n",
      "ONNX postprocessing took 0.002749919891357422 sec\n",
      "ONNX inference took 0.013480424880981445 sec\n",
      "ONNX postprocessing took 0.003246307373046875 sec\n",
      "ONNX inference took 0.013342618942260742 sec\n",
      "ONNX postprocessing took 0.005454540252685547 sec\n",
      "ONNX inference took 0.014113664627075195 sec\n",
      "ONNX postprocessing took 0.0019443035125732422 sec\n",
      "ONNX inference took 0.014070272445678711 sec\n",
      "ONNX postprocessing took 0.009278535842895508 sec\n",
      "ONNX inference took 0.014132022857666016 sec\n",
      "ONNX postprocessing took 0.002889394760131836 sec\n",
      "ONNX inference took 0.01362919807434082 sec\n",
      "ONNX postprocessing took 0.0026721954345703125 sec\n",
      "ONNX inference took 0.01461482048034668 sec\n",
      "ONNX postprocessing took 0.004703044891357422 sec\n",
      "ONNX inference took 0.013664722442626953 sec\n",
      "ONNX postprocessing took 0.002525806427001953 sec\n",
      "ONNX inference took 0.013918399810791016 sec\n",
      "ONNX postprocessing took 0.006658315658569336 sec\n",
      "ONNX inference took 0.013753175735473633 sec\n",
      "ONNX postprocessing took 0.003180980682373047 sec\n",
      "ONNX inference took 0.014680147171020508 sec\n",
      "ONNX postprocessing took 0.0044667720794677734 sec\n",
      "ONNX inference took 0.014893054962158203 sec\n",
      "ONNX postprocessing took 0.0039825439453125 sec\n",
      "ONNX inference took 0.013633012771606445 sec\n",
      "ONNX postprocessing took 0.003265857696533203 sec\n",
      "ONNX inference took 0.013751029968261719 sec\n",
      "ONNX postprocessing took 0.0038347244262695312 sec\n",
      "ONNX inference took 0.014792680740356445 sec\n",
      "ONNX postprocessing took 0.006040096282958984 sec\n",
      "ONNX inference took 0.013666868209838867 sec\n",
      "ONNX postprocessing took 0.0031795501708984375 sec\n",
      "ONNX inference took 0.01488041877746582 sec\n",
      "ONNX postprocessing took 0.004935026168823242 sec\n",
      "ONNX inference took 0.013421773910522461 sec\n",
      "ONNX postprocessing took 0.0033462047576904297 sec\n",
      "ONNX inference took 0.014018058776855469 sec\n",
      "ONNX postprocessing took 0.0048024654388427734 sec\n",
      "ONNX inference took 0.014289140701293945 sec\n",
      "ONNX postprocessing took 0.002063274383544922 sec\n",
      "ONNX inference took 0.014043807983398438 sec\n",
      "ONNX postprocessing took 0.0021054744720458984 sec\n",
      "ONNX inference took 0.014097452163696289 sec\n",
      "ONNX postprocessing took 0.002762317657470703 sec\n",
      "ONNX inference took 0.015448808670043945 sec\n",
      "ONNX postprocessing took 0.005275726318359375 sec\n",
      "ONNX inference took 0.012972593307495117 sec\n",
      "ONNX postprocessing took 0.0014526844024658203 sec\n",
      "ONNX inference took 0.01315450668334961 sec\n",
      "ONNX postprocessing took 0.0014026165008544922 sec\n",
      "ONNX inference took 0.01427149772644043 sec\n",
      "ONNX postprocessing took 0.004570484161376953 sec\n",
      "ONNX inference took 0.013400077819824219 sec\n",
      "ONNX postprocessing took 0.0017900466918945312 sec\n",
      "ONNX inference took 0.012378692626953125 sec\n",
      "ONNX postprocessing took 0.0016231536865234375 sec\n",
      "ONNX inference took 0.012634038925170898 sec\n",
      "ONNX postprocessing took 0.001455068588256836 sec\n",
      "ONNX inference took 0.014410018920898438 sec\n",
      "ONNX postprocessing took 0.0026776790618896484 sec\n",
      "ONNX inference took 0.014492273330688477 sec\n",
      "ONNX postprocessing took 0.0027620792388916016 sec\n",
      "ONNX inference took 0.014644622802734375 sec\n",
      "ONNX postprocessing took 0.004458189010620117 sec\n",
      "ONNX inference took 0.01508784294128418 sec\n",
      "ONNX postprocessing took 0.017447471618652344 sec\n",
      "ONNX inference took 0.01405191421508789 sec\n",
      "ONNX postprocessing took 0.003935098648071289 sec\n",
      "ONNX inference took 0.01387786865234375 sec\n",
      "ONNX postprocessing took 0.0043866634368896484 sec\n",
      "ONNX inference took 0.01232147216796875 sec\n",
      "ONNX postprocessing took 0.0010259151458740234 sec\n",
      "ONNX inference took 0.01408076286315918 sec\n",
      "ONNX postprocessing took 0.004168033599853516 sec\n",
      "ONNX inference took 0.014142751693725586 sec\n",
      "ONNX postprocessing took 0.003271818161010742 sec\n",
      "ONNX inference took 0.014161825180053711 sec\n",
      "ONNX postprocessing took 0.003278970718383789 sec\n",
      "ONNX inference took 0.012593507766723633 sec\n",
      "ONNX postprocessing took 0.0021991729736328125 sec\n",
      "ONNX inference took 0.014255523681640625 sec\n",
      "ONNX postprocessing took 0.0036542415618896484 sec\n",
      "ONNX inference took 0.014428853988647461 sec\n",
      "ONNX postprocessing took 0.003221273422241211 sec\n",
      "ONNX inference took 0.015085935592651367 sec\n",
      "ONNX postprocessing took 0.005803108215332031 sec\n",
      "ONNX inference took 0.014923810958862305 sec\n",
      "ONNX postprocessing took 0.004930973052978516 sec\n",
      "ONNX inference took 0.014544010162353516 sec\n",
      "ONNX postprocessing took 0.002841949462890625 sec\n",
      "ONNX inference took 0.013523578643798828 sec\n",
      "ONNX postprocessing took 0.0029876232147216797 sec\n",
      "ONNX inference took 0.013080835342407227 sec\n",
      "ONNX postprocessing took 0.0012328624725341797 sec\n",
      "ONNX inference took 0.015001535415649414 sec\n",
      "ONNX postprocessing took 0.0030019283294677734 sec\n",
      "ONNX inference took 0.012660980224609375 sec\n",
      "ONNX postprocessing took 0.0015268325805664062 sec\n",
      "ONNX inference took 0.012966156005859375 sec\n",
      "ONNX postprocessing took 0.0009875297546386719 sec\n",
      "ONNX inference took 0.01437067985534668 sec\n",
      "ONNX postprocessing took 0.0035092830657958984 sec\n",
      "ONNX inference took 0.014851808547973633 sec\n",
      "ONNX postprocessing took 0.00360107421875 sec\n",
      "ONNX inference took 0.01279139518737793 sec\n",
      "ONNX postprocessing took 0.0014107227325439453 sec\n",
      "ONNX inference took 0.013237714767456055 sec\n",
      "ONNX postprocessing took 0.001729726791381836 sec\n",
      "ONNX inference took 0.014539003372192383 sec\n",
      "ONNX postprocessing took 0.011445999145507812 sec\n",
      "ONNX inference took 0.013381719589233398 sec\n",
      "ONNX postprocessing took 0.002950906753540039 sec\n",
      "ONNX inference took 0.014374494552612305 sec\n",
      "ONNX postprocessing took 0.002689838409423828 sec\n",
      "ONNX inference took 0.012644052505493164 sec\n",
      "ONNX postprocessing took 0.0015647411346435547 sec\n",
      "ONNX inference took 0.013532638549804688 sec\n",
      "ONNX postprocessing took 0.0015413761138916016 sec\n",
      "ONNX inference took 0.013196706771850586 sec\n",
      "ONNX postprocessing took 0.0013480186462402344 sec\n",
      "ONNX inference took 0.01389932632446289 sec\n",
      "ONNX postprocessing took 0.003735065460205078 sec\n",
      "ONNX inference took 0.014075040817260742 sec\n",
      "ONNX postprocessing took 0.003411531448364258 sec\n",
      "ONNX inference took 0.013249874114990234 sec\n",
      "ONNX postprocessing took 0.001512765884399414 sec\n",
      "ONNX inference took 0.013245344161987305 sec\n",
      "ONNX postprocessing took 0.0015556812286376953 sec\n",
      "ONNX inference took 0.013410091400146484 sec\n",
      "ONNX postprocessing took 0.001634836196899414 sec\n",
      "ONNX inference took 0.013481378555297852 sec\n",
      "ONNX postprocessing took 0.001501321792602539 sec\n",
      "ONNX inference took 0.013003110885620117 sec\n",
      "ONNX postprocessing took 0.0014503002166748047 sec\n",
      "ONNX inference took 0.013303518295288086 sec\n",
      "ONNX postprocessing took 0.001672983169555664 sec\n",
      "ONNX inference took 0.0135345458984375 sec\n",
      "ONNX postprocessing took 0.0034880638122558594 sec\n",
      "ONNX inference took 0.013842344284057617 sec\n",
      "ONNX postprocessing took 0.004349231719970703 sec\n",
      "ONNX inference took 0.012506484985351562 sec\n",
      "ONNX postprocessing took 0.0015556812286376953 sec\n",
      "ONNX inference took 0.013130426406860352 sec\n",
      "ONNX postprocessing took 0.0030951499938964844 sec\n",
      "ONNX inference took 0.014705181121826172 sec\n",
      "ONNX postprocessing took 0.0027840137481689453 sec\n",
      "ONNX inference took 0.013885259628295898 sec\n",
      "ONNX postprocessing took 0.004353523254394531 sec\n",
      "ONNX inference took 0.015164375305175781 sec\n",
      "ONNX postprocessing took 0.003290891647338867 sec\n",
      "ONNX inference took 0.01439046859741211 sec\n",
      "ONNX postprocessing took 0.002430438995361328 sec\n",
      "ONNX inference took 0.014537572860717773 sec\n",
      "ONNX postprocessing took 0.005881547927856445 sec\n",
      "ONNX inference took 0.013236761093139648 sec\n",
      "ONNX postprocessing took 0.0020720958709716797 sec\n",
      "ONNX inference took 0.014235973358154297 sec\n",
      "ONNX postprocessing took 0.0021178722381591797 sec\n",
      "ONNX inference took 0.014250516891479492 sec\n",
      "ONNX postprocessing took 0.002071857452392578 sec\n",
      "ONNX inference took 0.01440119743347168 sec\n",
      "ONNX postprocessing took 0.002872943878173828 sec\n",
      "ONNX inference took 0.014403581619262695 sec\n",
      "ONNX postprocessing took 0.0031995773315429688 sec\n",
      "ONNX inference took 0.013804912567138672 sec\n",
      "ONNX postprocessing took 0.0028645992279052734 sec\n",
      "ONNX inference took 0.013524293899536133 sec\n",
      "ONNX postprocessing took 0.0030527114868164062 sec\n",
      "ONNX inference took 0.013975143432617188 sec\n",
      "ONNX postprocessing took 0.002315998077392578 sec\n",
      "ONNX inference took 0.01421499252319336 sec\n",
      "ONNX postprocessing took 0.002866506576538086 sec\n",
      "ONNX inference took 0.01396322250366211 sec\n",
      "ONNX postprocessing took 0.002279043197631836 sec\n",
      "ONNX inference took 0.014600038528442383 sec\n",
      "ONNX postprocessing took 0.003172159194946289 sec\n",
      "ONNX inference took 0.014502286911010742 sec\n",
      "ONNX postprocessing took 0.003047943115234375 sec\n",
      "ONNX inference took 0.013578653335571289 sec\n",
      "ONNX postprocessing took 0.005361318588256836 sec\n",
      "ONNX inference took 0.014191389083862305 sec\n",
      "ONNX postprocessing took 0.002676725387573242 sec\n",
      "ONNX inference took 0.014761686325073242 sec\n",
      "ONNX postprocessing took 0.004061460494995117 sec\n",
      "ONNX inference took 0.014255046844482422 sec\n",
      "ONNX postprocessing took 0.0022618770599365234 sec\n",
      "ONNX inference took 0.014323949813842773 sec\n",
      "ONNX postprocessing took 0.0032498836517333984 sec\n",
      "ONNX inference took 0.014834165573120117 sec\n",
      "ONNX postprocessing took 0.004640817642211914 sec\n",
      "ONNX inference took 0.013470649719238281 sec\n",
      "ONNX postprocessing took 0.002337217330932617 sec\n",
      "ONNX inference took 0.013653993606567383 sec\n",
      "ONNX postprocessing took 0.0016562938690185547 sec\n",
      "ONNX inference took 0.014129877090454102 sec\n",
      "ONNX postprocessing took 0.0033707618713378906 sec\n",
      "ONNX inference took 0.014418363571166992 sec\n",
      "ONNX postprocessing took 0.002331256866455078 sec\n",
      "ONNX inference took 0.013727426528930664 sec\n",
      "ONNX postprocessing took 0.0023458003997802734 sec\n",
      "ONNX inference took 0.013814449310302734 sec\n",
      "ONNX postprocessing took 0.003573179244995117 sec\n",
      "ONNX inference took 0.014509201049804688 sec\n",
      "ONNX postprocessing took 0.0035376548767089844 sec\n",
      "ONNX inference took 0.014447927474975586 sec\n",
      "ONNX postprocessing took 0.0040056705474853516 sec\n",
      "ONNX inference took 0.014325857162475586 sec\n",
      "ONNX postprocessing took 0.003315448760986328 sec\n",
      "ONNX inference took 0.013849258422851562 sec\n",
      "ONNX postprocessing took 0.0033903121948242188 sec\n",
      "ONNX inference took 0.013784646987915039 sec\n",
      "ONNX postprocessing took 0.002089977264404297 sec\n",
      "ONNX inference took 0.013890743255615234 sec\n",
      "ONNX postprocessing took 0.003468036651611328 sec\n",
      "ONNX inference took 0.014054298400878906 sec\n",
      "ONNX postprocessing took 0.00262451171875 sec\n",
      "ONNX inference took 0.013849020004272461 sec\n",
      "ONNX postprocessing took 0.0019426345825195312 sec\n",
      "ONNX inference took 0.013520002365112305 sec\n",
      "ONNX postprocessing took 0.0030264854431152344 sec\n",
      "ONNX inference took 0.01383829116821289 sec\n",
      "ONNX postprocessing took 0.00438690185546875 sec\n",
      "ONNX inference took 0.013983488082885742 sec\n",
      "ONNX postprocessing took 0.0033473968505859375 sec\n",
      "ONNX inference took 0.013744354248046875 sec\n",
      "ONNX postprocessing took 0.003502368927001953 sec\n",
      "ONNX inference took 0.01438760757446289 sec\n",
      "ONNX postprocessing took 0.004325389862060547 sec\n",
      "ONNX inference took 0.014495134353637695 sec\n",
      "ONNX postprocessing took 0.006629467010498047 sec\n",
      "ONNX inference took 0.01444101333618164 sec\n",
      "ONNX postprocessing took 0.0033385753631591797 sec\n",
      "ONNX inference took 0.01414632797241211 sec\n",
      "ONNX postprocessing took 0.002948284149169922 sec\n",
      "ONNX inference took 0.013382434844970703 sec\n",
      "ONNX postprocessing took 0.0028047561645507812 sec\n",
      "ONNX inference took 0.013873100280761719 sec\n",
      "ONNX postprocessing took 0.0051805973052978516 sec\n",
      "ONNX inference took 0.013972282409667969 sec\n",
      "ONNX postprocessing took 0.0026960372924804688 sec\n",
      "ONNX inference took 0.014196157455444336 sec\n",
      "ONNX postprocessing took 0.005313396453857422 sec\n",
      "ONNX inference took 0.013629674911499023 sec\n",
      "ONNX postprocessing took 0.003954410552978516 sec\n",
      "ONNX inference took 0.014214277267456055 sec\n",
      "ONNX postprocessing took 0.0033617019653320312 sec\n",
      "ONNX inference took 0.01422429084777832 sec\n",
      "ONNX postprocessing took 0.004212141036987305 sec\n",
      "ONNX inference took 0.014433145523071289 sec\n",
      "ONNX postprocessing took 0.0033218860626220703 sec\n",
      "ONNX inference took 0.01366567611694336 sec\n",
      "ONNX postprocessing took 0.0029196739196777344 sec\n",
      "ONNX inference took 0.013660192489624023 sec\n",
      "ONNX postprocessing took 0.002196073532104492 sec\n",
      "ONNX inference took 0.014590263366699219 sec\n",
      "ONNX postprocessing took 0.004576683044433594 sec\n",
      "ONNX inference took 0.014189720153808594 sec\n",
      "ONNX postprocessing took 0.002995014190673828 sec\n",
      "ONNX inference took 0.013865232467651367 sec\n",
      "ONNX postprocessing took 0.0024552345275878906 sec\n",
      "ONNX inference took 0.014428138732910156 sec\n",
      "ONNX postprocessing took 0.002691030502319336 sec\n",
      "ONNX inference took 0.013600826263427734 sec\n",
      "ONNX postprocessing took 0.0027589797973632812 sec\n",
      "ONNX inference took 0.015464305877685547 sec\n",
      "ONNX postprocessing took 0.004648685455322266 sec\n",
      "ONNX inference took 0.014567136764526367 sec\n",
      "ONNX postprocessing took 0.003823518753051758 sec\n",
      "ONNX inference took 0.014992237091064453 sec\n",
      "ONNX postprocessing took 0.00455784797668457 sec\n",
      "ONNX inference took 0.014281749725341797 sec\n",
      "ONNX postprocessing took 0.005312442779541016 sec\n",
      "ONNX inference took 0.014219284057617188 sec\n",
      "ONNX postprocessing took 0.004199028015136719 sec\n",
      "ONNX inference took 0.014177799224853516 sec\n",
      "ONNX postprocessing took 0.0029425621032714844 sec\n",
      "ONNX inference took 0.014006853103637695 sec\n",
      "ONNX postprocessing took 0.0024366378784179688 sec\n",
      "ONNX inference took 0.014644861221313477 sec\n",
      "ONNX postprocessing took 0.0031888484954833984 sec\n",
      "ONNX inference took 0.014661073684692383 sec\n",
      "ONNX postprocessing took 0.0023038387298583984 sec\n",
      "ONNX inference took 0.012755870819091797 sec\n",
      "ONNX postprocessing took 0.003005504608154297 sec\n",
      "ONNX inference took 0.01449131965637207 sec\n",
      "ONNX postprocessing took 0.005212068557739258 sec\n",
      "ONNX inference took 0.013917684555053711 sec\n",
      "ONNX postprocessing took 0.00415349006652832 sec\n",
      "ONNX inference took 0.01315617561340332 sec\n",
      "ONNX postprocessing took 0.003089427947998047 sec\n",
      "ONNX inference took 0.012988567352294922 sec\n",
      "ONNX postprocessing took 0.0013928413391113281 sec\n",
      "ONNX inference took 0.013594865798950195 sec\n",
      "ONNX postprocessing took 0.0030279159545898438 sec\n",
      "ONNX inference took 0.014122486114501953 sec\n",
      "ONNX postprocessing took 0.00538325309753418 sec\n",
      "ONNX inference took 0.012475967407226562 sec\n",
      "ONNX postprocessing took 0.001608133316040039 sec\n",
      "ONNX inference took 0.013391733169555664 sec\n",
      "ONNX postprocessing took 0.0031442642211914062 sec\n",
      "ONNX inference took 0.013634443283081055 sec\n",
      "ONNX postprocessing took 0.004333019256591797 sec\n",
      "ONNX inference took 0.013280391693115234 sec\n",
      "ONNX postprocessing took 0.0017910003662109375 sec\n",
      "ONNX inference took 0.013244390487670898 sec\n",
      "ONNX postprocessing took 0.0018742084503173828 sec\n",
      "ONNX inference took 0.013001203536987305 sec\n",
      "ONNX postprocessing took 0.0014865398406982422 sec\n",
      "ONNX inference took 0.013200759887695312 sec\n",
      "ONNX postprocessing took 0.001687765121459961 sec\n",
      "ONNX inference took 0.014630317687988281 sec\n",
      "ONNX postprocessing took 0.002054929733276367 sec\n",
      "ONNX inference took 0.015038251876831055 sec\n",
      "ONNX postprocessing took 0.004652738571166992 sec\n",
      "ONNX inference took 0.01758265495300293 sec\n",
      "ONNX postprocessing took 0.0049817562103271484 sec\n",
      "ONNX inference took 0.014084815979003906 sec\n",
      "ONNX postprocessing took 0.003260374069213867 sec\n",
      "ONNX inference took 0.014400243759155273 sec\n",
      "ONNX postprocessing took 0.002947568893432617 sec\n",
      "ONNX inference took 0.014460325241088867 sec\n",
      "ONNX postprocessing took 0.0031702518463134766 sec\n",
      "ONNX inference took 0.013772726058959961 sec\n",
      "ONNX postprocessing took 0.0033245086669921875 sec\n",
      "ONNX inference took 0.014481067657470703 sec\n",
      "ONNX postprocessing took 0.0026993751525878906 sec\n",
      "ONNX inference took 0.015017986297607422 sec\n",
      "ONNX postprocessing took 0.0023763179779052734 sec\n",
      "ONNX inference took 0.014671564102172852 sec\n",
      "ONNX postprocessing took 0.005625009536743164 sec\n",
      "ONNX inference took 0.013588666915893555 sec\n",
      "ONNX postprocessing took 0.0017423629760742188 sec\n",
      "ONNX inference took 0.014531135559082031 sec\n",
      "ONNX postprocessing took 0.0032596588134765625 sec\n",
      "ONNX inference took 0.015779733657836914 sec\n",
      "ONNX postprocessing took 0.006493568420410156 sec\n",
      "ONNX inference took 0.01371622085571289 sec\n",
      "ONNX postprocessing took 0.0027883052825927734 sec\n",
      "ONNX inference took 0.013543844223022461 sec\n",
      "ONNX postprocessing took 0.0017266273498535156 sec\n",
      "ONNX inference took 0.014177322387695312 sec\n",
      "ONNX postprocessing took 0.0029349327087402344 sec\n",
      "ONNX inference took 0.014004707336425781 sec\n",
      "ONNX postprocessing took 0.0022466182708740234 sec\n",
      "ONNX inference took 0.014374494552612305 sec\n",
      "ONNX postprocessing took 0.0037848949432373047 sec\n",
      "ONNX inference took 0.014239072799682617 sec\n",
      "ONNX postprocessing took 0.0029058456420898438 sec\n",
      "ONNX inference took 0.014406919479370117 sec\n",
      "ONNX postprocessing took 0.0021097660064697266 sec\n",
      "ONNX inference took 0.014517784118652344 sec\n",
      "ONNX postprocessing took 0.0022306442260742188 sec\n",
      "ONNX inference took 0.014818429946899414 sec\n",
      "ONNX postprocessing took 0.003614187240600586 sec\n",
      "ONNX inference took 0.013631105422973633 sec\n",
      "ONNX postprocessing took 0.0027916431427001953 sec\n",
      "ONNX inference took 0.01448965072631836 sec\n",
      "ONNX postprocessing took 0.0051403045654296875 sec\n",
      "ONNX inference took 0.013993978500366211 sec\n",
      "ONNX postprocessing took 0.0033931732177734375 sec\n",
      "ONNX inference took 0.013775348663330078 sec\n",
      "ONNX postprocessing took 0.0023696422576904297 sec\n",
      "ONNX inference took 0.014158964157104492 sec\n",
      "ONNX postprocessing took 0.002577066421508789 sec\n",
      "ONNX inference took 0.01429891586303711 sec\n",
      "ONNX postprocessing took 0.0042264461517333984 sec\n",
      "ONNX inference took 0.013698101043701172 sec\n",
      "ONNX postprocessing took 0.003049135208129883 sec\n",
      "ONNX inference took 0.013348102569580078 sec\n",
      "ONNX postprocessing took 0.003937959671020508 sec\n"
     ]
    }
   ],
   "source": [
    "from dlclive.benchmark_pytorch import analyze_video\n",
    "from dlclive import DLCLive\n",
    "\n",
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    device=\"tensorrt\",\n",
    "    # snapshot=\"snapshot-263.pt\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    "    precision=\"FP16\"\n",
    ")\n",
    "#short video\n",
    "# video_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/1_20cms_0degUP_first_1s.avi'\n",
    "video_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/1_20cms_0degUP_first.avi\"\n",
    "\n",
    "poses, times = analyze_video(video_path=video_path, dlc_live=dlc_live, save_poses=False, save_dir=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/out\", draw_keypoint_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time excluding 1st inference  13.86 ms  0.53\n",
      "Mean inference time including 1st inference  44.23 ms  1175.64\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean inference time excluding 1st inference \", np.round(np.mean(times[1:])*1000, 2), \"ms \", np.round(np.std(times[1:])*1000, 2))\n",
    "print(\"Mean inference time including 1st inference \", np.round(np.mean(times)*1000, 2), \"ms \", np.round(np.std(times)*1000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7d0350483d30>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1433417797088623,\n",
       " 0.019846677780151367,\n",
       " 0.01972174644470215,\n",
       " 0.019562959671020508,\n",
       " 0.02054119110107422,\n",
       " 0.019287586212158203,\n",
       " 0.01930975914001465,\n",
       " 0.019775390625,\n",
       " 0.021361589431762695,\n",
       " 0.020486831665039062,\n",
       " 0.023508310317993164,\n",
       " 0.019176483154296875,\n",
       " 0.022179841995239258,\n",
       " 0.023015975952148438,\n",
       " 0.019678354263305664,\n",
       " 0.020087718963623047,\n",
       " 0.020717859268188477,\n",
       " 0.02086043357849121,\n",
       " 0.023644685745239258,\n",
       " 0.0215909481048584,\n",
       " 0.02092742919921875,\n",
       " 0.020411014556884766,\n",
       " 0.023017406463623047,\n",
       " 0.021517038345336914,\n",
       " 0.021661043167114258,\n",
       " 0.02132582664489746,\n",
       " 0.02152848243713379,\n",
       " 0.019128799438476562,\n",
       " 0.02377772331237793,\n",
       " 0.020733118057250977,\n",
       " 0.021207809448242188,\n",
       " 0.020865917205810547,\n",
       " 0.01990199089050293,\n",
       " 0.019349336624145508,\n",
       " 0.02163100242614746,\n",
       " 0.020320653915405273,\n",
       " 0.020637989044189453,\n",
       " 0.020346879959106445,\n",
       " 0.01885223388671875,\n",
       " 0.01897597312927246,\n",
       " 0.02143716812133789,\n",
       " 0.01978278160095215,\n",
       " 0.022147655487060547,\n",
       " 0.021617650985717773,\n",
       " 0.02158665657043457,\n",
       " 0.02079319953918457,\n",
       " 0.020571470260620117,\n",
       " 0.02292799949645996,\n",
       " 0.021432876586914062,\n",
       " 0.020339012145996094,\n",
       " 0.0234525203704834,\n",
       " 0.019826889038085938,\n",
       " 0.023105382919311523,\n",
       " 0.020264148712158203,\n",
       " 0.019860506057739258,\n",
       " 0.0210268497467041,\n",
       " 0.021668672561645508,\n",
       " 0.021470308303833008,\n",
       " 0.02157735824584961,\n",
       " 0.020766019821166992,\n",
       " 0.021030664443969727,\n",
       " 0.019581079483032227,\n",
       " 0.02145528793334961,\n",
       " 0.01901102066040039,\n",
       " 0.02037334442138672,\n",
       " 0.022805213928222656,\n",
       " 0.021566390991210938,\n",
       " 0.01990199089050293,\n",
       " 0.019785642623901367,\n",
       " 0.021184206008911133,\n",
       " 0.02290511131286621,\n",
       " 0.01918792724609375,\n",
       " 0.021863222122192383,\n",
       " 0.021605491638183594,\n",
       " 0.021327495574951172,\n",
       " 0.01914381980895996,\n",
       " 0.021691322326660156,\n",
       " 0.023492097854614258,\n",
       " 0.01901388168334961,\n",
       " 0.018824100494384766,\n",
       " 0.018850088119506836,\n",
       " 0.018492698669433594,\n",
       " 0.018490314483642578,\n",
       " 0.02127528190612793,\n",
       " 0.02015399932861328,\n",
       " 0.020959854125976562,\n",
       " 0.021033287048339844,\n",
       " 0.020975351333618164,\n",
       " 0.02018117904663086,\n",
       " 0.01982712745666504,\n",
       " 0.020690441131591797,\n",
       " 0.021567583084106445,\n",
       " 0.01869034767150879,\n",
       " 0.019594430923461914,\n",
       " 0.019416332244873047,\n",
       " 0.0204622745513916,\n",
       " 0.019609928131103516,\n",
       " 0.020978689193725586,\n",
       " 0.022556304931640625,\n",
       " 0.019018888473510742,\n",
       " 0.0206301212310791,\n",
       " 0.021826744079589844,\n",
       " 0.02221989631652832,\n",
       " 0.020612001419067383,\n",
       " 0.020490169525146484,\n",
       " 0.021326780319213867,\n",
       " 0.021045684814453125,\n",
       " 0.022190332412719727,\n",
       " 0.020543336868286133,\n",
       " 0.02051520347595215,\n",
       " 0.023082256317138672,\n",
       " 0.020668506622314453,\n",
       " 0.021710872650146484,\n",
       " 0.023267745971679688,\n",
       " 0.01900029182434082,\n",
       " 0.01932048797607422,\n",
       " 0.019585609436035156,\n",
       " 0.023548603057861328,\n",
       " 0.020711183547973633,\n",
       " 0.01883387565612793,\n",
       " 0.019150733947753906,\n",
       " 0.02052593231201172,\n",
       " 0.02247762680053711,\n",
       " 0.021792173385620117,\n",
       " 0.02005624771118164,\n",
       " 0.022275686264038086,\n",
       " 0.021800518035888672,\n",
       " 0.0192110538482666,\n",
       " 0.021728992462158203,\n",
       " 0.021669864654541016,\n",
       " 0.022919416427612305,\n",
       " 0.021080493927001953,\n",
       " 0.021253347396850586,\n",
       " 0.02098870277404785,\n",
       " 0.01954507827758789,\n",
       " 0.021284818649291992,\n",
       " 0.021457910537719727,\n",
       " 0.020999670028686523,\n",
       " 0.021504878997802734,\n",
       " 0.02066779136657715,\n",
       " 0.020615339279174805,\n",
       " 0.02178359031677246,\n",
       " 0.021471023559570312,\n",
       " 0.02303481101989746,\n",
       " 0.020760536193847656,\n",
       " 0.021463632583618164,\n",
       " 0.021490812301635742,\n",
       " 0.0189664363861084,\n",
       " 0.020646333694458008,\n",
       " 0.02136373519897461,\n",
       " 0.022898435592651367,\n",
       " 0.021735668182373047,\n",
       " 0.01891469955444336,\n",
       " 0.019806385040283203,\n",
       " 0.021589279174804688,\n",
       " 0.0201263427734375,\n",
       " 0.019777774810791016,\n",
       " 0.0215609073638916,\n",
       " 0.021979093551635742,\n",
       " 0.022510051727294922,\n",
       " 0.0216522216796875,\n",
       " 0.021480560302734375,\n",
       " 0.02240610122680664,\n",
       " 0.0229642391204834,\n",
       " 0.020876169204711914,\n",
       " 0.02047896385192871,\n",
       " 0.019179582595825195,\n",
       " 0.022357463836669922,\n",
       " 0.021764516830444336,\n",
       " 0.020379304885864258,\n",
       " 0.022864818572998047,\n",
       " 0.020392894744873047,\n",
       " 0.023672103881835938,\n",
       " 0.02073836326599121,\n",
       " 0.023549318313598633,\n",
       " 0.0201718807220459,\n",
       " 0.021453142166137695,\n",
       " 0.018977642059326172,\n",
       " 0.020327091217041016,\n",
       " 0.02261638641357422,\n",
       " 0.023296356201171875,\n",
       " 0.021243572235107422,\n",
       " 0.023144960403442383,\n",
       " 0.022350072860717773,\n",
       " 0.019817113876342773,\n",
       " 0.021335840225219727,\n",
       " 0.020956039428710938,\n",
       " 0.0214846134185791,\n",
       " 0.02112722396850586,\n",
       " 0.022377729415893555,\n",
       " 0.021980762481689453,\n",
       " 0.019533634185791016,\n",
       " 0.021290302276611328,\n",
       " 0.021725177764892578,\n",
       " 0.019849300384521484,\n",
       " 0.0188140869140625,\n",
       " 0.020543575286865234,\n",
       " 0.020437240600585938,\n",
       " 0.019727468490600586,\n",
       " 0.0231168270111084,\n",
       " 0.019585847854614258,\n",
       " 0.020447969436645508,\n",
       " 0.021222829818725586,\n",
       " 0.02071094512939453,\n",
       " 0.022215604782104492,\n",
       " 0.021056413650512695,\n",
       " 0.020544767379760742,\n",
       " 0.02139735221862793,\n",
       " 0.021174192428588867,\n",
       " 0.022590160369873047,\n",
       " 0.023981094360351562,\n",
       " 0.02119135856628418,\n",
       " 0.023427963256835938,\n",
       " 0.02287578582763672,\n",
       " 0.021654605865478516,\n",
       " 0.01881122589111328,\n",
       " 0.019184112548828125,\n",
       " 0.018716096878051758,\n",
       " 0.019258737564086914,\n",
       " 0.021151304244995117,\n",
       " 0.019977569580078125,\n",
       " 0.02356696128845215,\n",
       " 0.0191497802734375,\n",
       " 0.019366025924682617,\n",
       " 0.02071070671081543,\n",
       " 0.018938302993774414,\n",
       " 0.0199434757232666,\n",
       " 0.020465850830078125,\n",
       " 0.020534515380859375,\n",
       " 0.02076244354248047,\n",
       " 0.020325422286987305,\n",
       " 0.019070148468017578,\n",
       " 0.019611358642578125,\n",
       " 0.0212554931640625,\n",
       " 0.019748210906982422,\n",
       " 0.021887779235839844,\n",
       " 0.020158767700195312,\n",
       " 0.022963523864746094,\n",
       " 0.021490097045898438,\n",
       " 0.02075028419494629,\n",
       " 0.01914811134338379,\n",
       " 0.02001476287841797,\n",
       " 0.02231907844543457,\n",
       " 0.0201570987701416,\n",
       " 0.01927924156188965,\n",
       " 0.02317523956298828,\n",
       " 0.021471261978149414,\n",
       " 0.019356727600097656,\n",
       " 0.019365310668945312,\n",
       " 0.019030094146728516,\n",
       " 0.021591901779174805,\n",
       " 0.0214083194732666,\n",
       " 0.021239042282104492,\n",
       " 0.02324676513671875,\n",
       " 0.02028489112854004,\n",
       " 0.021533966064453125,\n",
       " 0.02163076400756836,\n",
       " 0.022033214569091797,\n",
       " 0.019226551055908203,\n",
       " 0.01962590217590332,\n",
       " 0.019731998443603516,\n",
       " 0.018948793411254883,\n",
       " 0.02144145965576172,\n",
       " 0.02259659767150879,\n",
       " 0.02127528190612793,\n",
       " 0.02019357681274414,\n",
       " 0.02144336700439453,\n",
       " 0.023064136505126953,\n",
       " 0.021163225173950195,\n",
       " 0.022347450256347656,\n",
       " 0.02139592170715332,\n",
       " 0.0219573974609375,\n",
       " 0.01961207389831543,\n",
       " 0.021399736404418945,\n",
       " 0.020772933959960938,\n",
       " 0.020611047744750977,\n",
       " 0.021117210388183594,\n",
       " 0.020592212677001953,\n",
       " 0.022211790084838867,\n",
       " 0.019445419311523438,\n",
       " 0.023725509643554688,\n",
       " 0.022340059280395508,\n",
       " 0.020792484283447266,\n",
       " 0.022728681564331055,\n",
       " 0.021834611892700195,\n",
       " 0.01922893524169922,\n",
       " 0.020541906356811523,\n",
       " 0.023157835006713867,\n",
       " 0.019390583038330078,\n",
       " 0.022724628448486328,\n",
       " 0.02336907386779785,\n",
       " 0.021821260452270508,\n",
       " 0.02252483367919922,\n",
       " 0.019482135772705078,\n",
       " 0.019504547119140625,\n",
       " 0.022874832153320312,\n",
       " 0.022007465362548828,\n",
       " 0.019504785537719727,\n",
       " 0.020985841751098633,\n",
       " 0.021214962005615234,\n",
       " 0.023395061492919922,\n",
       " 0.02215123176574707,\n",
       " 0.020570039749145508,\n",
       " 0.02281641960144043,\n",
       " 0.0216677188873291,\n",
       " 0.018963336944580078,\n",
       " 0.020251750946044922,\n",
       " 0.020329952239990234,\n",
       " 0.019306182861328125,\n",
       " 0.018744707107543945,\n",
       " 0.01927042007446289,\n",
       " 0.02062082290649414,\n",
       " 0.021219968795776367,\n",
       " 0.01917409896850586,\n",
       " 0.018975257873535156,\n",
       " 0.02040386199951172,\n",
       " 0.022745847702026367,\n",
       " 0.020372867584228516,\n",
       " 0.020900964736938477,\n",
       " 0.0213162899017334,\n",
       " 0.019373178482055664,\n",
       " 0.01879119873046875,\n",
       " 0.019815921783447266,\n",
       " 0.021353960037231445,\n",
       " 0.021918296813964844,\n",
       " 0.020805835723876953,\n",
       " 0.022568225860595703,\n",
       " 0.022883892059326172,\n",
       " 0.020214319229125977,\n",
       " 0.020057201385498047,\n",
       " 0.02313065528869629,\n",
       " 0.024197101593017578,\n",
       " 0.019160032272338867,\n",
       " 0.022401094436645508,\n",
       " 0.021190881729125977,\n",
       " 0.020275115966796875,\n",
       " 0.020227670669555664,\n",
       " 0.020914316177368164,\n",
       " 0.022298574447631836,\n",
       " 0.019853591918945312,\n",
       " 0.01993250846862793,\n",
       " 0.02148723602294922,\n",
       " 0.02044820785522461,\n",
       " 0.0231931209564209,\n",
       " 0.020050764083862305,\n",
       " 0.019093751907348633,\n",
       " 0.021465301513671875,\n",
       " 0.020475149154663086,\n",
       " 0.020761489868164062,\n",
       " 0.01976299285888672,\n",
       " 0.023182392120361328,\n",
       " 0.01948094367980957,\n",
       " 0.02219557762145996,\n",
       " 0.019052743911743164,\n",
       " 0.019462108612060547,\n",
       " 0.020996809005737305,\n",
       " 0.022154569625854492,\n",
       " 0.021414995193481445,\n",
       " 0.023303985595703125,\n",
       " 0.019675016403198242,\n",
       " 0.019347190856933594,\n",
       " 0.022141456604003906,\n",
       " 0.019775867462158203,\n",
       " 0.0233156681060791,\n",
       " 0.02221202850341797,\n",
       " 0.019667387008666992,\n",
       " 0.021332263946533203,\n",
       " 0.021159887313842773,\n",
       " 0.019467830657958984,\n",
       " 0.019678354263305664,\n",
       " 0.02104783058166504,\n",
       " 0.022812604904174805,\n",
       " 0.019654273986816406,\n",
       " 0.02124929428100586,\n",
       " 0.022352218627929688,\n",
       " 0.01900506019592285,\n",
       " 0.020848751068115234,\n",
       " 0.019831418991088867,\n",
       " 0.01944255828857422,\n",
       " 0.020556926727294922,\n",
       " 0.020089387893676758,\n",
       " 0.021853208541870117,\n",
       " 0.020035982131958008,\n",
       " 0.02141594886779785,\n",
       " 0.020389556884765625,\n",
       " 0.021864891052246094,\n",
       " 0.01996612548828125,\n",
       " 0.0213165283203125,\n",
       " 0.021393775939941406,\n",
       " 0.021619558334350586,\n",
       " 0.02182745933532715,\n",
       " 0.021280765533447266,\n",
       " 0.02112436294555664,\n",
       " 0.021905183792114258,\n",
       " 0.020742177963256836,\n",
       " 0.01990032196044922,\n",
       " 0.01932358741760254,\n",
       " 0.019353389739990234,\n",
       " 0.021116018295288086,\n",
       " 0.021703720092773438,\n",
       " 0.019452333450317383,\n",
       " 0.021199464797973633,\n",
       " 0.02089095115661621,\n",
       " 0.021373987197875977,\n",
       " 0.019360780715942383,\n",
       " 0.022324085235595703,\n",
       " 0.020512104034423828,\n",
       " 0.019188880920410156,\n",
       " 0.0218198299407959,\n",
       " 0.02252054214477539,\n",
       " 0.01931619644165039,\n",
       " 0.021396875381469727,\n",
       " 0.019718170166015625,\n",
       " 0.022223472595214844,\n",
       " 0.019672632217407227,\n",
       " 0.02143383026123047,\n",
       " 0.020296335220336914,\n",
       " 0.020130634307861328,\n",
       " 0.019928693771362305,\n",
       " 0.02162480354309082,\n",
       " 0.02151942253112793,\n",
       " 0.022199630737304688,\n",
       " 0.021123170852661133,\n",
       " 0.021641254425048828,\n",
       " 0.02078390121459961,\n",
       " 0.02175140380859375,\n",
       " 0.020323753356933594,\n",
       " 0.0205996036529541,\n",
       " 0.021796226501464844,\n",
       " 0.02034282684326172,\n",
       " 0.02151179313659668,\n",
       " 0.020467281341552734,\n",
       " 0.021656274795532227,\n",
       " 0.020392656326293945,\n",
       " 0.02076578140258789,\n",
       " 0.021172523498535156,\n",
       " 0.021016359329223633,\n",
       " 0.019033193588256836,\n",
       " 0.02115917205810547,\n",
       " 0.020637989044189453,\n",
       " 0.020137786865234375,\n",
       " 0.020624637603759766,\n",
       " 0.02250075340270996,\n",
       " 0.020775318145751953,\n",
       " 0.019281864166259766,\n",
       " 0.020422697067260742,\n",
       " 0.021333932876586914,\n",
       " 0.02180957794189453,\n",
       " 0.019075393676757812,\n",
       " 0.0200192928314209,\n",
       " 0.02266979217529297,\n",
       " 0.021575212478637695,\n",
       " 0.02150750160217285,\n",
       " 0.02186751365661621,\n",
       " 0.020879507064819336,\n",
       " 0.021743297576904297,\n",
       " 0.020695924758911133,\n",
       " 0.021056175231933594,\n",
       " 0.02182292938232422,\n",
       " 0.01949334144592285,\n",
       " 0.019104480743408203,\n",
       " 0.019034624099731445,\n",
       " 0.022725582122802734,\n",
       " 0.020946502685546875,\n",
       " 0.02206254005432129,\n",
       " 0.019518136978149414,\n",
       " 0.020691871643066406,\n",
       " 0.01913905143737793,\n",
       " 0.019932270050048828,\n",
       " 0.022286176681518555,\n",
       " 0.021854877471923828,\n",
       " 0.021033287048339844,\n",
       " 0.022826671600341797,\n",
       " 0.02169942855834961,\n",
       " 0.019209623336791992,\n",
       " 0.021962404251098633,\n",
       " 0.02057480812072754,\n",
       " 0.021172046661376953,\n",
       " 0.021410226821899414,\n",
       " 0.021144866943359375,\n",
       " 0.01922607421875,\n",
       " 0.02200627326965332,\n",
       " 0.02003335952758789,\n",
       " 0.0205230712890625,\n",
       " 0.021235227584838867,\n",
       " 0.020823240280151367,\n",
       " 0.020825862884521484,\n",
       " 0.018769502639770508,\n",
       " 0.018922090530395508,\n",
       " 0.018922805786132812,\n",
       " 0.019093036651611328,\n",
       " 0.019538402557373047,\n",
       " 0.02052164077758789,\n",
       " 0.019904375076293945,\n",
       " 0.021085023880004883,\n",
       " 0.02022695541381836,\n",
       " 0.020022153854370117,\n",
       " 0.02133941650390625,\n",
       " 0.02165699005126953,\n",
       " 0.021571874618530273,\n",
       " 0.02069568634033203,\n",
       " 0.021895647048950195,\n",
       " 0.019156217575073242,\n",
       " 0.019731760025024414,\n",
       " 0.02179408073425293,\n",
       " 0.019191265106201172,\n",
       " 0.020704269409179688,\n",
       " 0.020735979080200195,\n",
       " 0.02232503890991211,\n",
       " 0.022122621536254883,\n",
       " 0.02066826820373535,\n",
       " 0.02283501625061035,\n",
       " 0.021404504776000977,\n",
       " 0.023372173309326172,\n",
       " 0.02223944664001465,\n",
       " 0.023698091506958008,\n",
       " 0.01947188377380371,\n",
       " 0.02103877067565918,\n",
       " 0.020482540130615234,\n",
       " 0.021442890167236328,\n",
       " 0.019976377487182617,\n",
       " 0.02075028419494629,\n",
       " 0.023246288299560547,\n",
       " 0.019224166870117188,\n",
       " 0.020118236541748047,\n",
       " 0.021548748016357422,\n",
       " 0.02142643928527832,\n",
       " 0.0201876163482666,\n",
       " 0.021120309829711914,\n",
       " 0.020542621612548828,\n",
       " 0.02120375633239746,\n",
       " 0.02219557762145996,\n",
       " 0.023209810256958008,\n",
       " 0.020686864852905273,\n",
       " 0.020998716354370117,\n",
       " 0.019214391708374023,\n",
       " 0.021522998809814453,\n",
       " 0.02111673355102539,\n",
       " 0.01937389373779297,\n",
       " 0.01936817169189453,\n",
       " 0.02038741111755371,\n",
       " 0.01918172836303711,\n",
       " 0.020258426666259766,\n",
       " 0.02080059051513672,\n",
       " 0.01936483383178711,\n",
       " 0.023479461669921875,\n",
       " 0.023150920867919922,\n",
       " 0.02186274528503418,\n",
       " 0.02017664909362793,\n",
       " 0.02156376838684082,\n",
       " 0.019669055938720703,\n",
       " 0.019812822341918945,\n",
       " 0.02030181884765625,\n",
       " 0.021402597427368164,\n",
       " 0.021210432052612305,\n",
       " 0.02046799659729004,\n",
       " 0.01973438262939453,\n",
       " 0.02095341682434082,\n",
       " 0.019820690155029297,\n",
       " 0.01966094970703125,\n",
       " 0.01980113983154297,\n",
       " 0.021009445190429688,\n",
       " 0.021938323974609375,\n",
       " 0.020122051239013672,\n",
       " 0.020894765853881836,\n",
       " 0.01973867416381836,\n",
       " 0.02068042755126953,\n",
       " 0.019885778427124023,\n",
       " 0.02152872085571289,\n",
       " 0.020755290985107422,\n",
       " 0.021454811096191406,\n",
       " 0.021465301513671875,\n",
       " 0.02169966697692871,\n",
       " 0.018919944763183594,\n",
       " 0.019083261489868164,\n",
       " 0.019208431243896484,\n",
       " 0.020143747329711914,\n",
       " 0.021584749221801758,\n",
       " 0.02459120750427246,\n",
       " 0.020534515380859375,\n",
       " 0.02045440673828125,\n",
       " 0.019381284713745117,\n",
       " 0.020267486572265625,\n",
       " 0.02004241943359375,\n",
       " 0.023289203643798828,\n",
       " 0.019057273864746094,\n",
       " 0.019367456436157227,\n",
       " 0.022497177124023438,\n",
       " 0.020339488983154297,\n",
       " 0.020130157470703125,\n",
       " 0.019950151443481445,\n",
       " 0.02308201789855957,\n",
       " 0.02069711685180664,\n",
       " 0.021235227584838867,\n",
       " 0.019842863082885742,\n",
       " 0.022076129913330078,\n",
       " 0.02106928825378418,\n",
       " 0.021924972534179688,\n",
       " 0.021890640258789062,\n",
       " 0.02023172378540039,\n",
       " 0.020537376403808594,\n",
       " 0.019469738006591797,\n",
       " 0.020878314971923828,\n",
       " 0.02084517478942871,\n",
       " 0.020531654357910156,\n",
       " 0.020079374313354492,\n",
       " 0.022400379180908203,\n",
       " 0.020773887634277344,\n",
       " 0.022637605667114258,\n",
       " 0.020659685134887695,\n",
       " 0.021433115005493164,\n",
       " 0.022002458572387695,\n",
       " 0.019501209259033203,\n",
       " 0.020611047744750977,\n",
       " 0.019896745681762695,\n",
       " 0.0219118595123291,\n",
       " 0.021678924560546875,\n",
       " 0.020172119140625,\n",
       " 0.019956111907958984,\n",
       " 0.01976752281188965,\n",
       " 0.022521257400512695,\n",
       " 0.020521163940429688,\n",
       " 0.022774219512939453,\n",
       " 0.023104190826416016,\n",
       " 0.020500659942626953,\n",
       " 0.021576404571533203,\n",
       " 0.02184581756591797,\n",
       " 0.022345781326293945,\n",
       " 0.020259380340576172,\n",
       " 0.021808624267578125,\n",
       " 0.019295692443847656,\n",
       " 0.021555662155151367,\n",
       " 0.019964933395385742,\n",
       " 0.02168130874633789,\n",
       " 0.021801233291625977,\n",
       " 0.021100759506225586,\n",
       " 0.02034139633178711,\n",
       " 0.021992206573486328,\n",
       " 0.022800683975219727,\n",
       " 0.020519733428955078,\n",
       " 0.021572589874267578,\n",
       " 0.021030664443969727,\n",
       " 0.02075672149658203,\n",
       " 0.020155668258666992,\n",
       " 0.020505666732788086,\n",
       " 0.021456480026245117,\n",
       " 0.0214691162109375,\n",
       " 0.021619558334350586,\n",
       " 0.019048452377319336,\n",
       " 0.019922256469726562,\n",
       " 0.0220029354095459,\n",
       " 0.021686553955078125,\n",
       " 0.02097606658935547,\n",
       " 0.019508838653564453,\n",
       " 0.019238710403442383,\n",
       " 0.02182316780090332,\n",
       " 0.02199077606201172,\n",
       " 0.020606040954589844,\n",
       " 0.02162027359008789,\n",
       " 0.019501686096191406,\n",
       " 0.02111649513244629,\n",
       " 0.021685123443603516,\n",
       " 0.021825790405273438,\n",
       " 0.020798683166503906,\n",
       " 0.023335695266723633,\n",
       " 0.020179033279418945,\n",
       " 0.01924443244934082,\n",
       " 0.020511865615844727,\n",
       " 0.0215303897857666,\n",
       " 0.019413232803344727,\n",
       " 0.019126415252685547,\n",
       " 0.019602060317993164,\n",
       " 0.020859718322753906,\n",
       " 0.022675752639770508,\n",
       " 0.022012710571289062,\n",
       " 0.021770477294921875,\n",
       " 0.023041248321533203,\n",
       " 0.01881694793701172,\n",
       " 0.019374608993530273,\n",
       " 0.02109527587890625,\n",
       " 0.021749019622802734,\n",
       " 0.02170872688293457,\n",
       " 0.023248910903930664,\n",
       " 0.019671916961669922,\n",
       " 0.02213287353515625,\n",
       " 0.020386934280395508,\n",
       " 0.020007848739624023,\n",
       " 0.020121097564697266,\n",
       " 0.0224611759185791,\n",
       " 0.019208431243896484,\n",
       " 0.020816802978515625,\n",
       " 0.020760297775268555,\n",
       " 0.020529747009277344,\n",
       " 0.019614696502685547,\n",
       " 0.01894521713256836,\n",
       " 0.02249884605407715,\n",
       " 0.01999068260192871,\n",
       " 0.02103567123413086,\n",
       " 0.020267009735107422,\n",
       " 0.019395828247070312,\n",
       " 0.019658565521240234,\n",
       " 0.01890850067138672,\n",
       " 0.018746376037597656,\n",
       " 0.01923990249633789,\n",
       " 0.021462440490722656,\n",
       " 0.020809173583984375,\n",
       " 0.01955890655517578,\n",
       " 0.020660877227783203,\n",
       " 0.019696712493896484,\n",
       " 0.019939899444580078,\n",
       " 0.020812034606933594,\n",
       " 0.020662307739257812,\n",
       " 0.021481752395629883,\n",
       " 0.021342992782592773,\n",
       " 0.0229489803314209,\n",
       " 0.021024227142333984,\n",
       " 0.02162957191467285,\n",
       " 0.021410703659057617,\n",
       " 0.021108150482177734,\n",
       " 0.021450281143188477,\n",
       " 0.022300004959106445,\n",
       " 0.0239717960357666,\n",
       " 0.02125382423400879,\n",
       " 0.019754886627197266,\n",
       " 0.022174835205078125,\n",
       " 0.021899938583374023,\n",
       " 0.020943403244018555,\n",
       " 0.020981311798095703,\n",
       " 0.020465850830078125,\n",
       " 0.02123403549194336,\n",
       " 0.02237105369567871,\n",
       " 0.020821332931518555,\n",
       " 0.019113779067993164,\n",
       " 0.018764019012451172,\n",
       " 0.01903247833251953,\n",
       " 0.01902937889099121,\n",
       " 0.019013166427612305,\n",
       " 0.01934027671813965,\n",
       " 0.0207669734954834,\n",
       " 0.018289804458618164,\n",
       " 0.01969456672668457,\n",
       " 0.018901348114013672,\n",
       " 0.019330739974975586,\n",
       " 0.0182950496673584,\n",
       " 0.018188953399658203,\n",
       " 0.018061399459838867,\n",
       " 0.01802825927734375,\n",
       " 0.017986774444580078,\n",
       " 0.01794147491455078,\n",
       " 0.018372297286987305,\n",
       " 0.0213320255279541,\n",
       " 0.02158641815185547,\n",
       " 0.019097328186035156,\n",
       " 0.01919412612915039,\n",
       " 0.01938652992248535,\n",
       " 0.021669626235961914,\n",
       " 0.01749110221862793,\n",
       " 0.01838994026184082,\n",
       " 0.01837754249572754,\n",
       " 0.01808643341064453,\n",
       " 0.019619226455688477,\n",
       " 0.019949913024902344,\n",
       " 0.019475936889648438,\n",
       " 0.02063155174255371,\n",
       " 0.021054506301879883,\n",
       " 0.01969289779663086,\n",
       " 0.020270586013793945,\n",
       " 0.019014835357666016,\n",
       " 0.01919412612915039,\n",
       " 0.019833087921142578,\n",
       " 0.01999807357788086,\n",
       " 0.018787384033203125,\n",
       " 0.021123409271240234,\n",
       " 0.022559165954589844,\n",
       " 0.021819114685058594,\n",
       " 0.019222021102905273,\n",
       " 0.020880937576293945,\n",
       " 0.020743370056152344,\n",
       " 0.0209805965423584,\n",
       " 0.019596099853515625,\n",
       " 0.02117633819580078,\n",
       " 0.019777536392211914,\n",
       " 0.020173072814941406,\n",
       " 0.022317886352539062,\n",
       " 0.023370742797851562,\n",
       " 0.020522356033325195,\n",
       " 0.019234180450439453,\n",
       " 0.020738840103149414,\n",
       " 0.021095752716064453,\n",
       " 0.023238182067871094,\n",
       " 0.020005226135253906,\n",
       " 0.021481990814208984,\n",
       " 0.020909547805786133,\n",
       " 0.022296428680419922,\n",
       " 0.022029638290405273,\n",
       " 0.021059036254882812,\n",
       " 0.019210338592529297,\n",
       " 0.022877216339111328,\n",
       " 0.023378610610961914,\n",
       " 0.020192623138427734,\n",
       " 0.022034168243408203,\n",
       " 0.022911787033081055,\n",
       " 0.02126908302307129,\n",
       " 0.021114826202392578,\n",
       " 0.01887965202331543,\n",
       " 0.018720149993896484,\n",
       " 0.018765926361083984,\n",
       " 0.01884317398071289,\n",
       " 0.01929616928100586,\n",
       " 0.0189816951751709,\n",
       " 0.021136760711669922,\n",
       " 0.021339893341064453,\n",
       " 0.021683216094970703,\n",
       " 0.019710540771484375,\n",
       " 0.02085709571838379,\n",
       " 0.02273392677307129,\n",
       " 0.023301124572753906,\n",
       " 0.020603418350219727,\n",
       " 0.021625280380249023,\n",
       " 0.019589662551879883,\n",
       " 0.0223696231842041,\n",
       " 0.019509077072143555,\n",
       " 0.021165132522583008,\n",
       " 0.02015972137451172,\n",
       " 0.021162748336791992,\n",
       " 0.02093791961669922,\n",
       " 0.022282838821411133,\n",
       " 0.020431041717529297,\n",
       " 0.020267248153686523,\n",
       " 0.022841215133666992,\n",
       " 0.020600318908691406,\n",
       " 0.02081298828125,\n",
       " 0.021532773971557617,\n",
       " 0.022948741912841797,\n",
       " 0.02350449562072754,\n",
       " 0.019273042678833008,\n",
       " 0.019165515899658203,\n",
       " 0.023587703704833984,\n",
       " 0.019948720932006836,\n",
       " 0.021440505981445312,\n",
       " 0.021198034286499023,\n",
       " 0.019675016403198242,\n",
       " 0.02026081085205078,\n",
       " 0.020540952682495117,\n",
       " 0.0198667049407959,\n",
       " 0.01921534538269043,\n",
       " 0.020057201385498047,\n",
       " 0.022623062133789062,\n",
       " 0.020596981048583984,\n",
       " 0.02051997184753418,\n",
       " 0.02133917808532715,\n",
       " 0.01981806755065918,\n",
       " 0.0215911865234375,\n",
       " 0.02112436294555664,\n",
       " 0.02084827423095703,\n",
       " 0.021676301956176758,\n",
       " 0.018947124481201172,\n",
       " 0.020818471908569336,\n",
       " 0.0205080509185791,\n",
       " 0.020051956176757812,\n",
       " 0.023363113403320312,\n",
       " 0.020110130310058594,\n",
       " 0.02160191535949707,\n",
       " 0.0213010311126709,\n",
       " 0.021530628204345703,\n",
       " 0.022612333297729492,\n",
       " 0.022186756134033203,\n",
       " 0.01953601837158203,\n",
       " 0.019748449325561523,\n",
       " 0.019608497619628906,\n",
       " 0.021326303482055664,\n",
       " 0.021682262420654297,\n",
       " 0.019667625427246094,\n",
       " 0.02212238311767578,\n",
       " 0.021617412567138672,\n",
       " 0.02081155776977539,\n",
       " 0.019154787063598633,\n",
       " 0.021234512329101562,\n",
       " 0.02116847038269043,\n",
       " 0.021973371505737305,\n",
       " 0.019080400466918945,\n",
       " 0.020239591598510742,\n",
       " 0.01936936378479004,\n",
       " 0.021477699279785156,\n",
       " 0.02303910255432129,\n",
       " 0.02159738540649414,\n",
       " 0.020961999893188477,\n",
       " 0.02225518226623535,\n",
       " 0.02091693878173828,\n",
       " 0.02078390121459961,\n",
       " 0.021319150924682617,\n",
       " 0.02091193199157715,\n",
       " 0.019489526748657227,\n",
       " 0.020314931869506836,\n",
       " 0.020856857299804688,\n",
       " 0.020949602127075195,\n",
       " 0.01958465576171875,\n",
       " 0.022083520889282227,\n",
       " 0.0206911563873291,\n",
       " 0.01993083953857422,\n",
       " 0.01963520050048828,\n",
       " 0.021007061004638672,\n",
       " 0.020088672637939453,\n",
       " 0.02110123634338379,\n",
       " 0.021489858627319336,\n",
       " 0.02045750617980957,\n",
       " 0.023632049560546875,\n",
       " 0.02042388916015625,\n",
       " 0.021248579025268555,\n",
       " 0.019644498825073242,\n",
       " 0.01912713050842285,\n",
       " 0.019719600677490234,\n",
       " 0.01917576789855957,\n",
       " 0.020475149154663086,\n",
       " 0.019188642501831055,\n",
       " 0.019168853759765625,\n",
       " 0.020058631896972656,\n",
       " 0.019062519073486328,\n",
       " 0.01936173439025879,\n",
       " 0.01936507225036621,\n",
       " 0.019608497619628906,\n",
       " 0.01739048957824707,\n",
       " 0.018625974655151367,\n",
       " 0.019321441650390625,\n",
       " 0.01823711395263672,\n",
       " 0.018396854400634766,\n",
       " 0.020140647888183594,\n",
       " 0.018059968948364258,\n",
       " 0.019476890563964844,\n",
       " 0.016481399536132812,\n",
       " 0.02048969268798828,\n",
       " 0.019481420516967773,\n",
       " 0.019747495651245117,\n",
       " 0.017023086547851562,\n",
       " 0.01972222328186035,\n",
       " 0.01937723159790039,\n",
       " 0.019919633865356445,\n",
       " 0.018189668655395508,\n",
       " 0.019678831100463867,\n",
       " 0.019313335418701172,\n",
       " 0.01818370819091797,\n",
       " 0.020837783813476562,\n",
       " 0.020170927047729492,\n",
       " 0.02206134796142578,\n",
       " 0.021350860595703125,\n",
       " 0.021316051483154297,\n",
       " 0.020891189575195312,\n",
       " 0.02089667320251465,\n",
       " 0.021488428115844727,\n",
       " 0.02121424674987793,\n",
       " 0.021326303482055664,\n",
       " 0.020886659622192383,\n",
       " 0.020555496215820312,\n",
       " 0.020099401473999023,\n",
       " 0.020883798599243164,\n",
       " 0.023235082626342773,\n",
       " 0.019799470901489258,\n",
       " 0.02107524871826172,\n",
       " 0.019367456436157227,\n",
       " 0.024115324020385742,\n",
       " 0.019803762435913086,\n",
       " 0.022844791412353516,\n",
       " 0.020523786544799805,\n",
       " 0.021437406539916992,\n",
       " 0.02208542823791504,\n",
       " 0.020971298217773438,\n",
       " 0.019729137420654297,\n",
       " 0.01998114585876465,\n",
       " 0.02094721794128418,\n",
       " 0.02063441276550293,\n",
       " 0.02019214630126953,\n",
       " 0.021288394927978516,\n",
       " 0.02063775062561035,\n",
       " 0.021292448043823242,\n",
       " 0.023349761962890625,\n",
       " 0.021724462509155273,\n",
       " 0.02040386199951172,\n",
       " 0.020169734954833984,\n",
       " 0.020675182342529297,\n",
       " 0.0209500789642334,\n",
       " 0.020704030990600586,\n",
       " 0.019257545471191406,\n",
       " 0.021803617477416992,\n",
       " 0.022823333740234375,\n",
       " 0.022238492965698242,\n",
       " 0.021407365798950195,\n",
       " 0.019550085067749023,\n",
       " 0.02027297019958496,\n",
       " 0.020955324172973633,\n",
       " 0.02204728126525879,\n",
       " 0.02077007293701172,\n",
       " 0.02082538604736328,\n",
       " 0.021271944046020508,\n",
       " 0.02178645133972168,\n",
       " 0.021040678024291992,\n",
       " 0.01982426643371582,\n",
       " 0.021657228469848633,\n",
       " 0.02051234245300293,\n",
       " 0.021570444107055664,\n",
       " 0.022859811782836914,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS: 72.19058242729338\n",
      "Standard Deviation of FPS: 3.260524296319363\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_fps_stats(inference_times):\n",
    "    \"\"\"\n",
    "    Calculates the average FPS rate and its standard deviation from a list of inference times.\n",
    "\n",
    "    Args:\n",
    "        inference_times (list): A list of inference times in seconds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average FPS rate and its standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate FPS for each frame\n",
    "    fps_values = [1 / time for time in inference_times]\n",
    "\n",
    "    # Calculate average FPS\n",
    "    average_fps = np.mean(fps_values)\n",
    "\n",
    "    # Calculate standard deviation of FPS\n",
    "    std_dev_fps = np.std(fps_values)\n",
    "\n",
    "    return average_fps, std_dev_fps\n",
    "\n",
    "average_fps, std_dev_fps = calculate_fps_stats(times)\n",
    "\n",
    "print(\"Average FPS:\", average_fps)\n",
    "print(\"Standard Deviation of FPS:\", std_dev_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21133/1837472020.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'epoch': 263, 'metrics': {'metrics/test.rmse': 3.967074360811349, 'metrics/test.rmse_pcutoff': 3.967074360811349, 'metrics/test.mAP': 100.0, 'metrics/test.mAR': 100.0, 'metrics/test.rmse_detections': 3.967074394226074, 'metrics/test.rmse_detections_pcutoff': 3.967074394226074}, 'losses': {'train.bodypart_heatmap': 0.00014600872236769646, 'train.bodypart_locref': 0.012144822627305984, 'train.bodypart_total_loss': 0.00037662492832168937, 'train.total_loss': 0.00037662492832168937, 'eval.bodypart_heatmap': 0.00018658707267604768, 'eval.bodypart_locref': 0.06498149037361145, 'eval.bodypart_total_loss': 0.0017178307753056288, 'eval.total_loss': 0.0017178307753056288}}, 'model': OrderedDict([('backbone.model.conv1.weight', tensor([[[[-1.1734e-03,  1.8400e-03,  2.8247e-03,  ..., -1.4431e-03,\n",
      "           -5.1662e-03, -1.7045e-03],\n",
      "          [ 3.8750e-04,  4.1279e-03, -1.0452e-03,  ..., -6.8253e-03,\n",
      "           -1.9387e-03,  4.8172e-04],\n",
      "          [ 5.0824e-03,  5.2458e-03,  3.1377e-04,  ..., -1.1233e-02,\n",
      "            4.4244e-03,  7.0866e-03],\n",
      "          ...,\n",
      "          [ 4.0868e-03, -1.4321e-03, -1.9171e-02,  ...,  4.9850e-03,\n",
      "            1.8025e-02,  1.7260e-02],\n",
      "          [-4.0767e-03, -4.9845e-03, -1.2389e-02,  ...,  1.0657e-03,\n",
      "            1.0856e-02,  1.0824e-02],\n",
      "          [-4.6780e-03, -6.9025e-03, -6.7356e-03,  ...,  4.7213e-03,\n",
      "            1.4865e-02,  1.3107e-02]],\n",
      "\n",
      "         [[ 8.3831e-03, -1.7392e-03,  3.6174e-03,  ..., -4.8476e-03,\n",
      "           -6.7051e-03, -4.9014e-03],\n",
      "          [ 5.4753e-03, -3.4296e-03,  3.2082e-03,  ..., -6.6423e-03,\n",
      "           -3.4110e-03, -7.3761e-04],\n",
      "          [-3.4774e-03, -7.2002e-03,  2.5210e-03,  ..., -6.9075e-03,\n",
      "            3.1652e-03, -5.6042e-03],\n",
      "          ...,\n",
      "          [-7.3336e-03, -2.3147e-03,  1.8195e-02,  ...,  2.9443e-02,\n",
      "           -1.2168e-02, -4.4035e-02],\n",
      "          [ 2.2664e-04, -1.0024e-03,  2.1615e-02,  ...,  6.2442e-03,\n",
      "           -5.0507e-02, -5.1025e-02],\n",
      "          [ 1.1362e-02, -1.1863e-02,  3.0826e-03,  ..., -5.0288e-03,\n",
      "           -2.0446e-02, -1.1344e-02]],\n",
      "\n",
      "         [[ 2.7087e-02, -1.7082e-02, -1.7682e-02,  ..., -3.5516e-03,\n",
      "            8.3558e-03,  1.4876e-02],\n",
      "          [ 1.5679e-02, -2.3936e-02, -1.6617e-02,  ..., -2.3666e-03,\n",
      "            4.0337e-03,  2.7436e-03],\n",
      "          [-3.1633e-02, -5.6053e-02,  6.6715e-03,  ...,  3.4435e-02,\n",
      "            6.2796e-03, -2.9654e-02],\n",
      "          ...,\n",
      "          [-2.3345e-02,  4.1167e-03,  1.6032e-01,  ...,  9.2925e-02,\n",
      "           -1.1691e-01, -2.2152e-01],\n",
      "          [ 2.7918e-02,  2.9201e-02,  1.3721e-01,  ..., -1.5408e-02,\n",
      "           -1.9746e-01, -2.2431e-01],\n",
      "          [ 2.5736e-02, -2.6586e-02,  2.4837e-02,  ..., -5.9989e-02,\n",
      "           -1.2857e-01, -1.0280e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1818e-02, -1.0843e-02, -5.8094e-03,  ...,  1.2087e-02,\n",
      "            8.2365e-03, -2.8099e-03],\n",
      "          [ 1.0123e-02,  9.5172e-04, -2.6223e-02,  ..., -3.8325e-03,\n",
      "            2.4876e-02,  1.9908e-02],\n",
      "          [-2.9192e-03, -2.6467e-03, -2.6819e-02,  ..., -1.6718e-01,\n",
      "           -1.3293e-01, -5.4490e-02],\n",
      "          ...,\n",
      "          [-1.3169e-03, -1.4465e-02, -2.9032e-02,  ...,  1.2946e-01,\n",
      "            1.2574e-01,  5.3471e-02],\n",
      "          [-9.3325e-03, -1.2132e-02, -4.5727e-02,  ..., -1.1224e-01,\n",
      "           -3.3631e-02,  2.3534e-02],\n",
      "          [ 1.6114e-03,  9.5180e-03,  1.0226e-02,  ..., -1.9930e-02,\n",
      "           -3.3555e-02, -1.2756e-02]],\n",
      "\n",
      "         [[-5.1736e-03, -1.1401e-02, -6.5958e-03,  ...,  1.4054e-02,\n",
      "            2.7076e-03, -3.3586e-03],\n",
      "          [ 7.8285e-03, -1.9157e-03, -3.3156e-02,  ..., -1.6973e-02,\n",
      "            1.8998e-02,  1.9492e-02],\n",
      "          [-1.1713e-02, -6.1706e-03, -3.5156e-02,  ..., -1.9842e-01,\n",
      "           -1.5839e-01, -6.4948e-02],\n",
      "          ...,\n",
      "          [ 9.3135e-03, -2.8707e-03, -1.2573e-02,  ...,  1.5766e-01,\n",
      "            1.5104e-01,  6.1314e-02],\n",
      "          [-1.1371e-02, -2.3910e-02, -5.4820e-02,  ..., -1.2788e-01,\n",
      "           -4.0836e-02,  1.6960e-02],\n",
      "          [ 3.2404e-04,  5.2594e-03,  1.2613e-02,  ..., -1.6970e-02,\n",
      "           -3.0513e-02, -7.6800e-03]],\n",
      "\n",
      "         [[-6.6267e-03, -7.8357e-03,  1.8724e-04,  ...,  1.8809e-03,\n",
      "            4.3579e-04, -7.8104e-03],\n",
      "          [ 4.6346e-03,  1.9360e-03, -6.0629e-03,  ...,  1.2522e-02,\n",
      "            2.7775e-02,  1.1316e-02],\n",
      "          [-1.0782e-02, -1.3018e-02, -2.2786e-02,  ..., -1.0079e-01,\n",
      "           -6.6272e-02, -2.1969e-02],\n",
      "          ...,\n",
      "          [ 1.2819e-02,  1.7279e-03, -2.1472e-02,  ...,  6.9384e-02,\n",
      "            7.5381e-02,  2.3742e-02],\n",
      "          [-1.1094e-02, -6.3011e-03, -1.7823e-02,  ..., -8.5730e-02,\n",
      "           -2.8064e-02, -5.8966e-03],\n",
      "          [-2.9412e-03, -1.6695e-03,  7.6203e-03,  ...,  2.0614e-03,\n",
      "           -7.1656e-03, -9.7257e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1976e-02,  1.5481e-02, -4.7873e-03,  ..., -1.3708e-02,\n",
      "            1.2245e-02, -6.2732e-03],\n",
      "          [ 1.8061e-02, -1.9526e-02, -7.6021e-02,  ..., -2.4476e-02,\n",
      "            1.7691e-02, -3.5460e-03],\n",
      "          [-1.2319e-02, -7.8276e-02, -1.1796e-01,  ...,  2.3060e-02,\n",
      "            4.5632e-02, -7.4658e-03],\n",
      "          ...,\n",
      "          [ 4.4151e-03, -7.8947e-03,  7.5886e-03,  ...,  1.4975e-01,\n",
      "            7.2877e-02, -3.7090e-02],\n",
      "          [-9.4557e-04, -7.0420e-03,  1.9053e-02,  ...,  6.2839e-02,\n",
      "           -1.3489e-02, -8.9893e-02],\n",
      "          [-1.0487e-02, -3.8763e-03,  2.4688e-02,  ..., -1.5948e-02,\n",
      "           -7.0601e-02, -7.3037e-02]],\n",
      "\n",
      "         [[ 3.9833e-02,  3.1349e-02, -1.2981e-02,  ..., -3.8367e-02,\n",
      "            3.0345e-03,  4.1519e-03],\n",
      "          [ 3.4142e-02, -2.9508e-02, -1.1053e-01,  ..., -4.7748e-02,\n",
      "            1.9952e-02,  5.2469e-03],\n",
      "          [-1.9107e-02, -1.2392e-01, -1.7244e-01,  ...,  2.0014e-02,\n",
      "            6.4755e-02,  1.8792e-02],\n",
      "          ...,\n",
      "          [-1.1935e-02, -4.0300e-02, -6.1368e-03,  ...,  2.1194e-01,\n",
      "            9.4453e-02, -3.3537e-02],\n",
      "          [-8.1600e-03, -1.6124e-02,  3.2044e-02,  ...,  1.1687e-01,\n",
      "           -9.6095e-03, -1.0105e-01],\n",
      "          [-5.0163e-03, -3.0744e-03,  3.8515e-02,  ..., -8.4907e-03,\n",
      "           -9.2889e-02, -8.4977e-02]],\n",
      "\n",
      "         [[ 6.0766e-03,  1.5240e-02, -3.1039e-03,  ..., -1.0645e-02,\n",
      "            5.7277e-03, -1.9996e-03],\n",
      "          [ 1.1453e-02, -1.2975e-03, -3.5687e-02,  ..., -1.6138e-02,\n",
      "            8.1178e-03, -6.9524e-03],\n",
      "          [-2.1227e-03, -3.6406e-02, -5.8435e-02,  ...,  7.6464e-04,\n",
      "            1.4493e-02, -8.4283e-03],\n",
      "          ...,\n",
      "          [ 3.2918e-03, -2.4590e-03, -1.4063e-02,  ...,  6.0360e-02,\n",
      "            3.0190e-02, -1.3018e-02],\n",
      "          [-2.3095e-03, -7.2629e-03, -1.2918e-03,  ...,  3.2904e-02,\n",
      "            5.4445e-03, -3.7139e-02],\n",
      "          [-4.4753e-03, -1.9673e-03,  4.5245e-03,  ..., -1.0479e-02,\n",
      "           -3.6606e-02, -3.6356e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.4142e-03, -2.1432e-04, -1.8190e-04,  ...,  2.6516e-03,\n",
      "            5.4140e-03, -7.2974e-04],\n",
      "          [-1.8129e-03,  3.0768e-03,  1.0407e-02,  ..., -4.2028e-03,\n",
      "           -7.9191e-03,  1.1834e-03],\n",
      "          [ 1.4165e-03, -1.2866e-02, -1.7157e-02,  ...,  5.4749e-02,\n",
      "            4.3692e-02, -7.1272e-04],\n",
      "          ...,\n",
      "          [-9.4689e-04, -4.6894e-04,  4.3952e-02,  ...,  2.1418e-01,\n",
      "            1.1873e-01,  1.4828e-02],\n",
      "          [-4.0989e-03, -1.0839e-02, -5.4748e-02,  ..., -1.6354e-01,\n",
      "           -7.4860e-02, -1.0541e-02],\n",
      "          [ 5.1115e-03,  4.5068e-03,  2.6699e-02,  ...,  6.1202e-02,\n",
      "            2.6270e-02,  5.0513e-04]],\n",
      "\n",
      "         [[-2.2595e-03,  3.9380e-03, -1.4466e-03,  ..., -4.0784e-03,\n",
      "            5.7480e-03,  5.7266e-03],\n",
      "          [-3.6478e-03, -2.7574e-04,  9.3746e-03,  ..., -3.5213e-03,\n",
      "           -9.1199e-03,  2.2742e-03],\n",
      "          [ 2.4360e-03, -1.1823e-02, -1.1356e-02,  ...,  6.1367e-02,\n",
      "            5.7086e-02,  2.9751e-03],\n",
      "          ...,\n",
      "          [ 3.9277e-03,  3.6251e-03,  5.6189e-02,  ...,  2.5977e-01,\n",
      "            1.4588e-01,  2.4001e-02],\n",
      "          [-5.6276e-03, -6.8854e-03, -6.2705e-02,  ..., -1.8795e-01,\n",
      "           -7.7243e-02, -6.5728e-03],\n",
      "          [ 1.9124e-03,  5.7188e-04,  2.5445e-02,  ...,  5.4264e-02,\n",
      "            1.9193e-02, -2.5402e-03]],\n",
      "\n",
      "         [[ 1.5133e-03,  2.7781e-03, -1.8148e-03,  ...,  1.7788e-03,\n",
      "            3.2028e-03,  4.5173e-03],\n",
      "          [-5.2059e-03,  1.3756e-03,  3.9126e-03,  ..., -1.4084e-02,\n",
      "           -1.2764e-02, -4.8353e-03],\n",
      "          [-3.2220e-04, -7.9308e-03, -3.5106e-03,  ...,  6.7435e-02,\n",
      "            5.2109e-02,  1.2207e-02],\n",
      "          ...,\n",
      "          [-1.5104e-03, -2.7269e-03,  3.1493e-02,  ...,  1.6962e-01,\n",
      "            8.3051e-02,  7.8761e-03],\n",
      "          [-4.3938e-03,  4.4892e-04, -3.3072e-02,  ..., -1.2170e-01,\n",
      "           -4.8742e-02,  6.2114e-03],\n",
      "          [ 7.5466e-04, -2.1109e-03,  1.2918e-02,  ...,  4.0808e-02,\n",
      "            1.3805e-02, -1.3926e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.4165e-03, -1.0459e-02, -5.1144e-03,  ..., -7.8246e-04,\n",
      "            2.1691e-03, -6.3636e-03],\n",
      "          [-8.2769e-03, -3.8802e-03, -8.2512e-03,  ...,  7.9225e-04,\n",
      "           -4.8156e-03, -4.5225e-03],\n",
      "          [-8.2705e-03, -1.0596e-02, -7.9995e-03,  ...,  1.1382e-02,\n",
      "            2.0498e-03, -7.5115e-03],\n",
      "          ...,\n",
      "          [ 3.7907e-03, -1.9415e-03, -7.1563e-03,  ..., -1.3794e-02,\n",
      "            6.1897e-03, -1.6245e-03],\n",
      "          [-3.4707e-03,  2.2449e-03,  8.3403e-03,  ...,  5.4192e-04,\n",
      "            6.0456e-03, -7.3917e-03],\n",
      "          [-8.2687e-03,  2.0058e-05,  7.2335e-03,  ...,  5.1520e-03,\n",
      "           -3.7709e-03, -3.7343e-03]],\n",
      "\n",
      "         [[-4.9588e-03,  2.1342e-03,  6.4050e-03,  ..., -2.1136e-04,\n",
      "            3.3780e-03,  2.6293e-03],\n",
      "          [-3.4285e-03,  8.4135e-03,  7.2568e-03,  ..., -4.6264e-04,\n",
      "            8.9345e-03,  1.4532e-02],\n",
      "          [ 3.3017e-04,  2.3171e-03, -2.2348e-03,  ...,  1.6736e-02,\n",
      "            9.7672e-03,  3.0537e-03],\n",
      "          ...,\n",
      "          [-4.9892e-03, -1.0085e-02, -3.4475e-02,  ..., -5.1165e-02,\n",
      "            6.1298e-05,  1.2666e-02],\n",
      "          [-3.9403e-03, -4.0298e-03,  3.7119e-03,  ..., -1.5130e-02,\n",
      "            2.9743e-03,  7.0110e-03],\n",
      "          [-9.7449e-04, -1.6909e-03,  5.9618e-03,  ...,  2.9765e-03,\n",
      "            2.3161e-03,  9.1377e-03]],\n",
      "\n",
      "         [[ 1.1210e-02,  6.7449e-03,  1.0299e-02,  ...,  1.2628e-02,\n",
      "            4.8978e-03,  9.5059e-03],\n",
      "          [ 5.7753e-03,  4.5290e-03,  3.6447e-03,  ..., -5.5139e-04,\n",
      "           -7.1058e-03,  3.2542e-03],\n",
      "          [ 1.8031e-03,  4.4530e-03,  7.9554e-03,  ...,  5.5132e-03,\n",
      "           -2.6098e-03,  8.7617e-04],\n",
      "          ...,\n",
      "          [-3.5586e-03, -5.4914e-03, -2.2756e-02,  ..., -8.4720e-02,\n",
      "           -4.9989e-03, -7.5529e-03],\n",
      "          [-2.1845e-04,  4.7580e-03, -2.9432e-03,  ..., -3.3162e-02,\n",
      "            1.9806e-03, -8.7562e-03],\n",
      "          [ 3.9492e-03,  4.9294e-04,  2.5223e-03,  ...,  3.2952e-03,\n",
      "            1.0249e-03,  6.6666e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.6252e-02, -2.0741e-02, -2.6643e-02,  ...,  3.4344e-02,\n",
      "           -1.3835e-02, -6.8427e-03],\n",
      "          [-4.3702e-03, -2.7835e-02, -7.4385e-02,  ...,  8.7817e-02,\n",
      "           -2.8869e-02, -3.2836e-02],\n",
      "          [ 6.0272e-03,  8.1997e-03, -1.4659e-01,  ...,  1.7337e-01,\n",
      "            1.9621e-02, -4.1644e-02],\n",
      "          ...,\n",
      "          [ 1.0217e-03,  8.8249e-02,  8.1954e-02,  ..., -1.0497e-01,\n",
      "            1.7078e-01,  3.0661e-02],\n",
      "          [-1.6981e-02,  2.9942e-02,  1.5218e-01,  ..., -2.2044e-01,\n",
      "            2.9432e-02,  6.1500e-02],\n",
      "          [-1.0169e-02, -1.5923e-02,  7.3051e-02,  ..., -9.1184e-02,\n",
      "           -8.0410e-02,  2.3245e-02]],\n",
      "\n",
      "         [[-5.1445e-04, -9.7249e-03, -2.5018e-02,  ...,  2.8500e-02,\n",
      "           -2.3144e-02, -8.7827e-03],\n",
      "          [ 2.7765e-03,  3.2481e-03, -5.4628e-02,  ...,  8.3189e-02,\n",
      "           -3.7555e-02, -2.8323e-02],\n",
      "          [ 3.4694e-03,  1.9220e-02, -1.2043e-01,  ...,  1.6152e-01,\n",
      "            1.4668e-03, -5.0136e-02],\n",
      "          ...,\n",
      "          [-5.2511e-03,  6.9149e-02,  8.0405e-02,  ..., -7.9098e-02,\n",
      "            1.6944e-01,  2.0187e-03],\n",
      "          [-9.9016e-03,  1.1483e-03,  1.3750e-01,  ..., -1.9587e-01,\n",
      "            4.0160e-02,  4.6761e-02],\n",
      "          [-8.5569e-03, -2.7737e-02,  5.0273e-02,  ..., -6.8416e-02,\n",
      "           -5.0162e-02,  2.0372e-02]],\n",
      "\n",
      "         [[ 6.7215e-03, -7.4823e-03, -2.3550e-02,  ...,  1.3188e-02,\n",
      "           -1.2457e-02, -2.5783e-03],\n",
      "          [ 9.1104e-03,  1.4601e-02, -1.9801e-02,  ...,  1.7950e-02,\n",
      "           -3.1331e-02,  1.7585e-03],\n",
      "          [-9.0108e-03,  1.5389e-02, -4.6844e-02,  ...,  4.6736e-02,\n",
      "           -3.0001e-02, -2.2392e-02],\n",
      "          ...,\n",
      "          [-6.0634e-03,  8.2634e-03,  7.3234e-02,  ..., -1.1329e-02,\n",
      "            7.9805e-02, -3.2138e-02],\n",
      "          [-9.6151e-03, -2.7836e-02,  6.1372e-02,  ..., -7.8082e-02,\n",
      "            3.3029e-02, -2.9617e-03],\n",
      "          [ 9.9649e-03, -2.8591e-02, -9.3271e-04,  ..., -1.1290e-02,\n",
      "            9.5008e-04,  1.1145e-02]]]], device='cuda:0')), ('backbone.model.bn1.weight', tensor([1.7876, 2.5254, 1.6390, 2.9114, 1.2332, 1.8373, 1.4545, 2.5826, 2.6530,\n",
      "        1.4469, 3.3580, 1.3236, 1.3181, 3.5734, 2.6170, 4.3175, 1.4212, 3.6755,\n",
      "        2.1573, 2.1476, 1.3405, 2.1181, 3.9769, 1.6498, 3.2134, 1.9369, 2.0425,\n",
      "        3.2870, 2.6476, 1.5937, 2.1775, 2.5328, 2.0269, 1.9120, 3.4547, 1.1965,\n",
      "        1.5909, 3.1216, 4.5299, 0.8388, 2.0152, 2.7532, 2.4780, 8.6496, 3.4165,\n",
      "        1.6702, 1.4704, 1.9562, 1.3331, 2.2066, 4.0105, 0.9839, 1.4432, 2.9148,\n",
      "        1.8772, 1.5722, 5.3290, 0.8459, 2.6959, 1.7604, 1.3635, 2.4899, 3.6431,\n",
      "        1.7896], device='cuda:0')), ('backbone.model.bn1.bias', tensor([ 0.1870,  0.1582,  0.3879,  0.5360,  0.1836,  0.2910,  0.1354,  0.3151,\n",
      "         0.0989,  0.2400, -1.2663,  0.8283,  0.9292,  1.7492,  0.6620,  0.1066,\n",
      "         0.3386,  0.3458,  0.4554,  1.5663,  0.2046,  0.0425,  0.0411,  0.4502,\n",
      "         0.1171,  0.3353,  0.2995,  0.1214,  0.1926,  0.3422,  0.9238,  2.0051,\n",
      "         0.1793,  0.1056,  1.3729,  1.0369,  0.9453,  1.2361,  3.0312,  0.9495,\n",
      "         0.3352,  0.1524,  0.5253,  0.1007,  0.2322,  0.3498,  0.3236,  0.2153,\n",
      "         0.1422,  0.1549,  2.5448,  0.8512,  0.2327,  0.0063,  0.2356,  0.1698,\n",
      "         1.0967,  0.7192,  0.5527,  0.4744,  0.2992,  0.0085, -2.2687,  1.2773],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.conv1.weight', tensor([[[[ 0.0087]],\n",
      "\n",
      "         [[ 0.0946]],\n",
      "\n",
      "         [[-0.0479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[ 0.0426]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0287]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[ 0.0322]],\n",
      "\n",
      "         [[-0.0192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0645]],\n",
      "\n",
      "         [[-0.0273]],\n",
      "\n",
      "         [[-0.1008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[-0.0006]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0241]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.0207]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1038]],\n",
      "\n",
      "         [[ 0.0245]],\n",
      "\n",
      "         [[ 0.0904]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[-0.0304]],\n",
      "\n",
      "         [[-0.1172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0925]],\n",
      "\n",
      "         [[ 0.0123]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         [[ 0.0239]]]], device='cuda:0')), ('backbone.model.layer1.0.bn1.weight', tensor([1.7428, 1.5640, 1.3053, 1.7825, 4.1857, 2.1554, 1.4645, 1.6804, 2.3791,\n",
      "        1.2556, 2.7384, 6.0693, 1.5955, 2.7801, 1.2149, 3.0980, 3.6712, 1.7295,\n",
      "        3.3715, 1.2341, 1.5174, 2.1061, 1.5205, 1.7611, 3.3311, 3.1296, 2.4081,\n",
      "        8.9941, 5.3295, 4.2380, 1.5728, 1.2217, 2.8876, 2.0055, 1.5555, 1.8953,\n",
      "        1.4974, 1.2801, 1.1860, 2.3449, 1.5353, 4.2369, 2.2893, 1.2913, 1.9702,\n",
      "        1.4982, 1.2804, 1.7228, 2.4568, 1.1380, 2.2174, 2.5969, 1.4088, 9.6609,\n",
      "        1.3526, 1.0051, 9.5551, 1.9973, 1.5984, 2.3720, 1.2752, 2.1899, 0.9772,\n",
      "        1.3504], device='cuda:0')), ('backbone.model.layer1.0.bn1.bias', tensor([ 6.1224e-01,  9.3451e-01, -7.9850e-03, -1.6505e-01,  9.9099e-01,\n",
      "         1.1976e+00,  3.7401e-02, -3.8077e-01, -5.1089e-01,  4.0862e-01,\n",
      "         4.6635e-01,  1.6425e+00, -2.3324e-01,  1.0812e+00, -1.0186e-01,\n",
      "         1.7760e+00,  3.0722e+00, -1.3958e+00,  3.9264e-01,  3.8957e-01,\n",
      "        -1.2142e-01,  9.3095e-01,  9.2406e-01, -2.1482e-01, -5.0555e-01,\n",
      "         5.4879e-01,  1.5769e-01,  1.5228e+00, -4.7571e-01, -1.8751e+00,\n",
      "         4.5959e-01,  2.4259e-01, -1.0087e+00,  9.8247e-01,  6.9772e-01,\n",
      "        -8.3210e-01,  1.0253e+00,  6.0734e-01,  3.6186e-01,  2.5036e-02,\n",
      "         9.1700e+00, -2.0061e+00,  3.0220e-02,  7.3245e-01,  3.1733e-01,\n",
      "         4.6182e-01,  3.4267e-01, -3.1618e-01,  9.8911e-01, -3.4359e-03,\n",
      "        -6.1637e-01,  4.8761e-01,  2.2192e-01,  1.8227e+00,  9.3184e-01,\n",
      "        -3.4683e-01,  1.5472e+00,  1.6594e-01,  1.0993e+00, -6.4279e-01,\n",
      "        -4.8168e-02, -1.5863e-02,  4.3915e-02,  7.5184e-02], device='cuda:0')), ('backbone.model.layer1.0.conv2.weight', tensor([[[[ 2.4695e-02,  1.0086e-02, -2.3858e-02],\n",
      "          [ 1.9179e-02,  6.0027e-03,  6.0981e-02],\n",
      "          [-4.0315e-03,  1.9103e-02,  4.8191e-02]],\n",
      "\n",
      "         [[ 1.0775e-01,  7.3541e-02,  4.2278e-02],\n",
      "          [ 1.5126e-01, -3.1031e-01, -1.2756e-01],\n",
      "          [ 1.0151e-01, -1.1620e-01, -1.0673e-01]],\n",
      "\n",
      "         [[-3.9536e-02, -6.3275e-02, -3.9595e-02],\n",
      "          [-3.6045e-03,  3.5791e-02,  6.4414e-02],\n",
      "          [-1.4039e-02,  1.0507e-01,  4.4776e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9047e-02,  7.1056e-03, -1.0831e-02],\n",
      "          [ 7.2402e-03,  2.5787e-02,  3.2578e-02],\n",
      "          [-2.8757e-02,  1.3951e-02,  2.1063e-03]],\n",
      "\n",
      "         [[ 9.4783e-03, -1.0199e-01,  5.0988e-02],\n",
      "          [-2.0060e-01,  1.0124e-01, -9.4664e-03],\n",
      "          [-6.7429e-02, -6.0749e-02, -1.5019e-01]],\n",
      "\n",
      "         [[-5.9941e-02,  9.1738e-03, -2.9570e-02],\n",
      "          [ 3.1002e-02, -1.6512e-01,  9.7076e-02],\n",
      "          [ 1.1224e-01, -1.1444e-01, -4.5157e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2259e-02,  2.4440e-02, -4.7731e-02],\n",
      "          [-9.2976e-02, -6.2424e-02,  1.4603e-02],\n",
      "          [-5.1080e-02,  6.1620e-02, -5.5175e-02]],\n",
      "\n",
      "         [[-3.6038e-03, -3.0751e-02,  9.4263e-03],\n",
      "          [-6.1979e-02,  8.6602e-03,  7.3297e-02],\n",
      "          [-1.8606e-02,  1.1381e-02,  2.7863e-02]],\n",
      "\n",
      "         [[ 3.1933e-02, -1.1556e-02, -1.2463e-02],\n",
      "          [ 1.1482e-02, -1.2715e-02, -2.9173e-03],\n",
      "          [ 3.5213e-02, -6.5394e-03,  3.0486e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0441e-02, -3.4228e-02,  1.0113e-01],\n",
      "          [ 2.3258e-02, -6.2896e-02,  8.2580e-02],\n",
      "          [ 6.7176e-02, -3.0926e-02,  4.2220e-02]],\n",
      "\n",
      "         [[-2.0710e-02,  2.7758e-02,  1.0272e-02],\n",
      "          [-1.2627e-01, -2.1827e-02, -2.8443e-02],\n",
      "          [-4.4869e-02, -1.8450e-02,  1.4296e-02]],\n",
      "\n",
      "         [[-1.0840e-02,  3.4252e-02,  6.8873e-02],\n",
      "          [-9.4221e-02,  1.2409e-01,  4.5053e-02],\n",
      "          [-1.6312e-02,  5.6827e-02,  4.1549e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8605e-02,  1.1836e-01, -3.1557e-02],\n",
      "          [ 1.6018e-01, -2.0068e-01, -4.3765e-02],\n",
      "          [ 6.9260e-02,  1.3684e-01, -3.2580e-02]],\n",
      "\n",
      "         [[ 2.7935e-02, -1.1802e-02,  5.9540e-03],\n",
      "          [-5.3205e-02,  7.5071e-02,  1.6758e-02],\n",
      "          [-1.9096e-02,  1.8013e-02,  1.0237e-02]],\n",
      "\n",
      "         [[-3.4140e-03, -3.2729e-02, -2.7878e-02],\n",
      "          [ 2.3979e-02,  1.3011e-02, -5.8251e-02],\n",
      "          [ 2.2897e-03,  1.0760e-02, -5.2589e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8977e-03,  1.9190e-02, -4.0983e-02],\n",
      "          [ 1.5535e-02,  1.8962e-02, -2.7518e-02],\n",
      "          [ 7.4788e-03,  2.8785e-02, -1.8197e-02]],\n",
      "\n",
      "         [[-3.0588e-03, -1.9175e-03,  6.1002e-03],\n",
      "          [-1.9269e-02, -4.2068e-02,  1.9014e-02],\n",
      "          [ 2.3260e-04, -4.8872e-02,  3.5621e-02]],\n",
      "\n",
      "         [[ 5.9145e-02, -5.3843e-03, -9.0316e-03],\n",
      "          [ 4.0422e-02, -1.9398e-02,  3.7339e-02],\n",
      "          [ 1.1750e-02, -2.2100e-02, -1.1058e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4277e-02, -3.6728e-02,  4.7166e-03],\n",
      "          [-7.5175e-02,  2.2898e-02, -1.1619e-02],\n",
      "          [ 1.1038e-02, -2.4845e-03,  1.5966e-02]],\n",
      "\n",
      "         [[-3.4809e-02, -8.5511e-02, -3.9355e-02],\n",
      "          [ 2.5847e-02,  4.3613e-02,  6.3030e-02],\n",
      "          [ 2.7137e-02,  8.3270e-02, -4.6762e-03]],\n",
      "\n",
      "         [[-1.8493e-01, -9.2023e-02,  6.9007e-02],\n",
      "          [-9.2960e-02,  7.8971e-02,  2.2204e-01],\n",
      "          [ 8.3000e-02,  2.3836e-01,  2.2416e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5713e-02, -1.4519e-02, -4.5565e-02],\n",
      "          [ 4.0620e-02,  7.0114e-02,  4.2747e-02],\n",
      "          [-3.5114e-03,  3.8729e-02,  8.3594e-02]],\n",
      "\n",
      "         [[-1.3570e-01,  4.0938e-02, -1.3230e-02],\n",
      "          [ 1.3934e-01,  1.2637e-01,  1.2041e-01],\n",
      "          [ 1.0908e-03,  5.9505e-02, -5.2806e-02]],\n",
      "\n",
      "         [[ 4.6313e-02, -5.2850e-02, -6.7227e-02],\n",
      "          [ 6.8413e-02,  6.5659e-02,  7.4004e-02],\n",
      "          [-8.3317e-02, -7.1110e-02, -4.1374e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7298e-02, -3.1057e-02,  2.2961e-02],\n",
      "          [-1.0007e-02, -4.8924e-02, -7.3099e-02],\n",
      "          [ 1.3376e-02, -4.7736e-02,  2.4357e-02]],\n",
      "\n",
      "         [[-7.8698e-03,  9.4809e-02,  1.1155e-01],\n",
      "          [ 1.6513e-02,  2.0548e-02,  6.1094e-02],\n",
      "          [-5.0944e-02, -1.2808e-02,  1.9099e-02]],\n",
      "\n",
      "         [[-6.7879e-03, -6.3103e-02, -6.5972e-02],\n",
      "          [ 1.2818e-03,  6.8528e-05, -1.7127e-02],\n",
      "          [-6.9763e-02,  3.1822e-02, -1.3510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9746e-02,  3.3414e-02,  2.0539e-03],\n",
      "          [ 2.2262e-02, -2.1942e-02,  9.3135e-03],\n",
      "          [-9.0557e-03,  4.4289e-02, -1.7880e-02]],\n",
      "\n",
      "         [[ 1.0962e-01, -2.2386e-03, -1.0721e-01],\n",
      "          [-7.6908e-02,  7.2222e-02,  6.6477e-02],\n",
      "          [-1.2113e-03, -2.3103e-02,  4.1097e-02]],\n",
      "\n",
      "         [[ 5.4525e-03, -1.0068e-01,  7.3182e-03],\n",
      "          [-5.8898e-02,  1.2019e-01, -5.8150e-02],\n",
      "          [ 3.7028e-02,  2.0137e-03,  7.4818e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7099e-02, -4.0706e-02,  2.0972e-02],\n",
      "          [ 1.1825e-01, -1.1538e-01,  1.0786e-01],\n",
      "          [ 4.6835e-02, -1.2157e-01,  2.8924e-02]],\n",
      "\n",
      "         [[ 1.2303e-01, -6.7888e-03, -4.3418e-02],\n",
      "          [ 7.7517e-02,  2.9168e-02,  9.3061e-03],\n",
      "          [-5.9690e-02, -4.7820e-02,  1.4894e-01]],\n",
      "\n",
      "         [[-4.2981e-02,  4.1343e-02, -8.8989e-03],\n",
      "          [ 5.0757e-02,  5.9587e-02, -2.7312e-02],\n",
      "          [-1.2416e-02, -2.0976e-02, -1.7179e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0532e-02,  2.7845e-02, -2.6771e-02],\n",
      "          [-3.9314e-02,  2.0444e-02, -3.6263e-02],\n",
      "          [-2.6364e-02,  2.3681e-02, -2.1631e-02]],\n",
      "\n",
      "         [[-8.4341e-02, -4.2637e-02,  6.0411e-02],\n",
      "          [-5.9907e-02,  2.4596e-02,  5.7906e-02],\n",
      "          [ 2.0350e-02, -7.8071e-04, -3.0761e-02]],\n",
      "\n",
      "         [[-1.0927e-02,  3.3617e-02,  2.8152e-02],\n",
      "          [-3.6588e-02,  2.9720e-02, -3.8277e-02],\n",
      "          [-3.9068e-02,  1.3212e-02, -3.9667e-02]]]], device='cuda:0')), ('backbone.model.layer1.0.bn2.weight', tensor([2.3098, 6.2165, 2.3180, 2.3186, 1.7283, 2.2958, 1.8183, 1.8273, 1.7565,\n",
      "        1.6705, 2.2368, 7.1225, 1.8691, 1.6268, 1.4413, 1.5248, 1.8891, 1.3580,\n",
      "        1.4509, 1.5953, 2.3563, 2.3276, 1.6597, 1.3249, 1.6593, 2.4352, 1.9265,\n",
      "        1.5715, 5.7173, 2.8938, 1.7565, 2.0056, 1.5090, 2.2284, 2.1027, 1.4202,\n",
      "        2.0672, 1.7560, 2.5711, 1.4537, 1.6233, 1.5005, 3.2902, 8.1475, 1.4744,\n",
      "        1.7990, 1.6299, 1.5976, 1.9617, 1.3232, 1.8432, 1.6721, 0.5588, 1.1917,\n",
      "        1.4744, 2.3719, 1.5472, 2.0343, 0.8025, 1.4810, 2.1802, 1.0507, 1.3812,\n",
      "        1.8187], device='cuda:0')), ('backbone.model.layer1.0.bn2.bias', tensor([-2.1738,  1.9930, -1.3362,  2.4051, -1.2322,  2.2132, -1.5980,  1.6567,\n",
      "        -1.4899,  1.6784, -1.8888,  2.5312, -1.6420,  1.3859,  1.1871, -1.3834,\n",
      "        -1.7274,  1.5120,  1.3241, -1.4442,  1.0726, -1.8409, -0.9557,  1.5892,\n",
      "        -1.3159,  2.0348, -1.3388,  1.5511,  0.6281, -2.9204,  1.6924, -1.7380,\n",
      "         1.6418, -1.9118, -1.5958,  1.4056,  1.9835, -1.4126, -2.3350,  1.4418,\n",
      "        -1.3811,  1.2999, -2.1558,  1.7961, -0.8399,  1.6280, -1.0014,  1.5985,\n",
      "        -1.5810,  1.4080, -1.5983,  1.6440, -0.7707,  0.3458,  1.6200, -1.6320,\n",
      "         1.4304, -1.6285,  0.8211, -1.4379, -1.2181,  0.8637,  1.4042, -1.1860],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.conv3.weight', tensor([[[[ 0.0471]],\n",
      "\n",
      "         [[-0.0243]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1113]],\n",
      "\n",
      "         [[ 0.0606]],\n",
      "\n",
      "         [[ 0.0177]]],\n",
      "\n",
      "\n",
      "        [[[-0.0099]],\n",
      "\n",
      "         [[ 0.0063]],\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0115]],\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[-0.0154]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0244]],\n",
      "\n",
      "         [[ 0.0236]],\n",
      "\n",
      "         [[-0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[-0.0357]],\n",
      "\n",
      "         [[-0.0455]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1043]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         [[-0.0537]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0782]],\n",
      "\n",
      "         [[ 0.0146]],\n",
      "\n",
      "         [[ 0.0520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0484]],\n",
      "\n",
      "         [[ 0.0423]],\n",
      "\n",
      "         [[-0.0275]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0490]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[-0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1716]],\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         [[ 0.0414]]]], device='cuda:0')), ('backbone.model.layer1.0.bn3.weight', tensor([-1.7403e+00,  4.2860e+00, -8.3712e-01, -3.2366e-01,  8.6464e-01,\n",
      "        -7.2928e-02,  3.2385e-01,  5.9597e-01,  3.5978e+00,  1.9886e+00,\n",
      "         5.5826e-02, -2.0875e-02,  2.9070e-02,  1.4638e+00, -1.7539e+00,\n",
      "        -7.7749e-01,  1.6916e+00,  9.6337e-01,  1.3972e+00, -3.3203e+00,\n",
      "         6.8063e-01,  1.0032e+00,  3.2995e-01, -9.5716e-01, -3.6745e+00,\n",
      "        -2.2638e+00,  1.1687e+00,  2.2973e+00,  3.5441e+00, -1.6387e+00,\n",
      "         3.6984e-01,  3.7155e+00, -5.5645e-01, -1.4268e+00,  3.9574e+00,\n",
      "        -3.9116e-02,  1.6752e-01, -3.3708e+00, -7.6030e-02, -4.0946e+00,\n",
      "         2.5805e-01, -2.5423e+00,  1.1727e+00, -1.3917e+00,  2.7416e+00,\n",
      "        -2.4714e+00,  4.4907e+00,  2.2306e-01,  1.7217e-02,  5.6961e-01,\n",
      "        -2.7793e-01,  1.5344e+00, -6.1234e-01,  1.2075e+00,  3.0612e+00,\n",
      "        -4.5734e-01, -1.1394e+00,  3.2970e+00,  1.4025e-01,  2.6926e+00,\n",
      "        -1.2162e+00, -6.0115e-01, -1.2616e+00, -7.2392e-02, -2.4452e+00,\n",
      "         1.1570e+00,  1.1009e+00, -1.5510e+00, -8.1254e-01,  1.3607e+00,\n",
      "         1.8647e+00,  1.8940e+00,  3.4161e+00,  2.6060e+00,  1.8309e+00,\n",
      "        -1.0592e+00,  5.1433e-01, -9.6745e-01, -9.2458e-01, -2.7540e+00,\n",
      "         1.6803e+00, -7.6127e+00, -2.8176e-01, -1.3732e+00,  5.0447e-01,\n",
      "        -4.0315e-01, -1.6604e+00, -2.4661e+00, -1.0735e+00,  4.1993e+00,\n",
      "        -1.4183e+00,  1.7483e+00,  1.2293e+00,  1.5896e+00, -2.4396e+00,\n",
      "         6.5198e-01, -2.6625e-02,  1.0285e+00, -2.2452e+00,  3.6153e+00,\n",
      "         3.6720e+00, -2.0815e+00,  3.3318e+00, -5.8989e-01,  8.7778e-01,\n",
      "        -2.4334e+00,  1.1643e+00, -3.4707e-01, -1.2429e+00, -8.5423e-01,\n",
      "        -1.7891e+00, -4.3558e-01,  1.5574e+00,  1.5729e+00,  9.5818e-01,\n",
      "        -1.8076e+00, -1.0501e+00, -1.3097e+00,  1.2108e+00, -3.2071e+00,\n",
      "        -1.8087e+00,  2.5271e+00,  2.6632e+00, -1.0835e+00,  2.5458e-01,\n",
      "        -1.5114e+00, -2.0092e+00,  9.2493e-01,  9.0242e-02, -1.3594e+00,\n",
      "         3.3692e+00,  2.4189e+00, -3.5297e-01, -1.2694e+00, -2.5830e+00,\n",
      "        -4.3125e+00,  3.1018e-02, -2.7532e+00,  1.5526e+00, -2.7741e+00,\n",
      "        -6.5347e-01, -7.7601e-02,  1.2397e+00, -2.8213e-01,  3.9739e+00,\n",
      "        -6.4317e+00,  1.0187e+00, -1.9177e+00, -8.0499e-01,  1.3661e+00,\n",
      "         3.4885e+00, -2.1841e+00,  7.8059e-01, -3.4142e+00,  1.4708e+00,\n",
      "         3.5233e+00, -3.0034e+00,  1.3043e+00, -3.1105e+00, -2.2040e+00,\n",
      "         2.3435e+00,  9.2082e-01,  9.5136e-01, -9.8944e-01, -2.2832e+00,\n",
      "        -1.7902e+00, -3.2788e-01,  1.0309e+00, -2.2042e+00, -1.4048e+00,\n",
      "         4.3582e-01, -1.2033e+00,  1.5434e+00, -1.6029e+00,  3.5200e+00,\n",
      "        -1.1659e+00, -7.1398e-01,  2.0785e+00,  9.6421e-01,  2.7582e+00,\n",
      "        -6.4305e-01,  2.6200e-01,  1.5402e+00,  1.4139e+00, -7.2825e-01,\n",
      "         1.6158e+00, -9.9987e-01,  3.4511e+00, -3.9850e+00, -3.3185e+00,\n",
      "         2.8787e+00,  1.9258e+00,  2.4323e+00, -3.1119e+00,  7.1674e-03,\n",
      "         4.5102e-03, -2.4143e+00, -1.0166e+00, -9.8332e-01, -1.6923e+00,\n",
      "        -1.6108e+00, -4.6831e-01, -3.7118e+00,  6.1253e-01, -1.0822e+00,\n",
      "         1.0624e+00, -1.4932e+00, -3.2999e+00, -1.0472e+00,  5.2967e-01,\n",
      "         3.5636e+00, -2.3075e+00, -8.0879e-01,  1.0790e+00,  2.9511e+00,\n",
      "        -3.0733e+00,  1.2901e+00,  2.2774e+00, -7.8632e-02,  2.4615e-01,\n",
      "         2.0602e+00, -1.9893e+00, -5.1354e-02,  9.1857e-01,  1.2644e+00,\n",
      "        -2.2370e+00,  3.8721e+00,  4.3976e+00, -8.5761e-01, -1.6976e+00,\n",
      "         2.4123e+00,  3.2546e+00,  1.8159e+00, -2.3795e+00, -1.4408e+00,\n",
      "        -1.1080e+00, -5.7956e-01,  6.9499e-01, -2.9183e+00, -1.1377e+00,\n",
      "        -6.3232e-01, -5.1891e-01, -4.3647e+00, -2.3753e+00,  3.1310e+00,\n",
      "        -1.3071e+00, -1.0362e+00,  1.2238e+00, -1.8426e+00, -3.0312e+00,\n",
      "         3.4583e-01, -2.5622e+00,  1.1681e+00,  2.0634e+00, -9.4285e-01,\n",
      "        -3.1877e+00], device='cuda:0')), ('backbone.model.layer1.0.bn3.bias', tensor([-0.1433,  3.9631, -0.1378,  0.1617,  0.7109, -0.4263,  0.6784, -0.1833,\n",
      "        -0.7120, -0.3659,  1.6142, -0.6518, -1.1245,  0.8053,  0.0739,  1.2166,\n",
      "         0.7268,  2.5406,  0.6380,  0.3794,  0.0605, -0.6514,  1.4830,  1.1963,\n",
      "         0.7331, -0.0684,  0.6388,  1.2360,  0.5716,  0.4660,  1.1423,  0.1811,\n",
      "         1.8862, -0.5286, -0.0224,  1.0179,  2.4492, -0.8219, -0.8479,  0.5242,\n",
      "         1.1452,  0.5192, -0.0271, -0.7797,  1.1569, -0.2032,  0.8612,  0.9125,\n",
      "         0.1113,  0.5695,  1.3195, -0.3934,  0.8467,  0.3010,  0.6758,  1.3206,\n",
      "         0.5636,  2.1382,  1.1673, -0.0929,  1.8233,  2.2080,  0.6498, -0.9419,\n",
      "         1.0441,  0.6534, -0.9413,  0.1661,  0.1427,  0.3577,  0.2685,  0.2962,\n",
      "        -0.9357, -0.5535, -0.3839, -1.0112,  0.5904, -0.5306,  3.9385,  1.2509,\n",
      "         1.1002, -1.1521, -1.5484, -0.4702, -1.3772, -1.1734, -0.2598, -0.4548,\n",
      "         0.4284,  2.8061, -0.4675,  1.0529,  0.5843,  1.6632,  0.1648, -0.4284,\n",
      "         0.7092,  0.4353, -0.1392,  2.6687,  0.4746, -0.6557, -0.5393, -1.4898,\n",
      "        -0.3449,  0.6643,  0.0542,  0.8787, -0.2430,  0.1787,  0.6465,  0.6821,\n",
      "         0.9181,  0.0195,  1.4305,  0.4897,  0.9140,  1.5378,  1.4559,  0.6479,\n",
      "         0.2489,  0.9929,  1.4122, -0.5784,  1.0513, -0.0438,  0.2901,  1.8751,\n",
      "         0.5864, -0.1949,  0.1255, -0.5268,  0.7490, -3.5267,  1.0624,  1.3725,\n",
      "         0.2298, -0.4299, -0.7566, -1.1788, -0.3230,  0.0944, -0.5743,  0.1269,\n",
      "         2.5217,  1.0308,  0.3594,  0.1391, -0.2210,  0.2807,  1.2584,  0.0174,\n",
      "         0.8410,  1.5288, -0.2195,  1.5748,  0.9527,  0.6225,  0.5053,  1.0288,\n",
      "        -0.1252, -1.7318, -0.4203, -0.4502,  1.3477,  0.3574,  0.2577,  1.4554,\n",
      "         0.6274,  0.6352,  0.1985, -0.2091,  2.2724,  0.1426,  1.6804,  1.4529,\n",
      "         0.3488,  0.7443,  1.9732,  1.7856, -1.3888,  1.3265,  1.2564, -0.9147,\n",
      "        -0.0946, -0.2956, -1.6635,  0.9774,  0.5130,  1.0257,  0.8095,  0.1206,\n",
      "         0.4062,  1.8264,  0.2485,  1.1693,  0.7225,  1.9733,  1.9992,  0.1578,\n",
      "        -0.2831, -0.6160,  1.7560, -0.0688, -0.2304,  0.6082, -0.9949,  0.6995,\n",
      "        -1.1430,  1.9911, -2.5203,  1.1075,  0.2107,  0.5232,  0.5860,  1.0788,\n",
      "         0.1240,  0.9159,  0.8836,  0.5451,  1.3733,  0.4772,  1.3352,  1.8314,\n",
      "         1.0254,  0.2568,  1.2999,  1.3164,  0.8044,  0.3004,  0.6941,  1.3724,\n",
      "         0.5819,  1.4052,  0.2064,  0.4824, -1.0385,  0.8320, -1.1576, -1.0856,\n",
      "         0.1684,  0.1326,  2.2150, -0.6418,  1.1336, -0.9601,  0.3483,  0.2783,\n",
      "         0.0451, -0.5781,  0.7067,  0.4985, -0.3594,  0.1605,  0.6702,  0.2843],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.downsample.0.weight', tensor([[[[-0.2944]],\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.0913]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0147]],\n",
      "\n",
      "         [[ 0.0047]],\n",
      "\n",
      "         [[ 0.0790]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490]],\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0443]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         [[ 0.0257]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0021]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4269]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0216]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0879]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0603]],\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         [[-0.1333]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0412]],\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         [[ 0.1797]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091]],\n",
      "\n",
      "         [[ 0.0106]],\n",
      "\n",
      "         [[-0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0809]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         [[ 0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0506]],\n",
      "\n",
      "         [[-0.0504]],\n",
      "\n",
      "         [[-0.1250]]]], device='cuda:0')), ('backbone.model.layer1.0.downsample.1.weight', tensor([ 4.6168e+00,  9.0811e-02,  3.8383e+00,  3.4998e+00,  8.2211e-01,\n",
      "         2.8237e+00,  3.7180e+00,  3.6437e+00,  1.7832e-01,  9.2665e-01,\n",
      "         2.2882e+00, -1.7838e-02,  1.2234e-01,  5.8606e+00,  3.0153e+00,\n",
      "         7.7844e+00,  1.2699e+00,  1.1338e+01,  1.4665e+00, -1.1839e-01,\n",
      "         8.2558e+00,  2.0027e+00,  4.2189e+00,  6.3844e+00, -1.5771e-01,\n",
      "         1.5288e+00,  4.2838e+00,  2.2791e+00,  7.1129e-01,  1.2603e-01,\n",
      "         6.4966e+00, -1.5250e-01,  6.5030e+00,  4.2867e+00,  1.4876e+00,\n",
      "         3.1079e+00,  8.6501e+00,  7.3492e+00,  2.2140e+00,  6.2599e-02,\n",
      "         4.9958e+00,  6.0356e+00,  7.8408e+00,  3.9363e+00,  1.6423e+00,\n",
      "         6.8914e+00,  1.6127e+01,  3.6284e+00,  2.1602e+00,  3.6352e+00,\n",
      "         4.3504e+00,  3.6973e+00,  5.9768e+00,  4.1040e+00,  9.1433e-01,\n",
      "         6.0594e+00,  3.0934e-01,  1.9837e-01,  6.6341e+00, -1.2135e+00,\n",
      "         6.9365e+00,  3.7688e+00,  6.3567e+00, -3.7646e-01,  1.5034e+00,\n",
      "         5.3865e-01,  5.1163e+00,  1.4538e+00,  4.3246e+00,  4.3025e+00,\n",
      "         1.8893e+00,  2.4682e+00,  3.1797e+00,  7.7570e-02,  2.0715e+00,\n",
      "         6.1458e+00,  3.9921e+00,  2.8650e+00,  3.6551e+00,  8.0108e-01,\n",
      "         1.5153e-01, -2.2397e-02,  3.1178e+00,  3.1718e+00,  4.2960e+00,\n",
      "         2.7340e+00,  4.0469e-02,  4.3525e-02,  8.2130e+00,  5.6835e-01,\n",
      "         7.0817e+00,  9.9201e-01,  5.3003e+00,  1.1090e+01, -8.9163e-01,\n",
      "         1.4087e+00,  2.5569e+00,  3.3622e+00, -4.6343e-02, -1.5681e-01,\n",
      "        -1.2970e-01,  2.8168e+00,  2.0399e-01,  2.5814e+00,  2.1722e+00,\n",
      "         1.1502e+00,  2.1639e+00,  4.1719e+00,  6.8564e+00,  3.0892e+00,\n",
      "         5.9682e-01,  3.1400e+00,  1.7392e+00,  2.2962e+00,  7.0112e+00,\n",
      "        -1.6817e+00, -7.6361e+00,  7.7995e+00,  9.6018e+00,  1.8040e+00,\n",
      "         7.3324e+00,  2.3921e+00,  2.4426e-01,  9.6035e+00,  6.0872e+00,\n",
      "         6.0326e-01, -7.5858e-02,  1.2131e+01,  1.7621e+00,  4.5230e+00,\n",
      "        -2.5236e-01,  1.1092e-02,  3.2007e+00,  5.1207e+00,  4.0117e-01,\n",
      "         4.8909e-01,  4.4720e+00, -1.4093e-01,  7.7665e+00,  1.0399e+00,\n",
      "         2.6660e+00,  2.7851e+00,  8.1129e+00,  5.3389e+00,  3.5917e-02,\n",
      "         4.9288e+00,  5.6382e+00,  5.6954e+00,  2.2192e+00,  2.4945e+00,\n",
      "         2.9095e-01,  2.3266e+00,  7.3684e+00,  1.1326e+01,  6.6655e+00,\n",
      "         2.7591e+00, -1.7037e+00,  5.9351e+00,  9.7622e-01,  1.9305e+00,\n",
      "         7.3704e+00,  1.9901e+00,  5.8236e+00, -1.8698e-01,  3.2140e+00,\n",
      "        -5.3678e-01,  7.7871e+00,  6.5627e+00,  1.0431e+00,  6.7705e+00,\n",
      "         2.6470e+00,  1.1712e+01,  1.8630e+01,  1.4658e+00, -4.5124e-02,\n",
      "         3.5059e+00,  2.4166e+00,  4.4398e+00,  7.0977e+00,  8.0849e-01,\n",
      "         4.2997e+00,  5.5763e+00,  5.6901e+00,  2.1268e-01,  6.6532e+00,\n",
      "         4.2950e+00,  3.5215e+00,  1.7133e-03,  1.9832e+00, -2.8516e-01,\n",
      "         3.0703e+00,  7.9427e-01,  1.3160e+00,  4.2156e-01,  3.3715e+00,\n",
      "         4.4382e+00,  2.3092e+00,  1.3385e+01,  4.4329e+00,  1.2965e+00,\n",
      "         3.9108e+00,  3.2581e+00,  2.2844e-01,  3.4274e+00,  1.8617e+00,\n",
      "         4.8370e+00,  3.9517e+00, -1.3155e-02,  3.4881e+00,  3.1088e+00,\n",
      "        -1.5496e-02,  7.7424e-01,  3.2517e+00,  2.2998e+00,  1.1824e+00,\n",
      "         7.1583e-02,  5.5075e+00,  1.2884e+00,  5.5139e+00,  2.2465e+00,\n",
      "         7.8806e-01,  2.2008e+00,  3.4639e+00,  9.7677e+00,  7.2683e+00,\n",
      "         3.9271e+00,  1.9381e+00, -9.5387e-02,  5.0818e+00,  1.7287e+00,\n",
      "         1.1571e+00,  4.4610e+00,  6.9910e-01,  1.8616e-01,  4.7131e-02,\n",
      "         5.0136e+00,  2.9368e+00,  2.0153e+00, -1.8285e-01,  4.9191e+00,\n",
      "         3.7464e+00,  3.5974e+00,  6.4137e-01,  3.6432e+00, -1.6521e-01,\n",
      "         3.2736e+00,  2.9486e+00,  1.1040e+00, -1.4318e-01,  2.6675e-01,\n",
      "         6.8733e+00,  1.5978e+00,  2.8780e+00,  6.2252e-02,  6.5668e+00,\n",
      "        -7.3047e-02], device='cuda:0')), ('backbone.model.layer1.0.downsample.1.bias', tensor([-0.1433,  3.9631, -0.1378,  0.1617,  0.7109, -0.4263,  0.6784, -0.1833,\n",
      "        -0.7120, -0.3659,  1.6142, -0.6518, -1.1245,  0.8053,  0.0739,  1.2166,\n",
      "         0.7268,  2.5406,  0.6380,  0.3794,  0.0605, -0.6514,  1.4830,  1.1963,\n",
      "         0.7331, -0.0684,  0.6388,  1.2360,  0.5716,  0.4660,  1.1423,  0.1811,\n",
      "         1.8862, -0.5286, -0.0224,  1.0179,  2.4492, -0.8219, -0.8479,  0.5242,\n",
      "         1.1452,  0.5192, -0.0271, -0.7797,  1.1569, -0.2032,  0.8612,  0.9125,\n",
      "         0.1113,  0.5695,  1.3195, -0.3934,  0.8467,  0.3010,  0.6758,  1.3206,\n",
      "         0.5636,  2.1382,  1.1673, -0.0929,  1.8233,  2.2080,  0.6498, -0.9419,\n",
      "         1.0441,  0.6534, -0.9413,  0.1661,  0.1427,  0.3577,  0.2685,  0.2962,\n",
      "        -0.9357, -0.5535, -0.3839, -1.0112,  0.5904, -0.5306,  3.9385,  1.2509,\n",
      "         1.1002, -1.1521, -1.5484, -0.4702, -1.3772, -1.1734, -0.2598, -0.4548,\n",
      "         0.4284,  2.8061, -0.4675,  1.0529,  0.5843,  1.6632,  0.1648, -0.4284,\n",
      "         0.7092,  0.4353, -0.1392,  2.6687,  0.4746, -0.6557, -0.5393, -1.4898,\n",
      "        -0.3449,  0.6643,  0.0542,  0.8787, -0.2430,  0.1787,  0.6465,  0.6821,\n",
      "         0.9181,  0.0195,  1.4305,  0.4897,  0.9140,  1.5378,  1.4559,  0.6479,\n",
      "         0.2489,  0.9929,  1.4122, -0.5784,  1.0513, -0.0438,  0.2901,  1.8751,\n",
      "         0.5864, -0.1949,  0.1255, -0.5268,  0.7490, -3.5267,  1.0624,  1.3725,\n",
      "         0.2298, -0.4299, -0.7566, -1.1788, -0.3230,  0.0944, -0.5743,  0.1269,\n",
      "         2.5217,  1.0308,  0.3594,  0.1391, -0.2210,  0.2807,  1.2584,  0.0174,\n",
      "         0.8410,  1.5288, -0.2195,  1.5748,  0.9527,  0.6225,  0.5053,  1.0288,\n",
      "        -0.1252, -1.7318, -0.4203, -0.4502,  1.3477,  0.3574,  0.2577,  1.4554,\n",
      "         0.6274,  0.6352,  0.1985, -0.2091,  2.2724,  0.1426,  1.6804,  1.4529,\n",
      "         0.3488,  0.7443,  1.9732,  1.7856, -1.3888,  1.3265,  1.2564, -0.9147,\n",
      "        -0.0946, -0.2956, -1.6635,  0.9774,  0.5130,  1.0257,  0.8095,  0.1206,\n",
      "         0.4062,  1.8264,  0.2485,  1.1693,  0.7225,  1.9733,  1.9992,  0.1578,\n",
      "        -0.2831, -0.6160,  1.7560, -0.0688, -0.2304,  0.6082, -0.9949,  0.6995,\n",
      "        -1.1430,  1.9911, -2.5203,  1.1075,  0.2107,  0.5232,  0.5860,  1.0788,\n",
      "         0.1240,  0.9159,  0.8836,  0.5451,  1.3733,  0.4772,  1.3352,  1.8314,\n",
      "         1.0254,  0.2568,  1.2999,  1.3164,  0.8044,  0.3004,  0.6941,  1.3724,\n",
      "         0.5819,  1.4052,  0.2064,  0.4824, -1.0385,  0.8320, -1.1576, -1.0856,\n",
      "         0.1684,  0.1326,  2.2150, -0.6418,  1.1336, -0.9601,  0.3483,  0.2783,\n",
      "         0.0451, -0.5781,  0.7067,  0.4985, -0.3594,  0.1605,  0.6702,  0.2843],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv1.weight', tensor([[[[ 0.0972]],\n",
      "\n",
      "         [[ 0.1206]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1477]],\n",
      "\n",
      "         [[-0.0330]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[-0.0662]],\n",
      "\n",
      "         [[-0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0525]],\n",
      "\n",
      "         [[-0.1164]],\n",
      "\n",
      "         [[-0.0699]]],\n",
      "\n",
      "\n",
      "        [[[-0.0666]],\n",
      "\n",
      "         [[-0.0521]],\n",
      "\n",
      "         [[ 0.0765]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0701]],\n",
      "\n",
      "         [[ 0.0433]],\n",
      "\n",
      "         [[ 0.0307]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0822]],\n",
      "\n",
      "         [[-0.1120]],\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[-0.0346]],\n",
      "\n",
      "         [[-0.0557]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0236]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[-0.1418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.0306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0662]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[-0.0079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0654]],\n",
      "\n",
      "         [[ 0.0391]],\n",
      "\n",
      "         [[-0.0745]]]], device='cuda:0')), ('backbone.model.layer1.1.bn1.weight', tensor([3.2255, 5.4521, 1.8643, 2.3486, 3.3921, 4.2949, 4.7178, 4.6659, 2.1008,\n",
      "        2.0660, 1.9307, 1.7551, 1.9384, 2.6163, 1.7885, 2.0918, 1.7041, 1.8221,\n",
      "        2.0933, 1.2485, 5.0473, 1.2190, 3.9392, 3.3216, 2.5884, 2.2565, 1.9883,\n",
      "        1.8902, 1.6453, 0.7023, 1.8713, 1.3534, 1.0201, 1.3402, 1.5942, 1.8855,\n",
      "        1.1353, 0.7357, 3.1083, 3.4441, 2.4149, 1.9106, 2.1535, 2.0625, 2.9858,\n",
      "        3.3844, 2.0838, 1.3120, 3.4414, 3.0686, 2.1811, 1.6444, 1.8262, 1.2412,\n",
      "        2.8610, 2.6065, 1.7665, 1.9179, 1.6724, 2.1824, 2.3933, 1.7754, 2.1745,\n",
      "        1.4584], device='cuda:0')), ('backbone.model.layer1.1.bn1.bias', tensor([-0.9892,  2.3441,  1.5775, -0.9554, -2.0282,  2.6131,  1.7644, -3.5670,\n",
      "         1.2615, -0.5792, -1.1472,  1.7501, -2.1657, -1.1552,  1.0290,  0.1253,\n",
      "         0.1221,  0.0761, -0.2707,  1.3161, -3.9474,  0.2531,  1.5280, -1.2663,\n",
      "         0.7259, -0.8019,  0.4911, -0.1449, -0.4298,  1.4907, -0.7737,  1.1900,\n",
      "         1.3900, -1.1093,  0.6939,  0.1100, -0.3645,  2.3542, -1.3582,  2.5795,\n",
      "        -1.5417,  1.3857, -0.4581,  1.1488, -1.9365,  2.0469, -1.4159, -0.2044,\n",
      "        -2.0042,  1.3710,  1.1431,  0.1513,  0.5315,  0.8019, -1.8874,  1.9965,\n",
      "         1.5067, -0.2626,  1.6003, -0.1984, -1.5308,  1.2346,  0.3949, -0.7947],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv2.weight', tensor([[[[-0.0307, -0.0454, -0.0236],\n",
      "          [-0.1666,  0.2277, -0.1815],\n",
      "          [ 0.0076, -0.0075, -0.0212]],\n",
      "\n",
      "         [[-0.0104,  0.0567,  0.0136],\n",
      "          [ 0.1201,  0.1226,  0.1139],\n",
      "          [ 0.0178,  0.0074,  0.0251]],\n",
      "\n",
      "         [[-0.0117,  0.0952, -0.0049],\n",
      "          [ 0.0532, -0.0496, -0.0322],\n",
      "          [-0.0638, -0.0777, -0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342, -0.1099,  0.0177],\n",
      "          [ 0.0198, -0.0825, -0.0045],\n",
      "          [ 0.0203, -0.1228, -0.0019]],\n",
      "\n",
      "         [[ 0.0075,  0.1376,  0.0935],\n",
      "          [-0.0726,  0.0408, -0.1849],\n",
      "          [-0.0338, -0.0986, -0.0075]],\n",
      "\n",
      "         [[-0.0025, -0.0165,  0.0545],\n",
      "          [ 0.0434, -0.0655,  0.0283],\n",
      "          [ 0.0719, -0.0033, -0.0463]]],\n",
      "\n",
      "\n",
      "        [[[-0.0152, -0.0586,  0.1095],\n",
      "          [ 0.0535,  0.1314,  0.0337],\n",
      "          [ 0.1157, -0.0185, -0.0366]],\n",
      "\n",
      "         [[-0.0781,  0.0898, -0.0336],\n",
      "          [-0.0223, -0.0482, -0.0445],\n",
      "          [-0.0088,  0.0847, -0.0588]],\n",
      "\n",
      "         [[-0.1195, -0.1933,  0.1147],\n",
      "          [ 0.0639,  0.0513,  0.0270],\n",
      "          [ 0.0338,  0.1760,  0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0300,  0.0198, -0.0537],\n",
      "          [-0.0200,  0.0218, -0.0419],\n",
      "          [-0.0245,  0.0371,  0.0655]],\n",
      "\n",
      "         [[-0.0789, -0.0600,  0.0470],\n",
      "          [ 0.0924,  0.0466, -0.1102],\n",
      "          [ 0.0636, -0.0636,  0.1206]],\n",
      "\n",
      "         [[-0.0392,  0.0040, -0.0074],\n",
      "          [ 0.0227,  0.1463,  0.0613],\n",
      "          [-0.0412, -0.0104,  0.0028]]],\n",
      "\n",
      "\n",
      "        [[[-0.0182, -0.0897, -0.1059],\n",
      "          [-0.1214, -0.0740, -0.0630],\n",
      "          [-0.1446, -0.0573, -0.0217]],\n",
      "\n",
      "         [[-0.1810, -0.0178, -0.0259],\n",
      "          [-0.0678,  0.0305, -0.0553],\n",
      "          [-0.0364, -0.0368, -0.1115]],\n",
      "\n",
      "         [[ 0.0373, -0.1294,  0.0250],\n",
      "          [-0.0833,  0.1324,  0.0535],\n",
      "          [ 0.0174,  0.0840, -0.0322]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0515,  0.0887, -0.1290],\n",
      "          [ 0.0968,  0.1119,  0.0557],\n",
      "          [-0.0879,  0.0399,  0.0066]],\n",
      "\n",
      "         [[-0.1089, -0.0996, -0.0060],\n",
      "          [ 0.0265,  0.0210, -0.0202],\n",
      "          [-0.0159,  0.0065,  0.1067]],\n",
      "\n",
      "         [[-0.0815, -0.1664, -0.0909],\n",
      "          [ 0.0277, -0.1125, -0.1371],\n",
      "          [-0.0477, -0.2464, -0.1471]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0550, -0.0442,  0.1318],\n",
      "          [-0.1927, -0.1812,  0.3060],\n",
      "          [-0.0231, -0.1031,  0.1275]],\n",
      "\n",
      "         [[-0.0759,  0.0322,  0.0543],\n",
      "          [-0.0502,  0.0246,  0.1015],\n",
      "          [ 0.0574, -0.1096, -0.0062]],\n",
      "\n",
      "         [[ 0.0632, -0.0156,  0.0142],\n",
      "          [ 0.0618, -0.1287, -0.0492],\n",
      "          [ 0.0892, -0.0161, -0.0522]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0298, -0.0352,  0.0823],\n",
      "          [ 0.0122, -0.0440, -0.0050],\n",
      "          [-0.0438, -0.0271,  0.0447]],\n",
      "\n",
      "         [[-0.0739, -0.0312,  0.0097],\n",
      "          [-0.1093, -0.0343,  0.1904],\n",
      "          [ 0.0299,  0.0430, -0.0501]],\n",
      "\n",
      "         [[-0.0151, -0.0531, -0.0203],\n",
      "          [-0.0231,  0.0557, -0.0080],\n",
      "          [-0.1036, -0.0055,  0.0521]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0563,  0.0988,  0.0358],\n",
      "          [ 0.0619,  0.1410,  0.0892],\n",
      "          [ 0.0320,  0.1057,  0.0888]],\n",
      "\n",
      "         [[ 0.3608,  0.1591,  0.1133],\n",
      "          [ 0.2177,  0.0803,  0.1360],\n",
      "          [ 0.1555,  0.1571,  0.3434]],\n",
      "\n",
      "         [[ 0.0282,  0.1189,  0.0525],\n",
      "          [ 0.0635, -0.0299, -0.0619],\n",
      "          [-0.0772, -0.0098, -0.0581]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1126, -0.0635, -0.0597],\n",
      "          [-0.0198,  0.1301,  0.0853],\n",
      "          [-0.0943, -0.0244, -0.0241]],\n",
      "\n",
      "         [[ 0.0793, -0.0008, -0.0488],\n",
      "          [ 0.0237, -0.0324, -0.1217],\n",
      "          [ 0.0678, -0.0381, -0.2170]],\n",
      "\n",
      "         [[-0.0546, -0.0256, -0.0186],\n",
      "          [ 0.0168,  0.0489,  0.1175],\n",
      "          [-0.0068,  0.0203, -0.0108]]],\n",
      "\n",
      "\n",
      "        [[[-0.0044, -0.0401,  0.0156],\n",
      "          [-0.0654, -0.0535,  0.0411],\n",
      "          [-0.0627, -0.0266, -0.0078]],\n",
      "\n",
      "         [[-0.0696, -0.1335,  0.0206],\n",
      "          [-0.0915,  0.0475, -0.0661],\n",
      "          [-0.0349, -0.0849, -0.0633]],\n",
      "\n",
      "         [[ 0.0116, -0.0640, -0.0100],\n",
      "          [-0.0597,  0.0025, -0.0316],\n",
      "          [ 0.0289, -0.0186, -0.0467]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0019,  0.0817,  0.0203],\n",
      "          [ 0.0468, -0.1131, -0.0153],\n",
      "          [ 0.0146, -0.0231,  0.0133]],\n",
      "\n",
      "         [[-0.0064, -0.0146,  0.0049],\n",
      "          [ 0.0284,  0.0248,  0.0319],\n",
      "          [-0.0065, -0.0086,  0.0426]],\n",
      "\n",
      "         [[-0.0427, -0.0620, -0.0596],\n",
      "          [-0.0466,  0.0637, -0.1281],\n",
      "          [-0.0951, -0.0789, -0.1318]]]], device='cuda:0')), ('backbone.model.layer1.1.bn2.weight', tensor([1.7916, 2.3705, 0.8039, 0.8268, 2.1546, 1.5692, 2.0239, 2.6892, 2.3259,\n",
      "        2.3044, 1.9858, 3.0782, 1.5930, 2.4379, 2.8254, 2.4894, 1.3925, 0.3935,\n",
      "        1.4443, 0.6879, 2.7114, 2.2801, 2.6586, 2.4428, 2.0601, 2.4208, 1.8261,\n",
      "        2.4762, 0.4714, 1.5236, 2.2131, 2.1186, 2.3576, 1.7589, 1.4384, 0.3525,\n",
      "        1.2938, 0.7569, 1.3889, 0.5004, 2.3640, 2.6192, 0.8096, 0.8750, 1.0451,\n",
      "        0.9976, 1.4397, 0.2424, 5.3001, 2.4137, 2.5881, 2.1713, 0.8982, 0.6000,\n",
      "        2.4643, 2.7684, 2.4165, 2.6517, 2.2931, 2.4100, 2.6692, 2.0572, 0.3188,\n",
      "        1.5088], device='cuda:0')), ('backbone.model.layer1.1.bn2.bias', tensor([ 2.0851, -1.9334,  0.3521,  0.4959, -0.5685,  1.9035,  1.5894, -1.4805,\n",
      "        -1.9591,  1.9045,  1.4118, -2.8879,  2.4605, -2.3474,  2.4598, -1.3701,\n",
      "        -0.9201,  0.2878,  0.5829, -0.4869, -2.6593,  1.7933, -2.3334,  2.0671,\n",
      "         1.4543, -1.9681,  1.4802, -1.4739,  0.5769, -0.9581,  2.5111, -1.1463,\n",
      "        -1.5300,  1.2756, -0.9329,  0.4548,  0.5285, -0.7760, -0.9820,  0.4021,\n",
      "         1.8991, -2.5145,  0.3861,  0.5878, -0.1995,  0.7160, -1.0315,  0.5508,\n",
      "         2.5575, -1.6291, -2.4942,  1.7395,  0.5580, -0.6141,  2.0318, -2.7923,\n",
      "         2.0439, -1.9598, -1.2297,  1.9252, -1.5978,  1.7111,  0.4090, -1.3005],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv3.weight', tensor([[[[-3.6021e-02]],\n",
      "\n",
      "         [[ 6.2003e-02]],\n",
      "\n",
      "         [[-1.2458e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0048e-02]],\n",
      "\n",
      "         [[-4.5005e-03]],\n",
      "\n",
      "         [[ 2.6009e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9201e-02]],\n",
      "\n",
      "         [[ 1.0059e-01]],\n",
      "\n",
      "         [[ 1.2573e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7288e-02]],\n",
      "\n",
      "         [[ 3.9465e-02]],\n",
      "\n",
      "         [[-6.1164e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9902e-03]],\n",
      "\n",
      "         [[ 5.0363e-02]],\n",
      "\n",
      "         [[-7.3282e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2831e-02]],\n",
      "\n",
      "         [[-1.3061e-02]],\n",
      "\n",
      "         [[ 1.1690e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.6192e-02]],\n",
      "\n",
      "         [[ 6.6034e-02]],\n",
      "\n",
      "         [[-8.4391e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2520e-02]],\n",
      "\n",
      "         [[-1.1344e-01]],\n",
      "\n",
      "         [[ 1.8090e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9720e-04]],\n",
      "\n",
      "         [[ 9.8898e-03]],\n",
      "\n",
      "         [[ 6.4677e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9629e-03]],\n",
      "\n",
      "         [[ 4.4057e-02]],\n",
      "\n",
      "         [[ 9.9189e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0304e-04]],\n",
      "\n",
      "         [[ 1.0274e-02]],\n",
      "\n",
      "         [[-1.8767e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8253e-02]],\n",
      "\n",
      "         [[-6.0436e-02]],\n",
      "\n",
      "         [[ 2.2992e-02]]]], device='cuda:0')), ('backbone.model.layer1.1.bn3.weight', tensor([-1.3718e+00, -1.5629e-01, -1.7885e+00,  4.3125e+00, -5.2521e+00,\n",
      "         1.6550e+00,  2.9763e+00,  1.9564e+00,  4.9294e-02, -1.1191e+00,\n",
      "         1.2271e-02,  1.1663e+00,  3.4912e+00, -1.1569e+00, -6.4164e-02,\n",
      "        -2.6590e+00,  1.2818e+00,  2.9815e+00, -8.9366e-01,  1.8358e+00,\n",
      "        -1.6243e+00, -7.3487e-01, -1.6049e+00,  1.0759e+00,  1.5582e-01,\n",
      "         2.4674e+00, -2.9049e+00,  5.0579e-01, -4.4905e-01, -5.8917e-01,\n",
      "        -6.7124e-02,  1.8120e+00, -5.5699e-01, -7.9589e-02, -1.1056e+00,\n",
      "        -2.2237e+00,  4.5209e+00, -2.1549e-02,  3.2776e+00,  1.1459e+00,\n",
      "        -1.4793e-02,  5.9748e-02, -7.6958e-01, -2.7664e-03, -4.2576e+00,\n",
      "        -1.6319e+00,  3.9485e+00, -2.0116e+00, -2.8267e+00,  7.7287e-02,\n",
      "        -1.9909e-03, -1.6031e-01, -2.4393e+00,  1.3966e-01,  1.3615e+00,\n",
      "         1.9549e+00, -1.2502e+00, -1.7600e-01,  4.1406e-02, -2.0533e+00,\n",
      "         7.0072e-01,  8.1767e-01, -7.2633e-02,  4.6389e+00, -1.3829e+00,\n",
      "         4.4929e+00, -7.2733e-01, -4.8120e-01, -1.6960e+00,  1.1766e+00,\n",
      "        -9.5817e-01,  6.6568e-02, -5.3395e-01,  9.1556e-01,  2.2194e-01,\n",
      "         1.0097e+00, -4.1979e+00,  1.1756e-01, -2.9639e-01,  1.9378e+00,\n",
      "        -3.6505e+00,  2.8678e+00, -1.9568e-01,  3.1495e+00, -4.8759e-01,\n",
      "         2.1878e+00, -4.0283e+00,  3.7039e+00, -1.6949e+00, -1.4119e+00,\n",
      "         5.0786e-01,  2.4893e+00, -1.4133e+00, -1.3703e-02,  2.3330e+00,\n",
      "         4.1335e-02, -1.8186e-01, -2.6210e-01, -1.3471e+00,  1.4883e+00,\n",
      "         3.0830e+00,  3.9693e-01,  5.5900e+00,  2.7651e-01, -8.7502e-02,\n",
      "        -2.3098e-02,  2.6546e+00, -2.1945e-02, -1.4464e-01, -3.3030e+00,\n",
      "         1.4041e-01,  9.9063e-03, -3.4930e+00, -2.1568e-01, -2.3417e+00,\n",
      "        -1.8471e-01, -3.0683e+00, -9.7043e-01,  1.9116e+00,  1.7202e+00,\n",
      "        -2.3323e+00, -2.2638e+00, -2.7788e+00,  1.8448e+00,  3.2498e-02,\n",
      "        -3.4572e+00,  4.4342e+00,  9.1994e-01, -3.1940e+00,  1.0413e-01,\n",
      "         3.8191e-01, -5.9380e-01, -4.9700e-01,  2.4838e-02, -5.9358e-01,\n",
      "        -8.6057e-03, -3.1196e+00,  1.2905e-01,  1.3768e+00,  2.4299e-02,\n",
      "        -1.9124e+00, -1.3833e+00, -1.3880e+00, -1.8592e+00,  1.7895e+00,\n",
      "         8.4022e+00, -1.6266e+00, -1.5762e+00, -6.1993e-01,  4.0809e+00,\n",
      "         3.8344e-01,  1.0418e-02, -7.0420e-01, -3.8726e+00,  2.0000e-01,\n",
      "         9.8096e-01, -2.3489e+00, -2.3683e+00,  4.2413e+00,  3.3379e+00,\n",
      "         4.1782e-02,  1.6009e+00,  3.5091e-01, -2.2444e+00, -1.4606e+00,\n",
      "        -1.8882e+00,  6.1494e-01,  9.9934e-01, -1.1893e+00,  1.8872e-01,\n",
      "        -5.4430e+00, -4.9340e-01,  8.3177e+00, -1.5204e+00, -2.6614e+00,\n",
      "         2.0412e+00,  5.3135e-01, -6.8495e-02,  2.1500e+00, -1.4842e+00,\n",
      "        -2.4895e-01, -2.6075e+00, -1.5452e+00, -2.4416e+00,  2.6322e+00,\n",
      "         1.6100e-01, -4.7241e-01,  3.4952e+00, -5.8432e+00,  2.6590e+00,\n",
      "         2.3544e+00, -1.5496e+00,  7.1720e-03, -5.0443e-01, -8.8980e-02,\n",
      "        -8.2613e-02,  2.6623e+00, -1.4793e+00, -1.7124e+00,  5.4300e-01,\n",
      "        -2.8193e+00, -1.5716e+00, -2.1806e+00, -1.0025e+00,  4.0776e-02,\n",
      "         1.8247e+00,  5.5751e+00,  5.8324e-01,  1.6477e+00, -6.7194e-02,\n",
      "         2.2132e+00,  8.7835e-01, -3.4949e+00,  1.5287e+00,  1.0953e+00,\n",
      "         2.2767e+00,  3.2006e-02,  1.5873e+00,  2.8752e-02, -1.9822e-02,\n",
      "         2.4777e+00, -4.0568e-01, -3.1995e+00, -8.3949e-01,  1.3805e+00,\n",
      "         3.2108e+00,  8.8609e-01,  5.0376e-02,  1.7131e+00, -6.9646e-01,\n",
      "         1.2979e+00,  2.2090e+00, -1.7786e+00,  2.5952e+00, -3.7048e+00,\n",
      "        -9.9263e-01,  9.4720e-02,  3.3081e-01, -2.6328e+00,  7.3138e-03,\n",
      "        -1.3884e+00,  4.4083e+00, -3.0255e-01, -6.2446e-01, -4.0893e-01,\n",
      "         1.6342e+00,  4.7158e-01,  4.5415e-01,  4.2409e+00, -2.1465e+00,\n",
      "         1.0448e-01,  1.7200e+00, -9.0491e-02,  1.2827e+00, -3.3899e+00,\n",
      "         2.3752e+00], device='cuda:0')), ('backbone.model.layer1.1.bn3.bias', tensor([-1.0659e+00,  7.3578e-02, -1.3410e+00, -9.7044e+00, -5.8285e-01,\n",
      "        -1.3477e-01, -1.4976e+00, -1.6769e-01, -1.0751e-03,  1.1756e+00,\n",
      "        -8.6749e-03,  4.1557e-01, -1.4532e+00, -1.4950e-01, -1.4227e-01,\n",
      "        -8.1816e-01,  5.2645e-01, -1.3673e+01,  7.8612e-01,  1.2400e-01,\n",
      "         5.5543e-01, -1.4506e-01, -1.8301e+00, -5.1386e-01, -4.6945e-02,\n",
      "        -5.3657e-01, -7.0064e-01, -2.7944e-01,  4.6476e-02,  3.7571e-02,\n",
      "        -9.6441e-02, -8.8108e+00, -2.4006e-01,  3.4489e-02, -9.8919e-01,\n",
      "        -1.6638e+00, -1.6786e+00,  7.6370e-03, -8.6502e-01, -4.6501e-01,\n",
      "         1.8142e-02, -4.6586e-02, -1.0322e+00,  1.0136e-02,  1.0148e+00,\n",
      "        -1.9418e+00,  5.2685e-01, -2.0508e+00,  9.0191e-01, -1.1437e-02,\n",
      "        -1.3081e-02,  1.2103e-01,  4.9080e-03,  4.2775e-02, -6.0589e-01,\n",
      "        -1.9776e+00,  1.1937e+00, -1.0981e-01, -2.7252e-02,  1.4278e+00,\n",
      "        -6.3525e-01, -8.4281e-02, -2.1708e-01,  9.8987e-01, -1.3458e+00,\n",
      "         9.9841e-01,  6.2638e-01, -2.5989e-01, -2.0737e+00, -5.7969e-01,\n",
      "        -2.3349e-02,  1.4997e-01,  7.6116e-02, -3.2744e-01, -1.0577e-01,\n",
      "        -1.8849e-01,  1.2065e+00, -9.3550e-01, -6.3089e-03, -1.7561e+00,\n",
      "        -8.9921e-01,  4.4346e-01,  1.0597e-01, -6.5665e-01,  3.8206e-01,\n",
      "        -6.5796e+00, -1.2348e+00, -1.9264e+00, -4.6335e+00, -1.1874e+00,\n",
      "        -6.8364e-01,  1.5367e+00, -8.5879e-03,  4.2273e-02, -1.0617e+00,\n",
      "        -2.1896e-02, -4.6566e-02, -1.1906e-01,  6.6566e-01, -1.5815e+00,\n",
      "        -6.1226e+00, -3.7708e-01,  1.4240e+00, -2.5136e-01,  5.4008e-01,\n",
      "        -8.0141e-03,  2.5559e+00, -2.7268e-02, -1.4107e+01,  8.2130e-01,\n",
      "        -2.1169e-01, -1.9044e-02, -4.5486e-01, -3.0095e-02, -1.3104e+00,\n",
      "        -3.0996e-01, -5.7243e+00, -1.4345e+00,  2.9600e-01, -2.4080e-02,\n",
      "        -8.3646e-01, -1.2732e+00, -7.8319e-01,  1.2346e+00,  3.1633e-02,\n",
      "         2.2527e-01, -1.5340e+00, -2.3234e+00,  3.3604e+00, -5.3010e-02,\n",
      "        -1.1525e+01, -1.1771e-01, -4.9443e-01, -6.9532e-03, -5.8437e-01,\n",
      "         8.8566e-04, -3.2854e+00,  1.9976e-01, -6.3236e-01, -1.9681e-02,\n",
      "         2.1037e+00, -2.1882e+00, -8.6270e-01, -1.2867e+00, -1.1349e+00,\n",
      "         1.1900e-01, -1.0546e+00, -1.5660e+00, -9.4311e-02,  1.1449e-01,\n",
      "        -2.8203e-01, -7.8110e-03, -1.5658e+00, -2.1855e+00, -4.5746e-01,\n",
      "        -1.6787e+00, -8.0073e-01, -2.7147e+00, -1.9688e+00, -7.5646e-01,\n",
      "         1.1561e-02, -2.2359e+00, -1.5436e-01, -2.6642e+00, -2.4789e-01,\n",
      "        -2.2064e+00, -1.6537e-01, -3.9095e-01,  6.1433e-01,  2.1334e-01,\n",
      "         1.0826e-01,  1.2696e+00,  2.1613e+00,  1.5447e-01, -4.5540e-01,\n",
      "        -5.8533e-01, -4.3917e-01,  5.3421e-02, -1.5927e+00, -4.9882e-01,\n",
      "        -4.5755e-01, -4.9006e-01, -1.3597e+00,  6.1186e-01,  1.2327e-01,\n",
      "        -1.0914e-01,  1.7239e-01, -1.1250e+00,  1.2620e-01,  1.1167e-01,\n",
      "         3.8893e-01,  4.8570e-01,  3.0877e-02, -6.5013e-01, -3.0564e-02,\n",
      "        -9.9272e-02, -1.7486e+00, -1.6610e+00,  1.4357e+00,  4.6435e-02,\n",
      "         2.8437e-01,  4.0119e-01, -1.2864e+00, -3.6789e-01, -5.3446e-02,\n",
      "        -2.5409e-01, -3.7203e+00, -1.2381e-01, -3.4731e-01,  7.7287e-02,\n",
      "        -3.7499e+00, -8.1784e-01, -3.5199e-01, -7.3583e-01,  6.6564e-01,\n",
      "        -1.5282e-01, -2.8763e-02,  8.7599e-01,  2.1085e-02, -1.4366e-02,\n",
      "        -1.8364e+00, -2.7832e-01, -1.6921e-01, -3.0430e-01, -5.0632e-01,\n",
      "        -1.7431e+00, -7.4542e-01,  2.4223e-02, -7.5281e-01,  2.1087e-01,\n",
      "         4.1128e-01, -3.9105e-01, -7.5432e-02, -9.3951e-01,  1.8348e+00,\n",
      "        -1.4166e+00,  3.3107e-02,  6.8407e-01, -5.8977e+00,  7.3073e-02,\n",
      "        -1.2291e+00,  2.3532e+00, -9.2946e-02, -2.6228e-01, -6.4299e-02,\n",
      "        -1.5889e-01, -4.4539e-01,  1.5774e-01,  1.1385e+00, -9.5846e-01,\n",
      "        -6.2207e-03, -1.3339e+00,  3.3296e-02, -5.5947e-01, -3.3512e+00,\n",
      "         1.1137e+00], device='cuda:0')), ('backbone.model.layer1.2.conv1.weight', tensor([[[[-0.0756]],\n",
      "\n",
      "         [[-0.0043]],\n",
      "\n",
      "         [[ 0.0673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         [[ 0.0223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0151]],\n",
      "\n",
      "         [[ 0.1022]],\n",
      "\n",
      "         [[-0.0719]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0076]]],\n",
      "\n",
      "\n",
      "        [[[-0.0426]],\n",
      "\n",
      "         [[ 0.0543]],\n",
      "\n",
      "         [[-0.0268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0575]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[ 0.0122]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[-0.0158]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[-0.1441]],\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0923]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[ 0.0036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0393]],\n",
      "\n",
      "         [[ 0.0333]],\n",
      "\n",
      "         [[ 0.0183]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[ 0.0069]],\n",
      "\n",
      "         [[-0.0509]]]], device='cuda:0')), ('backbone.model.layer1.2.bn1.weight', tensor([ 1.0689,  1.0164,  1.2347,  1.2707,  1.7736,  2.1487,  1.3309,  1.6811,\n",
      "         0.5816,  3.4309,  4.0312,  0.5981,  1.3814,  0.6964,  1.2170,  1.0419,\n",
      "         1.6521,  1.8728,  1.7762,  7.0059,  2.0077,  2.7583,  0.9091,  1.4622,\n",
      "         1.9236,  1.2980,  1.1425,  1.7365,  1.4654,  0.6978,  1.9783,  1.1531,\n",
      "         1.7426,  2.0882,  1.9292,  4.5488,  2.2597,  1.1393,  2.5044,  3.0667,\n",
      "         7.8127,  2.0439,  0.6699,  1.4794,  1.3223,  3.7102,  3.0846, 16.4887,\n",
      "         1.2642,  1.4663,  0.6096,  1.2024,  1.3916,  1.8093,  1.0377,  1.0729,\n",
      "         1.4399,  0.8784,  5.2488,  1.6971,  1.3041,  1.1778,  1.2912,  2.0394],\n",
      "       device='cuda:0')), ('backbone.model.layer1.2.bn1.bias', tensor([-1.7389e-01,  6.7523e-01,  2.4712e-02, -1.1986e+00,  7.0450e-01,\n",
      "        -2.2952e+00, -2.2399e+00, -5.4686e-01,  1.0028e+00, -2.6672e+00,\n",
      "        -6.9744e+00, -1.7512e-01, -1.0512e+00,  4.8479e-02,  4.3647e-03,\n",
      "        -1.1449e+00,  8.2519e-01, -1.2187e+00, -1.1053e+00,  2.6411e+00,\n",
      "        -1.2023e+00,  1.5203e+00,  1.6279e+00, -1.8545e+00, -1.1055e+00,\n",
      "         9.0297e-01,  9.3653e-01,  8.6528e-01, -6.9341e-01,  1.0762e-01,\n",
      "         9.1858e-01,  9.9787e-01, -9.5692e-01,  4.2607e+00, -1.5246e+00,\n",
      "        -3.5437e+00,  1.2051e-01, -5.8902e-01,  1.8777e+00, -3.9694e+00,\n",
      "        -3.3624e+00, -1.1731e+00, -3.6937e-01, -4.0179e-01, -1.2458e+00,\n",
      "         7.3625e-01, -3.7109e+00,  1.6324e+00,  3.9806e-02, -4.4950e-01,\n",
      "         9.8170e-01, -4.9737e-01, -4.3586e-01,  1.7394e+00, -7.7517e-01,\n",
      "        -7.7874e-01,  9.0792e-01, -8.2563e-01,  3.6669e+00, -1.2069e+00,\n",
      "         1.4605e+00, -3.3041e-01, -1.2780e+00, -2.1861e+00], device='cuda:0')), ('backbone.model.layer1.2.conv2.weight', tensor([[[[-4.8122e-02, -1.0132e-01, -9.3823e-02],\n",
      "          [-9.1978e-02, -1.8462e-01, -1.4014e-01],\n",
      "          [-4.7879e-02, -1.1343e-01, -8.0527e-02]],\n",
      "\n",
      "         [[ 9.1166e-03, -8.3523e-03,  5.3376e-02],\n",
      "          [-1.5246e-02, -6.7996e-02, -2.6669e-02],\n",
      "          [ 8.4100e-03, -4.6519e-02,  1.8728e-02]],\n",
      "\n",
      "         [[ 4.5904e-02,  5.9449e-02,  5.8353e-02],\n",
      "          [ 1.5882e-02, -6.7311e-02,  1.4752e-02],\n",
      "          [ 6.1281e-02, -2.9421e-02,  1.8829e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6936e-02, -1.1283e-01, -7.6695e-02],\n",
      "          [-1.1467e-01, -1.6072e-01, -1.1420e-01],\n",
      "          [-1.0202e-01, -1.2626e-01, -1.2441e-01]],\n",
      "\n",
      "         [[-7.3167e-02, -6.5631e-02, -3.4983e-02],\n",
      "          [-3.5105e-02, -5.4534e-02, -5.7749e-02],\n",
      "          [ 6.0104e-03, -4.8863e-02,  5.7119e-04]],\n",
      "\n",
      "         [[ 1.3251e-01,  5.9228e-02,  2.3473e-02],\n",
      "          [ 6.0324e-02,  2.8280e-02,  3.0904e-02],\n",
      "          [ 1.1269e-01,  7.1003e-02,  4.5424e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9975e-03,  9.4904e-03, -2.1614e-02],\n",
      "          [ 1.2504e-02,  3.4806e-02,  5.6039e-02],\n",
      "          [ 7.6676e-04, -1.1987e-01, -2.3389e-03]],\n",
      "\n",
      "         [[ 2.4556e-02,  4.2508e-02,  1.0048e-02],\n",
      "          [ 2.7147e-02,  6.3949e-02,  5.1510e-02],\n",
      "          [ 1.8143e-02, -6.1029e-02, -1.2093e-02]],\n",
      "\n",
      "         [[ 4.4525e-03,  1.2200e-01,  6.7180e-02],\n",
      "          [-5.4831e-02, -9.6267e-02,  2.6864e-02],\n",
      "          [-5.6007e-02, -1.5597e-02, -1.7325e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4093e-02,  5.7092e-02,  1.5262e-02],\n",
      "          [ 2.5740e-04,  1.8209e-02,  3.1720e-02],\n",
      "          [-2.0319e-02, -1.1244e-01, -1.5712e-02]],\n",
      "\n",
      "         [[ 9.5893e-02,  9.0334e-02,  1.0298e-01],\n",
      "          [ 8.6738e-02, -2.7019e-02,  6.4777e-02],\n",
      "          [ 6.1227e-02, -1.3069e-01, -7.7858e-02]],\n",
      "\n",
      "         [[ 1.5445e-02,  5.7287e-02, -9.6420e-03],\n",
      "          [ 1.1468e-01, -1.1010e-02,  1.0764e-01],\n",
      "          [-8.7792e-02, -1.3682e-02, -9.7569e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8531e-03,  2.2393e-03, -1.7149e-02],\n",
      "          [-3.2006e-02,  2.2191e-02, -2.8764e-02],\n",
      "          [-6.9467e-02, -4.9575e-02, -5.5290e-02]],\n",
      "\n",
      "         [[ 6.4690e-03,  7.9290e-03, -1.0111e-02],\n",
      "          [-6.8302e-03,  1.8760e-02, -8.5660e-03],\n",
      "          [-1.6849e-02, -1.7428e-02, -2.4494e-02]],\n",
      "\n",
      "         [[-3.3992e-02, -4.2348e-02, -1.5997e-02],\n",
      "          [-5.9134e-02, -1.6294e-02, -2.6574e-02],\n",
      "          [-3.8138e-02, -3.8333e-02, -2.1457e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7638e-02, -2.2734e-03, -2.8200e-02],\n",
      "          [-7.0825e-04,  4.8091e-02, -1.3987e-03],\n",
      "          [-6.0842e-02, -8.0619e-03, -2.2645e-02]],\n",
      "\n",
      "         [[-2.1905e-02, -7.6262e-02, -2.2758e-02],\n",
      "          [-3.8179e-02, -1.0467e-02, -1.1177e-02],\n",
      "          [-3.2759e-02, -3.0336e-02,  6.8328e-03]],\n",
      "\n",
      "         [[ 1.3684e-02, -1.3186e-02, -6.4235e-02],\n",
      "          [-1.2262e-02,  7.8548e-02,  3.3811e-02],\n",
      "          [-6.6433e-02, -2.0960e-02, -6.6813e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.5399e-02,  7.3217e-02,  5.8530e-02],\n",
      "          [ 7.4246e-02,  3.9589e-02,  8.1363e-02],\n",
      "          [ 4.8728e-02,  7.0342e-02,  7.2811e-02]],\n",
      "\n",
      "         [[-5.1006e-02, -3.3880e-02, -2.5717e-02],\n",
      "          [ 1.9710e-03,  2.2495e-02, -7.4535e-03],\n",
      "          [-3.6500e-02, -5.1222e-02, -4.2913e-02]],\n",
      "\n",
      "         [[-1.3571e-01, -8.4004e-02, -9.5602e-02],\n",
      "          [-7.8577e-02,  5.8174e-02, -9.3491e-02],\n",
      "          [-1.0850e-01, -5.9570e-02, -1.1923e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1136e-02, -8.6830e-02, -7.9670e-02],\n",
      "          [-9.7199e-02,  5.6532e-02, -8.3969e-02],\n",
      "          [-6.6071e-02, -8.5671e-02, -3.6140e-02]],\n",
      "\n",
      "         [[ 4.3222e-02,  4.8644e-02,  3.6801e-02],\n",
      "          [ 7.9945e-03,  4.2287e-02,  4.8047e-02],\n",
      "          [ 3.4945e-02,  2.7280e-02,  5.9850e-02]],\n",
      "\n",
      "         [[-1.5612e-02,  2.1743e-02,  2.3458e-02],\n",
      "          [ 2.0452e-02, -4.2482e-02,  3.1494e-02],\n",
      "          [ 1.0028e-02,  5.1147e-02,  9.6791e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4977e-03,  1.1180e-02, -3.7494e-05],\n",
      "          [-7.9217e-03, -1.0933e-01, -2.4074e-03],\n",
      "          [-1.0700e-02, -1.8005e-02,  1.9496e-02]],\n",
      "\n",
      "         [[-3.2756e-02,  1.7784e-03, -5.0789e-02],\n",
      "          [-4.7867e-02, -4.0979e-02, -7.7592e-02],\n",
      "          [-4.1489e-02, -3.7460e-02, -4.0829e-02]],\n",
      "\n",
      "         [[-2.5788e-02, -1.0696e-02, -4.4420e-02],\n",
      "          [-6.8317e-02, -1.1076e-01, -3.4488e-02],\n",
      "          [-3.7103e-02, -3.4811e-02,  1.6445e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2741e-03,  1.0230e-03,  1.0516e-02],\n",
      "          [ 8.8004e-03, -1.1078e-02, -1.6755e-02],\n",
      "          [ 1.8512e-02, -1.3732e-02,  1.5743e-02]],\n",
      "\n",
      "         [[ 1.6678e-02,  3.0599e-02,  4.8885e-02],\n",
      "          [ 2.2277e-02,  3.2640e-02,  1.2811e-02],\n",
      "          [-2.0627e-02,  1.1388e-02,  4.4097e-02]],\n",
      "\n",
      "         [[ 6.5682e-02,  1.9415e-03, -6.1987e-05],\n",
      "          [ 1.5179e-03,  4.2742e-03, -4.0234e-03],\n",
      "          [ 3.1951e-02,  7.5162e-03,  2.3232e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.1540e-02, -3.4272e-03, -2.7785e-02],\n",
      "          [ 4.5571e-03,  7.4736e-02,  1.8253e-02],\n",
      "          [-2.2846e-02,  3.7936e-02, -2.5545e-02]],\n",
      "\n",
      "         [[ 1.3196e-02,  3.5864e-02,  3.5892e-02],\n",
      "          [ 9.6321e-03,  6.0397e-02,  2.4265e-03],\n",
      "          [-1.9790e-02,  2.6241e-02, -7.3928e-03]],\n",
      "\n",
      "         [[ 3.0531e-02, -3.7883e-02,  4.2675e-02],\n",
      "          [-5.8772e-02, -2.8188e-01, -2.8662e-02],\n",
      "          [ 9.2655e-03, -5.5368e-02,  3.4514e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.9852e-03,  1.5687e-02, -2.4653e-02],\n",
      "          [ 1.0909e-02,  1.4453e-01,  1.4804e-02],\n",
      "          [-1.5972e-02,  1.4813e-02, -2.4333e-02]],\n",
      "\n",
      "         [[-5.8693e-02, -2.5502e-02, -5.2877e-02],\n",
      "          [-3.8955e-02,  5.5559e-02, -3.8759e-02],\n",
      "          [-7.0014e-02, -5.0153e-02, -4.3276e-02]],\n",
      "\n",
      "         [[-2.9908e-02, -8.2116e-02, -2.0663e-02],\n",
      "          [-6.6902e-02,  7.5750e-05, -3.8520e-02],\n",
      "          [ 4.4474e-02, -2.6194e-02, -1.1506e-02]]]], device='cuda:0')), ('backbone.model.layer1.2.bn2.weight', tensor([0.9482, 2.3034, 1.3806, 4.0139, 1.0733, 1.0792, 1.7602, 0.5322, 4.8022,\n",
      "        1.0656, 0.5182, 3.9784, 1.0638, 0.7418, 2.2884, 3.9452, 1.1351, 1.2449,\n",
      "        0.9449, 1.5260, 2.2845, 1.4770, 1.0316, 1.1228, 0.5794, 2.2513, 1.3013,\n",
      "        2.1585, 0.5050, 2.0214, 1.5028, 3.3650, 2.7578, 1.5451, 1.9328, 2.5817,\n",
      "        1.9818, 4.2110, 1.0484, 0.5993, 1.5565, 1.1121, 1.2220, 4.4673, 0.9500,\n",
      "        1.7138, 2.2572, 1.1380, 2.9053, 2.8678, 1.0932, 1.1622, 2.0669, 2.9580,\n",
      "        2.9383, 2.8746, 1.6019, 1.0802, 2.3955, 1.4384, 0.9525, 0.9469, 0.3546,\n",
      "        3.0954], device='cuda:0')), ('backbone.model.layer1.2.bn2.bias', tensor([-1.9545, -0.3402, -2.1961,  3.0568,  1.6428, -0.1372, -1.3491,  0.6801,\n",
      "        -3.8032,  0.0452, -1.0631, -0.6980, -1.9535,  0.5242, -2.5956,  3.1456,\n",
      "        -1.6027, -2.7511, -2.0206, -0.1499,  0.7168, -0.6906,  0.4780, -1.6314,\n",
      "         0.6835, -1.1875, -2.3489,  0.1526,  0.8689, -2.8294,  1.1358, -2.9692,\n",
      "        -1.9256,  1.8794,  0.9236, -1.4042, -2.2856,  3.4050,  0.6711,  0.4547,\n",
      "         0.3008, -1.8221, -2.0154,  1.3544, -1.9320, -0.5660, -2.3981,  0.9868,\n",
      "        -2.0111,  0.9541,  0.4100, -2.0227, -0.6938,  0.7460, -2.0029,  0.9095,\n",
      "         0.3788, -1.4257,  0.1743,  0.1566, -1.8016,  0.8358,  0.9502, -1.8690],\n",
      "       device='cuda:0')), ('backbone.model.layer1.2.conv3.weight', tensor([[[[-0.0203]],\n",
      "\n",
      "         [[-0.0447]],\n",
      "\n",
      "         [[ 0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0398]],\n",
      "\n",
      "         [[-0.0496]],\n",
      "\n",
      "         [[ 0.0172]]],\n",
      "\n",
      "\n",
      "        [[[-0.0489]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         [[ 0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0974]],\n",
      "\n",
      "         [[-0.0686]],\n",
      "\n",
      "         [[-0.1053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0490]],\n",
      "\n",
      "         [[-0.0428]],\n",
      "\n",
      "         [[-0.0202]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0442]],\n",
      "\n",
      "         [[-0.0656]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0042]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[-0.0304]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0012]],\n",
      "\n",
      "         [[-0.0716]],\n",
      "\n",
      "         [[ 0.0547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0489]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[-0.0920]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0120]],\n",
      "\n",
      "         [[-0.3650]],\n",
      "\n",
      "         [[-0.0855]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119]],\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[-0.2741]]]], device='cuda:0')), ('backbone.model.layer1.2.bn3.weight', tensor([-1.6893e-01,  2.3438e-03, -2.2475e-01,  2.2689e+00,  1.1898e-02,\n",
      "         2.4365e-02, -6.7704e-03,  4.9100e-02, -1.0372e+00, -1.0019e+00,\n",
      "         1.9733e+00,  3.5919e+00, -1.4251e-01, -7.0980e-01,  8.2549e-01,\n",
      "         1.4259e-01,  1.0080e+00,  2.3459e+00, -1.6457e+00, -3.4412e-03,\n",
      "         7.9055e-01, -1.7139e-01, -1.4101e-01,  4.3858e-02, -8.3955e-01,\n",
      "         5.7871e-01, -1.9841e-01,  3.2696e-01, -6.0181e-01,  3.3059e+00,\n",
      "        -4.7063e-01, -2.5671e+00, -2.0308e-01, -8.6411e-01,  8.7793e-01,\n",
      "        -1.4161e-01, -7.2770e-01,  3.5380e-01, -3.6666e-01, -5.8752e-01,\n",
      "         1.9508e+00,  8.0162e-01,  3.1814e-03, -1.8675e+00, -4.6898e-01,\n",
      "        -1.4491e-02,  3.4023e+00, -6.2913e-02,  6.8113e-03,  1.7744e+00,\n",
      "        -1.3931e+00, -9.7934e-01, -6.3612e-02,  3.2709e+00,  1.7257e-01,\n",
      "         4.4070e-02, -3.8677e+00, -1.8664e-03,  9.2622e-01,  1.1150e+00,\n",
      "         2.0983e-02, -5.1232e-01, -4.6829e-01,  2.7968e-02, -6.2150e-02,\n",
      "         8.6303e-01, -5.7074e-01,  2.5184e+00, -8.3564e-02, -6.5525e-01,\n",
      "        -2.8706e-01,  3.3167e+00,  1.2546e+00, -4.3212e+00,  9.3258e-01,\n",
      "        -7.5164e-02, -2.0427e-02,  2.6221e+00,  7.8182e-01, -5.8719e-02,\n",
      "         3.6236e-03, -2.4193e+00, -1.2827e-02, -5.8537e-02,  9.2796e-02,\n",
      "         2.7725e+00, -5.0689e-03,  3.4129e-02, -4.0158e+00, -4.5715e-02,\n",
      "        -2.0342e-02,  2.1061e-02,  1.3946e-02, -2.1418e-01,  3.2650e-03,\n",
      "        -2.9260e+00, -1.0569e+00, -2.8533e+00,  1.0491e+00, -6.1190e-01,\n",
      "        -4.4249e+00,  3.1320e+00, -6.0674e+00, -3.6061e-02, -3.2188e-01,\n",
      "         3.8721e+00, -3.4129e-03,  1.2144e+00, -2.9069e+00,  3.5473e-02,\n",
      "        -2.3017e+00, -5.8061e-01, -1.4373e-02,  2.9116e+00, -2.6411e-01,\n",
      "         4.5295e+00,  2.7895e+00, -2.4582e-01, -1.0869e-02, -2.1069e-02,\n",
      "        -2.8531e-01, -2.5919e-01,  1.5782e-01,  6.5228e-01,  8.9436e-01,\n",
      "        -5.7008e-03,  2.9479e-01, -1.1165e+00, -3.4198e-02,  2.3117e+00,\n",
      "        -3.7621e+00,  1.9659e-01,  5.8532e-03,  3.7534e+00, -5.5466e-02,\n",
      "        -1.3612e-03,  1.1993e+00, -1.0980e+00, -1.0720e+00, -4.0539e-01,\n",
      "        -1.6550e-01,  4.9776e-01,  1.0330e+00, -1.0581e-01,  6.3355e-01,\n",
      "        -1.5872e+00,  2.3834e-04, -3.4993e-01,  5.1834e-02, -1.4502e-01,\n",
      "         1.3401e-01, -3.1192e+00, -7.8008e-01, -6.9549e+00,  5.9951e-01,\n",
      "        -1.2491e+00, -8.6250e-03, -3.0882e-01, -1.6033e-01, -2.2360e-01,\n",
      "         2.8125e-01,  1.0361e+00,  6.1035e-01, -3.1887e-01, -5.3781e-02,\n",
      "        -1.7666e+00,  2.8282e-01,  8.1783e-02, -8.2726e-01,  5.2269e-01,\n",
      "        -1.2798e-01,  2.9564e+00, -1.2986e+01, -4.3144e+00, -9.2361e-01,\n",
      "         1.6953e-01,  8.3817e-02, -5.6974e-01,  1.1000e-01,  1.9333e-01,\n",
      "         5.3703e+00, -1.0293e-01, -1.6509e-01, -7.8845e-01,  1.5218e-02,\n",
      "         2.5536e+00, -1.3668e-02, -5.8109e-03, -1.5719e-02,  1.4386e-02,\n",
      "         1.1214e-02,  2.4703e+00, -1.1674e+00, -1.5825e+00,  4.1565e-01,\n",
      "        -5.6528e-01, -1.9463e-01,  4.1332e-01, -2.6326e-01,  2.1294e+00,\n",
      "         4.8563e-04,  8.8410e-03,  5.4875e-01,  7.2804e-03, -2.1302e+00,\n",
      "         6.8441e-02,  4.8835e+00,  5.9744e-02,  4.2403e-02,  6.8642e-01,\n",
      "         1.4166e+00,  2.5638e+00,  1.1629e-02, -7.0913e-02, -4.2492e+00,\n",
      "         1.9636e-02, -9.5844e-01, -2.9615e-01,  4.6357e-01,  2.0015e+00,\n",
      "        -1.5986e-02,  5.9663e-02,  4.9172e-02, -4.8119e-03,  2.9460e-02,\n",
      "         5.6085e-01,  2.9422e+00, -5.8603e-01, -3.4652e-01, -2.1250e+00,\n",
      "        -1.2382e+00,  3.1112e-02, -1.2960e-02,  3.0692e-02,  5.9907e-02,\n",
      "         3.5066e-01, -5.7933e-01, -8.1707e-02,  2.2408e+00,  6.6258e-01,\n",
      "         3.6540e+00, -1.0201e-02, -9.9185e-01,  3.1827e+00,  8.2112e-01,\n",
      "         3.7121e-01,  3.4296e-01, -1.9822e+00,  4.2961e-01, -2.2777e+00,\n",
      "         7.1792e-01,  8.1534e-01,  7.5583e-01, -2.2403e+00,  4.9884e+00,\n",
      "        -1.4112e-02], device='cuda:0')), ('backbone.model.layer1.2.bn3.bias', tensor([-6.2182e-01, -5.1251e-03, -4.4183e-01, -4.9594e+00, -5.4110e-02,\n",
      "        -2.4261e-02, -6.7758e-01, -2.6178e-02, -7.4748e-02, -4.7346e-01,\n",
      "        -2.0024e+00,  8.7358e-01, -1.1521e-01, -5.0739e-01, -8.9005e-01,\n",
      "        -1.0869e-01, -1.0369e+00, -1.3014e+00, -4.9282e-01, -1.9100e-02,\n",
      "        -1.6705e-01, -4.7091e-02, -5.2662e-01, -1.0772e-01, -9.9916e-01,\n",
      "        -4.2235e-02, -2.0368e-01, -3.7831e-01, -6.1449e-01,  2.0740e-01,\n",
      "        -5.3096e-01,  6.5767e-01, -5.2770e-01,  6.8899e-02, -7.2423e-02,\n",
      "        -3.4882e-01, -1.3869e+00, -4.3175e-01, -9.6060e-01, -5.3126e-01,\n",
      "         1.6858e-01, -9.1852e-01, -1.3996e-01, -1.0024e+00, -3.8854e-01,\n",
      "        -7.2055e-03,  2.1136e+00, -1.4500e-01, -2.9396e-02, -1.6042e+00,\n",
      "        -1.3319e+00, -1.6568e-02, -1.7886e-01,  1.7975e+00, -5.1742e-01,\n",
      "        -7.7759e-02,  2.4884e+00, -1.5381e-02, -7.1118e-01, -4.8072e-01,\n",
      "        -1.5608e-01, -2.2869e+00, -7.2505e-01, -3.2532e-02, -5.4869e-02,\n",
      "        -6.1976e-01, -3.3434e-01,  1.6459e+00,  2.2739e-02, -4.2295e-01,\n",
      "        -3.2644e-02,  1.7397e+00, -2.4107e+00, -2.0637e+00, -1.1542e+00,\n",
      "        -2.1329e-01, -6.2341e-02, -5.0923e+00, -3.2384e+00, -1.2025e-01,\n",
      "        -1.4795e-02, -3.6619e+00, -5.1211e-01, -1.3321e-01, -2.7423e-01,\n",
      "        -2.1299e+00, -8.3796e-02, -1.0718e-01, -3.1672e+00, -1.7050e-01,\n",
      "         1.4431e-02, -1.9623e-02, -5.8041e-02, -2.8380e-01, -1.9576e-02,\n",
      "        -3.8575e+00, -2.0067e+00,  3.8070e-01, -3.6033e-01, -7.0353e-01,\n",
      "        -1.9311e+00, -4.2529e-01, -5.6924e-01,  4.4346e-02, -5.5475e-01,\n",
      "         8.2277e-01, -8.1958e-03, -1.6722e+00,  6.7490e-01, -4.0649e-02,\n",
      "        -2.2026e+00, -7.6566e-01, -6.2866e-04, -3.2966e-01, -2.0327e-01,\n",
      "        -1.8435e+00,  2.1093e+00, -6.5162e-01, -1.2919e-02, -1.2208e-02,\n",
      "        -3.1675e-01, -5.8464e-01, -8.1924e-02,  3.8448e-01, -8.5799e-01,\n",
      "        -3.3208e-03, -4.7991e-01, -5.0128e-01, -2.5077e-01, -3.3566e+00,\n",
      "        -9.9572e-01, -4.5599e-01, -9.0983e-02, -1.7168e+00, -8.8729e-02,\n",
      "        -1.5234e-01, -1.1841e+00, -1.1848e+00,  5.8087e-01,  2.6546e-02,\n",
      "        -1.1534e-01, -2.2011e-01,  6.9596e-01, -1.4995e-01, -4.2586e-01,\n",
      "        -1.3524e+00, -2.0015e-02, -3.7933e-01, -2.0054e-02, -2.0238e-01,\n",
      "         3.7156e-02,  2.9409e+00, -1.4565e+00,  4.6184e-01,  7.3529e-02,\n",
      "        -1.1285e+00, -1.8296e-02, -4.2388e-01, -1.5580e-01, -3.3772e-01,\n",
      "        -4.0414e-01, -1.1775e+00, -6.2718e-01, -5.1288e-01, -1.1222e-01,\n",
      "        -3.2824e-01, -5.2021e-01, -2.6281e-01, -4.4966e-01, -4.3764e-01,\n",
      "        -4.3540e-01, -1.5905e+01, -5.3825e+00,  1.9818e+00, -3.6064e-01,\n",
      "        -4.3781e-01, -4.7273e-01, -2.0383e-01, -1.8503e-01, -2.7530e-01,\n",
      "         4.3541e+00, -3.6899e-01, -2.9243e-01, -2.0246e+00, -3.5107e-02,\n",
      "        -3.2385e+00, -1.3671e+00, -2.0610e-02, -3.7839e-01, -1.0797e-01,\n",
      "        -5.7379e-02, -2.0035e+00, -1.4409e+00,  2.3281e-01,  2.2608e-02,\n",
      "        -1.3312e+00, -8.1087e-02, -7.1981e-01, -4.9288e-01,  9.3075e-01,\n",
      "        -3.4035e-02, -2.6018e-02, -4.0551e-01, -5.2301e-02,  1.3941e+00,\n",
      "        -2.3245e-01,  9.8474e-01, -3.6513e-01, -2.8211e-02, -6.2744e-01,\n",
      "        -3.6198e+00, -2.0910e+00, -6.1581e-02, -2.0419e-01,  1.6552e+00,\n",
      "        -3.3650e-02, -9.4743e-01, -1.9566e-01, -9.2473e-01, -2.3454e+00,\n",
      "        -1.3910e-01, -2.1243e-02, -7.1130e-02, -2.2571e-02, -2.2625e-02,\n",
      "        -4.7552e-01, -2.4222e+00, -9.2975e-01, -4.0212e-01,  1.4490e+00,\n",
      "        -7.9385e-02, -1.9376e-02, -4.9993e-02, -1.5699e-01, -1.5152e-01,\n",
      "        -4.0417e-01, -2.1398e+00, -1.0610e+00, -2.3191e+00, -2.8534e-01,\n",
      "         2.1033e-01, -9.6547e-03, -2.2864e-01, -1.5663e+00, -8.6793e-01,\n",
      "        -2.6290e-01, -7.2525e-02,  1.0833e+00, -3.1355e-01, -7.7009e-02,\n",
      "        -3.6561e-01, -9.5230e-01, -2.8178e+00, -1.2827e+00, -5.5705e-01,\n",
      "         1.9011e-03], device='cuda:0')), ('backbone.model.layer2.0.conv1.weight', tensor([[[[-0.0008]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[ 0.0523]],\n",
      "\n",
      "         [[-0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1473]],\n",
      "\n",
      "         [[-0.0128]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0361]],\n",
      "\n",
      "         [[ 0.0543]],\n",
      "\n",
      "         [[-0.0115]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290]],\n",
      "\n",
      "         [[ 0.0762]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[-0.0359]],\n",
      "\n",
      "         [[ 0.0328]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0290]],\n",
      "\n",
      "         [[-0.0470]],\n",
      "\n",
      "         [[-0.0903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[-0.0680]],\n",
      "\n",
      "         [[ 0.2232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1078]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[-0.1680]],\n",
      "\n",
      "         [[-0.2778]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0465]],\n",
      "\n",
      "         [[-0.0164]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0120]],\n",
      "\n",
      "         [[-0.0822]],\n",
      "\n",
      "         [[-0.0582]]]], device='cuda:0')), ('backbone.model.layer2.0.bn1.weight', tensor([1.7200, 1.7910, 2.8168, 1.7769, 1.3017, 1.5168, 1.7186, 1.2908, 1.4699,\n",
      "        1.5808, 2.3528, 2.4938, 2.4354, 2.1842, 1.6175, 1.6828, 1.5720, 1.7993,\n",
      "        1.2527, 2.4548, 1.8867, 1.6522, 1.2285, 4.2687, 2.4800, 1.9238, 1.7430,\n",
      "        2.6477, 1.9470, 1.6809, 1.9565, 1.8284, 1.8359, 2.6516, 2.7160, 2.5202,\n",
      "        2.3426, 1.7868, 1.4043, 2.3384, 1.6758, 1.8494, 2.4024, 2.9968, 2.2216,\n",
      "        1.2511, 1.7831, 1.8303, 1.7193, 1.9683, 2.5074, 1.4396, 1.8071, 2.2534,\n",
      "        2.4391, 1.5382, 1.5580, 2.3520, 1.7262, 1.7546, 1.3115, 1.5737, 2.0587,\n",
      "        1.7568, 1.3876, 2.3528, 1.7477, 1.3958, 2.0124, 1.5167, 1.6085, 1.5003,\n",
      "        1.8604, 2.1887, 2.2142, 2.1446, 1.9337, 1.9744, 2.3459, 2.8008, 2.2901,\n",
      "        1.9119, 1.8692, 2.0388, 2.3063, 2.1042, 1.9774, 2.2474, 2.3641, 1.8910,\n",
      "        1.5332, 1.8889, 1.8608, 2.2540, 1.6357, 1.9403, 2.0203, 1.7419, 1.5528,\n",
      "        1.6992, 1.6134, 1.6185, 2.7046, 2.9681, 0.0223, 1.7569, 2.2122, 1.9053,\n",
      "        1.9546, 1.7980, 1.6158, 1.6760, 5.6614, 1.3410, 1.3093, 1.9028, 1.7363,\n",
      "        2.4976, 1.7595, 2.1071, 1.1863, 1.7761, 3.5553, 1.6335, 1.5860, 2.0833,\n",
      "        2.1315, 1.7636], device='cuda:0')), ('backbone.model.layer2.0.bn1.bias', tensor([ 2.5203e-01, -1.7694e+00, -1.9549e+00,  4.0734e-01,  1.3745e-01,\n",
      "        -1.1680e+00,  2.1586e-01,  2.3915e-01, -2.8158e-01, -1.8760e+00,\n",
      "        -5.7210e-01,  8.1107e-01, -1.2683e+00, -1.4051e+00, -3.1633e-01,\n",
      "         1.8124e-01, -8.5778e-01, -5.7469e-01,  1.7476e-01, -1.6232e+00,\n",
      "        -2.2939e+00, -1.7305e+00,  2.7361e-01, -3.9341e+00, -1.7490e-01,\n",
      "        -2.3985e+00,  6.8346e-01, -2.3965e-01, -1.5441e+00,  8.3298e-01,\n",
      "        -9.9960e-01, -1.5552e+00, -1.5384e+00, -1.0079e-01, -7.2183e-01,\n",
      "        -1.4711e+00, -3.8321e+00,  3.4702e-01, -1.1203e-01, -5.3681e-01,\n",
      "        -4.9213e-02, -1.2703e+00, -3.3272e+00, -2.7052e+00, -2.9785e+00,\n",
      "         7.7919e-01, -3.5925e-01, -9.4544e-01, -2.7993e-01, -2.1850e+00,\n",
      "        -1.0934e+00,  2.1735e-01, -1.2682e+00, -6.6840e-01, -1.1209e+00,\n",
      "         1.5250e-01,  4.4555e-01,  1.3638e-02, -3.6119e-01, -1.3921e+00,\n",
      "        -1.2031e+00, -3.3534e-01, -8.5482e-01,  1.4585e+00, -1.0342e+00,\n",
      "        -2.4861e+00, -3.3283e-01,  3.2925e-01, -7.1548e-01, -7.5958e-01,\n",
      "        -1.1776e+00,  1.1991e-01, -1.7016e+00, -4.4397e-01, -2.6121e+00,\n",
      "         3.1961e-01,  5.8005e-01, -1.0343e+00, -3.6709e+00, -1.6214e+00,\n",
      "        -1.2802e+00, -1.2229e+00,  2.8823e-01, -1.1603e+00, -1.5697e+00,\n",
      "         1.5112e+00, -7.4576e-01, -1.4323e+00, -3.8277e+00, -1.5910e-03,\n",
      "         4.6383e-01, -2.5488e-01, -2.0494e+00, -1.8231e+00,  1.1505e-01,\n",
      "        -1.3597e+00,  5.7820e-01,  8.6723e-01, -1.9780e-01, -2.2126e+00,\n",
      "        -3.8193e-01, -5.9497e-01, -3.5292e+00, -1.2764e+00, -1.1766e+00,\n",
      "        -1.7774e+00, -2.1859e+00, -1.6802e+00, -6.5175e-01, -2.5347e+00,\n",
      "        -2.1184e-01,  1.3379e-01, -3.3003e+00, -2.1921e-01, -1.9358e-01,\n",
      "        -2.1569e+00, -1.2554e+00,  2.4008e-01,  3.4888e-01, -8.4352e-01,\n",
      "        -9.5211e-01, -1.2642e+00, -1.7587e+00,  1.1958e+00, -6.5021e-01,\n",
      "        -1.0155e-01, -1.1736e+00,  1.7199e-01], device='cuda:0')), ('backbone.model.layer2.0.conv2.weight', tensor([[[[ 3.4793e-02, -1.1682e-01,  7.9975e-03],\n",
      "          [ 3.6265e-02, -8.4149e-02,  3.1866e-05],\n",
      "          [ 3.3237e-02, -7.9489e-02, -2.1221e-02]],\n",
      "\n",
      "         [[-1.6449e-02, -3.1321e-03, -6.0932e-03],\n",
      "          [-3.5074e-02,  6.8292e-02, -2.2003e-02],\n",
      "          [ 1.2712e-04,  2.4425e-02, -1.7457e-02]],\n",
      "\n",
      "         [[-1.5098e-02, -1.7915e-01,  3.5029e-02],\n",
      "          [ 3.1657e-02, -2.0141e-01,  3.7456e-02],\n",
      "          [ 9.9395e-03, -1.6614e-01,  4.5924e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6361e-02, -1.8623e-01, -1.5721e-02],\n",
      "          [ 5.0187e-02, -2.1321e-01,  3.0617e-02],\n",
      "          [ 6.3309e-03, -1.9540e-01,  9.5941e-02]],\n",
      "\n",
      "         [[-1.8462e-02,  4.1735e-02, -2.9739e-02],\n",
      "          [-8.5979e-02,  7.4946e-02, -5.4673e-02],\n",
      "          [-7.2101e-02,  7.1068e-02, -3.3285e-02]],\n",
      "\n",
      "         [[ 3.0355e-02, -4.8602e-02,  4.8654e-02],\n",
      "          [ 1.0009e-01, -2.1391e-01,  8.3665e-02],\n",
      "          [ 1.0443e-01, -8.9226e-02,  6.3843e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0717e-02,  8.8560e-02,  1.5312e-02],\n",
      "          [ 9.5987e-02,  2.5044e-02,  7.5916e-02],\n",
      "          [ 3.1635e-02,  6.7121e-02,  1.0902e-01]],\n",
      "\n",
      "         [[ 3.8169e-02,  1.1915e-02, -4.5517e-02],\n",
      "          [ 5.5564e-03, -3.6381e-02, -2.0597e-02],\n",
      "          [-2.2175e-02,  1.3087e-02,  3.8514e-02]],\n",
      "\n",
      "         [[ 1.0842e-03,  2.0012e-02,  3.2671e-02],\n",
      "          [-3.3287e-03, -1.5462e-02,  1.2168e-02],\n",
      "          [ 4.5672e-03,  4.1116e-03, -8.9293e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8186e-02, -3.9131e-02, -1.9208e-02],\n",
      "          [-1.2509e-02,  7.2525e-02, -3.8008e-02],\n",
      "          [ 5.9124e-03, -1.1461e-03, -4.4033e-02]],\n",
      "\n",
      "         [[-5.5622e-03, -4.6899e-02, -1.7369e-02],\n",
      "          [-1.0476e-01, -1.2266e-01, -8.3017e-02],\n",
      "          [-2.8090e-02, -6.9911e-02, -9.2828e-03]],\n",
      "\n",
      "         [[ 2.2148e-02,  3.1794e-02,  1.6556e-02],\n",
      "          [ 4.3087e-02,  6.5166e-02,  5.5968e-02],\n",
      "          [ 2.6117e-02, -2.8142e-03,  3.7297e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3389e-02,  1.2580e-02, -3.2256e-03],\n",
      "          [-2.8139e-02,  1.5548e-02, -3.7683e-02],\n",
      "          [-5.7841e-02, -1.1160e-03, -2.5895e-02]],\n",
      "\n",
      "         [[ 6.1011e-02,  4.2485e-02,  4.5739e-02],\n",
      "          [ 6.4914e-02,  3.3202e-03,  5.0211e-02],\n",
      "          [ 7.9553e-02,  2.7417e-02,  8.5696e-02]],\n",
      "\n",
      "         [[ 2.3781e-02, -4.7165e-02,  2.6500e-02],\n",
      "          [ 1.6487e-02, -6.9890e-02, -2.8006e-02],\n",
      "          [ 4.3073e-02,  4.9628e-02,  7.6914e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1481e-02, -8.5560e-02, -3.5451e-02],\n",
      "          [-4.8362e-02, -1.7137e-02, -4.8365e-02],\n",
      "          [-2.3754e-02, -4.2934e-02, -3.9122e-02]],\n",
      "\n",
      "         [[ 5.5163e-02,  9.0460e-02,  7.5096e-02],\n",
      "          [ 2.1405e-02,  2.1703e-02,  5.3094e-02],\n",
      "          [ 6.3871e-02,  2.7814e-02,  3.5310e-02]],\n",
      "\n",
      "         [[-1.1514e-01, -1.2496e-01, -5.7494e-02],\n",
      "          [-8.3335e-02, -7.8632e-02, -7.9857e-02],\n",
      "          [-8.4878e-02, -1.6406e-01, -9.4488e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.7121e-03, -3.8258e-03, -1.7786e-02],\n",
      "          [-1.5919e-03, -2.3567e-03, -3.7332e-03],\n",
      "          [ 2.1897e-02, -1.5567e-02,  1.3344e-02]],\n",
      "\n",
      "         [[-1.0496e-02,  2.2333e-02,  2.4710e-02],\n",
      "          [ 3.2914e-02,  2.6641e-02,  4.7012e-02],\n",
      "          [ 2.3165e-02,  3.7380e-02,  3.0998e-02]],\n",
      "\n",
      "         [[ 1.0803e-02,  6.7733e-02,  2.8677e-02],\n",
      "          [ 5.4363e-02,  9.1529e-02,  8.0334e-02],\n",
      "          [ 4.6982e-03,  5.3777e-02,  3.6550e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.1069e-02, -1.4965e-02, -7.7316e-03],\n",
      "          [-1.1739e-02, -8.7771e-04, -2.6936e-03],\n",
      "          [ 1.5415e-03, -1.3079e-03, -1.8854e-02]],\n",
      "\n",
      "         [[-1.7985e-02,  1.5560e-02,  5.9914e-04],\n",
      "          [-1.4221e-02, -1.1626e-04,  1.2551e-02],\n",
      "          [-9.6819e-03,  2.6931e-02,  1.5291e-02]],\n",
      "\n",
      "         [[-2.1776e-02, -5.6972e-03,  1.7158e-02],\n",
      "          [-2.7755e-02, -1.6391e-04,  6.4016e-03],\n",
      "          [-2.5462e-03, -1.7810e-02, -1.0519e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8030e-02,  1.5306e-01,  1.4961e-01],\n",
      "          [-5.4016e-02, -2.1118e-01, -1.5071e-01],\n",
      "          [-1.2107e-01, -2.2928e-01, -9.5552e-02]],\n",
      "\n",
      "         [[-4.5868e-02, -1.1102e-01, -6.1063e-02],\n",
      "          [-1.3498e-02,  1.1320e-02,  2.0450e-02],\n",
      "          [ 8.6506e-03,  1.3844e-02,  5.8495e-02]],\n",
      "\n",
      "         [[-1.8895e-01, -1.9961e-01, -1.4920e-01],\n",
      "          [ 9.2649e-02,  7.7119e-02,  4.2686e-02],\n",
      "          [ 1.9221e-02,  1.4480e-02,  3.9186e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8553e-03,  5.0080e-02, -2.6891e-03],\n",
      "          [-6.6931e-02, -4.7818e-03, -1.5932e-02],\n",
      "          [ 1.4268e-02, -1.6167e-03, -5.5981e-02]],\n",
      "\n",
      "         [[ 2.7811e-02, -2.7819e-02, -8.1705e-02],\n",
      "          [ 6.3321e-02,  5.8205e-02,  1.6575e-02],\n",
      "          [-2.9270e-02, -2.0783e-02, -1.0608e-02]],\n",
      "\n",
      "         [[ 6.3254e-02,  8.9726e-02,  3.4126e-02],\n",
      "          [-1.3295e-01, -1.7655e-01, -7.5084e-02],\n",
      "          [-1.4634e-02, -1.5757e-02, -6.9421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4449e-02, -9.0436e-03, -8.0371e-02],\n",
      "          [ 3.9856e-03,  3.2357e-02, -1.1730e-01],\n",
      "          [-1.3414e-02,  7.0745e-02, -1.4081e-01]],\n",
      "\n",
      "         [[ 6.4235e-04, -7.7577e-02,  5.8418e-02],\n",
      "          [ 1.3166e-02,  5.1159e-03, -8.9465e-02],\n",
      "          [-1.3332e-02,  6.9241e-02, -2.8077e-02]],\n",
      "\n",
      "         [[-1.1870e-01,  3.2826e-02,  5.0934e-02],\n",
      "          [-1.1332e-01, -1.2006e-01,  8.7351e-02],\n",
      "          [-3.5860e-02, -2.1867e-01, -4.3203e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4702e-03,  6.6772e-02,  6.7054e-02],\n",
      "          [ 4.0635e-02, -7.4904e-02,  1.6568e-01],\n",
      "          [ 8.0484e-02, -1.2304e-01,  9.8054e-02]],\n",
      "\n",
      "         [[-2.2328e-02, -1.1020e-01, -3.8126e-02],\n",
      "          [ 3.9621e-02,  1.3892e-02, -1.1270e-01],\n",
      "          [ 8.0779e-03,  4.3435e-02, -4.2784e-02]],\n",
      "\n",
      "         [[-3.6806e-02,  3.9987e-02,  5.7901e-03],\n",
      "          [ 2.4158e-02, -4.9721e-03,  8.5342e-02],\n",
      "          [ 1.3733e-02, -7.8582e-02,  5.5813e-02]]]], device='cuda:0')), ('backbone.model.layer2.0.bn2.weight', tensor([1.5396, 1.7487, 1.5244, 2.2709, 1.6043, 2.9140, 2.3637, 3.3936, 1.5976,\n",
      "        2.1094, 2.5723, 2.2036, 1.9948, 1.7272, 1.8990, 1.6931, 1.8969, 1.7667,\n",
      "        2.1943, 2.5137, 2.6814, 2.0705, 2.4113, 2.3775, 2.1889, 1.9288, 2.1096,\n",
      "        2.3274, 2.8937, 3.0406, 2.1887, 1.8924, 2.3420, 1.1390, 2.2360, 1.8885,\n",
      "        1.5119, 2.6943, 1.9991, 2.2817, 2.6540, 1.7577, 2.0949, 2.5280, 2.0978,\n",
      "        2.6760, 1.5226, 2.6191, 1.4060, 1.6575, 1.9176, 1.9208, 1.8862, 1.9670,\n",
      "        1.3952, 1.9864, 1.6470, 2.2589, 2.0927, 2.4957, 2.4354, 2.2141, 1.7324,\n",
      "        2.6287, 1.7494, 2.4731, 1.7460, 1.6201, 1.5811, 2.8106, 2.0982, 2.3973,\n",
      "        1.6840, 1.9846, 1.3073, 1.9746, 2.5634, 2.7953, 2.3761, 2.9608, 1.8885,\n",
      "        2.2747, 1.3107, 2.3031, 1.4288, 1.6276, 2.2292, 1.3817, 2.6280, 2.0873,\n",
      "        2.1411, 2.2650, 2.3484, 2.2388, 2.1461, 2.3892, 1.4726, 2.6524, 1.9562,\n",
      "        3.3624, 1.8172, 1.9277, 1.1689, 1.5448, 2.8680, 2.5305, 1.6352, 2.2088,\n",
      "        1.2356, 1.6509, 1.8306, 1.6498, 2.4140, 2.4396, 2.6504, 2.4194, 2.1466,\n",
      "        2.1344, 2.3565, 2.0278, 1.9375, 2.1518, 2.3959, 2.0978, 2.8609, 2.5530,\n",
      "        1.5804, 2.0956], device='cuda:0')), ('backbone.model.layer2.0.bn2.bias', tensor([-0.1060,  0.4981, -0.1713, -2.1112,  1.2210, -1.4544, -2.2008, -1.9524,\n",
      "         0.4851,  0.4810, -0.8985, -2.1933, -0.9503, -0.0978,  0.4150,  1.0153,\n",
      "         0.5932,  1.1903, -2.1553, -0.6217, -0.7014, -2.3193,  1.1291,  1.1171,\n",
      "        -0.3783,  1.1508, -2.7400, -0.7261, -0.4597,  0.3572,  2.1427, -0.6501,\n",
      "        -2.2405,  1.1948, -1.9746, -0.2420, -0.8165, -0.3327,  1.5096,  0.2912,\n",
      "        -1.6568,  1.3481,  0.1182, -0.9103,  0.1763, -0.1231,  0.7203, -2.9678,\n",
      "         0.3594,  0.9260, -1.5405, -0.1007,  1.4728, -2.2833,  0.7149, -0.7919,\n",
      "         1.2537, -1.5266,  0.4084, -2.8622, -0.2895, -2.6662,  0.1211,  0.7379,\n",
      "        -1.5147, -0.4109, -0.2351,  1.2479,  0.2712, -0.5599, -1.3616,  0.6584,\n",
      "        -0.9675,  0.7922, -0.0436,  1.1043,  1.2275,  0.6925, -2.2711,  0.4712,\n",
      "         1.8181, -1.2171,  0.5601,  0.0516, -0.2354, -1.1749,  0.6937,  0.9874,\n",
      "        -0.7914, -1.9218,  0.9727, -0.6406,  0.5182,  0.6682, -2.3735,  0.5317,\n",
      "         0.7836,  0.3020, -0.8829, -0.5448,  0.4725, -1.4502,  0.5379,  1.0796,\n",
      "        -0.8340, -0.2364,  1.5069, -1.8058,  0.8392,  0.3895, -2.0067, -0.3909,\n",
      "        -2.0467, -1.1439, -0.0545,  0.9429,  0.4562, -1.5992,  0.6398, -1.5939,\n",
      "         0.9451,  0.6725, -1.1609, -0.7248, -1.1637, -1.4278,  1.5307, -0.0457],\n",
      "       device='cuda:0')), ('backbone.model.layer2.0.conv3.weight', tensor([[[[ 0.0702]],\n",
      "\n",
      "         [[ 0.0807]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         [[-0.0276]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0255]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[ 0.0652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0161]],\n",
      "\n",
      "         [[ 0.0272]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[ 0.0684]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         [[ 0.0249]],\n",
      "\n",
      "         [[ 0.1023]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0993]],\n",
      "\n",
      "         [[ 0.0094]],\n",
      "\n",
      "         [[ 0.0376]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[-0.0892]],\n",
      "\n",
      "         [[ 0.1414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0688]],\n",
      "\n",
      "         [[-0.0054]],\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         [[-0.1044]]],\n",
      "\n",
      "\n",
      "        [[[-0.0777]],\n",
      "\n",
      "         [[-0.0018]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0900]],\n",
      "\n",
      "         [[ 0.0705]],\n",
      "\n",
      "         [[-0.0166]]]], device='cuda:0')), ('backbone.model.layer2.0.bn3.weight', tensor([-1.6556e+00,  1.5706e+00,  3.4830e+00,  8.5048e-01,  2.2449e+00,\n",
      "         1.4239e+00,  4.5225e+00, -2.3605e+00,  1.9086e+00,  3.8398e+00,\n",
      "         1.7715e-01,  2.9523e+00,  2.5779e+00, -4.1174e-02, -1.5245e+00,\n",
      "        -9.4215e-01, -2.2798e+00, -2.6109e+00,  7.3573e+00,  1.7421e+00,\n",
      "        -2.0971e+00,  3.6011e+00,  5.7548e-01, -2.7574e+00,  1.7019e+00,\n",
      "        -5.3316e+00, -4.6843e+00,  3.3718e-01,  4.5615e+00, -5.4868e+00,\n",
      "         3.5918e+00, -1.8976e+00,  3.0264e+00, -3.0531e+00, -2.9804e+00,\n",
      "        -2.2443e+00, -3.2490e+00, -8.5165e-01, -9.8656e-01,  2.9249e+00,\n",
      "        -5.9875e+00, -6.9451e-01,  4.9652e+00,  2.0827e+00,  1.9112e-01,\n",
      "        -2.0778e+00, -3.5348e+00,  3.0269e+00,  2.3363e+00,  3.8539e-01,\n",
      "         2.8935e+00, -9.4115e-01,  2.5082e+00, -1.8699e+00, -4.0410e-02,\n",
      "         9.6370e-01, -2.2902e+00,  9.1172e-01,  5.4896e+00, -2.1335e+00,\n",
      "         1.6886e-01, -2.2502e+00,  2.0937e+00, -1.0900e+00,  9.1429e+00,\n",
      "         5.6616e-02,  4.1995e-01,  3.0101e+00,  6.4685e-01,  5.3908e+00,\n",
      "        -1.8930e+00,  4.8568e+00, -3.0628e+00, -3.0999e+00, -2.0173e+00,\n",
      "         3.1863e+00, -1.6412e+00,  1.4792e+00, -4.6104e-01, -3.8794e+00,\n",
      "         1.4088e+00, -1.0470e+00,  1.6867e+00,  7.0119e-01,  1.8141e+00,\n",
      "        -3.4695e+00,  5.3434e-02,  4.0493e-02, -2.7622e+00,  2.8614e-01,\n",
      "        -2.4681e+00, -1.1191e+00,  3.5890e+00, -6.9788e-01,  4.0930e+00,\n",
      "        -1.9223e-02,  5.0753e+00,  3.7742e+00, -3.9272e+00,  9.3425e-01,\n",
      "         2.2115e+00, -3.3366e+00,  2.3308e+00, -1.4048e+00, -1.3467e+00,\n",
      "         2.8842e+00,  2.4981e+00,  3.2339e+00,  1.4046e+00,  1.5876e+00,\n",
      "         1.8380e+00, -6.0802e-01, -4.5105e-01, -3.6730e+00, -3.3922e+00,\n",
      "         1.1011e+00,  6.2028e-01, -2.0296e+00,  1.7272e+00,  4.2991e-01,\n",
      "         1.2035e-01,  1.6233e+00, -1.4265e+00,  2.0323e+00,  2.2197e+00,\n",
      "         2.5747e+00,  8.2620e+00,  5.2853e+00, -3.9875e+00,  8.6908e+00,\n",
      "        -4.3619e+00, -5.2644e-01,  2.6022e+00, -3.2419e-02, -1.5706e+00,\n",
      "         5.5844e+00,  5.2333e+00, -3.9078e+00,  1.2754e+00,  5.3893e-01,\n",
      "         1.4298e+00, -2.5441e+00, -2.1125e+00, -2.3715e+00,  2.3791e+00,\n",
      "        -4.4252e+00, -2.7266e+00, -1.1709e+00, -1.1319e+00, -2.4992e+00,\n",
      "         3.3039e+00,  4.2149e+00, -2.9111e+00,  2.7151e+00,  7.4854e-02,\n",
      "         4.0460e+00, -6.2695e+00, -4.2719e+00,  2.5390e+00,  5.6523e+00,\n",
      "         9.7281e-01, -4.7372e+00, -3.6494e+00,  1.1418e+00, -5.0538e+00,\n",
      "        -3.2419e+00, -5.7068e+00, -1.0871e+00, -1.5219e+00, -1.9945e+00,\n",
      "        -8.3360e-01, -1.9525e+00,  2.6987e+00, -1.9415e+00,  2.5342e-01,\n",
      "         3.2099e-01, -1.4963e+00,  1.9564e+00, -2.2042e+00, -1.2758e+00,\n",
      "         2.5125e+00,  4.0204e+00, -3.1110e-02, -1.5251e+00, -7.1271e-01,\n",
      "         5.5473e+00,  7.1926e-01,  2.1802e+00, -6.6692e-02,  2.6144e-01,\n",
      "        -7.2102e-01,  2.1780e+00, -1.2828e+00,  2.5703e+00,  1.8617e+00,\n",
      "        -2.3655e+00,  2.2599e+00, -2.8405e+00, -2.7720e+00, -3.3575e+00,\n",
      "        -1.0883e+00,  8.8690e-01, -3.3839e+00, -2.2281e+00, -2.3588e+00,\n",
      "        -2.4487e+00,  5.1001e+00,  3.0509e+00, -2.7428e+00, -2.0674e+00,\n",
      "        -2.7519e+00,  7.6169e-01, -8.7895e-01, -2.2912e+00, -3.6597e+00,\n",
      "        -4.6736e-01, -1.2831e-01, -3.0757e-01,  1.4126e-01,  1.3752e-01,\n",
      "        -4.0152e-01,  5.2100e-01,  2.9635e-02,  1.4603e+00, -2.2618e+00,\n",
      "        -9.9112e-01, -1.7104e+00, -1.1173e+00,  4.5283e+00,  3.9164e-01,\n",
      "        -1.3526e+00,  1.3578e+00, -1.8625e+00,  3.2918e+00, -3.8094e+00,\n",
      "        -3.8615e+00,  5.9070e+00,  2.4525e+00, -4.0657e-01, -1.4448e+00,\n",
      "        -2.8574e+00, -2.1856e+00, -2.4886e+00,  5.8764e+00,  2.0804e+00,\n",
      "         1.3294e+00, -2.0853e+00,  5.0300e+00,  4.1468e+00, -2.0194e-01,\n",
      "        -3.9687e-01, -1.2437e+00,  1.6219e-01,  8.3982e-01, -2.2857e+00,\n",
      "         3.0953e+00, -2.2263e+00, -7.1852e-01, -4.2750e-01,  1.8391e+00,\n",
      "         1.6158e+00, -2.0073e+00, -2.4105e+00,  2.7810e+00, -4.5878e-01,\n",
      "         3.0226e+00, -2.1373e+00, -2.7780e+00, -1.0371e-01,  1.4582e+00,\n",
      "         2.4641e+00,  1.9074e+00,  3.6553e+00,  1.2920e+00, -2.6908e-01,\n",
      "        -3.1635e+00,  8.6238e-01,  1.5176e+00,  3.3028e+00,  2.2195e+00,\n",
      "         3.1347e+00,  5.9811e+00, -2.9014e+00, -4.4943e-01, -2.0109e+00,\n",
      "         1.3542e+00,  5.4269e-01, -1.0978e+00, -8.5789e-01, -2.1300e+00,\n",
      "         2.3402e+00,  2.9425e+00, -2.1301e+01, -4.1791e+00, -2.4439e+00,\n",
      "        -7.4980e-01,  1.2913e-01, -2.4199e+00,  3.2872e+00, -4.1624e+00,\n",
      "        -1.8670e+00, -2.7605e-01, -1.9030e+00,  2.6381e+00,  9.9894e-01,\n",
      "        -2.6813e-01, -2.4844e+00,  3.8016e-01,  1.8016e+00,  1.7268e+00,\n",
      "         1.2766e-02,  3.2021e+00,  2.2113e-01,  2.7191e+00,  2.0918e-01,\n",
      "        -4.1682e+00, -8.7149e+00, -2.2096e+00,  1.7048e-01, -9.1263e-01,\n",
      "         2.2062e-01, -3.0058e+00, -2.2218e+00, -1.4364e+00, -4.5583e+00,\n",
      "        -3.5960e+00, -1.8727e+00,  3.6523e+00,  1.3371e+00, -1.4674e+00,\n",
      "        -3.0292e+00, -3.1025e+00, -3.7402e+00,  4.4824e-01, -2.5711e+00,\n",
      "         2.1376e+00, -2.2475e-02, -3.9135e+00,  8.4667e-01, -2.3741e+00,\n",
      "         1.6245e+00, -4.6987e+00,  1.4623e+00,  5.8604e+00, -6.4857e+00,\n",
      "        -6.4153e+00, -4.2399e+00, -9.0295e+00, -1.1936e+00,  3.0071e+00,\n",
      "        -4.2090e+00,  3.3413e+00, -5.5099e-01,  3.8520e+00,  1.8541e+00,\n",
      "        -6.2384e-01, -2.1659e+00, -4.0937e-01,  2.0029e-01, -1.1269e+00,\n",
      "        -1.0327e+00, -4.6992e-01,  3.0539e+00, -3.1375e+00,  2.2151e+00,\n",
      "         2.4929e+00,  4.2443e+00,  2.1873e+00, -5.6994e+00,  1.8099e+00,\n",
      "        -3.2079e+00, -6.1161e+00, -3.5759e+00, -3.1289e+00, -4.5946e+00,\n",
      "         2.5644e+00,  2.3731e+00,  5.1706e-01, -4.1498e-01, -2.8066e-01,\n",
      "         2.7298e+00,  2.6400e+00,  1.3180e+00, -3.2167e+00,  2.6236e+00,\n",
      "         1.4550e+00,  2.5902e+00, -6.4994e-01,  3.1431e+00, -1.7911e+00,\n",
      "         3.0101e+00, -3.6023e+00,  4.4388e+00,  1.2637e+00, -5.9028e-01,\n",
      "         1.5255e-01, -3.5319e+00, -2.8115e+00, -1.1524e-01,  5.9453e-01,\n",
      "         2.0244e+00, -3.5436e+00,  2.1214e+00, -8.5589e-01, -3.3964e+00,\n",
      "         2.4739e-01,  2.7361e+00, -7.2926e+00,  1.5871e+00,  1.5032e-01,\n",
      "         6.8394e+00, -9.0340e-02,  2.5093e+00,  1.6413e-01, -2.9811e+00,\n",
      "         2.0843e+00, -1.5680e+00,  1.1571e+00, -5.2224e-02, -2.1344e+00,\n",
      "         3.0311e+00, -3.3276e+00, -2.6017e+00,  7.0774e+00,  1.9221e+00,\n",
      "        -3.8881e+00, -3.1979e+00, -2.4384e+00,  3.5434e+00,  3.8833e+00,\n",
      "        -4.6050e+00,  5.4052e+00, -1.6691e+00, -1.3464e+00,  1.1651e-01,\n",
      "         2.2926e+00, -2.8087e+00,  3.2252e-02, -3.3391e+00, -1.5055e+00,\n",
      "        -2.9890e+00, -2.7055e+00, -4.4549e-02,  2.7659e-01,  2.7741e-01,\n",
      "         2.2608e+00,  3.7036e-01,  3.5756e+00, -7.9952e-01,  3.4437e+00,\n",
      "        -2.9656e+00,  4.0761e+00, -1.0099e-01, -1.6016e+00,  6.5346e+00,\n",
      "        -3.4053e+00,  4.0007e+00, -5.6588e-02,  1.7674e+01,  3.4714e+00,\n",
      "        -3.6798e+00,  1.1879e+00, -3.6336e+00, -2.7620e+00, -1.2607e+00,\n",
      "         1.5166e+00, -7.5199e-01, -3.5592e+00, -1.0351e-01, -5.3591e-01,\n",
      "        -3.3562e+00,  3.5655e+00,  1.1689e+00,  2.1429e+00, -4.2641e+00,\n",
      "        -2.4159e+00,  2.4236e+00, -4.6470e-01,  1.7686e+00,  1.7377e+00,\n",
      "         2.7358e+00,  2.3016e+00, -3.2416e-01, -8.4135e-01, -6.0099e+00,\n",
      "        -1.6929e+00, -1.5887e+00,  4.0629e-01, -1.0824e+00, -3.3010e+00,\n",
      "         3.3529e+00, -5.7570e+00,  2.0762e+00,  3.0505e+00,  2.9866e+00,\n",
      "         1.5118e+00,  1.9483e+00,  4.2226e+00, -2.8503e+00, -1.4626e+00,\n",
      "        -8.2683e-02, -3.2135e+00,  1.3742e+00,  3.5726e+00, -2.4089e-01,\n",
      "         9.7168e-01, -3.3821e+00,  2.5847e+00, -1.8111e+00, -1.3313e-01,\n",
      "         3.6218e+00, -1.3718e+00], device='cuda:0')), ('backbone.model.layer2.0.bn3.bias', tensor([ 1.3259e+00, -7.5733e-01,  4.0805e-01,  4.3565e-01, -3.8836e-01,\n",
      "        -2.0849e-01, -6.2283e-01,  4.2687e-01,  1.1959e-02,  1.3721e+00,\n",
      "         1.4077e+00, -1.1619e-01, -1.2285e+00,  5.0034e-01,  6.2312e-01,\n",
      "         7.7072e-01,  2.7209e-01, -7.3536e-01, -1.8072e-01,  6.2382e-01,\n",
      "        -6.8288e-01, -7.4585e-01,  1.2144e-01, -1.1576e+00,  1.5285e+00,\n",
      "         6.7132e-01,  1.5218e+00,  7.1457e-01,  2.3261e-02,  1.3856e+00,\n",
      "         6.8039e-01, -7.3066e-01, -3.2294e-02,  2.2259e-01,  1.1887e-01,\n",
      "         5.2493e-01,  1.4911e+00,  5.9990e-01,  5.1763e-01,  1.1939e+00,\n",
      "        -1.5443e-02,  4.2133e-01,  1.6987e+00,  4.8882e-01,  9.2548e-01,\n",
      "         1.6501e+00,  7.3845e-01, -3.8020e-01, -1.1500e+00,  1.1286e+00,\n",
      "        -6.7276e-01,  3.4824e-01, -5.7094e-01,  3.8178e-01,  5.2530e-01,\n",
      "         9.0484e-02,  6.3141e-01,  6.5880e-01, -1.4372e+00, -1.0363e+00,\n",
      "         6.4411e-01,  6.8102e-01,  1.5154e+00,  4.8440e-01,  2.7080e+00,\n",
      "         4.8506e-01,  6.1554e-01,  2.1119e+00,  9.9094e-01, -8.5103e-01,\n",
      "         9.3717e-01, -3.9733e-01,  1.4906e+00, -6.9684e-01,  1.0679e+00,\n",
      "         7.6735e-01,  1.6900e+00, -5.1453e-01,  6.7782e-01,  4.2215e-01,\n",
      "         9.5978e-02,  5.2110e-01,  3.8332e-01,  8.4292e-02,  1.4692e+00,\n",
      "        -3.7481e-01,  6.7083e-01, -2.8544e-01,  9.7836e-01,  5.9161e-01,\n",
      "         1.8272e+00,  1.5034e-01,  1.3440e-01,  3.9081e-01, -8.3972e-02,\n",
      "         5.1954e-01, -5.6998e-01, -1.7470e+00,  5.0381e-04, -3.8573e-01,\n",
      "        -5.6792e-01, -8.2629e-02,  6.5522e-01, -2.6939e-01,  6.7608e-01,\n",
      "         4.1502e-01,  2.4055e-02, -1.2951e+00,  1.8093e-01, -1.1844e-01,\n",
      "        -2.8582e-01, -2.8360e-01,  1.3103e-01,  1.1886e+00,  1.4932e+00,\n",
      "         1.0252e+00,  1.1500e+00,  2.8379e-01,  8.4459e-02,  4.9573e-01,\n",
      "        -5.6961e-01, -2.1908e-01,  5.3426e-01, -6.8506e-01,  2.4325e-01,\n",
      "         4.1154e-01, -1.2440e-01,  8.0925e-01,  3.7342e-01, -2.1421e+00,\n",
      "        -1.4805e-01,  1.7452e-01, -2.7922e-02,  3.9563e-01,  9.3072e-01,\n",
      "         1.0015e+00, -8.4893e-01,  1.6629e+00,  8.9033e-02,  9.6589e-01,\n",
      "         2.6677e-01,  1.6562e+00,  7.5039e-01,  1.0687e+00, -2.9098e-01,\n",
      "         2.6382e-01,  1.3561e+00,  4.6413e-01,  8.1927e-01,  1.0470e+00,\n",
      "         5.6048e-01,  4.6244e-01,  1.0337e+00, -9.6742e-01,  5.2499e-01,\n",
      "         6.0002e-01,  1.3704e+00, -2.7584e-01,  2.1904e-01, -5.5844e-01,\n",
      "        -2.2808e-01,  7.0411e-01, -5.4327e-01,  1.7693e+00, -5.1279e-01,\n",
      "         3.9203e-01, -2.7378e+00,  5.9938e-02, -1.4206e+00,  2.4582e-01,\n",
      "         3.5133e-01,  6.4118e-01, -2.1733e-02, -9.6526e-01,  1.2899e+00,\n",
      "         7.5730e-01,  6.1472e-01, -2.4806e-01,  5.2993e-01,  6.5677e-01,\n",
      "        -1.5022e+00, -9.2437e-01,  6.5556e-01, -1.4291e-01,  6.5132e-01,\n",
      "         6.3932e-01,  3.4854e-01,  1.3806e+00,  1.2223e+00,  4.4034e-01,\n",
      "        -5.1553e-01,  9.4942e-01,  8.4736e-01,  8.1633e-01,  5.9665e-01,\n",
      "         8.2488e-01,  1.3921e+00,  2.9431e+00, -9.8798e-02, -8.0159e-01,\n",
      "         4.2788e-01,  5.3526e-01, -1.8260e+00,  1.8556e-01,  2.7349e-01,\n",
      "        -3.2828e-01,  1.7253e+00,  1.7826e-01,  5.6908e-01,  3.3475e-01,\n",
      "         9.2984e-01,  8.9889e-01, -8.3238e-02,  5.9121e-01,  1.6459e+00,\n",
      "        -8.9186e-02,  5.0787e-01,  2.8630e-01,  5.4546e-01,  8.2273e-01,\n",
      "         3.0200e-01,  5.6421e-01,  1.2392e+00,  7.7243e-01,  2.6967e-01,\n",
      "         1.0567e+00,  8.4453e-01,  3.8322e-01,  2.2429e-01,  3.4130e-01,\n",
      "         1.0197e+00,  2.0507e-01,  1.0709e+00,  1.0346e+00,  3.2020e-03,\n",
      "        -3.3274e-01,  1.4493e+00,  4.5719e-01,  5.3370e-01,  7.1288e-01,\n",
      "         5.2927e-01,  1.0626e+00,  7.8677e-01,  1.6569e+00, -5.4349e-02,\n",
      "        -4.8392e-01,  1.2415e+00,  1.0458e+00,  1.1596e+00,  2.6356e-01,\n",
      "         9.5648e-02,  4.4679e-01,  2.7622e-01,  1.5052e-01, -9.9185e-01,\n",
      "         1.3952e+00, -5.3404e-02,  1.1850e+00,  1.0367e+00, -8.0200e-01,\n",
      "         8.0713e-01, -2.6759e-01,  1.7664e+00, -9.9624e-02,  4.7496e-01,\n",
      "         6.9642e-02, -2.1368e+00,  7.9374e-01, -5.5203e+00,  4.8129e-01,\n",
      "        -1.0102e+00,  8.2718e-01,  1.5013e+00, -1.0100e+00,  3.5627e-01,\n",
      "         2.6693e-01,  1.1420e+00,  4.2318e-01,  5.7889e-01,  1.1072e+00,\n",
      "        -7.4493e-01,  1.2885e+00, -5.6180e-02,  9.1780e-01,  1.2238e+00,\n",
      "        -1.3920e-01,  9.6843e-01,  1.3501e+00,  1.4324e-01,  1.0604e-01,\n",
      "         1.8346e+00,  4.2647e-01,  1.8760e+00,  8.9095e-01, -5.7517e-02,\n",
      "         5.6991e-01, -6.0158e-01,  8.6025e-01,  1.6438e+00, -9.4556e-01,\n",
      "        -1.9220e-02,  7.6514e-01,  1.0607e+00,  3.0908e-01,  4.7915e-01,\n",
      "         8.7699e-01,  7.6960e-01,  6.0051e-01, -5.4710e-01,  1.1519e+00,\n",
      "        -8.7169e-01,  6.2725e-02, -1.0859e+00, -8.7554e-01,  4.0872e-01,\n",
      "         7.1285e-01, -6.6166e+00,  3.3395e-01,  7.6852e-01,  2.9042e-01,\n",
      "         5.6989e-01, -2.4736e-02,  1.3602e+00, -1.3145e+00,  1.8350e+00,\n",
      "        -5.3056e-01,  2.5626e-01,  1.5585e+00,  1.8006e-01, -9.3937e-01,\n",
      "         3.9297e-01,  1.3727e+00,  4.2944e-01,  3.2830e-01, -4.6919e-01,\n",
      "         5.4563e-01, -3.7496e-01, -3.7835e-01, -9.0336e-01, -3.4103e+00,\n",
      "         8.5031e-01,  7.8649e-01,  5.8404e-01, -4.0685e-01,  9.6981e-01,\n",
      "        -1.0057e+00, -7.1698e-01,  3.4586e-01,  8.2681e-01,  4.1154e-01,\n",
      "        -8.6799e-01, -5.5565e-01, -1.3887e-01, -1.9732e+00,  3.6281e-02,\n",
      "         5.9633e-01,  7.3253e-01,  9.6559e-01,  6.8234e-02,  4.9578e-01,\n",
      "         9.9528e-01,  5.1229e-01,  9.2529e-01, -2.0807e-01, -5.4094e-02,\n",
      "        -4.4207e-01,  2.6495e-01, -7.4914e-01,  7.5913e-01, -6.8668e-01,\n",
      "         1.1849e+00,  9.0520e-01,  9.3572e-01, -1.3293e+00, -4.3167e-01,\n",
      "        -5.7133e-01,  1.4036e+00,  2.1308e-01,  6.5404e-01, -1.7365e-02,\n",
      "        -8.4618e-01,  2.2319e+00, -4.9450e-02, -1.6063e+00,  4.7520e-03,\n",
      "        -4.4709e-01,  5.0307e-01,  7.5218e-02,  6.3111e-01,  4.7923e-01,\n",
      "         5.4027e-01,  2.5166e+00, -3.5219e-01, -4.0207e-01,  5.0740e-01,\n",
      "         3.4605e-01,  1.7799e-01,  1.2761e+00,  2.8777e-01,  4.4599e-01,\n",
      "         1.2572e+00,  8.0343e-01, -2.9797e-01,  2.9971e-01,  4.0434e-01,\n",
      "        -9.8361e-01, -4.2700e-01, -6.7614e-02,  4.8425e-01,  3.8787e-01,\n",
      "        -2.3912e-01,  5.1971e-01, -6.6085e-01,  4.5770e-01,  1.8515e+00,\n",
      "         1.6647e-01,  2.8341e-01,  1.1015e+00, -7.3609e-01, -3.7830e-01,\n",
      "        -1.5824e+00,  9.6258e-01, -1.4095e-01,  1.1925e+00,  2.5191e-02,\n",
      "         1.8540e-01, -6.6274e-01,  8.7834e-02,  8.1499e-01,  1.2707e+00,\n",
      "        -2.2013e-01, -5.5799e-01, -3.8914e-01, -8.5091e-01,  7.3627e-01,\n",
      "        -1.1208e+00, -6.9713e-01,  3.9798e-01,  6.0518e-01,  1.3940e+00,\n",
      "         9.5319e-01,  2.2207e+00,  5.5534e-01,  6.1154e-01, -8.0124e-01,\n",
      "        -1.3220e+00,  4.5755e-01, -7.9152e-01,  2.0185e+00, -1.7607e+00,\n",
      "        -1.3880e+00,  4.5412e-01,  5.7813e-01,  1.8177e-01, -2.8100e-01,\n",
      "        -4.4995e-01, -1.4581e-01,  6.8641e-01, -4.0304e-01, -7.5418e-02,\n",
      "         1.2711e+00,  6.0542e-01,  3.6461e+00,  6.9536e-01,  7.7113e-01,\n",
      "         3.6895e-01,  1.5052e+00,  9.1533e-01,  1.8394e-01,  1.1039e+00,\n",
      "         1.0684e+00,  7.5712e-01,  8.4750e-01,  2.3906e-01,  6.5527e-01,\n",
      "         7.3225e-01,  9.9825e-01,  2.8741e-01,  7.5106e-01, -1.1820e+00,\n",
      "         2.9928e-01, -4.7607e-02,  7.5062e-01,  1.7898e+00, -9.2333e+00,\n",
      "         1.4117e-01,  2.3692e-01,  6.0577e-01,  1.1130e+00,  2.4859e-01,\n",
      "         4.9566e-01, -1.1746e+00,  6.4144e-01,  1.9337e+00,  3.8587e-01,\n",
      "         7.3971e-01,  8.2984e-01,  1.2595e+00,  1.1714e+00,  1.0665e+00,\n",
      "        -1.1296e+00,  1.1678e+00,  7.0291e-01, -8.8490e-02,  3.7747e-01,\n",
      "         1.2508e+00,  9.1084e-01,  6.0961e-01,  6.0514e-01, -7.2627e-01,\n",
      "         4.8476e-01, -4.1116e-02], device='cuda:0')), ('backbone.model.layer2.0.downsample.0.weight', tensor([[[[-1.3920e-01]],\n",
      "\n",
      "         [[ 4.3258e-02]],\n",
      "\n",
      "         [[-2.5287e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9265e-02]],\n",
      "\n",
      "         [[-5.9821e-03]],\n",
      "\n",
      "         [[ 5.4859e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2418e-02]],\n",
      "\n",
      "         [[ 5.8764e-02]],\n",
      "\n",
      "         [[-1.2432e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0063e-02]],\n",
      "\n",
      "         [[-2.8535e-02]],\n",
      "\n",
      "         [[-2.3265e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4753e-02]],\n",
      "\n",
      "         [[ 1.5536e-02]],\n",
      "\n",
      "         [[ 2.8598e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5263e-03]],\n",
      "\n",
      "         [[ 4.0757e-02]],\n",
      "\n",
      "         [[ 5.0744e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4614e-01]],\n",
      "\n",
      "         [[-4.4233e-02]],\n",
      "\n",
      "         [[ 9.0213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8612e-02]],\n",
      "\n",
      "         [[ 8.5788e-02]],\n",
      "\n",
      "         [[-4.7920e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0390e-04]],\n",
      "\n",
      "         [[ 1.7024e-02]],\n",
      "\n",
      "         [[-3.3435e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3420e-02]],\n",
      "\n",
      "         [[-9.7308e-02]],\n",
      "\n",
      "         [[ 2.0660e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4245e-02]],\n",
      "\n",
      "         [[ 4.0574e-02]],\n",
      "\n",
      "         [[ 3.4845e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8961e-02]],\n",
      "\n",
      "         [[ 2.3442e-02]],\n",
      "\n",
      "         [[ 2.0956e-02]]]], device='cuda:0')), ('backbone.model.layer2.0.downsample.1.weight', tensor([-3.2739e-02,  2.7011e+00,  1.1133e+00,  3.5505e+00,  2.0692e+00,\n",
      "         5.6712e+00,  1.6304e+00,  2.3363e+00,  6.8484e+00,  1.4895e+00,\n",
      "         2.1920e+00,  1.1584e+00,  1.7123e+00,  5.4948e+00,  2.8731e+00,\n",
      "         4.3251e+00,  1.7501e+00,  1.0582e-01,  3.7248e+00,  2.2383e+00,\n",
      "         3.0193e+00,  1.5975e+00,  3.6493e+00,  2.3523e+00,  8.6685e-01,\n",
      "         3.5803e+00,  2.4683e+00,  2.7051e+00,  2.5829e-01,  3.2965e+00,\n",
      "         2.2138e+00,  2.3771e+00,  3.2153e+00, -1.7865e-01,  2.7627e+00,\n",
      "         2.2978e+00,  7.5215e-02,  2.5493e+00,  1.6123e+00,  1.9208e+00,\n",
      "         2.8177e+00,  4.1984e+00,  4.0122e+00,  1.4263e+00,  3.3768e+00,\n",
      "         1.5248e+00,  2.1337e+00,  7.8702e-01,  4.3136e-01,  3.3435e+00,\n",
      "         1.5621e+00,  7.4470e-01,  3.0308e+00,  6.7016e-01,  3.7323e+00,\n",
      "         4.1218e+00,  1.6219e+00,  6.0170e-01,  4.6103e+00,  1.7205e+00,\n",
      "         4.6531e+00,  8.9326e-01,  1.5763e+00,  2.4102e+00,  5.0438e+00,\n",
      "         3.0961e+00,  2.9533e+00,  1.2640e+00,  2.9428e+00,  2.6957e+00,\n",
      "         9.1022e-01, -2.6795e-02,  7.2164e-01,  1.7064e+00,  3.0849e+00,\n",
      "         9.9171e-01,  1.7983e+00,  5.2484e-01,  3.2669e+00,  1.7677e+00,\n",
      "         1.2837e+00,  3.0056e+00,  2.7071e+00,  2.1326e+00,  2.1920e+00,\n",
      "         4.2404e+00,  3.0104e+00,  3.2033e+00, -1.1758e-02,  2.0175e+00,\n",
      "         7.4286e+00,  3.0273e+00, -3.1092e-03,  4.0113e+00,  3.8020e+00,\n",
      "         3.0862e+00,  6.1200e+00,  1.4916e+00,  2.4507e+00,  5.2796e+00,\n",
      "         2.5316e+00,  3.2079e+00,  1.7213e+00,  4.4364e+00,  6.3150e-01,\n",
      "         2.6174e+00, -5.6397e-01,  3.1358e+00,  1.7314e+00,  1.5793e+00,\n",
      "         1.7939e+00,  2.6429e+00,  3.4713e+00,  1.8937e+00,  2.9255e+00,\n",
      "         1.8970e-01,  3.8830e+00,  1.7481e+00,  1.9846e+00,  2.4842e+00,\n",
      "         3.8777e-02,  4.0833e-01,  2.6369e+00,  7.1681e-01,  7.2905e-01,\n",
      "         3.3753e+00,  1.4420e+01,  2.8145e+00,  9.6734e-01,  7.8030e+00,\n",
      "         2.0043e+00,  4.9302e+00,  3.3395e-01,  3.3497e+00,  6.8489e+00,\n",
      "         3.2974e+00,  2.4894e+00,  1.4306e+00,  3.5146e-01,  4.2628e-01,\n",
      "         2.6656e+00,  5.0850e+00,  1.7349e+00,  5.8801e+00,  9.7619e-01,\n",
      "         2.3893e+00,  1.3794e+00, -6.9845e-01,  1.7041e-01,  7.6743e+00,\n",
      "         1.3441e+00,  2.4624e+00,  2.2772e+00,  1.5704e+00,  3.6886e+00,\n",
      "         4.4507e+00,  3.8369e+00,  3.0166e+00,  1.9126e+00, -1.6666e+00,\n",
      "         1.1055e+00, -1.0224e+00, -2.5466e-01,  1.5484e+00,  2.6629e+00,\n",
      "         9.4709e-01,  2.1575e+01,  5.3176e-01,  1.8679e+00,  1.5419e+00,\n",
      "         3.6430e+00,  4.2501e-01,  1.7122e+00,  1.6976e+00,  2.6308e+00,\n",
      "         2.7345e+00,  2.9433e+00,  8.5603e-01,  1.1367e+00,  6.3618e+00,\n",
      "         5.2481e+00,  1.7072e+00,  3.0726e+00,  6.9912e+00,  5.5512e+00,\n",
      "         4.6981e-01,  3.1606e+00,  6.2584e+00,  1.9913e+00,  5.1600e+00,\n",
      "         1.8138e+00,  1.1187e+00,  9.6463e+00,  1.5665e+00,  1.5021e+00,\n",
      "         8.7520e-01,  2.6238e+00,  2.5464e+00,  4.6382e-01,  2.7543e+00,\n",
      "         3.6454e+00,  3.1490e+00,  3.0840e+00,  1.2382e+00,  2.7480e+00,\n",
      "         1.5906e+00,  4.6213e+00,  2.1426e+00, -4.8379e-02, -1.0581e-01,\n",
      "         1.6112e+00,  3.9652e+00,  3.9676e+00, -3.8236e-02,  9.0916e-01,\n",
      "         4.9404e+00,  4.1178e+00,  3.3515e+00,  1.9860e+00,  2.4064e+00,\n",
      "         5.0057e+00,  1.4690e+00,  2.3592e+00,  3.1575e+00,  1.4949e+00,\n",
      "         8.7968e-01,  2.2911e+00,  1.2898e+00,  2.4502e+00,  4.6029e+00,\n",
      "         5.0931e+00,  1.3531e+00,  2.5676e+00,  2.0065e+00,  1.1590e+00,\n",
      "         9.0906e-01,  2.2585e+00,  1.0986e+00,  4.7554e+00,  1.0683e+00,\n",
      "         1.3298e+00,  1.1727e+00,  1.8245e-01,  4.2143e+00,  3.4030e+00,\n",
      "         1.6936e+00,  4.4811e-01,  6.9556e-02,  2.5054e+00,  2.9682e+00,\n",
      "         3.4996e+00,  3.7284e+00,  4.2943e+00,  2.4577e+00,  1.5455e+00,\n",
      "         3.0336e-02,  6.9086e-02,  1.6596e+00,  2.0474e+00,  1.4920e+00,\n",
      "         7.8698e+00,  2.1573e+00,  1.3599e+00,  1.1582e+00,  3.4109e+00,\n",
      "         1.5323e+00,  1.5145e+00,  1.1744e+00,  2.0716e+00,  7.7177e-01,\n",
      "         1.0830e+00,  1.4885e+00,  4.5740e+00,  3.0208e+00,  3.9137e+00,\n",
      "         1.3329e+00, -2.0621e-02,  3.5449e+00,  1.6097e+00,  1.0874e+00,\n",
      "         6.9354e+00,  9.6106e-02,  1.6916e+00,  4.9346e+00,  1.4016e+00,\n",
      "         2.8372e+00,  5.0679e+00,  8.6254e-01,  3.3427e+00, -3.3560e-02,\n",
      "         2.2764e+00,  1.5611e+00,  8.8315e+00,  2.7473e+00,  1.9670e+00,\n",
      "         3.4863e+00,  1.1680e-01,  1.7351e+00,  1.6078e+00,  1.3597e+00,\n",
      "         1.4115e+00,  1.8378e+00,  4.6243e+00,  2.9279e+00,  3.3365e+00,\n",
      "         2.0899e+00,  3.0438e+00,  2.8573e+00,  1.7288e+00,  4.3536e+00,\n",
      "         1.6441e-01,  1.5300e+00,  1.0585e-01,  1.7027e+00,  3.2498e+00,\n",
      "         3.3506e+00,  1.1713e+01,  1.6912e+00,  2.8698e+00,  3.6744e+00,\n",
      "         4.2602e+00,  2.4296e+00,  4.5036e+00,  2.5838e+00,  7.7513e+00,\n",
      "         1.3281e-02,  2.7949e+00,  1.2772e+00,  1.6285e+00,  1.5841e+00,\n",
      "         1.6492e+01,  4.5232e+00,  1.1252e+00,  5.0910e+00,  1.8455e+00,\n",
      "         2.8329e+00, -4.8078e-03,  1.1787e+00,  1.3704e-01,  4.5276e+00,\n",
      "         4.7890e+00,  2.4450e+00,  9.2891e-01,  1.2535e+00,  2.6709e+00,\n",
      "         3.5633e+00,  3.1634e+00,  1.0601e+01,  6.1966e-01,  9.4874e-01,\n",
      "         4.0783e+00,  1.8760e+00,  2.0396e+00,  3.6638e+00,  1.0401e+00,\n",
      "         5.2889e+00,  2.8561e-01,  3.3141e+00,  3.0834e+00,  3.5482e+00,\n",
      "         2.7971e+00,  2.6221e+00,  2.0296e+00,  2.6759e+00,  2.8957e+00,\n",
      "         1.8435e+00,  8.6142e-01,  1.5417e+00,  2.6951e+00,  1.3829e+00,\n",
      "         1.1186e+00,  1.0769e+01,  2.0117e+00,  3.4360e+00,  9.2972e-01,\n",
      "         2.0163e+00,  1.0677e+00,  2.2165e+00,  4.6521e+00,  4.5202e+00,\n",
      "         1.9076e+00,  2.2632e+00,  4.5269e-01,  2.9258e+00,  1.2815e+00,\n",
      "         2.6826e+00,  1.3226e+00,  2.5890e+00, -2.9174e-02,  2.3662e-02,\n",
      "         2.1423e+00,  1.9731e+00,  4.9438e+00,  2.1027e-02,  2.3294e+00,\n",
      "         3.5240e+00,  3.3788e+00,  1.2313e+00,  3.8938e+00,  3.5538e+00,\n",
      "         6.0367e+00,  2.2408e+00,  3.1636e+00,  4.3215e+00,  1.4677e+00,\n",
      "         5.1732e-02,  2.6604e+00,  2.9625e+00,  1.3962e+00,  2.7432e+00,\n",
      "         1.9966e+00,  3.3818e+00,  2.6384e+00,  3.8184e+00, -1.7860e-02,\n",
      "         2.7729e-02,  3.7896e+00,  9.9325e-01,  7.6798e-02,  3.1156e+00,\n",
      "         2.0989e+00,  2.7023e-02,  8.6935e-02,  4.2185e+00,  5.2146e+00,\n",
      "         4.4869e+00,  9.6959e-01,  1.7833e+00,  2.3404e+00,  2.1255e+00,\n",
      "         1.0035e+00,  3.1608e-01, -6.1732e-01,  2.8457e+00,  3.3871e+00,\n",
      "         3.1234e+00,  4.6561e+00,  1.7584e+00,  3.1268e-01,  3.5295e+00,\n",
      "         2.9150e+00,  2.8380e+00,  3.7620e+00,  3.8924e+00,  4.0239e-02,\n",
      "         1.9667e+00,  3.1729e+00,  1.0922e+00,  2.9591e+00,  2.6986e+00,\n",
      "         1.3225e-01,  1.0938e+00,  3.9545e+00,  9.0275e-01,  1.8156e+00,\n",
      "         1.5500e-01,  1.5511e+00,  3.4699e+00,  1.5152e+01,  1.6638e+00,\n",
      "         4.2455e+00,  3.5082e+00,  2.0500e+00,  8.2782e-01,  5.2980e+00,\n",
      "         2.2748e+00,  1.5353e+00,  2.0409e+00,  2.8557e+00,  4.0504e+00,\n",
      "         2.2591e+00,  1.2433e+00, -1.7409e-01,  2.6247e+00,  2.0259e+00,\n",
      "         6.1022e-01,  1.2896e+00,  4.6470e+00,  4.1860e+00,  1.5639e+00,\n",
      "         2.0675e+00,  2.3797e+00,  5.3487e+00,  7.4534e-01,  3.3267e+00,\n",
      "         3.3097e+00,  1.8960e+00,  3.5867e+00,  3.8115e+00,  2.0956e+00,\n",
      "         1.4725e+00,  1.5774e+00,  2.3280e+00,  1.2815e+00,  1.2100e+00,\n",
      "         3.3091e+00,  2.2951e+00,  1.2587e+00,  7.2210e-01,  7.5943e+00,\n",
      "         3.7169e-02,  1.1851e+00,  9.8514e-01,  1.4180e+00,  4.7884e+00,\n",
      "         2.3131e+00,  8.2929e-01,  1.3737e+00,  7.2930e+00,  3.5713e-02,\n",
      "         1.2283e+00,  1.9385e+00], device='cuda:0')), ('backbone.model.layer2.0.downsample.1.bias', tensor([ 1.4662e+00,  3.3312e-01,  2.2945e+00,  1.2007e-01,  8.2862e-01,\n",
      "        -2.8029e+00,  6.2198e-01,  1.1247e+00, -2.3557e-01,  1.6016e+00,\n",
      "        -1.1942e+00,  1.1650e+00, -6.0478e-01, -1.7196e+00,  7.9190e-01,\n",
      "        -6.3432e-01,  1.4246e+00,  1.1843e+00,  2.6145e+00,  2.5874e-01,\n",
      "         1.4258e+00,  1.0583e+00,  7.0614e-02, -3.6489e-01,  8.0846e-01,\n",
      "         3.0643e-01,  1.7596e+00, -5.9738e-01,  2.6044e+00, -9.5382e-01,\n",
      "         1.6601e+00, -2.6177e-01,  2.6592e+00, -8.2097e-02,  4.2893e-01,\n",
      "         8.7054e-01, -3.5829e-02, -1.0747e-01,  5.6012e-01,  1.6797e+00,\n",
      "        -5.9809e-02, -1.0788e+00,  3.2850e+00,  1.1992e+00,  1.2813e+00,\n",
      "         8.3040e-01,  8.9093e-01,  1.6291e+00,  1.4434e-01,  1.2068e-01,\n",
      "         1.4974e+00,  7.4335e-01,  2.2760e+00,  9.2718e-01, -1.0040e+00,\n",
      "        -1.5230e+00,  6.0642e-02,  1.8876e+00,  1.5082e+00,  1.0951e+00,\n",
      "        -6.4415e-01,  7.2802e-01,  2.3917e+00,  1.2685e+00,  8.0264e-01,\n",
      "        -1.4356e+00, -2.7182e+00,  1.0201e+00, -5.5858e-01,  9.7570e-01,\n",
      "         5.3913e-01, -6.0671e-02,  1.3595e+00,  8.8758e-01, -5.6950e-01,\n",
      "         1.0016e+00,  2.3426e-01,  3.7199e-01, -2.1865e+00,  1.3308e+00,\n",
      "         9.2781e-01, -2.4985e-02,  1.0255e+00, -6.1580e-02,  3.5191e-01,\n",
      "         3.4697e-01, -1.0031e+00, -3.5505e+00, -3.9435e-01,  4.0027e-01,\n",
      "        -6.4298e+00, -5.6909e-01,  2.0333e+00, -2.3881e+00, -7.1724e-01,\n",
      "        -4.2313e-01, -1.1946e-01,  1.0995e+00, -1.1050e+00, -3.1858e-01,\n",
      "         1.7508e+00,  1.1291e+00, -8.5287e-01,  3.9303e-01,  8.8647e-01,\n",
      "        -1.2941e-01, -4.6957e-01,  1.1286e+00,  1.5478e+00, -3.7515e-02,\n",
      "         9.6553e-01, -1.2229e+00, -1.8540e+00,  1.6017e+00,  1.1714e+00,\n",
      "        -9.7210e-02, -1.9347e+00, -1.2344e-01,  2.2733e+00, -1.5972e+00,\n",
      "        -7.4609e-01,  1.6660e-02,  3.2790e-01,  1.2293e+00,  1.5935e+00,\n",
      "         1.9038e-01, -4.6747e+00,  1.7424e+00,  7.9569e-02, -4.5236e+00,\n",
      "        -8.8732e-01, -7.8449e-01,  1.0245e+00, -7.8367e-01,  1.1738e-01,\n",
      "        -7.6636e-01,  4.2368e-01,  1.8868e+00,  8.4301e-01,  1.7182e-01,\n",
      "        -1.1057e+00,  1.5327e+00,  4.2679e-01, -1.2878e+00,  1.5875e+00,\n",
      "         1.6587e+00,  1.5894e+00,  4.4307e-01,  8.9400e-01,  1.3286e+00,\n",
      "         1.4133e+00,  1.5882e+00,  3.1315e+00,  6.1942e-01,  1.6151e-01,\n",
      "        -1.5488e+00,  1.3020e+00,  2.1478e+00,  7.1642e-01,  9.5138e-01,\n",
      "         3.1905e-02,  1.4132e+00,  1.8755e+00,  4.3262e-01,  1.2840e+00,\n",
      "         1.5793e+00, -3.9040e+00,  4.7858e-01, -4.0047e-01,  1.3982e+00,\n",
      "         7.8675e-01,  1.1315e+00,  1.8163e+00,  1.2299e-02, -1.1815e+00,\n",
      "        -1.5183e+00,  1.2438e+00,  1.7396e-01,  1.3030e+00, -1.7769e-01,\n",
      "         8.3467e-01,  5.9658e-01, -3.5963e-02, -1.6350e+00, -4.4623e+00,\n",
      "         3.6729e-01,  5.2227e-01,  5.0672e-01, -4.3601e-01,  1.9429e-01,\n",
      "        -2.3844e+00, -8.8763e-02, -2.8764e+00,  9.6314e-02,  2.0560e+00,\n",
      "         1.2229e+00,  1.6848e+00,  7.8317e-01, -3.4765e-01,  3.7056e+00,\n",
      "        -1.1017e+00, -5.9016e-02, -2.5689e-01,  7.8792e-01,  1.0978e+00,\n",
      "         5.2486e-01, -1.3211e+00,  1.1115e+00,  1.3015e+00,  1.5485e+00,\n",
      "         2.2464e+00, -8.7652e-01, -2.9577e+00,  7.5478e-01,  7.6512e-01,\n",
      "        -2.3839e+00, -1.2915e+00, -2.7132e+00, -2.1637e+00, -7.0818e-01,\n",
      "        -1.1214e-01, -4.9317e-01, -3.3283e-01,  8.4129e-01,  1.5024e+00,\n",
      "        -4.1027e-01,  1.8788e-01,  6.1316e-01, -2.1413e-01, -5.6990e-01,\n",
      "        -1.8110e-01, -1.2486e-01,  4.0264e-01,  8.1462e-01,  6.0697e-01,\n",
      "         7.3324e-01,  9.8087e-01,  1.2006e+00,  8.6701e-01,  9.4966e-01,\n",
      "         2.0266e+00,  1.2579e+00,  1.7048e-01,  1.0434e+00, -1.0250e+00,\n",
      "         7.9268e-01,  2.6408e+00,  8.7609e-01,  1.6487e+00, -1.3613e+00,\n",
      "        -1.7787e+00, -1.2188e+00, -1.3951e+00,  1.3996e-01,  1.2827e+00,\n",
      "         1.4675e+00,  8.6522e-01, -1.4539e-01, -1.3884e+00,  5.0664e-01,\n",
      "        -3.2974e+00, -1.0610e+00,  8.8281e-01,  1.6316e+00,  5.2176e-01,\n",
      "         8.6399e-01, -1.5874e+00,  1.5752e+00,  8.8962e-01,  1.4462e+00,\n",
      "         1.2497e+00,  1.3683e+00, -7.1327e-01, -7.7495e-01, -2.2570e+00,\n",
      "         1.7164e+00,  6.6561e-02,  1.6487e+00,  1.8167e+00,  2.6800e-01,\n",
      "        -2.7736e+00,  6.5234e-01, -5.2576e-01, -6.5364e-01,  1.4704e+00,\n",
      "        -3.1046e-02, -1.7694e+00,  7.3175e-01, -2.4662e+00,  1.6106e+00,\n",
      "         1.1152e+00,  1.8039e+00,  1.0204e+00,  1.2804e+00,  8.3012e-01,\n",
      "         1.3040e-01, -1.1141e+00, -3.2333e-01,  9.4493e-01,  1.0394e+00,\n",
      "         1.3423e+00, -2.4896e-02, -5.1994e-01,  7.0315e-01, -9.8758e-01,\n",
      "         3.8695e-01,  1.6311e+00, -1.0891e+00,  1.0227e+00, -1.5139e+00,\n",
      "        -1.8420e+00,  9.3148e-01, -1.1559e+00,  2.4795e+00, -1.6152e+00,\n",
      "         1.2984e+00, -9.0706e+00,  3.1156e-01, -1.3936e+00, -1.6388e+00,\n",
      "        -7.2524e-01,  1.2999e+00,  1.5664e+00, -2.3811e-01, -8.7200e-01,\n",
      "         1.5156e-01,  3.4451e-02,  2.4861e+00,  5.3948e-01,  1.0277e-01,\n",
      "         5.3278e-02, -2.7521e+00, -9.8249e-03, -4.6680e-01, -2.4947e-01,\n",
      "         5.2851e-01, -3.8499e-01,  2.1732e+00, -1.7427e+00,  1.2530e+00,\n",
      "        -1.7205e+00,  1.3889e-02,  1.3433e+00,  1.5711e+00,  7.9721e-01,\n",
      "        -2.5604e-01,  9.0541e-01, -5.5125e+00,  2.0431e+00,  9.6762e-01,\n",
      "         1.1938e+00,  1.3369e-01, -9.3057e-01, -1.9761e+00,  1.9516e+00,\n",
      "         1.0132e-01,  2.1059e-01, -3.0720e-01, -1.3526e+00, -2.7396e-02,\n",
      "        -1.2975e+00, -9.4604e-03,  1.2839e+00,  5.7005e-01,  9.3288e-01,\n",
      "         6.0701e-01,  1.6276e+00,  2.0297e-01,  1.4150e+00,  3.9850e-02,\n",
      "         7.1516e-02, -2.1934e+00,  6.5841e-01, -1.6260e-01,  1.2598e-01,\n",
      "         4.7472e-01,  8.6054e-01, -1.4188e+00, -7.0318e-01, -2.9227e+00,\n",
      "         1.3922e+00,  2.0075e+00, -4.2727e-01,  2.2827e+00,  6.2678e-01,\n",
      "        -6.1530e-01,  1.1930e+00,  8.1490e-01,  1.0092e+00, -1.5774e-01,\n",
      "         1.0401e+00,  1.7709e+00, -1.0008e-01,  8.3930e-01,  7.2350e-01,\n",
      "        -1.2504e+00,  5.1632e-02,  2.5352e+00, -1.2187e+00, -1.7186e+00,\n",
      "        -1.0371e+00,  1.5539e+00, -1.7602e-01, -2.8821e+00,  1.1901e+00,\n",
      "        -8.9714e-01,  5.5429e-01,  3.1823e+00,  1.0861e+00, -6.9410e-01,\n",
      "         2.5165e+00, -2.9382e+00,  5.9030e-01, -1.3122e+00,  7.9877e-01,\n",
      "         1.6404e+00, -3.4205e-01,  2.4325e-01, -8.0951e-01, -9.1543e-01,\n",
      "         7.8596e-01,  1.5379e+00,  1.4163e+00,  9.5384e-01,  7.1578e-01,\n",
      "        -1.4653e+00,  1.9815e-01,  3.4285e-01, -6.6789e-02,  2.9644e-01,\n",
      "         1.0784e+00,  1.0200e+00, -7.6180e-01, -2.6377e+00, -9.8124e-01,\n",
      "         8.2918e-01, -2.9691e+00, -9.4201e-01, -6.8480e-01, -1.0706e+00,\n",
      "         4.4842e-01,  7.7625e-02, -9.7335e-01, -2.4026e-01, -7.2817e-01,\n",
      "         1.1074e+00, -1.9237e+00,  1.1945e+00,  1.4612e+00, -5.3470e-01,\n",
      "        -1.5807e+00,  1.5626e+00, -1.3987e+00, -1.7139e-01,  4.4649e-03,\n",
      "         1.2663e+00,  4.1069e-01, -1.6591e+00, -5.8714e+00, -4.1085e-01,\n",
      "        -6.1781e-01, -2.2914e-01,  2.7799e+00,  7.1215e-01,  4.4974e-01,\n",
      "        -2.0453e-01,  1.9351e+00,  1.7638e+00, -6.4628e-01,  3.5690e-01,\n",
      "         1.3569e+00,  2.6661e+00,  4.9333e-01, -1.0900e-01,  1.5011e+00,\n",
      "         2.1255e+00,  7.3171e-01, -1.1783e+00,  2.0355e+00, -1.4523e+00,\n",
      "         7.2171e-01,  2.5612e-01, -9.6569e-02, -7.7973e-01,  1.8832e+00,\n",
      "         1.0784e+00,  6.3527e-01, -3.5240e-01, -4.1867e-01, -2.5145e-01,\n",
      "         1.4494e+00,  1.2196e+00,  7.0959e-01,  2.1452e+00,  1.1163e+00,\n",
      "         7.1705e-01, -7.2336e-01,  1.2256e+00,  2.2249e+00, -1.4227e+00,\n",
      "        -8.5531e-01,  1.8397e+00,  1.8449e+00,  1.3274e+00, -2.1221e-01,\n",
      "        -8.4513e-01,  1.8551e+00,  2.0417e+00, -1.1555e+00, -9.3590e-01,\n",
      "         9.7671e-01,  1.5253e-01], device='cuda:0')), ('backbone.model.layer2.1.conv1.weight', tensor([[[[-7.1208e-02]],\n",
      "\n",
      "         [[ 4.0799e-02]],\n",
      "\n",
      "         [[ 1.1406e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6990e-07]],\n",
      "\n",
      "         [[-2.0584e-01]],\n",
      "\n",
      "         [[-1.1116e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5885e-02]],\n",
      "\n",
      "         [[-4.7515e-02]],\n",
      "\n",
      "         [[-2.6467e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7372e-07]],\n",
      "\n",
      "         [[ 1.0114e-01]],\n",
      "\n",
      "         [[ 4.8603e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9571e-02]],\n",
      "\n",
      "         [[ 4.4194e-02]],\n",
      "\n",
      "         [[-6.0700e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3386e-06]],\n",
      "\n",
      "         [[-3.9330e-02]],\n",
      "\n",
      "         [[-1.4925e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.6771e-02]],\n",
      "\n",
      "         [[ 9.6230e-02]],\n",
      "\n",
      "         [[ 4.6856e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8692e-07]],\n",
      "\n",
      "         [[ 4.3925e-02]],\n",
      "\n",
      "         [[-1.4971e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7222e-02]],\n",
      "\n",
      "         [[-3.2712e-03]],\n",
      "\n",
      "         [[ 4.2790e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2774e-07]],\n",
      "\n",
      "         [[-3.8975e-02]],\n",
      "\n",
      "         [[-2.4785e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4901e-02]],\n",
      "\n",
      "         [[ 4.9066e-03]],\n",
      "\n",
      "         [[-6.2396e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5563e-07]],\n",
      "\n",
      "         [[-1.0124e-01]],\n",
      "\n",
      "         [[ 7.6349e-03]]]], device='cuda:0')), ('backbone.model.layer2.1.bn1.weight', tensor([2.7963, 1.4807, 3.2186, 3.8779, 2.2763, 1.5781, 2.5374, 2.0274, 2.1254,\n",
      "        2.0726, 2.6967, 1.1769, 2.1917, 2.9028, 2.1061, 1.5712, 4.8172, 1.7801,\n",
      "        2.3305, 1.8804, 1.3707, 2.3472, 2.4419, 2.3963, 2.5802, 1.7289, 7.4525,\n",
      "        1.5467, 1.6810, 2.4365, 2.1430, 2.3562, 2.0898, 1.8603, 2.6200, 2.6481,\n",
      "        1.7822, 1.5173, 1.9484, 1.7651, 1.2735, 1.9048, 2.0350, 1.3439, 1.2905,\n",
      "        2.4395, 2.5872, 2.5914, 1.8516, 1.2112, 2.0882, 1.5786, 1.7906, 2.1635,\n",
      "        1.4491, 2.0385, 2.6344, 2.1038, 1.5583, 2.5336, 2.1546, 1.6318, 2.5240,\n",
      "        1.2420, 2.3705, 2.2609, 2.4633, 1.9454, 1.2956, 1.8542, 2.1096, 1.3950,\n",
      "        2.0469, 2.3939, 2.5996, 2.2015, 1.1296, 1.5466, 1.5799, 1.5908, 3.5469,\n",
      "        1.8307, 3.2651, 3.0546, 1.4346, 2.0385, 2.0620, 2.5240, 2.0525, 1.3457,\n",
      "        1.7376, 2.0316, 1.8102, 2.0156, 1.7798, 2.3330, 1.7866, 2.8689, 1.6756,\n",
      "        1.8886, 1.8848, 1.6041, 2.3510, 1.6524, 1.7988, 2.5263, 0.7924, 1.6921,\n",
      "        1.9042, 1.9570, 2.1635, 1.8580, 1.5632, 1.4245, 1.7273, 1.6268, 2.2759,\n",
      "        2.0657, 2.8535, 1.9216, 2.2493, 1.9185, 2.3742, 2.6744, 2.1453, 1.8920,\n",
      "        2.1691, 2.4774], device='cuda:0')), ('backbone.model.layer2.1.bn1.bias', tensor([ 1.4466e+00,  1.3653e+00, -1.5486e+00, -3.0071e+00, -1.2278e-01,\n",
      "         7.9534e-02,  7.8720e-01, -3.0614e+00, -3.0232e-01,  3.4797e-01,\n",
      "        -2.8688e+00,  1.3315e+00, -2.4656e-01, -7.8004e-01, -4.0506e-01,\n",
      "        -1.7086e+00, -7.9976e-01, -7.6275e-01,  2.5768e-01, -1.7857e+00,\n",
      "        -8.5062e-01, -3.2159e+00, -6.3335e-01, -9.0335e-02, -8.8182e-02,\n",
      "         1.1639e+00, -3.1562e+00, -1.8160e+00,  1.6114e+00, -2.3555e-01,\n",
      "        -2.6678e+00, -5.6148e-01,  9.5718e-01, -2.1194e+00, -3.3098e-01,\n",
      "        -3.9871e-02, -1.8219e+00, -1.1992e+00,  5.6626e-01, -5.5666e-01,\n",
      "         9.8221e-02, -2.1368e+00,  2.2642e-01,  1.7353e-01,  7.6880e-01,\n",
      "         2.2891e-01, -9.8506e-01, -3.1876e+00, -2.0045e+00, -3.1120e-04,\n",
      "         4.6742e-01,  7.1150e-01,  2.2822e-02, -3.0200e+00, -6.0963e-01,\n",
      "        -8.8773e-01, -1.5008e+00, -1.1813e+00,  1.9635e+00, -9.5776e-01,\n",
      "        -1.3287e+00,  2.2552e-01, -8.2502e-02, -1.8738e+00, -1.5815e+00,\n",
      "        -8.4408e-01, -3.5549e+00, -1.4560e-01,  6.1872e-01, -2.2749e-01,\n",
      "        -1.7157e+00, -2.9295e-01, -9.2586e-01, -2.2672e-01,  1.6840e-01,\n",
      "        -3.0156e+00,  9.3028e-01, -1.1181e-01, -4.9884e-01, -3.8534e-01,\n",
      "        -3.3860e+00, -9.4449e-01,  1.0766e+00, -3.6876e-01,  4.2811e-01,\n",
      "         2.2184e-01, -3.3568e+00,  7.4144e-01, -9.1788e-01, -2.0602e+00,\n",
      "        -9.8428e-01, -6.2544e-01, -7.0767e-01,  1.7810e-01, -1.7412e+00,\n",
      "        -3.9990e-01,  4.8414e-01, -8.7979e-01,  7.6643e-02, -2.1764e+00,\n",
      "        -2.3276e+00,  9.0054e-01,  1.2647e-01,  4.7541e-01, -2.8590e+00,\n",
      "        -1.7723e+00, -5.0603e-02,  8.0450e-01, -2.4050e-01,  7.3706e-01,\n",
      "        -2.4951e+00, -1.3044e+00,  7.9180e-02,  8.8719e-01, -2.9511e+00,\n",
      "         9.2614e-02,  4.2875e-01, -1.8084e+00, -3.3991e-01, -1.8815e+00,\n",
      "         4.6907e-01, -3.9751e-01, -3.7863e+00, -9.7480e-01, -1.2641e+00,\n",
      "        -6.5815e-01, -2.7597e+00, -5.7840e-01], device='cuda:0')), ('backbone.model.layer2.1.conv2.weight', tensor([[[[-0.0211, -0.0477, -0.0202],\n",
      "          [ 0.0191, -0.0074, -0.0436],\n",
      "          [ 0.0139,  0.0095, -0.0385]],\n",
      "\n",
      "         [[ 0.0191,  0.0136,  0.0082],\n",
      "          [-0.0174,  0.0146,  0.1208],\n",
      "          [-0.0076, -0.0023,  0.0424]],\n",
      "\n",
      "         [[ 0.0633,  0.0083,  0.0279],\n",
      "          [ 0.0154,  0.0142,  0.0476],\n",
      "          [ 0.0789,  0.0691,  0.0504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0464, -0.0311,  0.0291],\n",
      "          [ 0.0004,  0.0153, -0.0453],\n",
      "          [-0.0419,  0.0516, -0.0166]],\n",
      "\n",
      "         [[ 0.0141,  0.0382,  0.0434],\n",
      "          [-0.0289,  0.0578,  0.0410],\n",
      "          [-0.0470, -0.0539, -0.0107]],\n",
      "\n",
      "         [[-0.0214,  0.0916,  0.0224],\n",
      "          [-0.0504, -0.0687, -0.0395],\n",
      "          [ 0.0628,  0.0928, -0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0215, -0.1318,  0.0304],\n",
      "          [ 0.0061, -0.2426, -0.0467],\n",
      "          [-0.0085,  0.1016,  0.0631]],\n",
      "\n",
      "         [[ 0.0058, -0.0324, -0.1917],\n",
      "          [ 0.0498, -0.0122, -0.1451],\n",
      "          [ 0.1162,  0.0787, -0.0357]],\n",
      "\n",
      "         [[ 0.0411,  0.0279,  0.0261],\n",
      "          [ 0.0251,  0.0280,  0.0907],\n",
      "          [-0.0068, -0.0498,  0.0497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0111, -0.0123, -0.0343],\n",
      "          [-0.0079, -0.2506, -0.0808],\n",
      "          [ 0.1261, -0.1199,  0.0790]],\n",
      "\n",
      "         [[-0.0113, -0.0199, -0.0128],\n",
      "          [ 0.0015, -0.1391,  0.0173],\n",
      "          [-0.0187, -0.0130,  0.0126]],\n",
      "\n",
      "         [[-0.0425,  0.0318,  0.0168],\n",
      "          [ 0.0957,  0.1445,  0.0625],\n",
      "          [-0.0146, -0.0599,  0.0110]]],\n",
      "\n",
      "\n",
      "        [[[-0.0572, -0.0098,  0.0359],\n",
      "          [-0.0175, -0.0784, -0.0416],\n",
      "          [-0.0050, -0.0356, -0.0557]],\n",
      "\n",
      "         [[ 0.0716,  0.1091,  0.0246],\n",
      "          [ 0.0030, -0.0440, -0.1129],\n",
      "          [-0.0175,  0.0380, -0.0133]],\n",
      "\n",
      "         [[-0.0205, -0.0426,  0.0286],\n",
      "          [ 0.1381,  0.1201,  0.0914],\n",
      "          [ 0.0419,  0.0334,  0.0773]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0136, -0.0065, -0.1230],\n",
      "          [-0.0190,  0.0328,  0.1658],\n",
      "          [ 0.0920,  0.1097,  0.0014]],\n",
      "\n",
      "         [[-0.0058,  0.0129,  0.0495],\n",
      "          [ 0.0304, -0.0613,  0.0434],\n",
      "          [ 0.0625,  0.0650, -0.0629]],\n",
      "\n",
      "         [[-0.0106, -0.0024,  0.0654],\n",
      "          [-0.0108,  0.0205,  0.0081],\n",
      "          [ 0.0065,  0.0594,  0.0869]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0200, -0.0525, -0.0145],\n",
      "          [-0.0115, -0.2936,  0.0877],\n",
      "          [ 0.0012, -0.1097,  0.0525]],\n",
      "\n",
      "         [[-0.0631, -0.0223, -0.0041],\n",
      "          [-0.1238, -0.1522,  0.1024],\n",
      "          [-0.0432, -0.0591,  0.0270]],\n",
      "\n",
      "         [[-0.0171,  0.0037,  0.0417],\n",
      "          [-0.0599,  0.0725,  0.1139],\n",
      "          [ 0.0308,  0.0283,  0.0792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0310,  0.0738, -0.0027],\n",
      "          [-0.0356,  0.0816,  0.1166],\n",
      "          [-0.0122,  0.0520, -0.0035]],\n",
      "\n",
      "         [[-0.0062, -0.0690, -0.0191],\n",
      "          [ 0.0630, -0.1161,  0.0145],\n",
      "          [-0.0299,  0.0433,  0.1179]],\n",
      "\n",
      "         [[ 0.0156, -0.0025,  0.0114],\n",
      "          [-0.0018, -0.0315,  0.1325],\n",
      "          [-0.0107,  0.0092,  0.0596]]],\n",
      "\n",
      "\n",
      "        [[[-0.0283, -0.0225, -0.0526],\n",
      "          [-0.0054,  0.0059,  0.0052],\n",
      "          [-0.0080, -0.1187,  0.0164]],\n",
      "\n",
      "         [[ 0.0482,  0.0021, -0.0204],\n",
      "          [-0.0619,  0.0722, -0.0370],\n",
      "          [-0.1231,  0.1738,  0.0456]],\n",
      "\n",
      "         [[ 0.0472, -0.0305, -0.0478],\n",
      "          [-0.0882, -0.0469,  0.0091],\n",
      "          [-0.0307, -0.1309, -0.0561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0084, -0.0331, -0.0005],\n",
      "          [-0.0074,  0.0216, -0.0538],\n",
      "          [ 0.0249, -0.0939, -0.1052]],\n",
      "\n",
      "         [[ 0.0028,  0.0321,  0.0429],\n",
      "          [ 0.0885, -0.0757,  0.0417],\n",
      "          [ 0.0890, -0.0824,  0.0961]],\n",
      "\n",
      "         [[ 0.0214, -0.0220, -0.0023],\n",
      "          [ 0.0322,  0.0391,  0.0320],\n",
      "          [ 0.0408,  0.0743, -0.0246]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0585, -0.0332,  0.0129],\n",
      "          [ 0.0968,  0.0160,  0.0471],\n",
      "          [-0.0214,  0.0621,  0.0333]],\n",
      "\n",
      "         [[ 0.0237,  0.0470,  0.0972],\n",
      "          [-0.0871,  0.0423,  0.1314],\n",
      "          [-0.0566,  0.0528,  0.0616]],\n",
      "\n",
      "         [[-0.0651, -0.0447,  0.0354],\n",
      "          [-0.0517,  0.0446,  0.1071],\n",
      "          [ 0.0003,  0.0072,  0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0330, -0.0146,  0.0424],\n",
      "          [ 0.0948, -0.0266,  0.0032],\n",
      "          [ 0.0131, -0.0211, -0.0127]],\n",
      "\n",
      "         [[-0.0079, -0.0077, -0.0651],\n",
      "          [-0.0268, -0.0627, -0.0419],\n",
      "          [ 0.0124, -0.1505, -0.1105]],\n",
      "\n",
      "         [[-0.0192,  0.1122,  0.0306],\n",
      "          [ 0.0531, -0.0725, -0.0051],\n",
      "          [-0.0879, -0.0288, -0.0032]]]], device='cuda:0')), ('backbone.model.layer2.1.bn2.weight', tensor([2.4630, 2.3990, 2.5384, 2.2259, 3.2885, 1.6490, 2.4192, 2.9999, 1.7369,\n",
      "        2.8978, 3.2402, 2.4004, 2.3489, 2.0790, 1.4635, 2.1317, 2.3882, 1.7116,\n",
      "        2.7667, 2.1499, 2.3669, 1.7359, 1.4175, 1.6218, 1.8692, 2.4789, 1.7392,\n",
      "        2.2216, 1.7413, 1.6163, 2.0984, 1.7253, 2.0846, 2.3938, 2.3226, 2.5546,\n",
      "        1.5866, 2.3967, 1.8207, 1.3779, 1.9622, 2.1001, 1.6506, 2.3061, 2.0708,\n",
      "        2.2775, 1.8257, 2.4021, 2.4587, 2.3057, 1.9357, 2.1473, 3.5111, 1.9857,\n",
      "        1.7744, 1.7119, 2.0294, 2.5292, 2.1704, 2.6607, 2.4563, 4.1119, 1.3442,\n",
      "        2.0500, 1.3585, 2.5023, 1.1861, 2.1202, 1.8290, 1.4105, 2.1658, 2.4142,\n",
      "        1.9240, 1.8155, 2.5274, 2.2318, 2.5050, 1.8814, 1.8406, 2.2357, 2.5335,\n",
      "        1.7294, 2.6681, 2.9143, 2.2941, 1.7454, 2.0093, 1.7076, 1.9080, 1.4604,\n",
      "        2.1776, 2.5097, 1.8451, 1.6364, 1.8910, 2.0441, 2.0498, 1.9414, 1.9301,\n",
      "        2.7402, 1.9375, 1.8810, 2.0456, 1.7579, 2.0691, 1.8154, 1.8784, 1.9177,\n",
      "        2.1405, 2.3574, 1.4262, 1.8220, 1.3778, 2.4319, 2.7258, 1.7797, 2.4666,\n",
      "        1.7357, 3.0922, 2.4248, 2.3939, 1.9402, 1.8279, 1.7519, 3.2987, 2.3488,\n",
      "        2.3261, 2.1310], device='cuda:0')), ('backbone.model.layer2.1.bn2.bias', tensor([-2.9496,  0.2227, -1.7529,  0.1352, -1.1702,  1.1935, -2.3078, -0.0483,\n",
      "        -1.8907,  1.2571,  0.7828,  0.9941, -0.6311, -1.0811,  0.8574, -1.6915,\n",
      "        -1.0765,  0.7641, -0.6709, -2.5409, -1.2832,  1.3186, -0.0999, -1.4872,\n",
      "        -3.0797,  0.3449,  0.4840,  0.7355, -1.4562, -0.5829,  0.6535, -0.2702,\n",
      "        -2.8599,  1.0143,  0.0664, -1.1527,  0.1545, -1.5421, -1.1693,  1.1555,\n",
      "        -0.5297, -1.3744,  1.2661, -0.5513, -0.8627,  1.1091, -1.0918,  0.1271,\n",
      "        -1.3752, -1.8309,  1.5315, -0.6099, -1.4871,  1.6547, -1.3771, -0.6163,\n",
      "         0.3779,  0.8320, -2.0474,  0.2080, -1.0694, -1.9522,  0.4643, -2.1945,\n",
      "         0.4554, -1.3259,  0.7541, -1.8723,  0.1450,  1.1721, -3.2052, -0.1413,\n",
      "         0.5139,  0.1243, -1.5526, -1.9554,  0.0289, -2.6241, -0.2150,  0.4996,\n",
      "        -2.6455,  0.6104,  0.1847, -3.3322,  1.4646, -0.1191, -1.8661, -0.8136,\n",
      "        -0.8831,  0.4912,  0.0707, -2.8699, -1.3456, -0.8598, -0.3515,  1.7579,\n",
      "        -2.5627,  0.4397,  1.0500, -0.7471,  0.2436,  0.3774, -2.0730,  0.3199,\n",
      "        -0.5398,  0.5928, -1.9123,  0.5816, -0.1172, -2.1307,  0.2222,  0.1248,\n",
      "        -0.3435, -2.1249, -0.0230, -0.0196,  0.8508, -1.2917,  0.3283, -2.0193,\n",
      "         0.2073, -1.2642,  0.2927, -1.4780, -3.5346,  1.3716,  0.6984, -2.2283],\n",
      "       device='cuda:0')), ('backbone.model.layer2.1.conv3.weight', tensor([[[[-0.0231]],\n",
      "\n",
      "         [[-0.0955]],\n",
      "\n",
      "         [[ 0.0204]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1098]],\n",
      "\n",
      "         [[-0.1635]],\n",
      "\n",
      "         [[-0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0217]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         [[ 0.0493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627]],\n",
      "\n",
      "         [[ 0.0038]],\n",
      "\n",
      "         [[ 0.0086]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0002]],\n",
      "\n",
      "         [[-0.1335]],\n",
      "\n",
      "         [[-0.0739]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0702]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[ 0.0111]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0432]],\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         [[-0.0226]],\n",
      "\n",
      "         [[-0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0050]],\n",
      "\n",
      "         [[ 0.0130]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         [[-0.0223]]],\n",
      "\n",
      "\n",
      "        [[[-0.0536]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.1463]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0274]],\n",
      "\n",
      "         [[ 0.0505]],\n",
      "\n",
      "         [[-0.0507]]]], device='cuda:0')), ('backbone.model.layer2.1.bn3.weight', tensor([ 3.4573e+00,  5.6236e-01, -4.1266e+00,  7.2433e-01,  3.4651e-02,\n",
      "         2.6664e-02,  2.4844e+00,  9.4162e-01, -6.3927e-01, -1.8457e+00,\n",
      "        -2.1123e-01,  2.8683e+00, -3.0488e+00, -1.0418e-01, -2.3043e-01,\n",
      "         1.3478e-01, -2.7870e+00, -2.3106e+00, -1.3027e+01, -1.8402e-01,\n",
      "         8.8408e-01,  7.3213e-01,  7.2974e-01, -1.7498e-01,  4.0356e+00,\n",
      "        -6.5109e+00,  1.5971e+00, -4.8956e-02, -3.7552e+00, -2.6074e+00,\n",
      "         1.9047e+00, -4.0317e-02,  2.2296e+00,  8.3217e+00,  6.7441e-01,\n",
      "        -7.9957e-01,  4.3501e+00, -1.4135e-02,  2.4439e+00, -7.2447e-01,\n",
      "         3.2812e+00,  3.5427e-03, -6.7761e+00, -1.5254e+00,  9.1105e-02,\n",
      "         2.5481e+00,  2.3823e+00, -2.6598e+00,  3.2810e+00, -8.2729e-02,\n",
      "         2.4355e+00, -1.9415e+00,  1.4000e+00, -2.5690e+00,  3.2185e-02,\n",
      "        -1.1476e-02, -2.5410e-01,  2.7317e+00, -1.1278e+01,  4.3319e-02,\n",
      "        -2.1874e-02, -2.7412e+00,  2.9323e+00,  2.3237e+00,  3.3771e+00,\n",
      "         1.0210e-01, -1.9397e-01,  8.8463e-01,  1.2114e+00,  1.3170e+00,\n",
      "        -3.2835e+00, -5.5215e+00,  2.3290e+00, -5.4782e-01, -3.4598e-01,\n",
      "        -4.0016e+00, -1.2783e-02, -2.2577e+00, -3.3710e-02,  2.1120e-02,\n",
      "        -1.8382e+00, -4.5028e-01, -8.3953e-01, -2.2117e-01,  3.6045e-01,\n",
      "         4.2683e-01, -1.5743e-02, -5.7698e-03, -3.0018e+00, -1.8791e-02,\n",
      "        -9.5166e-01,  1.6129e-02,  2.5643e+00, -2.1278e-01,  1.3087e+00,\n",
      "        -1.1936e-01, -1.1402e+00, -6.3374e+00, -3.6441e+00,  2.8786e-01,\n",
      "         2.8031e-01, -8.3086e-01, -1.1894e+00,  5.6749e-01,  5.6247e+00,\n",
      "        -8.0153e-01, -3.9186e+00,  1.1559e+00, -2.6328e+00, -7.2306e-01,\n",
      "        -8.9686e-01,  1.2157e-01,  2.3536e-01,  2.4298e+00,  8.3806e-01,\n",
      "         2.2364e+00, -2.7117e-02, -3.0153e-01,  2.6293e+00, -2.6812e-02,\n",
      "        -3.2505e+00, -2.8923e+00, -6.6606e-01,  2.4772e+00, -3.3553e+00,\n",
      "         4.9619e-01, -1.7405e-01,  2.6808e+00,  1.6977e+00, -1.5708e+00,\n",
      "         1.2587e+00,  4.7782e-02, -2.7142e+00, -3.3421e-03,  2.8212e-01,\n",
      "         1.5684e+00,  9.9568e-01, -1.1779e+00,  4.3985e+00,  2.2888e+00,\n",
      "        -6.2573e-03, -5.5719e+00, -1.8551e+00, -1.7052e-01, -2.6829e+00,\n",
      "         3.6252e+00,  3.5536e+00, -3.8827e+00,  2.5260e+00,  8.9283e-01,\n",
      "        -2.5715e+00,  8.8996e+00, -3.3078e+00,  3.4547e-02,  1.3777e-02,\n",
      "        -1.0400e-01,  1.4096e+01,  2.4924e-01,  9.3792e-03,  5.6324e+00,\n",
      "         1.7464e+00, -8.6536e-01, -3.0063e+00,  1.1781e+00, -2.5916e+00,\n",
      "        -3.3334e+00,  1.1576e+01,  2.3640e+00, -3.2659e+00, -6.6199e+00,\n",
      "         3.5622e-01,  2.2484e+00,  1.0439e+00,  4.0642e-01,  1.0252e-01,\n",
      "        -1.5078e-01,  9.1269e-01,  1.7815e+00,  3.5236e+00, -8.4713e-02,\n",
      "        -9.8839e+00,  3.4248e+00, -4.4142e-02,  1.4357e-01, -1.6915e-01,\n",
      "        -1.7045e+00, -9.5336e-02, -5.1801e+00,  2.0273e-02,  2.0419e-01,\n",
      "        -6.7858e-01, -4.1437e+00,  7.0516e-02,  3.2506e+00, -2.7320e+00,\n",
      "         2.2419e+00, -5.7369e-01,  3.8964e-01, -4.5245e+00,  3.0559e+00,\n",
      "        -3.1628e-01,  1.4359e-02,  1.9227e+00,  1.4739e+00, -1.2282e-01,\n",
      "        -5.4496e-03, -1.4045e+00,  9.8231e-01,  2.6233e+00, -2.2981e+00,\n",
      "        -8.2236e-01, -3.6016e-02,  5.2460e-01, -2.3567e+00, -7.6085e-01,\n",
      "         8.2825e-01,  2.9603e-02, -6.1483e-02, -1.0653e-01, -1.1048e-02,\n",
      "        -1.7899e-01, -2.7152e-02, -9.2607e-03, -2.2607e+00,  2.0436e+00,\n",
      "        -2.8212e+00,  1.5578e-01, -1.2971e+00,  1.3551e+00,  1.2477e-01,\n",
      "        -1.1229e-02,  8.9316e-04, -3.7261e-02,  1.3371e+00,  3.1317e+00,\n",
      "         3.6917e+00,  1.5832e+00, -3.2111e+00,  1.9179e-02,  2.4666e+00,\n",
      "        -1.8842e+00,  2.5863e-01,  3.2277e+00, -1.4160e+00,  2.0593e+00,\n",
      "         1.5642e-02, -2.2442e+00,  1.2354e+00,  1.5607e+00,  3.3666e-02,\n",
      "         1.4402e-01, -5.5927e-03, -1.2437e-02, -1.5213e-03,  2.3523e+00,\n",
      "        -3.2801e+00, -2.2976e+00,  7.0443e-05,  2.2683e-02,  1.1155e-01,\n",
      "         2.4192e-01, -6.7929e-01, -3.1946e+00, -1.4506e+00,  1.5656e-01,\n",
      "        -1.4491e-02, -2.0105e+00,  7.8490e-01,  4.2646e+00,  2.5724e+00,\n",
      "        -3.4302e+00, -2.7527e+00,  1.4589e+00, -1.9330e+00,  2.1687e-01,\n",
      "        -1.4236e+00,  3.2506e+00, -4.0976e-01,  5.5731e+00, -3.7845e+00,\n",
      "         2.3341e-01,  1.1062e+00,  3.9251e-01,  2.6562e-02,  1.1019e+00,\n",
      "         4.6374e-03, -2.2640e-01, -2.4142e+00,  4.1446e-01,  2.3352e+00,\n",
      "        -1.1246e+00,  1.0393e+00, -2.4538e+01,  8.1165e-01, -6.5685e-01,\n",
      "         4.4141e-01, -2.7334e-02,  4.5584e-01,  4.2918e-01,  1.4989e+00,\n",
      "        -3.5068e-03, -2.4614e-02,  1.0598e-01, -3.5372e-01, -1.5138e-01,\n",
      "         1.4105e-03, -5.0746e-01, -3.5819e-02,  9.0768e-01, -5.8001e-02,\n",
      "         1.9902e+00, -3.4320e+00, -2.0787e+00,  1.4754e+00,  1.9611e-01,\n",
      "         5.3731e+00, -4.8376e+00, -2.1140e-02,  4.4894e-02,  7.0826e-01,\n",
      "        -1.8032e-02,  5.6542e-01, -7.3830e-01,  3.3043e-01,  2.5956e+00,\n",
      "         7.4657e+00,  1.7049e-02,  3.6028e+00,  3.0964e-01,  1.8329e+00,\n",
      "        -1.6398e+00, -9.4079e-01, -1.1807e+00,  1.7654e-01,  4.0723e+00,\n",
      "        -6.5830e-01, -4.4690e+00,  1.3339e+00,  1.6507e+00,  3.2991e+00,\n",
      "         2.6363e-01, -5.2455e-01, -2.2479e+00,  3.5886e+00, -2.7232e+00,\n",
      "        -7.0447e-01, -6.9091e-01, -7.3668e-02,  2.4298e+00,  3.0328e+00,\n",
      "         1.2937e+00,  1.3613e+00,  3.6027e-01, -5.6955e-01, -2.0698e+00,\n",
      "         2.1972e-01,  2.8168e+00, -1.7331e-02, -6.3945e-01,  2.2391e-01,\n",
      "        -6.7132e-03, -1.4163e-02,  9.2588e-01,  6.0031e-01,  5.6323e-01,\n",
      "         2.3295e+00, -4.7878e+00,  1.2407e+00, -3.0849e+00, -3.0075e+00,\n",
      "        -4.9385e+00, -2.9642e+00,  2.5841e+00, -5.7932e-01,  9.2421e-01,\n",
      "        -1.0190e+00,  2.3981e+00,  5.8838e-02,  6.1468e-02, -4.7870e-02,\n",
      "         3.4522e+00,  1.2592e+00,  5.1354e+00, -7.8083e-01, -2.2804e+00,\n",
      "         2.4620e-01, -6.9021e-01, -2.2580e-04,  3.4999e+00, -2.1917e+00,\n",
      "        -2.4179e+00,  9.9815e-01,  1.5398e+00,  3.2508e+00,  5.1653e-02,\n",
      "        -1.6236e-02,  5.5802e+00,  4.2767e-01,  1.0555e-02,  5.7716e-02,\n",
      "        -7.6172e-01, -1.4034e+00,  6.0359e-01,  6.0178e-01, -6.3459e-01,\n",
      "        -4.2185e+00, -8.3275e-01,  1.1475e+01, -2.7760e+00, -1.5440e-01,\n",
      "         1.0450e+01, -9.0650e-02,  8.4674e-01,  1.0135e-02, -2.9815e+00,\n",
      "         3.2024e+00, -2.4237e-01,  7.2913e-01,  4.1005e+00,  8.3280e-01,\n",
      "         7.8195e-01, -3.1046e+00,  5.6455e+00, -1.0456e+01,  1.1899e-02,\n",
      "        -9.0614e-01, -3.6139e+00, -1.3839e+00,  6.7826e-01,  2.6897e+00,\n",
      "        -2.8821e+00,  5.7299e+00, -1.8538e+00, -5.2231e-01, -3.4442e-02,\n",
      "        -5.2338e-01, -1.3742e+00, -8.4564e-03, -2.4631e+00,  1.3957e-02,\n",
      "        -3.5397e-02, -1.7456e-01,  4.2589e-02, -2.8770e-02, -3.7677e+00,\n",
      "         4.7468e-01, -4.8706e-02,  4.5388e-01,  4.1633e-01,  4.7829e-01,\n",
      "         2.7783e+00, -2.3960e+00, -1.3048e-01,  1.6289e+00,  1.5898e+00,\n",
      "         5.7274e+00, -1.9091e-01, -9.1275e-02,  1.6001e+01,  7.2665e-03,\n",
      "         1.2950e+00,  3.4612e-01, -2.1706e+00, -2.8998e+00,  6.2802e-01,\n",
      "         3.6223e+00,  2.1601e-01, -1.4223e+00, -1.8501e-02,  4.2752e-01,\n",
      "        -3.9906e+00, -4.1625e+00, -2.4442e+00,  6.1871e+00, -2.8835e+00,\n",
      "        -2.3867e+00, -1.8702e+00,  2.7311e-02, -4.6491e-01,  2.1747e+00,\n",
      "         2.0553e+00, -1.7798e-01,  1.3785e-02, -4.0757e+00,  8.8342e-01,\n",
      "         4.6844e-01,  8.1824e-01, -2.7010e-01,  5.6578e-01, -2.3322e-03,\n",
      "         9.4081e-02, -4.5608e+00, -2.5651e+00, -1.7410e+00, -2.8219e+00,\n",
      "        -7.1415e-01, -3.7489e-02, -3.4621e+00,  3.1690e+00, -4.0365e-02,\n",
      "        -3.5478e+00, -3.6968e+00, -2.8169e+00, -1.6455e+00, -1.9186e-02,\n",
      "         2.0452e-01,  3.1770e+00,  3.2584e+00,  7.4265e-02, -2.9182e+00,\n",
      "         4.4100e+00, -1.0846e+00], device='cuda:0')), ('backbone.model.layer2.1.bn3.bias', tensor([-3.9757e-01, -1.5368e-01, -1.9053e+00, -1.4472e-01, -6.2918e-03,\n",
      "        -4.9819e-02,  4.8095e-01,  1.9882e-01, -7.1606e-01,  2.4985e-01,\n",
      "         5.7262e-02, -8.1078e-01, -1.0714e-01, -7.6874e-02, -2.2175e-02,\n",
      "        -1.5624e-02, -1.0658e+00, -1.8747e+00, -1.3667e+01,  2.9291e-03,\n",
      "        -1.0293e-01, -1.5651e-01,  5.9951e-02, -2.7505e-02,  4.0804e-01,\n",
      "        -4.6841e-02,  2.5704e-01, -1.8171e-02, -2.1027e+00,  4.8749e-01,\n",
      "        -7.9008e-02, -3.6419e-02, -1.1962e+00, -8.7108e-01, -2.8046e-01,\n",
      "        -4.5517e-01, -2.0481e+00, -1.9575e-02,  2.6444e-01, -3.8017e-01,\n",
      "        -6.4595e-01, -5.5522e-04,  1.1921e-01, -7.9997e-01, -5.3449e-03,\n",
      "         9.2589e-03, -1.0128e+00, -2.4248e+00, -6.3457e-01, -9.6929e-02,\n",
      "        -3.3171e-01,  7.9856e-01, -4.2841e-01, -3.7185e-01, -2.6009e-02,\n",
      "         4.3222e-03, -9.2544e-02, -1.3085e+00, -1.7481e+01,  1.4989e-02,\n",
      "        -3.2850e-02, -1.5924e-01, -5.8901e-01, -1.4984e+00,  5.9128e-01,\n",
      "        -4.6479e-02, -1.6210e-01, -3.0446e-01,  4.4559e-01, -4.4912e-01,\n",
      "         2.8507e+00, -8.5541e-01,  5.5060e-01, -1.8903e-01, -7.8910e-02,\n",
      "        -9.1031e-03, -1.1378e-02, -2.0060e+00,  5.6769e-02, -4.2795e-03,\n",
      "        -5.8690e-01, -1.5360e-01, -4.8882e-01, -1.1273e-01, -6.4403e-02,\n",
      "        -2.6270e-01, -1.2744e-02, -2.9609e-02,  2.5543e-01, -1.5006e-02,\n",
      "        -3.0468e-01,  2.8466e-03, -5.8908e-01, -1.6203e-01,  1.2019e-01,\n",
      "        -5.9880e-02, -1.7572e-01, -4.0538e+00,  1.0645e+00, -2.7343e-01,\n",
      "        -1.3694e-01, -7.0253e-01, -7.1276e-02, -2.8742e-01,  1.1668e+00,\n",
      "        -4.6314e-01,  1.4866e-01, -1.4294e-01, -2.1406e+00, -2.8615e-01,\n",
      "        -3.2758e-01,  7.8085e-02, -2.2667e-01, -3.7332e-01, -7.4118e-01,\n",
      "         1.2502e+00, -8.0933e-03,  1.4010e-01, -4.1979e-01, -2.6036e-02,\n",
      "         1.2451e+00, -9.7940e-01, -1.2769e+00, -4.3643e-01,  1.4104e-01,\n",
      "        -2.7896e-01,  2.2133e-01, -7.8166e-01, -4.6131e-01, -2.7661e+00,\n",
      "        -4.2733e-01, -5.4613e-02, -1.6312e+00, -1.7166e-02, -5.9383e-01,\n",
      "        -3.5649e-01, -2.3820e-01, -1.1917e+00, -8.7155e-01, -4.4410e-01,\n",
      "        -1.7881e-02, -1.6465e+01, -1.3347e+00, -2.8235e-02,  8.0818e-03,\n",
      "        -8.2592e-01, -1.1562e+00,  3.4374e+00, -3.7346e-01, -4.4435e-01,\n",
      "        -5.3454e-01,  1.7794e+00, -2.3711e+00, -6.3877e-02, -9.6509e-03,\n",
      "         1.4432e-01, -8.2320e+00, -2.8448e-01, -4.0282e-04,  1.7950e+00,\n",
      "         7.6701e-01, -3.6501e-02,  1.0273e-01, -5.7834e-01, -8.9946e-01,\n",
      "        -9.5609e-01, -2.3813e+00, -9.2717e-01, -2.2549e+00, -1.8441e+00,\n",
      "         1.5112e-01,  8.9924e-02, -8.9365e-01,  5.2026e-02, -1.6953e-02,\n",
      "        -5.3391e-02, -3.1044e-01, -2.7263e-02, -1.0220e+00, -1.0714e-02,\n",
      "        -2.6536e+00, -5.0837e-01, -4.3534e-03, -4.9392e-02, -2.4547e-01,\n",
      "        -1.1322e+00, -1.7724e-02, -1.5391e+01, -7.9142e-04, -1.0255e-01,\n",
      "        -4.2036e-01, -1.1281e+00, -1.1068e-01, -2.0805e+00, -1.0943e+00,\n",
      "         2.4889e-01, -3.7233e-01, -2.0423e-01, -4.0734e-01, -1.9293e+00,\n",
      "         3.0323e-02, -1.5642e-02, -1.2185e+00,  4.8443e-02, -2.9004e-02,\n",
      "        -2.0517e-02, -1.5483e+00, -5.1608e-01, -1.2864e+00, -8.0215e-01,\n",
      "        -6.4938e-01, -3.6474e-02, -2.1343e-01, -1.3665e+00, -8.6043e-01,\n",
      "         2.3200e-01, -5.6398e-02, -6.4152e-02, -3.2381e-02, -1.7980e-02,\n",
      "        -8.7532e-02,  5.8769e-03, -7.1511e-03, -1.2508e+00, -5.4788e-02,\n",
      "         2.0873e+00, -2.7090e-01, -8.5015e-01,  2.4622e-01, -7.7072e-04,\n",
      "        -1.7649e-03,  1.4243e-02, -1.7885e-02, -1.3471e+00, -9.5354e-01,\n",
      "        -1.1624e+00, -3.4794e-01, -1.6600e-01, -7.7410e-03,  1.3506e+00,\n",
      "        -3.1122e-01, -7.5456e-02, -1.8530e-01, -1.2751e+00, -3.1576e+00,\n",
      "         1.0401e-02,  9.6701e-01, -8.7121e-01, -7.5517e-01, -1.0931e-02,\n",
      "        -5.9877e-02, -9.6070e-03,  1.2196e-03, -3.2439e-02, -1.6212e+00,\n",
      "        -2.5287e+00, -7.5404e-01,  3.6613e-03, -3.3966e-02, -2.5936e-02,\n",
      "        -1.3094e-01, -1.2287e+00, -2.3392e+00, -1.4374e-01, -5.0155e-03,\n",
      "        -1.1484e-02, -9.1967e-01, -2.1874e-01,  9.1431e-01,  8.4518e-01,\n",
      "         1.0702e-01, -8.5627e-01, -3.5147e-01, -1.2665e+01, -8.2864e-02,\n",
      "        -3.8243e-01, -1.0920e+00, -2.3981e-01,  1.0978e+00,  3.5986e+00,\n",
      "        -4.1724e-02, -1.1303e+00, -1.6798e-01, -3.2877e-03, -4.7907e-01,\n",
      "        -2.2667e-03, -2.1355e-01,  8.0926e-01, -3.9147e-01,  6.9910e-01,\n",
      "        -1.8711e-01, -9.9307e-01, -1.9099e+00, -5.1819e-01, -5.5837e-01,\n",
      "        -2.5607e-01, -6.5671e-01, -2.9483e-01, -4.2445e-03, -1.2913e+00,\n",
      "        -3.6089e-02, -3.0820e-02,  2.1823e-02, -1.1292e-01,  1.8634e-02,\n",
      "         5.0456e-03, -1.9627e-01, -2.7601e-02, -3.4109e-01, -5.1115e-02,\n",
      "        -5.9616e-01, -1.1570e+00,  7.3590e-01, -6.7162e-01, -1.0236e-01,\n",
      "        -1.2161e+01, -1.7429e+00, -3.8018e-02, -5.2219e-02, -5.0343e-01,\n",
      "         1.8980e-03, -2.8100e-01, -1.1969e+00, -2.0909e-01, -2.3248e-01,\n",
      "        -8.5497e-01, -1.1176e-02, -2.0919e+00, -1.2241e-01, -4.4760e-01,\n",
      "         8.2679e-01,  1.8494e-01,  6.0836e-01, -2.1549e-01, -1.0326e+00,\n",
      "        -2.7911e-01, -6.2824e-01, -1.8804e+00,  9.1052e-01, -1.5302e+01,\n",
      "        -2.0268e-01, -1.9853e-01, -4.6668e-02, -1.8647e+01, -5.2762e-01,\n",
      "        -7.1742e-01, -1.5413e-01, -6.8315e-01, -1.6779e+00, -9.0579e-01,\n",
      "        -1.6772e+01, -9.2337e-01, -3.2173e-01,  5.9405e-02, -6.8512e-01,\n",
      "        -3.1671e-01,  6.9525e-01, -4.1775e-02,  7.1332e-02, -1.7733e-01,\n",
      "        -3.5534e-02, -8.4297e-03, -1.0519e+00, -2.7362e-01, -7.0279e-01,\n",
      "        -3.3918e-01,  9.1977e-01, -1.0845e+00, -1.3629e+00, -2.9812e-01,\n",
      "         1.1154e+00, -1.3250e-01, -6.4018e-01, -9.3658e-01,  1.1203e+00,\n",
      "        -2.5907e-01, -7.7782e-01,  1.8323e-02, -8.2381e-02, -1.0538e-01,\n",
      "        -4.4082e+00, -1.0337e+00,  2.3928e+00, -5.6336e-01,  1.4732e-01,\n",
      "        -5.9272e-01, -3.3814e-01,  1.1781e-03, -1.4896e+00, -2.7777e-01,\n",
      "        -9.1131e-03, -2.2753e-01,  4.7717e-03,  1.1587e+00, -1.5336e-02,\n",
      "         1.8304e-02, -1.4198e-01, -1.5619e-01, -1.8902e-03, -3.7279e-02,\n",
      "        -4.3593e-01, -6.5854e-01, -5.5442e-01, -4.8995e-01, -1.9663e-01,\n",
      "         6.0178e-01, -5.6047e-01, -1.3201e+01,  5.9266e-01, -1.1412e-01,\n",
      "        -1.7185e+01,  7.5365e-03, -2.5935e-02, -1.2486e-02, -2.0237e+00,\n",
      "        -1.1283e+00, -1.1209e-01,  4.2113e-01, -1.8157e-02, -8.6583e-01,\n",
      "        -6.2743e-01, -2.5413e+00, -2.1236e-01, -1.5087e+01,  4.9716e-04,\n",
      "        -1.3610e+00,  2.8813e-01, -3.3612e-01, -7.8296e-02, -1.6814e+00,\n",
      "        -7.0836e-01, -5.8917e-02,  5.1042e-01, -3.1351e-01, -2.0848e-02,\n",
      "        -2.1687e-02, -7.5200e-02, -6.1064e-02, -3.0179e+00, -6.3219e-03,\n",
      "         8.0090e-03, -1.7351e-01, -1.9831e-02, -2.1928e-02, -2.1095e+00,\n",
      "        -3.8035e-01, -7.9840e-02, -3.6880e-01, -3.7827e-01, -5.4425e-01,\n",
      "        -4.1783e+00,  8.3691e-01, -1.6016e-01, -1.8716e+00, -1.5604e-01,\n",
      "        -9.7162e-01, -8.6521e-02, -6.1300e-02, -3.4737e-01, -1.3461e-02,\n",
      "        -1.3491e+00, -1.6565e-01,  3.1560e-01, -9.6641e-01, -1.5932e-01,\n",
      "        -1.9298e+00,  1.0995e-01, -1.1836e+00,  1.1035e-02, -1.1980e-01,\n",
      "        -1.1910e+00, -2.8095e+00, -1.9011e-01, -4.8042e-01, -9.3004e-01,\n",
      "        -9.5486e-01, -2.9091e-01,  2.1515e-02, -2.5364e-02, -3.3804e-02,\n",
      "         4.5117e-01,  6.4495e-02, -7.3850e-03,  3.2547e+00, -4.4966e-01,\n",
      "        -5.6766e-02,  1.3415e-01, -8.3776e-02,  8.6386e-02,  1.3001e-03,\n",
      "        -3.7424e-02, -1.3979e+01, -2.0824e+00, -6.8803e-01, -2.7001e+00,\n",
      "        -6.2857e-01, -2.6599e-02, -2.0484e+00, -1.4938e+00,  4.0327e-02,\n",
      "        -1.7955e+00, -1.7813e+00,  1.3951e-01, -9.2568e-01, -1.9321e-02,\n",
      "         6.6908e-02, -6.2934e-01, -8.2832e-01, -9.3723e-02,  2.5432e+00,\n",
      "         8.7647e-01, -6.0654e-01], device='cuda:0')), ('backbone.model.layer2.2.conv1.weight', tensor([[[[-0.0258]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[-0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[-0.0744]]],\n",
      "\n",
      "\n",
      "        [[[-0.0512]],\n",
      "\n",
      "         [[ 0.0649]],\n",
      "\n",
      "         [[-0.0720]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1060]],\n",
      "\n",
      "         [[-0.0591]],\n",
      "\n",
      "         [[-0.0738]]],\n",
      "\n",
      "\n",
      "        [[[-0.0204]],\n",
      "\n",
      "         [[-0.0364]],\n",
      "\n",
      "         [[-0.0338]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0414]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[ 0.0123]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0006]],\n",
      "\n",
      "         [[-0.0858]],\n",
      "\n",
      "         [[-0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0315]],\n",
      "\n",
      "         [[-0.0169]],\n",
      "\n",
      "         [[-0.0442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0160]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         [[-0.0100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0563]],\n",
      "\n",
      "         [[-0.0193]],\n",
      "\n",
      "         [[ 0.0454]]],\n",
      "\n",
      "\n",
      "        [[[-0.0103]],\n",
      "\n",
      "         [[ 0.1501]],\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0124]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         [[ 0.0316]]]], device='cuda:0')), ('backbone.model.layer2.2.bn1.weight', tensor([2.4784, 0.5545, 1.7838, 2.1182, 2.4709, 0.6087, 2.3136, 2.3792, 0.9516,\n",
      "        3.3976, 1.1411, 3.1005, 2.6115, 2.4658, 1.1138, 1.3615, 1.7123, 2.1650,\n",
      "        1.3287, 1.0420, 1.0096, 2.2702, 2.0224, 1.0566, 1.4019, 1.7891, 1.6062,\n",
      "        1.6037, 1.9492, 2.1620, 1.4818, 0.7251, 1.3431, 1.6739, 1.1273, 2.3257,\n",
      "        1.3165, 0.7803, 2.4435, 1.4981, 1.6764, 2.4481, 0.8833, 0.7693, 1.3065,\n",
      "        1.7714, 0.8127, 1.7916, 1.2219, 1.5892, 5.1242, 0.8574, 1.6043, 0.8965,\n",
      "        1.3448, 2.4498, 0.8099, 2.6066, 2.5665, 0.3389, 2.3127, 2.4275, 1.8047,\n",
      "        0.3584, 1.7101, 1.2784, 1.8943, 1.4860, 1.6508, 1.6759, 1.2222, 1.5714,\n",
      "        1.5144, 1.3272, 1.5561, 1.6858, 2.0525, 1.4307, 1.4172, 1.6491, 1.0709,\n",
      "        2.2255, 1.6621, 1.2208, 1.9675, 1.3820, 1.5288, 0.7555, 1.0325, 0.8226,\n",
      "        1.5454, 1.4687, 1.6286, 2.1952, 1.6849, 2.2683, 2.9762, 1.6724, 1.0199,\n",
      "        0.9062, 1.9773, 1.1788, 1.0233, 0.7643, 2.0649, 1.5390, 1.6988, 2.9782,\n",
      "        2.6333, 0.7080, 1.4565, 0.9708, 1.2795, 1.7655, 1.1694, 1.6254, 0.9229,\n",
      "        0.9747, 1.2770, 1.4576, 1.4332, 1.3823, 1.3433, 2.4007, 3.3628, 1.6965,\n",
      "        2.9364, 0.5337], device='cuda:0')), ('backbone.model.layer2.2.bn1.bias', tensor([-3.0981, -0.6809, -1.1825, -1.5954, -3.3285,  0.1082, -1.8729, -1.1749,\n",
      "        -0.1901, -2.1079, -1.1933, -1.5338, -4.2381, -2.2627,  0.1462,  0.0552,\n",
      "        -1.4485, -1.3798, -0.5582, -0.3261,  0.1295, -2.1052, -2.5913,  0.1650,\n",
      "         1.1732, -1.5604, -1.6733,  0.0525, -1.7713, -3.2983,  0.1277,  0.3033,\n",
      "        -1.6310, -0.2772,  0.4227, -0.6826, -0.1038, -0.0074, -0.4725, -2.1791,\n",
      "        -1.8164, -2.8468,  0.2461,  0.2967, -1.3734, -0.6877,  0.6298, -1.1782,\n",
      "        -0.7466,  1.3493, -0.2265, -0.2876, -0.3393, -1.1051, -0.7000,  2.2874,\n",
      "        -0.2694, -1.3564, -3.2901,  0.1520, -3.1237, -1.1458, -1.4924,  0.1044,\n",
      "        -1.8765, -0.0953, -0.4870, -0.5579, -2.0200, -0.7726,  0.3323,  0.3765,\n",
      "        -1.8430,  0.2912,  0.0916, -0.3741,  2.0991, -0.6612, -1.4032, -0.6571,\n",
      "         0.4187, -2.1202, -1.7078,  0.2899, -3.1460, -0.1294, -0.4181,  0.4247,\n",
      "         0.0786,  1.2562, -1.6658, -0.1774,  0.0286, -0.2913, -0.4889, -3.4396,\n",
      "         1.8560, -3.1085, -0.0507,  0.3834, -3.4946, -0.0183, -0.0313,  0.2452,\n",
      "        -0.3696,  1.3627, -2.4704, -1.4562, -2.3016,  0.0579, -0.1716, -0.5627,\n",
      "        -0.0718, -1.8799,  0.7571, -0.1240,  0.1140,  0.7025,  0.8006, -1.4302,\n",
      "        -1.0264,  0.3034, -1.5083,  0.9064, -1.4393, -1.1587, -5.0514, -0.1018],\n",
      "       device='cuda:0')), ('backbone.model.layer2.2.conv2.weight', tensor([[[[-1.0361e-02, -2.2203e-02,  6.1756e-03],\n",
      "          [-2.8853e-02,  6.3716e-02, -2.1564e-02],\n",
      "          [-6.5319e-03, -9.8661e-05, -7.3703e-03]],\n",
      "\n",
      "         [[-5.5121e-02,  4.9610e-02, -1.4520e-02],\n",
      "          [ 3.4722e-03,  2.0497e-02,  5.5298e-02],\n",
      "          [ 1.5448e-03, -3.4382e-02, -4.9978e-03]],\n",
      "\n",
      "         [[-1.9632e-02, -5.3378e-02,  4.4554e-03],\n",
      "          [-5.8882e-02,  5.3980e-03, -3.7819e-02],\n",
      "          [-2.9080e-02, -2.8406e-02, -1.7864e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3943e-02, -2.0288e-02, -3.8252e-02],\n",
      "          [-6.8416e-02,  4.6609e-02, -4.4219e-02],\n",
      "          [-7.1652e-02, -1.0338e-01, -3.1177e-02]],\n",
      "\n",
      "         [[-9.1977e-03, -2.6572e-02, -4.3124e-02],\n",
      "          [-4.3808e-02, -4.9592e-02, -3.7406e-02],\n",
      "          [-1.5634e-02, -3.2134e-02, -2.4564e-02]],\n",
      "\n",
      "         [[ 9.2528e-03,  3.6909e-02,  2.1322e-02],\n",
      "          [ 2.9623e-02, -9.4605e-02,  5.0634e-02],\n",
      "          [ 3.6112e-03, -2.7156e-03, -1.0266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1937e-02, -2.4779e-02, -7.2063e-03],\n",
      "          [-5.9721e-02,  4.8791e-02, -9.6025e-02],\n",
      "          [-6.2835e-02, -5.3277e-02, -5.6675e-02]],\n",
      "\n",
      "         [[-7.9422e-03, -7.1849e-02, -2.1801e-02],\n",
      "          [ 1.2816e-02, -8.8504e-03,  1.3741e-02],\n",
      "          [ 4.8102e-02,  1.5202e-01,  7.1614e-02]],\n",
      "\n",
      "         [[ 2.4763e-02,  9.3100e-02,  3.3478e-02],\n",
      "          [ 5.2519e-02,  8.1564e-02,  3.3749e-02],\n",
      "          [-3.8050e-02, -1.2515e-01, -4.5437e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4559e-02,  2.2181e-03,  2.0131e-02],\n",
      "          [-1.4897e-03, -5.4804e-02, -3.8885e-02],\n",
      "          [ 5.9412e-03, -3.2472e-02,  2.3276e-03]],\n",
      "\n",
      "         [[-2.9573e-02, -6.0096e-03, -1.8078e-02],\n",
      "          [-3.9200e-02,  6.1339e-03, -4.4849e-02],\n",
      "          [-8.9222e-03, -8.8422e-03, -4.0353e-02]],\n",
      "\n",
      "         [[-3.5902e-02,  9.2743e-02, -3.9658e-02],\n",
      "          [ 1.3163e-02,  8.3129e-02, -3.1913e-02],\n",
      "          [-4.5928e-02,  8.7334e-02, -3.9222e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4615e-02, -5.3774e-03, -2.5414e-03],\n",
      "          [ 1.7755e-02,  2.5465e-03, -2.2334e-02],\n",
      "          [ 1.5954e-03,  1.6913e-02, -9.0237e-03]],\n",
      "\n",
      "         [[-6.6170e-02,  5.3650e-02, -6.2802e-03],\n",
      "          [-3.0794e-02, -3.9246e-02,  2.6995e-02],\n",
      "          [-4.1633e-03, -6.1663e-02,  4.8206e-02]],\n",
      "\n",
      "         [[ 2.4689e-02, -1.4409e-02, -1.6062e-02],\n",
      "          [ 1.3141e-02, -1.7919e-02,  9.6651e-03],\n",
      "          [ 2.0150e-02,  1.4682e-02,  5.2289e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2491e-02, -4.2045e-02,  1.9555e-02],\n",
      "          [-9.0739e-02, -6.1131e-02,  8.6229e-02],\n",
      "          [-2.4550e-02, -3.3064e-02,  7.4883e-02]],\n",
      "\n",
      "         [[-1.9215e-02,  6.1994e-03,  3.9802e-02],\n",
      "          [-4.1397e-03, -2.9128e-02, -2.4151e-02],\n",
      "          [ 6.6139e-03,  1.4622e-02, -8.1646e-03]],\n",
      "\n",
      "         [[ 1.3529e-02, -3.7081e-02, -4.1355e-03],\n",
      "          [ 2.3365e-02, -1.5152e-02,  2.6928e-02],\n",
      "          [ 2.8737e-02,  1.0750e-02,  2.9361e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.3271e-03, -3.6191e-03, -4.5228e-02],\n",
      "          [ 4.1270e-02,  4.9410e-02,  4.9547e-03],\n",
      "          [ 2.1048e-02,  2.4163e-02,  2.6308e-02]],\n",
      "\n",
      "         [[ 4.8300e-03, -2.4347e-03,  9.4471e-04],\n",
      "          [-3.9373e-02, -1.5288e-01, -1.6056e-02],\n",
      "          [-9.4788e-02, -1.5175e-01, -5.8375e-02]],\n",
      "\n",
      "         [[-3.9184e-02, -2.0424e-02, -4.2184e-02],\n",
      "          [ 2.6060e-02, -2.1676e-02,  4.8196e-02],\n",
      "          [-8.4462e-03,  4.8595e-02,  3.7022e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0749e-02, -2.8296e-02, -5.5208e-02],\n",
      "          [-5.4119e-02, -2.3544e-02, -9.5444e-02],\n",
      "          [-4.2122e-02, -1.2381e-01, -1.5266e-02]],\n",
      "\n",
      "         [[ 7.6803e-02,  6.2548e-02,  5.6617e-02],\n",
      "          [ 4.9320e-02,  3.5314e-02,  2.8117e-02],\n",
      "          [ 2.7324e-02,  2.7061e-02,  3.3356e-02]],\n",
      "\n",
      "         [[-9.7827e-03, -3.4981e-02, -1.1517e-02],\n",
      "          [ 5.7093e-03, -1.9743e-02, -2.5570e-02],\n",
      "          [-1.4001e-02, -7.1102e-02, -6.8236e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4856e-03, -7.7559e-02, -4.6625e-02],\n",
      "          [-3.2715e-02,  7.2385e-03, -7.1132e-02],\n",
      "          [-2.7422e-02,  2.4733e-03, -5.6342e-02]],\n",
      "\n",
      "         [[ 7.0347e-02,  3.4049e-02,  8.4694e-03],\n",
      "          [-9.3058e-03, -5.8286e-03, -1.4427e-02],\n",
      "          [ 5.0368e-02,  1.3086e-01,  3.5621e-02]],\n",
      "\n",
      "         [[-7.3561e-02, -9.8452e-03, -3.3207e-02],\n",
      "          [ 1.4623e-02,  5.7660e-02,  2.4192e-02],\n",
      "          [ 1.9078e-02,  3.4967e-02,  2.3176e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5975e-02, -4.4717e-02, -3.4905e-02],\n",
      "          [ 3.3016e-03,  8.3707e-02,  5.3538e-02],\n",
      "          [ 1.1855e-03,  3.2469e-02,  1.5197e-02]],\n",
      "\n",
      "         [[-2.8507e-02, -4.1007e-02, -4.6694e-02],\n",
      "          [-3.8230e-02, -6.8556e-02, -5.3450e-02],\n",
      "          [-3.3190e-02, -1.9787e-02,  2.3645e-04]],\n",
      "\n",
      "         [[-1.2333e-01, -7.5726e-02, -1.1621e-01],\n",
      "          [-1.5829e-01, -5.5007e-02, -1.7472e-01],\n",
      "          [-1.4187e-01, -1.4472e-01, -1.1350e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4836e-02,  3.7817e-02,  4.0951e-02],\n",
      "          [ 1.2985e-02, -9.8133e-03,  1.4569e-02],\n",
      "          [-8.0374e-03,  3.2373e-02,  2.3200e-02]],\n",
      "\n",
      "         [[ 1.6339e-02,  5.2785e-02,  8.8356e-02],\n",
      "          [-1.6925e-02, -2.1348e-02,  2.1071e-02],\n",
      "          [-6.9675e-03,  6.4186e-02,  2.8696e-02]],\n",
      "\n",
      "         [[ 8.4286e-03,  3.2897e-02,  4.5724e-02],\n",
      "          [-9.3579e-03, -5.5406e-02, -2.4064e-02],\n",
      "          [-2.2210e-03,  2.4480e-04,  1.4270e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8250e-03, -8.1372e-02, -6.7268e-02],\n",
      "          [-8.3487e-02, -7.7744e-02, -7.5969e-02],\n",
      "          [-5.0758e-02, -9.3397e-02, -6.9582e-02]],\n",
      "\n",
      "         [[ 7.5432e-03, -1.9935e-02,  9.1555e-04],\n",
      "          [-4.0147e-02, -2.2404e-03,  1.5512e-02],\n",
      "          [-5.9639e-02,  1.1122e-02, -3.8223e-02]],\n",
      "\n",
      "         [[ 3.7420e-02, -5.6771e-04, -9.1690e-04],\n",
      "          [-2.8274e-02, -5.6394e-02, -1.1695e-02],\n",
      "          [-2.6845e-02, -2.4143e-02,  3.0564e-02]]]], device='cuda:0')), ('backbone.model.layer2.2.bn2.weight', tensor([2.4570, 1.0272, 2.0697, 1.6433, 2.7637, 3.6787, 3.3469, 2.7678, 1.8090,\n",
      "        1.4583, 1.3661, 2.1688, 2.3121, 1.1749, 1.2366, 2.2472, 2.1808, 0.6463,\n",
      "        1.6125, 1.9202, 1.9373, 0.9459, 2.8045, 2.2683, 1.1795, 2.2527, 2.0335,\n",
      "        2.3411, 2.1545, 1.3083, 4.7682, 1.8907, 2.2511, 2.1918, 1.8015, 1.9759,\n",
      "        3.2912, 1.1595, 5.9367, 2.4930, 0.9916, 1.3967, 1.5869, 1.8557, 3.6706,\n",
      "        2.0933, 0.9408, 2.3737, 0.0650, 0.0476, 0.3841, 8.5548, 1.5597, 1.6252,\n",
      "        1.5673, 1.6076, 2.4419, 2.5357, 1.0259, 1.7296, 3.5344, 0.0447, 3.5290,\n",
      "        0.9524, 2.0200, 1.6819, 1.7142, 0.9856, 3.4680, 2.2853, 2.6700, 0.9782,\n",
      "        1.9904, 4.4904, 2.2833, 2.0499, 0.3879, 1.9330, 1.4482, 2.1580, 1.0900,\n",
      "        1.3028, 2.5049, 2.5904, 3.1299, 1.3949, 3.1476, 1.2244, 1.8326, 0.7647,\n",
      "        2.5729, 2.7028, 0.6898, 2.2831, 1.5224, 2.1629, 2.5870, 1.0940, 0.7150,\n",
      "        0.9478, 0.5864, 1.6867, 1.2997, 2.7586, 0.9704, 0.9858, 1.1168, 1.5682,\n",
      "        1.1051, 0.8172, 6.0005, 1.5480, 1.1286, 1.0246, 2.1106, 1.7889, 1.1963,\n",
      "        0.3811, 5.5156, 3.1732, 1.5917, 0.8148, 0.0565, 4.7456, 1.0771, 1.2207,\n",
      "        2.7771, 0.8791], device='cuda:0')), ('backbone.model.layer2.2.bn2.bias', tensor([-1.7213e+00, -7.2443e-01,  2.6464e-01,  8.3243e-01, -5.3584e-01,\n",
      "        -7.4509e-01, -3.5465e+00,  1.3892e-03, -3.2027e-01,  6.3371e-01,\n",
      "        -6.1449e-02, -1.7804e+00, -2.7883e+00,  1.0833e+00,  1.0362e+00,\n",
      "        -2.0328e+00, -4.7978e-01,  4.7296e-01, -2.5268e-02, -1.7885e+00,\n",
      "         4.8008e-01, -1.7760e+00,  1.7100e+00,  5.8369e-01, -1.4075e+00,\n",
      "         6.7636e-01,  3.8111e-01, -2.1580e-01,  8.6449e-01, -1.3388e+00,\n",
      "        -2.3396e+00,  5.0714e-01, -2.6328e-01,  6.9529e-01,  1.9902e-01,\n",
      "        -2.3499e+00, -3.3255e-02, -1.3601e+00, -2.0645e+00,  6.2905e-01,\n",
      "        -1.6023e+00,  3.3048e-01,  5.3221e-01,  7.0955e-01, -6.2022e-01,\n",
      "        -2.6017e-02, -1.6462e+00,  1.3331e+00, -1.3717e+00, -1.0452e+00,\n",
      "        -2.8453e-01, -3.8816e+00, -1.3842e+00,  1.2326e+00,  3.8218e-01,\n",
      "        -1.4540e+00,  4.5411e-01,  1.0612e-01, -1.7266e+00,  8.6405e-01,\n",
      "        -1.8012e+00, -1.1433e+00, -1.1911e+00,  1.1227e+00, -7.4212e-01,\n",
      "         5.6241e-01, -1.1808e+00,  3.8613e-01, -3.8721e-02, -1.9563e+00,\n",
      "        -2.7154e+00,  5.3356e-01,  2.8615e-01,  1.1374e+00, -3.6684e+00,\n",
      "         1.2877e-01,  2.4152e-03,  1.1299e+00,  1.4581e-01, -1.0596e+00,\n",
      "         1.4729e+00, -6.4395e-01, -1.9666e+00, -6.4094e-01,  1.1815e+00,\n",
      "        -1.8572e-01, -1.7352e+00, -1.1927e+00, -2.1785e-01, -1.3617e+00,\n",
      "         1.0497e+00,  1.1670e+00, -8.8076e-01, -3.5258e-01, -4.6813e-01,\n",
      "        -1.3480e+00, -2.5765e+00,  6.4580e-01,  2.8536e-01, -4.5187e-01,\n",
      "        -6.8680e-01, -6.3279e-01, -3.8293e-01, -5.8905e-01, -1.5707e+00,\n",
      "         6.9974e-01,  5.9852e-01,  1.2720e-01,  8.6674e-01,  2.7288e-01,\n",
      "        -2.6285e+00, -2.3762e+00, -1.6512e+00,  1.5401e-01, -2.1165e-01,\n",
      "        -1.4153e-02,  1.6514e-01, -1.6780e-01, -6.0987e+00, -2.2146e+00,\n",
      "         5.1991e-01, -6.0335e-01, -1.3473e+00, -4.4168e+00,  2.8707e-01,\n",
      "         2.9805e-01, -3.6119e-01, -2.0262e+00], device='cuda:0')), ('backbone.model.layer2.2.conv3.weight', tensor([[[[-0.0546]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0585]],\n",
      "\n",
      "         [[ 0.0296]],\n",
      "\n",
      "         [[-0.2411]]],\n",
      "\n",
      "\n",
      "        [[[-0.0266]],\n",
      "\n",
      "         [[-0.0829]],\n",
      "\n",
      "         [[-0.0329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0339]],\n",
      "\n",
      "         [[-0.0444]],\n",
      "\n",
      "         [[-0.0167]]],\n",
      "\n",
      "\n",
      "        [[[-0.0514]],\n",
      "\n",
      "         [[ 0.0117]],\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[ 0.0448]],\n",
      "\n",
      "         [[-0.2488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0209]],\n",
      "\n",
      "         [[ 0.0071]],\n",
      "\n",
      "         [[ 0.0916]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1416]],\n",
      "\n",
      "         [[ 0.1610]],\n",
      "\n",
      "         [[-0.1141]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0106]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[-0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1091]],\n",
      "\n",
      "         [[ 0.0312]],\n",
      "\n",
      "         [[-0.0485]]],\n",
      "\n",
      "\n",
      "        [[[-0.0283]],\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0058]],\n",
      "\n",
      "         [[-0.1827]],\n",
      "\n",
      "         [[-0.0022]]]], device='cuda:0')), ('backbone.model.layer2.2.bn3.weight', tensor([ 2.3075e-03, -1.0563e+00, -1.1297e-02,  1.6085e+00,  2.9123e+00,\n",
      "        -3.0159e+00,  7.8737e-01,  1.8012e-01,  3.2508e+00,  7.8941e-01,\n",
      "         4.7591e+00, -1.6448e+00,  1.3530e-01, -1.5572e+00, -4.8714e+00,\n",
      "        -9.6602e-01,  6.4177e-01, -7.3299e-01, -4.7307e+00, -2.2685e-01,\n",
      "         1.3845e-01,  9.6803e-02,  1.6347e+00,  2.8614e-01, -1.0638e-02,\n",
      "         6.2179e+00, -8.7644e-01,  3.0529e+00,  2.1048e-02, -7.3075e+00,\n",
      "         1.4947e+00, -3.0866e+00, -5.5253e-01, -4.9166e-03, -5.4400e-01,\n",
      "         2.8376e+00,  1.1521e-03, -3.9829e+00, -1.2007e+00,  9.3377e-01,\n",
      "        -1.6675e-02, -2.0521e+00,  7.5446e+00,  1.3584e-01,  3.3911e+00,\n",
      "         9.1644e-01,  3.8429e-01, -3.7752e-04, -8.4654e-01,  4.3804e-01,\n",
      "         1.2356e-01, -2.3242e+00, -9.4448e-01, -8.7056e-03, -9.1201e-01,\n",
      "         1.1303e+00,  6.4498e-01, -2.4634e-02,  8.8025e+00,  2.7952e+00,\n",
      "        -4.1968e-01, -8.2134e-01, -1.2124e+00,  4.1112e-01,  3.9011e+00,\n",
      "        -1.0552e+00, -1.8046e+00, -2.8069e-01, -2.9903e+00,  7.3285e-01,\n",
      "        -3.0767e+00,  9.6946e-03,  2.2120e-01,  2.6036e+00,  1.5383e+00,\n",
      "         1.3064e-02, -3.8789e+00,  8.6016e-01, -4.2008e+00,  2.3140e+00,\n",
      "         1.9757e+00, -3.2820e+00, -2.3099e+00, -5.1387e+00, -1.3372e+00,\n",
      "         2.4183e-02,  2.4724e+00,  1.5239e+00, -5.0090e-03,  4.6114e+00,\n",
      "         5.4190e+00,  3.9359e+00,  7.5482e-02, -2.9228e+00,  3.0252e-01,\n",
      "        -1.6852e+00, -5.8435e-01,  3.0783e+00, -2.1072e+00,  1.6113e+00,\n",
      "         2.5171e+00, -8.6728e-01, -8.7666e-01,  1.5630e+00, -5.1391e-03,\n",
      "        -6.5662e-01, -2.3733e-02, -8.8534e-01, -4.0904e-01, -4.2174e+00,\n",
      "         2.0929e+00,  3.2551e+00,  1.7708e+00, -1.3163e+00, -1.6445e+00,\n",
      "         1.8201e+00, -2.7390e+00, -5.1252e+00, -1.1645e+00,  2.1446e+00,\n",
      "        -1.0449e+00,  1.1826e-02, -1.6588e+00,  1.0652e+00, -5.5368e-01,\n",
      "        -3.2970e+00,  1.2703e+01,  4.9071e-01, -1.0276e+00, -1.0175e+01,\n",
      "        -1.7828e+00,  9.2836e-01, -1.9517e-01,  1.1057e+00,  5.0410e+00,\n",
      "        -4.4390e-01, -4.4817e-01,  7.0870e-01, -1.3248e-01,  4.1932e-01,\n",
      "        -3.6725e+00, -1.0800e-01, -2.1273e+00,  2.2279e+00,  1.2355e+00,\n",
      "         3.5027e-01, -4.6082e-02, -5.0389e-02, -3.1963e-01, -3.5195e+00,\n",
      "         4.3543e-01, -1.3630e+01, -4.5660e-01, -2.1794e+00, -3.7148e-01,\n",
      "        -5.1034e+00,  8.2612e+00,  4.1647e-01,  3.2561e+00, -4.8052e+00,\n",
      "         1.1227e+00, -7.3745e-01,  5.6804e-02,  2.6032e+00,  6.9123e-01,\n",
      "         4.5583e-01, -1.4079e+01,  1.1527e+00, -2.2343e+00,  7.0378e-02,\n",
      "         2.7092e+00,  9.2401e-01,  4.4741e-01, -9.9732e-01,  1.0139e+00,\n",
      "        -1.8139e+00, -1.8395e+00, -1.8291e-02,  1.0378e-01,  2.0124e+00,\n",
      "         2.6748e+00, -4.6575e-03, -1.0542e+00,  3.3695e+00, -5.8576e+00,\n",
      "         6.3993e-02, -3.6282e+00, -3.6483e-01, -6.6419e+00,  7.0779e-01,\n",
      "        -2.0716e+00,  5.7660e-02,  7.1465e+00, -2.4859e+00,  5.2879e-01,\n",
      "        -5.5434e-02,  2.8195e-01,  1.4607e+00,  4.9944e-02, -1.4848e-01,\n",
      "         3.3627e+00, -2.7695e+00,  1.8133e+00,  3.1807e-01,  2.6179e+00,\n",
      "        -3.1226e+00,  4.4633e+00, -2.4794e-01,  1.4778e-02, -1.9981e-02,\n",
      "        -1.9695e-01, -1.2473e+00,  2.5957e+00,  7.6220e-02, -5.0360e-02,\n",
      "        -7.7732e-01,  1.0598e+00, -1.2712e+00,  3.1003e+00,  3.2195e+00,\n",
      "        -7.2355e-01,  4.4073e+00, -9.5743e+00,  9.3450e-01,  8.8193e-01,\n",
      "         4.6714e+00, -4.3856e+00, -5.0165e+00, -1.3632e+00, -1.3669e+00,\n",
      "         4.7190e+00,  4.0709e+00,  3.9389e+00, -3.7052e-01, -5.2480e-01,\n",
      "         5.2303e-01, -1.8644e-02, -2.8303e-02,  1.3592e+00, -1.3604e+00,\n",
      "         5.7483e-01,  5.4301e-01,  6.4480e-01, -2.8539e+00, -1.9462e+00,\n",
      "         3.1549e+00, -1.2310e-01,  4.5207e-02,  5.6563e-01, -1.3391e+00,\n",
      "        -1.3235e+00, -1.3670e+00,  9.4833e-01, -2.4555e+00,  2.3609e-01,\n",
      "         3.6326e-01, -2.5621e-02, -3.5824e+00,  4.3858e+00, -6.0261e+00,\n",
      "         7.8718e+00,  3.7465e+00, -6.2409e-01, -2.8203e+00, -2.4288e+00,\n",
      "         3.1938e+00,  2.6822e+00,  8.5046e-01,  4.0025e-02, -8.5210e-03,\n",
      "        -3.2370e-01,  8.4306e-01, -2.4365e+00,  2.4073e+00, -1.2464e+00,\n",
      "         3.1347e-01,  2.5860e-01, -2.8367e+00,  3.9534e+00,  2.8735e+00,\n",
      "        -6.5498e+00,  7.8436e-02,  4.2818e-01, -1.6526e+00, -1.3077e+00,\n",
      "        -4.4025e+00, -2.0603e+00, -4.7052e+00, -5.6065e-01, -7.7702e-01,\n",
      "         5.2772e-02,  1.2571e+00, -2.1300e+01,  4.9785e-01, -1.7901e+00,\n",
      "        -1.6455e+00, -2.9393e+00,  1.0931e-01, -1.5730e+00, -3.2241e-02,\n",
      "         3.5844e+00,  2.6952e+00,  1.8484e+00,  4.1862e-01,  7.9711e-01,\n",
      "         1.2519e+00, -3.1314e-02,  2.9282e+00,  1.1878e+00,  6.0814e+00,\n",
      "        -6.0395e-02,  2.0428e-02, -2.2831e-03, -5.0254e-02,  3.7194e-01,\n",
      "         1.5209e-01, -3.7090e+00,  4.8571e+00,  6.3380e+00, -1.1268e+00,\n",
      "         4.1987e+00, -9.1555e-01, -1.5334e+00,  2.9142e+00, -8.0122e+00,\n",
      "        -4.3505e-02,  6.0270e+00,  5.3888e-03, -2.6992e+00, -2.6046e-01,\n",
      "         6.4173e+00,  4.1957e+00, -3.9417e-01,  6.7121e-01, -2.5139e-01,\n",
      "        -3.1972e+00, -7.2229e-03,  1.3715e-02,  3.8724e-02, -4.0082e+00,\n",
      "        -2.9904e-01, -5.0464e-02, -6.1333e-03, -4.0204e+00,  3.0842e-02,\n",
      "        -5.5992e+00,  4.9855e-02, -1.0921e+01,  1.7548e-02, -7.9910e-02,\n",
      "        -3.8586e+00, -8.4615e-02,  3.1543e+00, -2.4630e-02,  5.4083e-01,\n",
      "         2.1999e+00, -3.2166e-02,  2.0955e+00, -4.2851e+00, -2.1580e-01,\n",
      "        -6.2213e+00,  3.1514e+00, -9.7181e-01, -1.6262e+00,  6.7602e-01,\n",
      "         7.7824e-02,  6.5741e+00,  4.9008e-01, -1.1634e+00, -1.3641e-02,\n",
      "         1.7400e+00, -1.1707e+01,  1.3604e-01, -6.2717e-01, -4.2162e+00,\n",
      "        -2.0077e+00, -1.6725e+00,  3.3979e+00,  1.9076e+00,  4.0903e+00,\n",
      "        -2.3843e+00, -6.1780e-01,  5.1021e-01, -5.6202e-02, -9.3818e-01,\n",
      "        -2.6031e+00, -1.8752e-01, -3.2209e+00,  1.4201e-01,  2.8504e-01,\n",
      "         1.7278e-01, -7.4711e-01,  1.8012e+00, -2.3324e-02, -3.3290e+00,\n",
      "        -1.6703e+00,  5.6896e-03,  1.8502e+00,  7.6134e-01, -1.9982e+00,\n",
      "         5.5980e+00,  4.5511e-01,  5.8074e+00, -4.0024e+00, -4.5398e+00,\n",
      "        -2.5634e-02,  3.5174e+00,  6.3210e-01,  1.7309e+00,  3.2005e+00,\n",
      "        -2.9239e-01,  3.1550e+00, -8.9400e-01,  2.7297e+00,  1.6067e-02,\n",
      "        -4.2798e-02, -5.6124e+00, -4.1503e+00,  9.8143e-01,  1.3400e-02,\n",
      "         6.5925e-01,  4.0881e-01,  5.4554e-02,  6.4821e+00, -1.5799e+00,\n",
      "         5.1838e+00,  4.9462e-02, -1.9555e+00, -3.2416e+00,  1.7662e+00,\n",
      "         1.1221e+00, -1.5263e-02, -9.7444e-01, -1.9899e+00, -2.7136e+00,\n",
      "        -2.9510e+00,  3.8055e+00,  3.4087e+00, -1.7285e+00,  7.3173e+00,\n",
      "        -2.7165e+00,  3.4941e+00, -7.1802e-01, -9.4637e-01,  2.4079e-03,\n",
      "        -5.8023e-02,  1.9886e+00, -3.0550e+00,  1.0060e+00, -1.8336e+00,\n",
      "        -2.4946e+00, -6.3114e-01, -1.5763e+00, -1.3276e+00,  2.6261e-02,\n",
      "        -1.3009e-03,  2.2621e+00, -1.1741e+00,  1.9860e+01, -3.7529e+00,\n",
      "        -4.3153e-01, -1.6589e+00,  1.5747e+00,  5.2439e-02,  8.6179e+00,\n",
      "         5.4748e-02,  4.5991e+00,  2.1247e-01,  9.6626e-01, -8.2299e-01,\n",
      "        -4.7377e-02, -3.3177e-02,  7.6994e-02, -2.8453e-02,  7.8441e-02,\n",
      "        -6.3937e-03,  1.2268e+00, -7.1413e+00,  2.0405e+00, -1.1331e+00,\n",
      "        -1.1406e-02, -7.3819e-02, -7.3907e-01,  4.8379e-01,  1.1880e-01,\n",
      "        -8.7572e-01, -2.4248e+00, -1.1224e+00,  5.9710e+00,  4.6771e+00,\n",
      "         2.4224e+00,  4.5415e+00,  6.5239e-01, -1.5087e+00,  9.8070e-01,\n",
      "        -2.5814e+00, -3.4410e+00, -5.3548e-02,  6.0397e-02, -4.2016e+00,\n",
      "        -2.8348e+00, -3.3870e-01, -6.5031e-01, -1.1252e+00,  6.2583e-01,\n",
      "         4.5565e+00, -5.0897e-01,  1.7096e-02,  7.1500e+00,  2.5865e-02,\n",
      "        -8.9279e-02,  2.7734e+00], device='cuda:0')), ('backbone.model.layer2.2.bn3.bias', tensor([-3.0372e-02, -3.6013e-01, -6.8196e-02, -2.2203e+00,  1.2409e-01,\n",
      "        -2.3568e+00, -1.8070e-01, -1.9079e-01, -1.4981e+00, -2.6416e-01,\n",
      "        -1.9984e+00,  8.7115e-02, -1.0519e+00, -6.9086e-01, -3.3878e+00,\n",
      "        -4.0999e-01, -2.4861e-01, -3.2607e-02, -1.0992e+01, -2.2642e-02,\n",
      "        -1.7191e-01, -7.0627e-03, -2.6331e+00, -1.2686e-01, -7.9855e-03,\n",
      "        -1.3327e-03, -3.3190e-01, -9.7689e-01, -6.3842e-02, -1.2553e+00,\n",
      "        -1.0920e+00, -1.7186e+00, -1.8839e-01, -2.2864e-03, -1.6255e-01,\n",
      "        -9.4523e-01, -3.0810e-03,  8.0320e-01,  4.4345e-01, -3.1529e-01,\n",
      "         2.8992e-02, -6.2195e-01,  3.2976e-01, -4.5258e-02, -1.8993e-01,\n",
      "        -5.4002e-01, -1.7962e-01,  3.6499e-02, -4.1448e-01, -2.1725e-01,\n",
      "        -9.4910e-02,  4.3304e-01, -7.4113e-01, -1.3904e-02, -6.2818e-01,\n",
      "        -6.6420e-01, -3.4935e-01, -3.6205e-03, -1.2615e+01, -6.6266e-01,\n",
      "        -3.9240e-01,  1.0186e-01,  4.2504e-01, -2.7924e-01,  6.1389e-01,\n",
      "        -7.6397e-01, -1.0026e+00, -6.0520e-03, -3.2574e-02, -2.5448e-01,\n",
      "         2.5747e-01,  1.4394e-03,  1.7595e-01, -1.6025e+00,  2.0070e-01,\n",
      "        -3.3928e-02, -4.6293e-01, -1.5185e-01, -8.1172e-02, -8.8399e-01,\n",
      "        -2.3846e-01, -1.6094e+00, -9.9956e-01,  5.6732e-01,  8.2727e-01,\n",
      "        -2.1931e-03, -5.4499e-01, -8.1644e-01, -1.3701e-02, -4.3567e-01,\n",
      "        -1.0140e+00, -1.6087e-02, -2.8529e-01, -1.1001e+00,  1.9680e-01,\n",
      "        -7.9523e-01,  3.9061e-01, -1.6304e+00,  4.5140e-01, -6.3498e-01,\n",
      "        -1.9264e+00, -3.9787e-01, -7.2370e-02, -4.8354e-01, -2.5905e-02,\n",
      "         4.1456e-02, -2.7620e-02, -2.0597e-01, -8.5054e-02,  1.4053e+00,\n",
      "        -3.3019e-01,  2.5910e-01, -2.0508e-01, -5.0115e-01, -6.4962e-01,\n",
      "         2.9390e-01, -1.7182e-02, -5.2617e-01, -2.5609e-01, -9.1918e-02,\n",
      "         2.6830e-02, -5.3812e-02, -7.3486e-02,  2.7355e-01, -8.6916e-02,\n",
      "        -1.1806e+00, -1.5138e+01, -3.9432e-02,  6.0595e-02, -1.3560e+01,\n",
      "        -5.8420e-01, -7.9510e-01, -8.5106e-02, -4.6310e-01, -8.5066e-01,\n",
      "        -2.6373e-02, -2.4734e-01, -2.3703e-01, -1.6794e-02,  5.7961e-02,\n",
      "         4.8424e-01, -1.6162e+00, -1.8706e-02, -4.1187e-01,  1.4474e-01,\n",
      "         8.4120e-03,  1.0706e-03, -1.6626e-02, -4.2950e-02, -1.3116e+00,\n",
      "        -1.3859e-01,  4.3919e+00, -9.8508e-02, -8.5629e-01, -1.4450e-01,\n",
      "         6.3491e-01, -1.2915e+01, -1.8956e-01,  7.3832e-01,  9.6894e-02,\n",
      "        -6.7027e-01, -3.3946e-01,  9.7727e-02, -1.3398e+00, -1.7314e-01,\n",
      "        -1.1981e-01, -3.0772e+00, -2.1538e-01, -2.3514e+00, -5.1901e-01,\n",
      "        -2.7884e-01, -6.5771e-01, -1.3161e-02, -6.3647e-01, -4.8694e-01,\n",
      "        -6.1949e-01, -1.3548e+00, -3.4081e-03,  4.4947e-02, -3.0448e+00,\n",
      "        -1.2398e+01, -3.0199e-03, -8.0409e-01, -1.7933e+00, -5.2533e+00,\n",
      "        -1.0323e-02, -1.0670e+00, -7.7091e+00, -7.5040e+00, -6.9344e-01,\n",
      "        -8.1075e-02, -8.6093e-03, -2.8792e-01,  3.5854e-01, -3.5779e-01,\n",
      "         1.9653e-02, -8.5348e-02, -5.6702e-01, -5.3925e-02, -2.7699e-01,\n",
      "        -8.9490e-01, -1.4788e+00, -1.2728e+00, -8.9845e-02, -2.6879e+00,\n",
      "        -2.7008e-01, -1.2292e+00, -8.1369e-02, -1.9312e-03,  2.4360e-01,\n",
      "        -2.2317e-01, -8.9805e-01, -1.3640e+00, -5.3204e-02,  1.4198e-02,\n",
      "        -1.1192e+01, -8.6034e-01, -1.0807e+00, -4.6175e-01, -3.4344e+00,\n",
      "        -9.0865e-01, -3.7147e+00, -2.8972e+00,  1.8889e-01, -3.9178e-01,\n",
      "         1.8314e+00, -7.4801e-01,  1.9897e+00, -2.6939e-01, -8.6277e-01,\n",
      "        -1.1678e-01, -9.3973e-01, -1.1693e+00,  8.7210e-05,  8.4642e-02,\n",
      "        -4.6281e-01, -4.6014e-02, -3.8063e-03, -2.0824e-01,  3.1415e-01,\n",
      "        -3.0200e-01,  5.4646e-02,  2.0714e-01,  7.1641e-01, -1.5527e+00,\n",
      "        -2.0475e-01, -4.6649e-02, -1.9682e-01, -2.0925e-02, -9.8950e-02,\n",
      "        -2.3815e-01, -6.1852e-01, -3.7741e-01, -1.6682e-01,  1.7631e-02,\n",
      "        -6.8135e-02, -5.2822e-02, -1.2100e-01, -8.2552e-01, -1.4093e+00,\n",
      "        -5.1001e+00, -1.2296e+00, -3.5127e-01,  1.2953e+00, -3.3230e-01,\n",
      "        -1.1670e+00, -3.0493e+00, -1.5088e-01, -2.6013e-02, -2.3546e-03,\n",
      "         1.6469e-01, -2.0270e-01, -1.4429e+00,  1.6484e+00, -6.9622e-01,\n",
      "         1.1562e-01, -7.7979e-02, -3.4068e+00,  3.9940e+00,  1.0447e+00,\n",
      "         1.2214e-01, -1.9789e-01, -8.5253e-02, -8.8361e-01, -1.8327e+00,\n",
      "        -3.3868e+00, -7.6771e-01,  2.0130e-01, -1.3689e-01, -9.6543e-02,\n",
      "         8.6055e-02, -1.3123e+00, -6.4639e+00, -1.3420e-01, -5.9109e-01,\n",
      "        -1.1414e+00,  1.8750e-01,  9.5925e-03, -7.3728e-02, -5.0857e-03,\n",
      "        -9.8685e-01, -1.3349e+00, -5.4089e-01,  1.0172e-01, -1.4626e-01,\n",
      "        -5.0641e-01, -1.0678e-02, -3.1280e+00, -8.6254e-01, -5.2471e+00,\n",
      "         7.1509e-02, -6.7478e-02, -4.3003e-03, -1.3887e-01, -2.2069e-01,\n",
      "        -2.5537e+00, -8.4826e+00, -5.0078e+00, -6.6043e+00, -1.4126e+00,\n",
      "        -1.7746e+00, -7.4018e-02, -6.5916e-01, -1.1868e+00, -2.1826e+00,\n",
      "        -5.3139e-03, -1.8992e+00, -3.5540e-02,  2.4421e-01, -1.3484e-01,\n",
      "        -2.4825e+00, -1.4624e+00, -1.5217e-01, -6.0436e-01, -6.3116e-01,\n",
      "        -1.7783e+00, -1.4102e-02, -9.3415e-03, -3.3054e-02, -5.6544e+00,\n",
      "        -3.6573e-01, -1.6446e-01, -1.2689e-03, -4.7525e+00, -8.3913e-02,\n",
      "        -7.5256e+00, -2.5887e-04, -2.2441e+01, -1.9541e-02, -1.0053e-02,\n",
      "        -3.5866e+00, -6.1721e-02, -1.1609e+00, -6.1921e-02, -1.8144e-01,\n",
      "        -7.7356e-01,  1.3956e-03, -1.3600e+00, -6.0244e-01, -4.8730e-01,\n",
      "        -3.6182e+00, -4.6267e-01, -2.0486e-01,  4.4281e-01, -2.7344e-01,\n",
      "        -2.5574e-01, -1.0398e+00, -8.1560e-02, -3.4355e-01, -1.9042e-02,\n",
      "        -8.5807e-01, -3.9662e+00, -2.0422e-02, -5.1950e-01, -1.0407e+00,\n",
      "        -6.1617e-01,  1.1326e+00, -6.1308e-02, -1.5307e+00,  2.7584e-01,\n",
      "        -1.3252e-01, -1.4480e-01, -1.0489e-01, -2.5622e-01, -2.4433e-01,\n",
      "        -1.5598e+00,  1.4975e-02, -2.3559e+00, -1.6417e-01,  8.8580e-02,\n",
      "        -2.5226e-01, -7.1118e-01,  2.0529e-01, -2.7014e-02, -1.9274e+00,\n",
      "        -1.2333e+00, -7.0003e-02,  5.2058e-01, -2.2588e-01, -2.2215e+00,\n",
      "         9.5516e-03, -1.3955e-01, -9.3184e-01,  7.2043e-03, -2.8692e-01,\n",
      "        -1.0306e-01, -6.3916e-01, -2.4915e+00, -1.5243e-01, -6.5366e-01,\n",
      "        -7.7562e+00, -4.1175e-01, -5.6904e-02, -7.4505e-01, -1.4333e-03,\n",
      "        -4.7284e-03, -1.6486e+00,  3.1967e+00, -9.0597e-02, -2.6379e-02,\n",
      "        -8.3936e-02, -9.9854e-02, -6.7147e-02, -1.4503e+01, -1.0833e+00,\n",
      "         1.1697e+00, -3.8925e-02, -1.2052e+00, -1.1279e+00, -1.0290e+00,\n",
      "        -1.0740e+00,  1.7657e-03,  2.1856e-01, -3.9210e-01, -1.6678e+00,\n",
      "         6.1059e-01, -2.1236e+00,  4.5593e-01, -9.7067e-01,  9.4548e-01,\n",
      "        -2.1914e+00, -4.2849e-01, -5.1202e-01, -4.4609e-01, -2.9257e-02,\n",
      "        -8.3492e-02, -1.1122e+00, -2.0330e+00, -1.9028e-01, -2.0054e+00,\n",
      "         9.9116e-01,  3.3685e-02, -8.3585e-01,  7.1650e-01, -1.0844e-02,\n",
      "        -1.2094e-02, -2.0127e-01, -5.5460e-01,  4.0645e+00, -1.2410e+00,\n",
      "        -1.1087e-01, -1.4255e+00,  1.7603e-01, -2.8454e-02,  6.1961e+00,\n",
      "        -6.9184e-01, -4.9010e-02, -1.5702e-01, -1.5014e+00, -6.2341e-01,\n",
      "        -2.6633e-01, -8.1102e-02, -5.2898e-02, -7.8254e-02, -7.2802e-02,\n",
      "        -9.8168e-03, -6.5324e-01,  4.6638e+00, -3.5006e+00, -4.1009e-01,\n",
      "         2.9861e-03, -1.2865e-01, -5.8529e-01,  6.5772e-02,  4.3343e-03,\n",
      "        -4.5907e-01, -1.4184e+00, -3.9634e-01, -2.3799e-01, -9.1257e-01,\n",
      "        -7.0451e-01, -3.5064e-01, -2.3913e-01, -6.6952e-01,  3.9689e-01,\n",
      "        -1.6824e+00, -2.9218e-01, -2.0490e-01, -2.2598e-01, -5.7747e-01,\n",
      "         6.7744e-02, -9.0197e-02, -1.6389e-01, -1.0672e+00, -2.9549e-01,\n",
      "         1.2283e+00, -3.2539e-01, -3.8547e-02, -7.1450e-02, -2.5624e-02,\n",
      "        -7.4278e-02,  7.7715e-01], device='cuda:0')), ('backbone.model.layer2.3.conv1.weight', tensor([[[[ 0.0274]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         [[ 0.0119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0371]],\n",
      "\n",
      "         [[ 0.0883]],\n",
      "\n",
      "         [[ 0.0358]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114]],\n",
      "\n",
      "         [[ 0.0669]],\n",
      "\n",
      "         [[ 0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         [[ 0.0224]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         [[-0.0069]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2101]],\n",
      "\n",
      "         [[-0.0435]],\n",
      "\n",
      "         [[-0.0898]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0282]],\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1690]],\n",
      "\n",
      "         [[ 0.0150]],\n",
      "\n",
      "         [[ 0.0187]]],\n",
      "\n",
      "\n",
      "        [[[-0.1192]],\n",
      "\n",
      "         [[ 0.0116]],\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0483]],\n",
      "\n",
      "         [[ 0.1317]],\n",
      "\n",
      "         [[ 0.0216]]],\n",
      "\n",
      "\n",
      "        [[[-0.0850]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         [[ 0.1323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1142]],\n",
      "\n",
      "         [[ 0.0723]],\n",
      "\n",
      "         [[ 0.0171]]]], device='cuda:0')), ('backbone.model.layer2.3.bn1.weight', tensor([1.0925, 1.7373, 2.0978, 3.3289, 5.2793, 2.1381, 2.0259, 1.7136, 2.0694,\n",
      "        2.1511, 2.0869, 2.4931, 1.7814, 1.5570, 1.6621, 5.9601, 1.9484, 2.7741,\n",
      "        2.9652, 2.9120, 2.3752, 2.5658, 1.5301, 2.1865, 1.6270, 1.8290, 2.2078,\n",
      "        2.6696, 2.2498, 1.8030, 2.1894, 2.3468, 1.7680, 2.2242, 1.9801, 2.4021,\n",
      "        2.6702, 2.8821, 2.8103, 1.7367, 1.7840, 2.7143, 2.0588, 2.1039, 1.4793,\n",
      "        2.3198, 1.7516, 1.6068, 3.3329, 2.8838, 2.2007, 2.6359, 2.2944, 1.4743,\n",
      "        4.7057, 1.2779, 1.6847, 2.8183, 1.7077, 2.4179, 0.6769, 2.8050, 2.6300,\n",
      "        1.6188, 1.9959, 1.3267, 1.9532, 2.4336, 1.4520, 1.7735, 2.3662, 1.4285,\n",
      "        1.6844, 3.7941, 1.6070, 1.8211, 1.7839, 0.8087, 2.9441, 2.8830, 2.1188,\n",
      "        2.2922, 1.3849, 1.1835, 1.8011, 2.0171, 2.0599, 1.9230, 2.3073, 2.2823,\n",
      "        2.2196, 2.1270, 2.0582, 2.4802, 1.9053, 1.8676, 1.9032, 1.8502, 2.5834,\n",
      "        1.4722, 3.4655, 2.2381, 1.8782, 2.0647, 2.2968, 2.0850, 1.8610, 2.5684,\n",
      "        2.5906, 1.9841, 2.6740, 1.4404, 1.6930, 1.7989, 1.7478, 2.1159, 1.9067,\n",
      "        1.9951, 1.6172, 1.7641, 2.4866, 2.0190, 1.2287, 1.6630, 1.8753, 1.7355,\n",
      "        2.4744, 3.4971], device='cuda:0')), ('backbone.model.layer2.3.bn1.bias', tensor([-0.2175, -0.1410,  0.2103, -1.8191, -0.6176, -1.8859,  0.0376,  0.2678,\n",
      "         0.9710, -2.0555, -0.4539, -2.4380,  0.3451,  0.6392, -1.8881, -0.4723,\n",
      "         1.1293, -3.9236,  0.5846, -0.6995, -1.2219,  0.0094,  0.9074, -3.1203,\n",
      "        -0.4553, -0.7191,  0.2639,  0.7852, -2.2556, -0.7041, -0.9777, -2.8155,\n",
      "         1.6122, -1.9459, -0.0943, -2.2412,  1.6138, -0.1749, -1.9090, -1.3190,\n",
      "        -2.7071, -0.1883,  0.0503, -0.0227, -1.2146, -1.2171, -0.6901,  1.2852,\n",
      "         1.5627,  0.7523, -2.5152, -0.4427, -1.9648,  0.2043, -2.1295, -1.0958,\n",
      "         0.2887, -2.8814, -0.3937,  0.3605,  0.0809, -5.6805, -4.3974, -1.1320,\n",
      "        -0.4527, -1.2320, -0.4115,  0.4159,  0.9477, -1.8042, -2.9002,  1.3321,\n",
      "        -0.7937, -2.9179,  0.1239, -0.9257, -0.0442, -1.8806, -1.9009, -1.0796,\n",
      "        -2.4138, -0.8840, -0.0690,  0.9192, -1.8706, -1.3127, -0.5155,  1.7244,\n",
      "         1.0018, -0.4730, -2.7697,  0.0331, -0.0634, -0.2792, -2.2881,  1.1930,\n",
      "         0.5477,  0.1176, -4.9398, -0.1859, -1.1381, -1.6101,  0.3075, -1.4548,\n",
      "        -2.1860, -1.5336,  0.2797,  1.3492, -2.7043,  0.6155,  0.2910, -0.3491,\n",
      "         1.1703,  0.2075, -0.3598, -1.1892, -1.3321, -0.3077, -0.9411, -0.3844,\n",
      "        -0.7089, -1.3520,  0.6115, -1.4380,  1.5359, -1.9564, -0.7221, -0.6796],\n",
      "       device='cuda:0')), ('backbone.model.layer2.3.conv2.weight', tensor([[[[ 1.1427e-02, -6.7076e-02,  1.7370e-02],\n",
      "          [ 2.2245e-02,  2.2217e-02,  2.9655e-02],\n",
      "          [ 2.3897e-02, -6.0134e-02, -4.9463e-03]],\n",
      "\n",
      "         [[ 4.0253e-02,  7.0585e-02, -2.0271e-02],\n",
      "          [-4.3750e-03,  1.6787e-01,  1.3973e-03],\n",
      "          [-1.4949e-02,  4.5996e-02,  1.0137e-02]],\n",
      "\n",
      "         [[ 6.1529e-02, -4.0182e-02, -4.1348e-02],\n",
      "          [ 8.6703e-02, -4.5270e-02, -8.7461e-02],\n",
      "          [ 4.6815e-02,  3.3868e-02,  1.2742e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1486e-02, -5.5195e-02, -4.9737e-02],\n",
      "          [ 4.5743e-02, -1.9695e-02, -1.3098e-01],\n",
      "          [ 6.4697e-02,  2.3231e-02, -5.6115e-02]],\n",
      "\n",
      "         [[-1.0495e-02,  8.9052e-02, -7.7461e-02],\n",
      "          [-6.4816e-03,  9.5931e-02, -1.2489e-02],\n",
      "          [ 6.7890e-05,  6.8347e-02, -1.6424e-02]],\n",
      "\n",
      "         [[-1.5447e-02,  2.0509e-02,  1.4870e-02],\n",
      "          [-6.5631e-04,  2.9518e-02,  4.4989e-02],\n",
      "          [-3.4970e-02, -1.5307e-02, -2.1034e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8936e-03, -1.6246e-03, -1.7904e-02],\n",
      "          [-2.7907e-02, -5.9859e-02, -1.9867e-02],\n",
      "          [-1.5280e-02, -3.6888e-02, -5.3823e-03]],\n",
      "\n",
      "         [[ 7.2002e-03, -1.2090e-02,  2.3013e-02],\n",
      "          [ 3.1492e-02, -3.8068e-02,  1.6500e-02],\n",
      "          [ 4.4727e-02, -1.1728e-02,  5.0263e-02]],\n",
      "\n",
      "         [[-3.8438e-02, -4.1569e-03,  7.9764e-02],\n",
      "          [ 9.8878e-03,  1.5087e-02,  3.7444e-02],\n",
      "          [ 6.5027e-02,  2.6889e-02,  1.3076e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9181e-02, -3.5646e-02, -6.2300e-02],\n",
      "          [ 4.7427e-02, -1.7139e-02, -1.8297e-02],\n",
      "          [ 6.1461e-02,  2.7680e-02,  1.2661e-02]],\n",
      "\n",
      "         [[-4.3361e-02, -5.6541e-02,  1.2083e-02],\n",
      "          [-1.2630e-02, -5.3582e-02,  2.1885e-02],\n",
      "          [-2.2714e-02, -4.6463e-02, -3.8505e-03]],\n",
      "\n",
      "         [[-1.1076e-02,  2.0971e-03, -5.7394e-03],\n",
      "          [-1.0688e-02,  9.1333e-04,  1.5980e-02],\n",
      "          [-3.7414e-03,  2.5449e-02,  4.7309e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6329e-02,  2.6720e-02, -2.8752e-02],\n",
      "          [-4.1491e-02, -4.8799e-03, -5.0840e-02],\n",
      "          [-4.2526e-02,  1.3796e-03, -2.5517e-02]],\n",
      "\n",
      "         [[ 1.4862e-02,  2.2865e-02,  1.3827e-02],\n",
      "          [ 3.1606e-02,  8.6311e-02,  2.0593e-02],\n",
      "          [ 2.3899e-02, -3.0004e-03, -7.1238e-03]],\n",
      "\n",
      "         [[ 2.4462e-02,  4.8369e-03,  1.9657e-03],\n",
      "          [-6.2982e-03, -3.0429e-02,  1.6307e-02],\n",
      "          [-3.5398e-02, -2.6175e-03,  4.9476e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1973e-02, -2.9184e-02, -6.6564e-03],\n",
      "          [ 6.0660e-04,  1.4431e-03,  3.5108e-02],\n",
      "          [ 1.1198e-02,  5.5122e-03,  5.4988e-02]],\n",
      "\n",
      "         [[ 1.8184e-03,  4.8830e-02,  4.8523e-02],\n",
      "          [-3.7605e-02,  1.6713e-02, -7.9722e-03],\n",
      "          [-1.7204e-02,  5.0038e-03, -1.5581e-02]],\n",
      "\n",
      "         [[ 7.7825e-03,  7.4771e-03, -6.2076e-03],\n",
      "          [ 3.7002e-03,  2.6140e-02,  1.2999e-02],\n",
      "          [-1.2169e-02, -1.0044e-02, -1.6803e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.6043e-02,  8.4767e-02,  2.3667e-02],\n",
      "          [-4.4055e-02, -2.5298e-01, -1.3680e-02],\n",
      "          [-2.3762e-02, -9.0293e-03,  4.2188e-02]],\n",
      "\n",
      "         [[-6.5245e-02, -1.1241e-01, -8.8372e-02],\n",
      "          [-2.7429e-02,  1.3535e-01, -4.2949e-02],\n",
      "          [-8.7624e-02, -6.1948e-02, -9.1809e-02]],\n",
      "\n",
      "         [[-1.2551e-02, -6.7373e-02, -1.5221e-02],\n",
      "          [ 7.5013e-02, -3.1797e-03, -1.7925e-02],\n",
      "          [ 3.6378e-02,  1.0535e-02, -7.2830e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2017e-02,  2.6587e-02, -6.0070e-04],\n",
      "          [-2.1537e-02,  5.9976e-02,  5.2686e-02],\n",
      "          [-1.1711e-02, -1.6165e-02,  4.6500e-02]],\n",
      "\n",
      "         [[ 8.3580e-02,  1.2803e-01,  1.1755e-01],\n",
      "          [ 5.7101e-03, -8.5015e-02,  8.9248e-02],\n",
      "          [ 8.8390e-02,  1.8534e-01,  1.1651e-01]],\n",
      "\n",
      "         [[ 2.8083e-02,  3.6117e-02, -3.3773e-02],\n",
      "          [ 5.5596e-02, -1.1165e-02, -5.3525e-02],\n",
      "          [-2.0877e-02,  1.5204e-02, -7.1408e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6881e-02,  5.5649e-02, -1.4510e-03],\n",
      "          [ 5.3952e-02, -7.9618e-02,  5.4977e-02],\n",
      "          [ 7.0217e-02,  1.0690e-01,  6.8987e-02]],\n",
      "\n",
      "         [[ 1.5700e-02,  2.1718e-03,  1.3118e-02],\n",
      "          [-1.5827e-02,  4.6924e-02,  1.7490e-02],\n",
      "          [ 6.3182e-03,  9.3197e-02,  1.3747e-02]],\n",
      "\n",
      "         [[ 3.6119e-02,  9.2193e-02,  9.5079e-02],\n",
      "          [ 1.6545e-01, -7.4675e-02,  8.4281e-02],\n",
      "          [ 1.1876e-01,  1.4606e-01,  2.2443e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3107e-01, -9.2410e-02, -3.8463e-02],\n",
      "          [-1.0427e-01, -2.5349e-02,  3.0748e-02],\n",
      "          [ 1.0266e-01,  6.9203e-03,  1.6390e-02]],\n",
      "\n",
      "         [[ 2.5365e-02, -1.0747e-03,  1.1038e-02],\n",
      "          [ 3.2864e-02, -8.8452e-02,  1.8762e-03],\n",
      "          [ 2.6643e-02, -1.8603e-02, -4.3254e-02]],\n",
      "\n",
      "         [[ 2.7194e-02,  1.1043e-02, -7.5994e-02],\n",
      "          [-1.8912e-02,  6.2102e-02, -1.4584e-02],\n",
      "          [-8.3947e-02, -6.4752e-03,  6.3529e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3037e-02, -9.3480e-03, -2.8921e-02],\n",
      "          [ 1.0964e-03, -5.9702e-02,  4.3296e-02],\n",
      "          [-2.1851e-02, -1.9015e-02, -1.6419e-02]],\n",
      "\n",
      "         [[ 4.6271e-04, -1.5532e-02,  1.5513e-02],\n",
      "          [-4.7129e-02, -6.9391e-03, -2.9038e-02],\n",
      "          [-1.0644e-02, -4.3069e-02,  1.4477e-02]],\n",
      "\n",
      "         [[ 2.1743e-03, -2.8934e-02, -1.0375e-01],\n",
      "          [ 7.3973e-02,  7.2373e-02, -9.2731e-02],\n",
      "          [-1.3718e-02,  4.8270e-02, -2.2242e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7660e-02,  9.4762e-03,  2.0076e-02],\n",
      "          [-4.5980e-03, -6.2027e-02, -5.6482e-02],\n",
      "          [ 2.2770e-02, -4.6314e-02, -8.1293e-02]],\n",
      "\n",
      "         [[ 2.6767e-02,  3.7439e-02, -1.7815e-02],\n",
      "          [ 1.5619e-03, -1.8415e-02, -3.9672e-02],\n",
      "          [-6.7121e-03, -2.8206e-02,  1.0577e-02]],\n",
      "\n",
      "         [[-1.6349e-03,  2.0421e-02, -2.3470e-02],\n",
      "          [-6.0596e-03,  9.4141e-03, -3.4885e-02],\n",
      "          [-3.3662e-02,  1.2831e-02,  1.1888e-02]]]], device='cuda:0')), ('backbone.model.layer2.3.bn2.weight', tensor([5.6973, 1.4595, 4.9349, 0.9037, 1.8089, 2.2966, 1.6035, 1.4311, 1.9212,\n",
      "        2.3541, 1.6359, 2.3673, 1.7614, 2.0006, 2.4492, 2.1449, 1.9942, 3.3423,\n",
      "        2.0320, 1.8560, 2.2645, 2.6611, 2.8884, 2.5297, 1.9502, 1.7748, 1.5308,\n",
      "        1.8790, 2.2449, 1.6429, 2.1567, 2.7782, 1.9212, 1.4536, 1.9646, 1.7024,\n",
      "        2.2376, 3.3123, 3.6080, 3.3567, 1.9995, 2.0012, 2.5472, 1.6632, 2.9029,\n",
      "        2.3859, 2.3126, 2.1615, 1.8135, 1.5382, 1.6492, 1.6071, 1.5610, 2.3820,\n",
      "        1.8358, 2.5951, 2.0943, 1.3812, 2.1657, 2.7511, 1.1433, 1.6891, 1.2060,\n",
      "        2.0534, 2.3314, 1.5009, 1.5339, 2.4177, 2.3173, 2.0321, 1.9600, 2.6468,\n",
      "        2.3410, 1.7522, 2.3572, 1.8445, 3.3686, 6.7940, 3.4588, 2.4813, 1.5082,\n",
      "        1.9451, 1.3924, 1.1392, 4.8822, 1.7821, 1.6086, 2.1699, 1.9579, 3.1126,\n",
      "        2.1522, 1.7614, 2.0615, 2.3754, 1.6669, 2.3752, 1.9068, 2.5200, 2.7019,\n",
      "        1.6936, 2.3574, 2.7168, 1.6967, 2.3914, 2.8423, 1.2903, 2.1509, 1.9346,\n",
      "        2.7823, 1.9584, 1.6940, 1.8365, 1.7942, 2.3304, 1.9005, 2.6611, 2.5722,\n",
      "        3.6369, 1.3871, 2.6636, 1.2618, 2.1588, 1.6951, 1.4474, 1.7397, 1.2142,\n",
      "        1.3627, 1.8978], device='cuda:0')), ('backbone.model.layer2.3.bn2.bias', tensor([-1.2953, -1.0587, -3.7921,  0.7452, -0.4832,  0.0544, -0.9491,  1.2543,\n",
      "        -0.0943, -2.5885,  1.1547, -0.5674, -2.3448,  0.6461,  0.1568, -0.1771,\n",
      "         1.4691, -0.8383, -0.6757, -0.9115, -1.1751,  1.0095, -1.7023, -0.2988,\n",
      "        -0.4014,  0.2940,  0.0917, -1.6943,  1.2027, -1.4499, -0.4716, -0.4812,\n",
      "        -1.0946,  0.5865, -0.9406,  0.3156, -1.8390,  1.5232, -1.6613,  1.0459,\n",
      "        -0.6680,  1.6317, -0.0367, -1.7253, -0.1689, -2.6954,  0.6930, -1.5351,\n",
      "        -1.4601, -0.0385, -0.7783,  0.1553,  0.9965, -3.7415,  0.0958, -0.5914,\n",
      "         1.1690,  0.5166, -1.3872, -2.4223,  0.3925, -0.1606,  0.5775, -2.1815,\n",
      "        -0.9498,  0.5056,  1.1586, -3.5100,  0.3422, -0.9083,  0.9102, -2.4963,\n",
      "        -0.3403, -1.7312,  0.0954, -0.1505, -0.1330, -1.0747, -0.1111, -3.8868,\n",
      "        -0.3602, -1.4243,  0.5525,  0.4478,  2.3460, -1.7992,  0.8209, -0.5945,\n",
      "        -1.4645, -1.0956,  1.7941,  0.3732, -0.2824,  0.0540, -1.1420,  0.4216,\n",
      "        -0.5868, -0.3998, -3.0720,  1.5097,  0.5402, -3.5326, -0.0371, -1.4277,\n",
      "        -2.2384, -0.0521, -1.7322, -0.4089, -1.2765, -1.1429,  0.1264,  1.1980,\n",
      "        -1.2850, -0.1435, -0.4353,  1.9006, -2.7378,  0.3209, -0.6855, -1.0223,\n",
      "         0.0096, -2.5517,  0.1829, -0.3753,  0.5695,  0.6817, -0.8821,  0.4595],\n",
      "       device='cuda:0')), ('backbone.model.layer2.3.conv3.weight', tensor([[[[-0.0281]],\n",
      "\n",
      "         [[-0.0247]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0617]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.0028]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0155]],\n",
      "\n",
      "         [[ 0.0293]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.0880]],\n",
      "\n",
      "         [[-0.0391]]],\n",
      "\n",
      "\n",
      "        [[[-0.0214]],\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         [[-0.0471]],\n",
      "\n",
      "         [[ 0.0113]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0194]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[-0.0268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0098]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[-0.0139]]],\n",
      "\n",
      "\n",
      "        [[[-0.0022]],\n",
      "\n",
      "         [[-0.0232]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0447]],\n",
      "\n",
      "         [[-0.0735]],\n",
      "\n",
      "         [[-0.0432]]],\n",
      "\n",
      "\n",
      "        [[[-0.0984]],\n",
      "\n",
      "         [[-0.0169]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0097]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0900]]]], device='cuda:0')), ('backbone.model.layer2.3.bn3.weight', tensor([ 2.2927e+00, -5.5295e-01,  4.1106e+00, -1.1403e+00,  5.8369e-01,\n",
      "        -6.7262e-01,  3.0167e+00, -1.3787e+00, -1.3556e+00,  2.5492e+00,\n",
      "         3.2538e-02,  4.0289e+00, -5.2314e+00, -3.7278e-01,  8.5332e-01,\n",
      "        -4.0987e-01,  3.4347e+00, -4.1894e+00, -5.3795e+00,  5.0132e-01,\n",
      "         8.9160e-01,  1.2794e+00, -8.0445e-01, -1.2094e-01,  2.0856e+00,\n",
      "        -6.3076e+00, -2.8567e+00, -2.6939e-01, -2.6804e+00, -2.7558e+00,\n",
      "         2.6487e+00,  7.9964e-01, -1.6141e+00, -3.0181e+00, -1.3071e+00,\n",
      "        -1.2200e+00,  3.9826e+00, -7.4884e-01,  3.1953e+00, -8.7915e-01,\n",
      "        -3.0102e+00, -1.6233e-01,  2.0131e+00,  7.3057e-01, -4.2768e-01,\n",
      "        -3.7504e+00, -1.1230e+00,  4.0228e+00, -4.3535e+00,  2.8373e-01,\n",
      "        -5.2134e-01,  2.1783e+00, -1.9359e+00,  2.3349e+00,  6.3065e-02,\n",
      "         6.6062e-02,  4.7911e-01, -1.3536e+00,  3.2902e+00,  7.4484e-01,\n",
      "         1.3009e-01, -3.1081e+00, -3.2290e+00, -2.0881e+00, -3.4023e+00,\n",
      "        -2.0654e-01, -2.4660e-01, -9.8869e-01,  7.1386e-01, -1.5823e+00,\n",
      "         4.5318e+00, -4.3781e+00, -2.6921e+00,  1.5390e+00,  7.8984e-01,\n",
      "         2.2337e+00,  8.9214e-01, -3.8941e+00,  1.5497e-01,  6.0471e-01,\n",
      "        -1.7901e+00,  5.9305e-01, -1.3472e+00,  2.3799e-01,  8.6442e-01,\n",
      "         8.1712e-01,  2.0358e-02,  1.3318e-01,  6.7488e-01,  8.4175e-02,\n",
      "        -3.1942e-01, -7.1012e-03, -3.0176e+00,  3.9333e-01, -5.6605e+00,\n",
      "         1.4414e-01, -2.7497e+00,  5.7301e+00,  2.0586e+00,  3.4745e-01,\n",
      "         7.8385e-01, -1.0170e+00,  1.4807e+00,  4.8993e-01,  2.2015e+00,\n",
      "         9.7875e-01, -1.0772e+00, -1.6635e+00,  2.7052e+00, -1.2283e+00,\n",
      "        -1.1434e+00, -7.2135e-01, -1.9328e-01, -3.1013e+00,  1.3661e+00,\n",
      "        -2.7626e+00,  3.2617e-01,  1.0344e+00,  3.5256e+00, -4.0763e-01,\n",
      "         2.9410e+00, -4.2463e+00, -9.9652e-01, -3.8094e+00, -3.4270e+00,\n",
      "         1.1271e+00,  6.6557e+00, -1.2726e+00,  1.9917e+00,  4.0288e+00,\n",
      "        -2.8014e+00,  6.0342e-01, -2.4550e+00,  1.4020e-01, -2.7235e-01,\n",
      "         1.3243e+00,  1.4789e+00, -1.3457e+00,  9.8213e-01,  1.1031e+00,\n",
      "         6.9948e-01, -2.2557e+00,  3.0210e+00,  6.4807e-01, -2.4604e+00,\n",
      "         4.0090e+00, -3.5734e+00,  1.2867e+00, -1.5050e+00,  9.4281e-01,\n",
      "         2.9258e+00, -1.4646e+01, -3.5509e+00,  6.2393e-01,  2.6792e-01,\n",
      "         2.6767e+00,  4.4661e+00,  1.1501e+00,  1.2894e+00, -6.9733e+00,\n",
      "        -3.2658e+00, -9.2315e-01, -3.5704e+00,  2.5478e+00, -2.4941e+00,\n",
      "         3.2731e+00,  1.2887e+01,  3.2975e+00, -3.7774e+00, -4.5900e+00,\n",
      "        -8.6994e-01, -3.6574e+00,  1.1341e+00,  6.3948e-01,  1.7116e-01,\n",
      "         2.9143e-01, -1.3354e+00, -3.7943e+00,  3.3736e+00,  2.7110e-01,\n",
      "         9.8864e+00, -2.4562e+00,  3.4327e-03,  1.5123e-01, -7.1238e-01,\n",
      "         2.3684e+00,  5.7193e-01, -5.1689e+00,  6.6295e-01, -2.9558e-01,\n",
      "        -7.2844e-01, -5.7924e-01, -7.1731e-01, -5.2042e+00,  2.0453e+00,\n",
      "        -2.5157e+00,  6.7824e-01,  6.2773e-01,  1.1476e+00,  4.6714e+00,\n",
      "         6.2701e-01, -7.2237e-01, -2.2064e+00, -9.5020e-01,  8.6185e-01,\n",
      "         9.1053e-01,  7.1237e-01, -7.9342e-01,  2.6614e+00, -4.7029e+00,\n",
      "        -1.3849e+00,  7.0132e-01, -4.9001e-01, -2.5490e+00,  9.1642e-01,\n",
      "         2.9017e+00,  1.2722e-01,  2.7467e-01,  8.4825e-02,  7.2161e-02,\n",
      "        -4.0466e-02,  4.1050e-01,  5.3114e-01, -9.0114e-01, -2.4406e+00,\n",
      "         3.2452e+00, -9.4014e-01, -1.3089e+00,  1.8514e+00, -4.0290e-01,\n",
      "         4.4284e-01,  5.7300e-01, -1.4073e+00,  1.4120e+00,  4.0084e+00,\n",
      "         3.5247e+00, -1.5722e+00, -2.4262e+00,  8.0949e-01, -2.6947e+00,\n",
      "        -2.0613e+00, -7.6062e-01,  3.9328e+00,  3.7505e+00,  4.7395e+00,\n",
      "        -4.4148e-01, -1.3903e+00,  1.7682e+00,  1.3394e+00, -2.4875e-01,\n",
      "        -6.3461e-01,  2.8475e-01, -2.0638e-01, -1.4211e-01, -2.2422e+00,\n",
      "         4.2504e+00,  3.6237e+00, -5.6466e-02,  4.2098e-01, -7.2320e-01,\n",
      "         1.6703e+00, -1.6941e+00, -3.2140e+00,  2.1435e+00,  5.7353e-01,\n",
      "        -5.6573e-01,  3.8169e+00,  6.9602e-01, -8.3875e-01, -1.8848e+00,\n",
      "        -3.8755e+00,  2.9534e+00,  1.7095e+00, -5.5336e-01,  6.6646e-01,\n",
      "         1.8545e+00, -2.6635e+00,  8.4705e-01,  5.3516e+00, -4.7362e+00,\n",
      "        -1.4686e+00,  1.7414e+00,  9.6873e-01,  2.4739e-01,  2.2414e+00,\n",
      "        -4.1505e-01, -3.2386e-01, -2.8511e+00,  2.8217e+00, -3.7207e+00,\n",
      "         1.8759e+00,  2.0473e+00, -2.1271e+01, -7.4784e-01,  1.5277e+00,\n",
      "        -5.7215e-01, -5.1360e-02,  2.6538e+00, -4.4615e-01,  1.5374e+00,\n",
      "         1.3638e-01,  3.2596e-02,  4.8267e-01, -1.3587e+00,  2.3905e-01,\n",
      "         2.3418e-01, -1.0297e+00,  2.1510e-01,  1.5953e+00,  7.6661e-01,\n",
      "        -2.6410e+00,  1.8695e+00, -3.3138e+00,  9.8879e-01,  2.3075e-01,\n",
      "        -3.1905e+00,  5.6811e+00, -1.5484e-01, -5.8313e-01, -9.4209e-01,\n",
      "         1.8496e-01,  8.7639e-01,  1.1923e+00,  8.4373e-01, -4.4820e+00,\n",
      "         3.1975e+00,  5.7185e-01, -3.4355e+00,  3.0476e-01, -2.3871e+00,\n",
      "         1.4392e+00, -1.4746e+00, -1.6787e+00,  3.1563e-01, -5.2009e+00,\n",
      "        -1.1148e+00, -1.0094e+00,  1.0074e+00, -4.1230e+00,  3.5337e-01,\n",
      "         3.1993e-01, -1.1622e+00,  2.1106e+00, -2.6958e+00, -3.0786e+00,\n",
      "         4.6101e+00, -7.6235e-01,  3.4846e+00,  1.5695e+00, -3.1331e+00,\n",
      "         1.2256e+00, -1.2253e+00,  9.4020e-01, -1.8511e+00, -1.3410e+00,\n",
      "         3.5697e-01, -4.2734e+00,  1.9833e-01,  6.8816e-01,  4.3025e-01,\n",
      "         5.4613e-01, -3.6649e-01, -1.1256e+00,  1.5127e+00,  1.0242e+00,\n",
      "        -2.3281e+00,  6.3451e+00, -2.9085e+00, -2.3424e+00, -4.2955e+00,\n",
      "         4.4402e+00, -7.5300e+00, -9.4642e-03,  5.2915e-01,  2.0121e+00,\n",
      "         1.7771e+00, -4.2852e+00, -2.6419e-01, -3.1109e-01,  5.2036e-02,\n",
      "         3.5042e+00, -1.0156e+00, -3.1234e+00,  8.9994e-01, -3.4373e+00,\n",
      "         2.5550e-01, -6.1075e-01,  5.3215e-01,  3.8835e+00,  2.7312e+00,\n",
      "         7.2414e-01,  7.8963e-01, -3.8255e+00, -3.8673e+00, -5.6314e-01,\n",
      "         5.0995e-02,  4.4518e+00, -6.5897e-01,  1.9413e-01,  4.0701e-01,\n",
      "         1.1652e+00,  1.0885e+00, -1.5204e+00,  8.5320e-01, -1.2456e+00,\n",
      "        -2.7138e+00, -1.9499e+00, -5.6929e-01, -3.2834e+00,  1.7798e-01,\n",
      "        -6.5918e+00, -2.7645e-01,  9.7011e-01,  2.7065e-01, -4.2888e+00,\n",
      "         2.3529e+00,  1.2300e+00,  9.3503e-01, -1.4064e+00, -8.0939e-03,\n",
      "         1.1155e+00, -4.1198e+00,  3.4273e+00, -3.4874e+00, -2.2112e-01,\n",
      "         1.7395e+00, -2.8007e+00, -2.6474e+00,  1.5153e+00, -4.3003e+00,\n",
      "        -4.5206e+00,  3.7533e+00,  2.3572e+00, -8.1211e-01,  2.6653e-02,\n",
      "        -7.7604e-01,  1.4721e+00,  1.0953e-01, -5.1864e+00, -4.8470e-01,\n",
      "        -1.0950e+00, -7.3751e-01, -3.3045e-04, -3.5832e-03, -3.3688e+00,\n",
      "         3.7470e+00,  2.0473e-01,  7.1799e-01,  5.1716e-01,  5.9023e-01,\n",
      "        -3.5424e+00, -3.0251e+00, -5.1387e-01, -3.5028e+00,  2.1799e+00,\n",
      "        -3.3429e+00,  8.1119e-01, -1.0870e-01,  1.4751e+01,  3.6766e-01,\n",
      "        -9.8958e-01,  7.4331e-01,  2.8997e+00,  3.5030e+00,  1.3648e+00,\n",
      "        -6.9605e+00, -7.7395e-01,  1.4039e+00,  6.2684e-02,  8.8519e-02,\n",
      "        -1.7427e+00,  3.8455e+00,  3.3453e+00,  4.7943e+00, -2.0955e+00,\n",
      "        -5.0259e+00,  2.9736e+00, -1.0166e+00, -1.0885e+00,  2.2754e+00,\n",
      "        -1.6291e-02,  3.2005e+00,  8.1461e-03,  1.4042e+00, -2.2449e-01,\n",
      "        -2.9871e-01,  4.3792e-01, -5.6949e-02, -8.9813e-01, -1.5550e-02,\n",
      "        -8.9971e-02,  3.0064e-01,  1.7684e+00, -6.5002e-01, -1.9918e+00,\n",
      "         1.9316e-01, -4.9817e-01,  3.5463e+00, -3.8782e+00, -9.4149e-01,\n",
      "         4.0489e+00, -1.9577e+00,  2.1727e+00, -1.4189e+00,  1.7378e-03,\n",
      "         8.6178e-01, -3.2682e+00, -3.3703e+00,  8.7049e-01,  3.4826e+00,\n",
      "        -2.0825e+00,  1.1424e+00], device='cuda:0')), ('backbone.model.layer2.3.bn3.bias', tensor([-1.0450e-01, -7.6160e-02, -2.4103e-01, -8.1215e-01, -3.2384e-01,\n",
      "        -8.8076e-03, -1.4549e-01, -3.4506e-01, -6.9065e-01,  2.6746e-01,\n",
      "        -8.1530e-04,  9.8053e-01, -2.0066e+00, -3.2920e-01, -1.6361e+00,\n",
      "        -1.4268e-01, -1.5971e+00, -3.6274e-01, -4.8698e-01, -3.2348e-01,\n",
      "        -5.4906e-01, -2.8163e-01, -6.6505e-01, -5.5429e-02, -4.8057e-01,\n",
      "        -5.0277e-01, -1.3001e+00, -2.8641e-01, -9.1332e-01,  5.7959e-01,\n",
      "         1.8871e-01, -1.0905e-01, -1.0253e+00, -1.1831e+00, -1.1819e+00,\n",
      "        -1.5434e+00, -2.0826e-02, -6.7558e-01,  1.0438e+00, -8.5010e-01,\n",
      "        -4.6085e-01, -9.2286e-02,  1.8049e+00, -4.1934e-01, -6.1816e-01,\n",
      "        -8.8657e-01, -1.0008e+00, -1.5802e+00, -1.5935e+00, -3.6120e-01,\n",
      "        -3.2281e-01, -6.5347e-01, -2.0796e-01, -7.7272e-01, -6.5494e-02,\n",
      "         3.1228e-02, -3.6723e-01, -3.7492e-01, -6.4306e-02, -2.9623e-01,\n",
      "        -2.0829e-01, -4.1095e-01, -3.3032e+00, -1.1320e+00, -1.5989e-01,\n",
      "        -8.8040e-02, -1.1467e-01, -5.7700e-01, -2.3180e-01, -1.0060e+00,\n",
      "        -5.2398e-01, -2.7931e-01,  6.8891e-01, -5.4718e-01, -1.2137e-01,\n",
      "        -1.8889e-01, -6.8811e-01, -6.2632e-01, -7.5173e-01, -2.3684e-01,\n",
      "        -1.9077e+00, -5.6958e-01, -1.9314e+00, -2.1946e-01, -1.2248e+00,\n",
      "        -2.1364e-01, -1.3299e-01, -7.8088e-02, -6.7441e-01, -1.3692e-01,\n",
      "        -9.3645e-01, -2.6344e-02, -2.3033e+00, -6.4290e-01, -5.5240e+00,\n",
      "        -2.7014e-01, -8.1828e-02, -9.2518e-01, -1.2424e-01, -2.3025e-01,\n",
      "        -1.0382e+00, -2.7288e-01,  6.2430e-02, -6.0154e-01, -9.1322e-01,\n",
      "        -2.7134e-01, -4.7766e-01, -7.7186e-01, -6.9872e-01,  1.0903e-01,\n",
      "        -1.4373e-01, -5.2305e-01, -5.6118e-02, -6.6929e-01, -7.8047e-01,\n",
      "         6.6026e-01, -2.9190e-01, -1.5699e-01, -1.9145e-01, -3.6929e-01,\n",
      "        -1.1630e+00, -1.7069e+00, -8.3355e-01, -6.8265e-02, -2.2510e+00,\n",
      "        -2.2098e-01,  1.1297e+00, -2.5653e-01, -9.0567e-01, -6.4318e-01,\n",
      "        -1.8282e+00, -4.7045e-01,  1.2361e-01, -9.1059e-02, -2.0660e-01,\n",
      "         4.7020e-02, -8.9220e-01,  9.3902e-02, -7.6539e-01, -9.5716e-01,\n",
      "        -4.3028e-01, -3.8260e+00,  7.9352e-02, -1.2131e-01,  7.0425e-02,\n",
      "        -6.6731e-01, -2.6524e+00, -4.6433e-01, -3.2448e-01, -5.7473e-01,\n",
      "        -9.0223e-01, -7.3552e-01, -4.5722e+00, -4.0272e-01, -2.1088e-01,\n",
      "        -4.9074e-01,  2.1114e+00, -6.4359e-01, -4.3209e-01,  1.0546e+00,\n",
      "        -1.5274e+00, -5.5943e-01, -2.7365e-01, -2.7012e+00, -5.5060e-01,\n",
      "         5.9692e-01,  1.8774e+00, -1.2696e+00, -2.1099e+00, -8.6836e-01,\n",
      "        -8.7138e-01, -1.6356e+00, -2.2511e-01, -6.3496e-03, -3.6212e-01,\n",
      "        -3.3056e-01, -1.1485e+00, -7.3922e-01,  2.6376e-01, -5.5623e-02,\n",
      "         2.9164e+00, -9.7618e-02, -2.5021e-02, -8.1503e-02, -1.3872e-01,\n",
      "        -2.8739e-01, -4.3879e-01,  1.9088e+00, -3.1627e-01, -2.1298e-01,\n",
      "        -2.7152e-01, -1.5386e-01,  3.7772e-02, -4.4823e-01, -1.4829e+00,\n",
      "         1.6676e-01, -6.0110e-01, -4.4781e-01, -3.8255e-01, -3.7508e+00,\n",
      "        -7.7940e-02, -6.3277e-01, -9.3857e-01, -1.0344e-01, -1.2868e+00,\n",
      "        -3.0703e-01, -3.6034e-01, -2.9668e-01, -2.1072e-01, -2.6887e+00,\n",
      "        -4.6215e-01, -5.3043e-01, -2.0962e-01,  1.0761e+00, -1.9667e-01,\n",
      "         4.6253e-01, -9.1583e-02, -2.4514e-01, -4.1616e-02, -4.9188e-02,\n",
      "        -4.6749e-02, -2.2969e-01, -1.2608e+00, -6.0472e-01, -1.1494e+00,\n",
      "        -1.2949e+00, -2.6886e-01, -6.6662e-01, -1.9119e-01, -3.7639e-01,\n",
      "        -9.3985e-01, -1.0123e-01, -3.7854e-01, -4.3852e-01, -1.0058e+00,\n",
      "        -3.2849e-01, -2.9001e-01, -2.0522e-01, -4.3721e-01, -6.1771e-01,\n",
      "        -7.1272e-01, -3.4168e-01, -7.4467e-02,  1.5250e-01, -1.5599e+00,\n",
      "        -1.9065e-01, -5.3051e-01, -1.0076e+00, -7.7971e-01, -4.5368e-01,\n",
      "        -8.4828e-01, -1.3967e-01,  1.7337e-02,  5.2293e-02, -5.6607e-01,\n",
      "        -4.6035e-01, -1.2137e-01, -1.0750e-02, -3.9210e-01, -1.6820e+00,\n",
      "        -1.0903e+00, -2.0608e-01,  5.2856e-01, -3.4192e-01, -5.6050e-01,\n",
      "        -4.0615e-01,  4.5338e-01, -4.2487e-01, -3.8196e-01, -4.4682e-01,\n",
      "         9.1157e-01, -1.7488e+00, -9.2518e-01, -5.5146e-01, -4.6396e-01,\n",
      "        -4.6214e-01, -6.5550e-02, -1.5281e+00, -9.3768e-01,  7.3433e-01,\n",
      "        -6.8716e-01, -1.1951e+00, -3.7638e-01, -2.9709e-01, -1.4884e+00,\n",
      "        -5.1852e-02, -5.7532e-01, -6.0385e-01, -1.5555e+00, -1.6274e+00,\n",
      "        -1.4593e+00, -3.6112e-01, -1.2803e+01, -9.4132e-01, -6.0722e-01,\n",
      "        -6.4438e-01, -8.5746e-02, -7.1017e-01, -3.1394e-01, -6.5053e-01,\n",
      "        -9.6207e-02, -1.0919e-01, -3.4669e-01, -6.7322e-01, -6.1149e-02,\n",
      "        -3.0211e-01, -5.5101e-01, -1.7456e-01, -7.5929e-01, -1.0390e+00,\n",
      "        -1.2856e+00, -8.9916e-01, -6.8450e-01, -8.8378e-01, -1.4509e-01,\n",
      "         9.6108e-01, -3.7589e+00, -8.0569e-01, -7.4971e-01, -6.9237e-01,\n",
      "        -7.7758e-01, -4.2677e-01, -9.6922e-01, -2.0572e-01, -1.0861e+00,\n",
      "        -9.6315e-01, -4.6512e-01, -1.5710e+00, -7.7069e-02, -2.2223e-01,\n",
      "         3.1690e-01, -2.5333e-01,  2.4276e-01, -2.3138e-01,  3.2271e-01,\n",
      "        -5.0731e-01, -3.5126e-01, -3.4376e-01, -1.1532e+00,  2.5084e-01,\n",
      "        -3.7508e-01,  2.8093e-01, -8.3613e-02,  5.4124e-01, -1.2397e+00,\n",
      "         2.3454e-01, -7.2127e-01, -6.7844e-02, -8.6274e-01,  9.4626e-01,\n",
      "         3.7880e-02, -5.0812e-01, -4.2201e-01, -5.3416e-01, -1.2338e-01,\n",
      "        -2.7846e-01, -2.1080e-02, -5.8903e-02, -4.6329e-01, -1.6272e-01,\n",
      "        -7.3813e-01, -3.4966e-01, -1.8098e-01, -4.8009e-01, -6.3279e-01,\n",
      "        -1.1229e+00,  3.5315e-02, -2.7369e-01, -1.0850e+00, -6.2442e-01,\n",
      "        -1.9613e+00, -1.2497e+00, -2.2761e-03, -3.4488e-01, -2.8392e-01,\n",
      "         5.7549e-03, -3.6429e-02,  4.1751e-02, -7.6363e-02, -7.5640e-03,\n",
      "        -2.5342e+00, -1.9131e+00, -1.5191e+00, -4.2478e-01,  8.9636e-01,\n",
      "        -3.7505e-03, -3.0907e-01, -4.0257e-01,  9.2930e-02, -1.2881e+00,\n",
      "        -5.0257e-01, -6.9435e-01, -6.7992e-01,  1.0386e+00, -2.0809e-01,\n",
      "        -7.7550e-02, -1.9842e+00, -1.2801e-01, -2.1842e-01, -4.7177e-01,\n",
      "        -3.1844e-01, -5.5747e-01, -3.4728e-01, -5.3484e-01, -8.6808e-01,\n",
      "         1.8829e-01, -8.2167e-01, -6.1256e+00, -1.8075e+00, -1.4063e-01,\n",
      "         1.1109e+00, -2.2181e-01, -4.4846e-01, -1.0413e-01, -1.2700e+00,\n",
      "        -8.7958e-01, -6.1455e-01, -2.6531e-01, -4.9000e-01, -8.8517e-03,\n",
      "        -5.6332e-01, -9.4647e-01,  7.3135e-02,  1.5795e+00, -1.9373e-01,\n",
      "        -1.7538e-01, -3.2860e-01,  2.4148e-01,  2.6699e-01,  5.2800e-01,\n",
      "         2.6873e-01, -4.4490e-01, -1.0285e+00, -6.5958e-01, -3.7464e-02,\n",
      "        -6.7504e-01, -1.0118e+00, -8.4557e-02, -1.5422e+00, -1.2366e+00,\n",
      "        -4.1008e-01, -3.7316e-01, -1.3764e-02, -1.6502e-02,  6.3490e-01,\n",
      "         4.3623e-01, -9.5499e-02, -8.2774e-01, -5.8855e-01, -3.2662e-01,\n",
      "        -6.6577e-01,  2.6557e-01, -5.6351e-01, -9.4349e-02, -3.5260e-01,\n",
      "        -4.3118e-01, -3.8161e-01, -4.3645e-02, -2.3791e+00, -5.3519e-01,\n",
      "        -5.5591e-01, -8.3301e-01, -1.6772e+00, -1.7523e+00, -1.2681e+00,\n",
      "        -7.8885e-01, -2.1193e-01, -6.3782e-01, -3.4354e-01,  7.4975e-04,\n",
      "        -1.3132e+00, -1.0781e+00, -9.5478e-01, -6.3118e-01, -5.8454e-01,\n",
      "        -8.2792e-01,  5.2473e-01, -1.0988e+00, -9.7936e-01, -5.1197e-01,\n",
      "         2.2269e-04, -4.9923e+00, -1.0161e-01, -1.2407e+00, -9.0680e-01,\n",
      "        -1.7663e-01, -4.5357e-01, -3.4322e-01, -6.5401e-01, -1.0824e+00,\n",
      "        -1.0917e-01, -1.6560e-01, -2.4170e+00, -3.9576e-01, -2.4489e+00,\n",
      "        -5.2399e-01, -1.4512e-01, -6.2009e-01, -7.1596e-01, -5.2846e-01,\n",
      "        -4.9967e-01, -1.2557e+00, -9.9176e-01, -3.7481e-01, -6.6773e-02,\n",
      "        -3.5419e-01, -1.0024e+00, -2.0498e+00,  6.5031e-02, -9.2537e-01,\n",
      "        -8.1080e-01, -1.4488e-01], device='cuda:0')), ('backbone.model.layer3.0.conv1.weight', tensor([[[[-0.0290]],\n",
      "\n",
      "         [[-0.3052]],\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1204]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[-0.0375]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0221]],\n",
      "\n",
      "         [[-0.1422]],\n",
      "\n",
      "         [[ 0.0219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0023]],\n",
      "\n",
      "         [[-0.0157]],\n",
      "\n",
      "         [[-0.1060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0396]],\n",
      "\n",
      "         [[-0.0360]],\n",
      "\n",
      "         [[-0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[-0.0769]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0064]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[-0.0041]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0597]],\n",
      "\n",
      "         [[-0.0468]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[ 0.0099]],\n",
      "\n",
      "         [[ 0.0571]]],\n",
      "\n",
      "\n",
      "        [[[-0.0946]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[-0.0448]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[-0.0938]],\n",
      "\n",
      "         [[ 0.0231]]]], device='cuda:0')), ('backbone.model.layer3.0.bn1.weight', tensor([1.3818, 2.4005, 1.9929, 1.7261, 2.0373, 1.5541, 2.0843, 2.0068, 1.6865,\n",
      "        1.6545, 1.3007, 1.7019, 1.8481, 1.8224, 2.0687, 1.2496, 1.9884, 2.1074,\n",
      "        2.3025, 2.4671, 1.4962, 1.6718, 1.6511, 2.7960, 1.7271, 1.6658, 1.2855,\n",
      "        2.3966, 1.9463, 1.5989, 1.9017, 1.7207, 1.7209, 2.3627, 1.8639, 1.5323,\n",
      "        1.7866, 1.7605, 1.1550, 2.2844, 1.3311, 1.6372, 1.4570, 1.4548, 2.1674,\n",
      "        1.8206, 2.2512, 2.2904, 1.7831, 1.8667, 1.1885, 2.0444, 1.6935, 1.8113,\n",
      "        1.4770, 1.4331, 1.3031, 1.8630, 2.2280, 1.8482, 1.7039, 2.2486, 2.3825,\n",
      "        1.5759, 1.5421, 2.3403, 1.5411, 2.5369, 2.0754, 2.5003, 1.6215, 2.7755,\n",
      "        1.8534, 1.6234, 1.8611, 2.0627, 2.1524, 2.3170, 2.1483, 1.4962, 1.6539,\n",
      "        1.9989, 1.6124, 1.5981, 1.5681, 1.6554, 1.5498, 1.4285, 1.5385, 3.1633,\n",
      "        1.8503, 1.3620, 2.9588, 2.6918, 0.7936, 1.5792, 1.7348, 1.7531, 1.3222,\n",
      "        2.1056, 2.1848, 1.2509, 1.7157, 1.6442, 1.9561, 2.4229, 1.9871, 1.7777,\n",
      "        2.0029, 3.5708, 0.8472, 3.0185, 1.6280, 1.8177, 2.3080, 1.6331, 2.6793,\n",
      "        1.9600, 1.9849, 1.6115, 2.2543, 1.9918, 1.4026, 1.3293, 1.8530, 1.5077,\n",
      "        1.9958, 1.6113, 2.1345, 1.9164, 1.4857, 1.3583, 1.4114, 1.5574, 1.5625,\n",
      "        2.6150, 1.7100, 1.9051, 1.9030, 1.1057, 1.2707, 1.3287, 1.3257, 1.3029,\n",
      "        1.7837, 2.0772, 2.7040, 1.9172, 2.2969, 1.5484, 1.4882, 1.3389, 3.0068,\n",
      "        1.6652, 1.5900, 1.8609, 2.2470, 1.8382, 1.7412, 2.0527, 1.4503, 1.3322,\n",
      "        3.2296, 1.5163, 1.3606, 1.9568, 1.6668, 2.2362, 1.6155, 1.4497, 1.8261,\n",
      "        1.8008, 2.2063, 1.8974, 1.3557, 1.9936, 1.9088, 1.4903, 1.5899, 2.5538,\n",
      "        1.9106, 1.3701, 1.4578, 1.7859, 2.4634, 1.4167, 1.6494, 2.0281, 2.2022,\n",
      "        2.7596, 1.7287, 1.6847, 1.6502, 1.5325, 1.9613, 2.1516, 2.1222, 1.7415,\n",
      "        1.6669, 2.0140, 1.4430, 1.7394, 1.5477, 1.4993, 3.2575, 1.7638, 2.2680,\n",
      "        1.6489, 2.2096, 1.7237, 2.4649, 1.9973, 1.3591, 1.6465, 2.1585, 1.8575,\n",
      "        1.4351, 1.8186, 1.1529, 1.2969, 1.0219, 1.8872, 1.3161, 1.9931, 0.8925,\n",
      "        2.0073, 1.7165, 2.1107, 2.2083, 2.1055, 2.9398, 2.2467, 1.4778, 1.6046,\n",
      "        1.7304, 2.3741, 2.8529, 2.2870, 1.2072, 3.4187, 1.5230, 1.8687, 1.6737,\n",
      "        2.4732, 2.4726, 2.2325, 2.1713, 1.0857, 1.6770, 1.4385, 1.5873, 2.1689,\n",
      "        1.7741, 2.3038, 1.6080, 1.4287], device='cuda:0')), ('backbone.model.layer3.0.bn1.bias', tensor([-5.3549e-01, -1.3850e+00, -1.6246e+00, -2.3286e+00, -1.8782e+00,\n",
      "        -6.0011e-01, -2.5596e+00, -1.6396e+00, -6.9549e-01, -2.4908e+00,\n",
      "         1.0530e-01, -7.8171e-02, -8.4186e-01, -1.5046e+00, -1.3964e+00,\n",
      "        -6.0002e-01, -1.4791e+00, -4.0096e+00, -2.2138e+00, -2.4667e+00,\n",
      "         3.2927e-01, -3.5939e-01, -8.4399e-01, -3.0849e+00, -1.1779e+00,\n",
      "        -1.5739e+00,  1.8917e-01, -9.7749e-01, -5.6238e-01, -1.7486e+00,\n",
      "        -1.0285e+00, -1.4462e+00, -1.0488e+00, -1.7560e+00, -4.7522e-01,\n",
      "        -7.1113e-01, -2.2037e+00, -1.3278e+00, -6.3974e-01, -2.4015e+00,\n",
      "         2.1284e-01, -2.7109e+00, -1.6244e+00, -2.7868e-01, -6.5474e-01,\n",
      "        -9.8571e-01, -4.0171e-01, -1.8694e+00, -7.7027e-01, -1.1721e+00,\n",
      "        -1.5051e+00, -1.4543e+00, -2.3714e-01, -4.8320e-01, -9.0775e-01,\n",
      "        -3.5612e-01, -1.5303e-01, -1.1828e+00, -2.9714e+00, -3.4224e-01,\n",
      "        -2.4098e+00, -1.9919e+00, -7.6372e-01, -6.4830e-01, -1.4187e-01,\n",
      "        -2.8337e-01, -2.5934e-01, -1.5181e+00, -2.5757e+00, -1.8276e+00,\n",
      "        -2.2482e+00, -1.7081e+00, -1.0252e+00, -2.4075e+00, -7.3528e-01,\n",
      "        -9.5940e-01, -1.4263e+00, -1.2747e+00, -1.5032e+00,  1.1319e-01,\n",
      "        -1.8541e+00, -7.6887e-01, -1.0465e+00, -1.0500e+00, -2.5514e+00,\n",
      "        -1.8760e-01, -4.5588e-01, -1.6288e-01, -1.0280e+00, -1.9370e+00,\n",
      "        -1.2792e+00, -7.1010e-02, -4.3763e+00, -3.7278e+00, -4.2135e-01,\n",
      "        -5.4612e-01, -8.9776e-01, -1.3897e+00, -1.1246e-01, -1.3730e+00,\n",
      "        -1.1988e+00,  1.4921e-01, -1.3715e+00, -1.6765e+00,  5.7892e-01,\n",
      "        -1.4446e+00, -2.0118e+00, -1.4179e+00, -1.8389e+00, -2.7892e+00,\n",
      "        -1.6784e+00, -2.5272e+00, -3.8766e-01, -1.4696e+00, -7.3134e-01,\n",
      "        -9.5269e-01, -5.1012e-01, -3.1354e+00, -1.4432e+00, -5.7277e-01,\n",
      "        -1.3399e+00, -1.4853e+00, -2.8380e-01,  6.8512e-02, -1.8946e+00,\n",
      "        -3.0583e-01, -1.5291e+00, -2.1347e+00, -1.2131e+00, -3.2671e-01,\n",
      "         2.8840e-01, -9.3176e-01, -2.8119e-01, -6.5585e-01, -2.7735e+00,\n",
      "        -1.5937e+00, -1.0579e+00, -4.4954e-01, -1.8332e+00,  3.2354e-01,\n",
      "        -3.0750e-01,  3.1995e-01, -1.1689e+00, -5.7984e-01, -7.6337e-01,\n",
      "        -2.8360e+00, -1.8503e+00, -1.5128e+00, -2.6746e+00, -1.5481e+00,\n",
      "        -1.6132e+00,  4.8510e-01, -3.1454e+00, -1.6073e-01, -1.2214e+00,\n",
      "        -1.1697e+00, -1.3831e+00, -2.8847e+00, -1.9114e-01, -2.0113e+00,\n",
      "        -1.0946e+00, -7.7182e-01, -1.1798e+00, -2.0714e+00, -3.2528e-01,\n",
      "        -1.0541e+00, -1.5468e+00, -2.3059e+00, -1.5889e+00, -1.0735e+00,\n",
      "        -1.0174e+00, -1.5846e+00, -1.4898e+00, -1.0086e+00,  9.4509e-01,\n",
      "        -1.8271e+00, -1.7397e+00,  7.9101e-01, -8.8241e-01, -1.9971e+00,\n",
      "        -8.6809e-01, -7.4346e-01, -1.5044e+00, -1.0378e+00, -2.1347e+00,\n",
      "        -7.9677e-01, -1.4380e+00, -1.4580e+00, -9.2806e-01, -1.9891e+00,\n",
      "        -1.6576e+00,  6.0133e-01, -6.5299e-04,  3.9139e-02, -1.4727e+00,\n",
      "        -1.2954e+00, -2.2995e+00, -1.0160e+00, -8.9763e-01, -1.5543e+00,\n",
      "        -1.8227e+00, -3.5680e-01, -4.5975e-01, -1.0744e+00, -3.1714e+00,\n",
      "        -3.8814e-01, -1.7796e+00, -7.6655e-01, -2.0616e+00, -7.4710e-01,\n",
      "        -3.1296e+00, -2.1727e+00,  8.9834e-01, -1.1946e+00, -4.8159e-01,\n",
      "        -1.6434e+00, -2.6362e-01, -1.8958e-01,  1.8791e-01, -1.5014e+00,\n",
      "        -1.3158e-01, -2.2779e+00, -1.5637e-01, -1.8549e+00,  8.3054e-01,\n",
      "        -1.4831e+00, -2.4135e+00, -2.2083e+00, -2.6825e+00, -9.7973e-01,\n",
      "        -2.7029e+00, -2.2681e+00, -6.4452e-01, -7.3881e-01, -4.5343e-01,\n",
      "        -1.8319e+00, -2.1304e+00, -7.6061e-01, -2.3178e+00, -2.5425e+00,\n",
      "        -6.4342e-01, -2.5049e+00, -1.5478e+00, -1.1527e+00, -1.1501e+00,\n",
      "        -2.6219e+00, -1.2835e+00,  3.9172e-01, -4.9119e-01, -2.5988e-01,\n",
      "        -1.7261e+00, -1.0508e+00, -1.2308e+00, -1.2267e+00, -1.4844e+00,\n",
      "        -8.5897e-01], device='cuda:0')), ('backbone.model.layer3.0.conv2.weight', tensor([[[[-2.3330e-02,  1.3749e-02, -2.0991e-02],\n",
      "          [-3.0048e-02,  1.9823e-02,  2.7604e-03],\n",
      "          [ 8.0429e-03,  4.4661e-03, -1.8055e-02]],\n",
      "\n",
      "         [[ 3.1061e-02, -1.1023e-01, -6.2896e-02],\n",
      "          [-9.3494e-02, -1.5337e-01, -1.1371e-01],\n",
      "          [-6.3223e-02, -2.1529e-01, -1.1982e-01]],\n",
      "\n",
      "         [[ 3.2827e-02, -7.0539e-03, -1.2319e-03],\n",
      "          [ 1.1752e-02,  5.2173e-03,  2.3580e-02],\n",
      "          [ 5.8188e-04, -2.8852e-03, -1.5252e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2823e-02,  2.5860e-02,  4.4502e-02],\n",
      "          [-2.4704e-02, -4.5595e-02,  6.9792e-04],\n",
      "          [-5.2458e-02, -5.6758e-02, -4.0394e-02]],\n",
      "\n",
      "         [[ 3.9448e-02,  2.7733e-02,  7.1700e-02],\n",
      "          [ 3.8692e-02,  6.7443e-02,  5.8163e-02],\n",
      "          [ 2.9803e-02,  2.3441e-02,  4.3101e-02]],\n",
      "\n",
      "         [[ 5.4555e-02, -5.7310e-02, -7.1439e-03],\n",
      "          [-1.2024e-02, -3.3045e-02, -4.7406e-02],\n",
      "          [ 1.9995e-02, -2.8558e-03,  1.1004e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9770e-02,  4.8554e-03, -2.5810e-02],\n",
      "          [-3.8796e-02, -2.4218e-02, -5.1247e-02],\n",
      "          [-1.0010e-01, -8.3773e-02, -5.1251e-02]],\n",
      "\n",
      "         [[ 2.1118e-02,  5.1124e-02,  5.9232e-02],\n",
      "          [ 9.4653e-02,  4.2381e-02,  6.5558e-02],\n",
      "          [ 9.2166e-02,  8.8554e-02,  5.1775e-02]],\n",
      "\n",
      "         [[-1.3232e-02,  6.5246e-03, -1.0733e-02],\n",
      "          [ 2.6461e-02,  5.7768e-02,  5.1077e-02],\n",
      "          [ 3.1192e-02,  5.6701e-02,  3.6919e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8807e-02,  7.3878e-02,  1.7204e-02],\n",
      "          [ 3.8570e-03,  6.5806e-02,  5.1977e-02],\n",
      "          [-4.7130e-02, -1.0205e-03, -9.9053e-03]],\n",
      "\n",
      "         [[ 1.4808e-02, -7.7037e-03, -1.2222e-02],\n",
      "          [-4.2083e-02, -7.4875e-02, -1.5762e-02],\n",
      "          [-7.2704e-02, -5.5499e-02, -5.5227e-02]],\n",
      "\n",
      "         [[ 1.8562e-02, -6.7928e-03, -1.0830e-02],\n",
      "          [-1.9527e-02, -7.1786e-02, -6.9376e-03],\n",
      "          [-2.8776e-03, -4.8825e-02, -3.2739e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2869e-02,  5.3698e-02,  6.6712e-02],\n",
      "          [ 8.3122e-02,  6.5281e-02,  9.0602e-02],\n",
      "          [ 6.3596e-02,  1.3354e-01,  9.2067e-02]],\n",
      "\n",
      "         [[ 1.1064e-02, -1.3220e-02, -8.2529e-03],\n",
      "          [-2.1986e-02, -9.2613e-02, -4.2092e-02],\n",
      "          [ 2.2488e-02, -9.2076e-02, -6.4365e-02]],\n",
      "\n",
      "         [[ 3.0329e-02,  8.1470e-02,  6.5200e-02],\n",
      "          [ 4.5597e-03, -6.7672e-03,  4.3849e-02],\n",
      "          [-7.2471e-03, -2.3645e-02, -2.1651e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9276e-02, -6.7762e-03, -4.1073e-02],\n",
      "          [-4.2894e-02, -1.7100e-02,  1.8957e-02],\n",
      "          [-2.0169e-02, -4.5453e-02, -4.1598e-02]],\n",
      "\n",
      "         [[-1.6830e-02, -2.5403e-02, -4.1790e-04],\n",
      "          [-3.5964e-02,  1.2683e-03,  6.7549e-03],\n",
      "          [ 4.3253e-02,  3.2593e-02,  3.6527e-02]],\n",
      "\n",
      "         [[-1.4133e-02, -4.9107e-02,  5.0107e-03],\n",
      "          [-4.6777e-02, -8.4056e-02, -2.0366e-02],\n",
      "          [-6.1236e-02, -6.9905e-02, -2.5334e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.9680e-02,  1.1085e-01,  1.2000e-01],\n",
      "          [ 1.2128e-01, -3.2214e-02,  1.3268e-01],\n",
      "          [ 9.2624e-02,  8.8550e-02,  7.6184e-02]],\n",
      "\n",
      "         [[-1.2680e-01, -1.6773e-01, -1.6257e-01],\n",
      "          [-2.9500e-01, -3.0910e-01, -2.7058e-01],\n",
      "          [-2.5487e-01, -2.2068e-01, -1.5026e-01]],\n",
      "\n",
      "         [[ 2.9042e-02,  1.8501e-02,  5.2416e-02],\n",
      "          [ 4.2540e-02,  8.7026e-02,  3.9777e-02],\n",
      "          [ 5.0570e-02,  5.2144e-02,  3.4114e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1413e-02,  1.4871e-02,  4.8572e-02],\n",
      "          [ 6.5825e-02,  4.1889e-02,  2.1117e-02],\n",
      "          [-2.3682e-02, -4.4766e-02, -3.3801e-02]],\n",
      "\n",
      "         [[-3.3957e-02, -2.5945e-02, -4.0854e-02],\n",
      "          [ 2.4744e-02, -4.0596e-02,  7.1095e-03],\n",
      "          [-1.4280e-03,  3.1312e-02, -7.4854e-03]],\n",
      "\n",
      "         [[-1.4057e-02,  1.9890e-03,  3.1197e-03],\n",
      "          [ 5.5037e-02, -3.9364e-02,  7.1327e-03],\n",
      "          [ 2.1515e-02,  5.8202e-02,  4.5174e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2420e-03,  8.0913e-03,  2.8650e-02],\n",
      "          [-3.1239e-02, -1.4904e-02,  1.4698e-03],\n",
      "          [ 1.8555e-02,  8.4930e-04,  5.3623e-02]],\n",
      "\n",
      "         [[-4.5858e-02, -9.6714e-03,  2.2297e-02],\n",
      "          [ 5.3952e-02, -2.9093e-02, -3.0939e-02],\n",
      "          [ 2.9152e-02,  3.0492e-02,  6.1778e-02]],\n",
      "\n",
      "         [[ 1.3378e-01,  2.0232e-01,  9.2511e-02],\n",
      "          [ 1.0479e-01,  8.8445e-02,  1.4869e-01],\n",
      "          [ 5.9779e-02,  7.2932e-02,  6.3863e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9452e-04,  3.9184e-02,  2.8184e-02],\n",
      "          [-4.5438e-02,  1.6477e-02, -4.9009e-02],\n",
      "          [-3.1339e-02, -5.6705e-02, -3.7872e-02]],\n",
      "\n",
      "         [[-7.3454e-03,  4.3204e-02,  1.3448e-02],\n",
      "          [-4.7564e-02, -4.2085e-03, -2.7744e-02],\n",
      "          [ 1.8874e-03, -4.8578e-02,  1.2682e-02]],\n",
      "\n",
      "         [[ 4.3183e-03, -1.7338e-02, -3.7154e-03],\n",
      "          [-3.7131e-02, -1.0494e-01, -4.7659e-02],\n",
      "          [-7.0058e-02, -7.7497e-02, -3.0451e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9818e-03,  2.2126e-02,  3.7010e-02],\n",
      "          [-2.5567e-02, -2.6465e-02,  3.5896e-02],\n",
      "          [ 1.4248e-02,  6.5722e-03,  3.7818e-02]],\n",
      "\n",
      "         [[-1.4503e-02,  5.1375e-04, -4.5367e-02],\n",
      "          [-4.7281e-02,  1.8946e-02, -3.4604e-02],\n",
      "          [-2.3065e-02, -4.9321e-02, -4.3732e-02]],\n",
      "\n",
      "         [[ 9.1071e-02,  5.0323e-02,  5.3092e-02],\n",
      "          [ 4.7183e-02, -8.0551e-02,  4.4472e-02],\n",
      "          [ 1.8287e-02,  1.2229e-02,  1.6121e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2883e-02,  8.8764e-02,  1.5848e-02],\n",
      "          [-3.1045e-03, -2.5651e-02,  1.0305e-02],\n",
      "          [-6.7127e-02, -9.6404e-02, -4.0220e-02]],\n",
      "\n",
      "         [[ 1.3473e-02,  2.1478e-02, -2.4523e-03],\n",
      "          [-1.1124e-03, -1.7383e-02, -1.2540e-03],\n",
      "          [-4.7135e-02, -3.4955e-02,  1.0995e-02]],\n",
      "\n",
      "         [[-7.6981e-02, -1.7742e-01, -1.3096e-01],\n",
      "          [ 2.5057e-02, -2.6312e-02, -6.8279e-03],\n",
      "          [ 3.7551e-02,  2.2853e-02,  3.0979e-02]]]], device='cuda:0')), ('backbone.model.layer3.0.bn2.weight', tensor([1.9794, 2.4785, 2.3989, 2.2265, 3.3271, 3.0045, 3.8320, 2.5598, 1.3481,\n",
      "        2.5990, 2.8583, 3.6317, 2.7333, 3.0132, 3.0797, 2.5523, 3.1617, 2.7068,\n",
      "        2.1381, 3.1929, 2.6072, 1.9646, 2.3381, 2.5981, 3.0953, 2.1861, 2.2640,\n",
      "        2.7742, 2.7633, 2.4308, 2.5673, 2.3734, 2.3714, 3.0107, 2.5475, 2.3895,\n",
      "        2.9655, 3.2151, 2.5048, 2.1225, 2.9208, 2.5650, 2.5173, 2.1144, 2.9072,\n",
      "        2.5494, 2.8688, 2.8362, 3.1828, 2.7717, 2.7916, 2.6848, 2.9785, 2.9026,\n",
      "        2.2002, 2.2965, 2.3520, 3.0812, 2.5037, 2.1269, 2.7396, 2.6614, 2.5977,\n",
      "        2.1692, 2.7664, 2.3781, 2.6769, 2.6369, 2.6426, 3.0058, 2.8170, 3.0475,\n",
      "        2.7012, 3.3292, 3.0206, 3.5348, 2.8055, 2.7541, 2.6222, 2.9008, 2.5099,\n",
      "        2.4422, 2.0299, 2.8736, 3.1078, 2.5207, 2.4896, 2.7031, 2.4799, 2.6036,\n",
      "        2.4790, 2.6483, 2.2601, 2.7657, 2.3967, 2.4945, 2.1961, 1.8840, 2.1864,\n",
      "        3.6253, 2.9548, 2.6648, 2.2894, 2.4184, 2.9611, 2.4793, 2.5560, 2.1931,\n",
      "        2.8726, 3.1119, 2.7535, 3.0861, 2.1142, 3.0997, 2.4422, 2.8405, 2.1731,\n",
      "        2.9403, 3.3174, 2.3898, 2.4116, 2.7210, 2.3691, 2.4276, 2.2008, 2.5933,\n",
      "        2.0804, 2.1113, 2.1133, 2.5962, 2.3476, 2.3996, 2.0707, 2.7015, 2.2120,\n",
      "        3.2902, 2.5917, 2.7115, 2.2127, 2.5380, 2.8711, 2.6667, 2.4816, 2.5813,\n",
      "        2.3225, 2.2720, 2.7166, 2.8560, 3.3239, 2.2040, 3.2092, 2.9285, 2.4895,\n",
      "        2.6075, 2.6992, 2.1177, 2.4470, 2.2213, 2.1388, 2.7571, 2.2836, 2.4342,\n",
      "        2.5783, 4.0081, 2.2663, 2.4175, 2.7602, 2.3833, 2.8929, 1.9788, 2.9588,\n",
      "        2.7378, 1.9208, 2.5757, 2.5153, 2.0720, 3.4902, 3.2542, 3.6290, 5.3415,\n",
      "        3.1127, 3.4105, 2.7898, 1.4108, 1.6364, 2.2583, 2.3605, 1.7560, 2.7943,\n",
      "        1.7679, 2.5667, 3.0117, 2.4226, 2.4656, 3.0474, 2.6352, 2.0751, 2.4129,\n",
      "        2.5428, 2.2931, 2.4351, 3.9104, 2.5914, 3.1353, 3.2945, 2.7529, 2.1639,\n",
      "        1.7216, 2.5069, 1.8568, 2.3596, 2.9778, 2.9164, 2.8303, 2.6746, 2.3713,\n",
      "        2.3701, 2.6238, 3.3482, 2.5029, 2.2235, 3.3644, 2.5343, 2.2769, 2.4689,\n",
      "        2.5054, 3.0362, 2.6833, 2.4235, 2.4458, 2.1112, 3.1123, 3.0293, 2.6214,\n",
      "        2.6289, 3.0982, 2.3420, 3.1709, 2.4449, 2.4941, 2.9095, 2.6963, 2.1873,\n",
      "        2.8779, 2.5635, 2.3742, 3.0699, 2.2821, 2.9976, 4.5371, 2.3645, 2.7306,\n",
      "        2.7226, 1.6442, 2.2537, 2.8295], device='cuda:0')), ('backbone.model.layer3.0.bn2.bias', tensor([-5.9156e-01, -2.0443e-01, -2.5677e-01, -1.3915e+00,  4.3628e-01,\n",
      "         3.7143e-01,  4.8889e-01,  4.2592e-01, -2.1715e+00,  1.6333e-01,\n",
      "         2.0908e-01,  8.6869e-02,  5.4837e-02,  6.3667e-01,  6.8399e-01,\n",
      "         7.4638e-01,  1.2130e-01,  9.9107e-02,  2.1591e-02,  8.4331e-01,\n",
      "         1.5174e-01, -8.0766e-01, -3.6746e-01, -9.4662e-01, -1.9317e-01,\n",
      "         4.5152e-01,  3.3458e-01,  4.4652e-02, -6.6162e-01, -5.9431e-01,\n",
      "        -3.7740e-01,  7.2911e-01,  5.2142e-01,  5.2623e-01,  4.5101e-01,\n",
      "        -7.7519e-01, -4.4288e-02, -1.3065e-01,  9.4442e-02,  1.8845e-01,\n",
      "         2.7407e-01, -1.3969e+00, -1.3610e+00,  6.2860e-02,  3.2115e-01,\n",
      "         3.1777e-01, -1.3000e+00, -2.1504e-01,  3.6836e-01,  9.7051e-01,\n",
      "        -7.2617e-03,  5.3855e-01, -2.8411e-01, -2.7585e-01, -7.7133e-01,\n",
      "        -7.2881e-01, -5.8382e-01, -5.3860e-01, -4.2237e-01,  1.6487e-01,\n",
      "        -3.6118e-03, -3.5838e-01, -1.4981e-01, -4.2242e-01, -8.0584e-01,\n",
      "        -2.1588e-01, -8.6025e-01, -6.1865e-01, -3.1695e-01, -6.1921e-01,\n",
      "         6.4198e-01, -3.0555e-01, -7.6996e-01,  1.3907e-01,  3.7670e-01,\n",
      "        -1.9912e-01, -3.4139e-01,  1.9129e-01, -2.4996e+00, -7.1242e-01,\n",
      "         3.1013e-01,  1.4918e-01, -3.8684e-01,  2.1456e-01, -1.4448e-01,\n",
      "         3.8367e-01,  2.5923e-01,  3.6138e-01,  2.2417e-02,  3.4328e-01,\n",
      "         2.5043e-01, -1.4443e-01, -3.4157e-01, -9.1719e-01, -6.9595e-01,\n",
      "         1.0922e-01,  3.0445e-01, -1.2386e-01,  4.8021e-03,  9.9656e-02,\n",
      "         3.4755e-01,  1.5979e-01,  4.7755e-01, -1.0175e-02,  9.3755e-02,\n",
      "         5.0878e-01, -1.8696e+00,  6.8907e-02, -1.1885e+00, -5.8767e-01,\n",
      "        -5.6727e-01, -1.3482e+00,  4.0221e-01, -5.9934e-01, -5.0918e-01,\n",
      "        -6.3169e-01, -4.0639e-01,  3.8141e-01,  1.9546e-01,  3.6471e-02,\n",
      "         5.2028e-01,  3.1515e-01, -5.3181e-01, -1.4485e-01,  4.8656e-01,\n",
      "         4.1031e-01, -1.1393e+00,  2.9859e-01, -1.6551e-01, -4.9150e-01,\n",
      "         1.0255e-01, -3.4509e-01, -3.1055e-02, -2.5530e-01,  3.3812e-01,\n",
      "        -4.4858e-01, -5.2522e-02, -1.6826e-01, -2.4397e-01,  3.8229e-02,\n",
      "         2.2632e-01, -1.9515e-01, -4.0876e-01,  7.6982e-01,  8.1725e-02,\n",
      "        -3.1773e-01, -6.0390e-01, -3.8339e-02, -6.3867e-02, -9.7373e-02,\n",
      "        -1.2923e-01,  2.2948e-01, -4.3351e-03, -8.4017e-02,  8.1752e-02,\n",
      "        -3.9789e-01,  9.1900e-02,  1.2198e-01,  8.9437e-02, -3.3779e-01,\n",
      "        -8.8421e-01, -5.9639e-02,  5.9517e-01,  8.2184e-01, -1.8440e-01,\n",
      "        -2.1702e-01,  1.7867e-01,  2.7692e-02,  6.2369e-02,  7.7357e-02,\n",
      "         3.4885e-01, -1.2572e+00, -5.7932e-03, -7.4562e-02,  3.6568e-01,\n",
      "         5.6116e-03, -3.2001e-01, -1.6160e-01,  9.2267e-01, -7.2403e-01,\n",
      "         5.8313e-01,  8.5610e-01,  3.8056e-01, -2.1782e+00,  1.9667e+00,\n",
      "        -1.6424e-01,  4.5223e-04, -6.8438e-01,  2.5431e-01,  5.2780e-02,\n",
      "        -8.7699e-01, -1.7513e+00,  4.1600e-01, -5.4076e-01,  4.8753e-01,\n",
      "         1.9701e-01,  3.9321e-01,  2.3334e-01, -8.8361e-01, -6.6764e-02,\n",
      "         2.3901e-01,  3.3566e-01,  1.1546e-01,  5.3106e-01,  1.7551e-01,\n",
      "         5.2536e-02,  1.1116e-01, -1.7173e+00, -1.9687e-01, -1.2650e+00,\n",
      "         2.6804e-01,  5.9014e-01, -7.0351e-01, -3.4452e-01, -1.8340e-01,\n",
      "        -2.8956e-01, -1.1856e-01, -5.1600e-01,  8.4102e-02,  9.4279e-02,\n",
      "        -6.5928e-02,  2.3595e-02, -8.9216e-01, -2.7125e-01, -1.0124e+00,\n",
      "        -1.4994e-01,  4.8747e-01, -1.1452e-01,  1.1420e+00,  3.4802e-01,\n",
      "        -8.8472e-01,  5.8024e-01, -5.4239e-02, -8.1834e-02, -3.1481e-01,\n",
      "        -1.1927e-01, -2.0503e-01, -8.3474e-01, -2.1493e-01,  8.8331e-02,\n",
      "         5.5211e-01, -1.8695e-01,  4.1600e-01, -1.9251e-01, -1.9048e-01,\n",
      "        -1.5933e+00,  5.1294e-01, -1.9242e-01,  6.3469e-01,  9.5598e-01,\n",
      "         5.1396e-01,  7.8017e-01,  3.5819e-01, -2.5130e+00,  6.0891e-01,\n",
      "         5.1556e-01], device='cuda:0')), ('backbone.model.layer3.0.conv3.weight', tensor([[[[-0.0105]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[-0.1052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1052]],\n",
      "\n",
      "         [[ 0.0328]],\n",
      "\n",
      "         [[-0.0594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0480]],\n",
      "\n",
      "         [[-0.0216]],\n",
      "\n",
      "         [[ 0.0751]]],\n",
      "\n",
      "\n",
      "        [[[-0.0451]],\n",
      "\n",
      "         [[ 0.0574]],\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0741]],\n",
      "\n",
      "         [[ 0.0688]],\n",
      "\n",
      "         [[-0.2329]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0827]],\n",
      "\n",
      "         [[ 0.0173]],\n",
      "\n",
      "         [[ 0.0789]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0906]],\n",
      "\n",
      "         [[ 0.0584]],\n",
      "\n",
      "         [[ 0.0178]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0096]],\n",
      "\n",
      "         [[ 0.0500]],\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[-0.1631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0087]],\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[-0.0409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[-0.0647]],\n",
      "\n",
      "         [[-0.0037]]]], device='cuda:0')), ('backbone.model.layer3.0.bn3.weight', tensor([-2.2544, -6.5997,  2.5872,  ...,  3.4501, -2.6730, -5.9061],\n",
      "       device='cuda:0')), ('backbone.model.layer3.0.bn3.bias', tensor([-0.1048,  3.2123, -0.6145,  ..., -0.5720,  1.0802,  1.0210],\n",
      "       device='cuda:0')), ('backbone.model.layer3.0.downsample.0.weight', tensor([[[[-0.0791]],\n",
      "\n",
      "         [[-0.0194]],\n",
      "\n",
      "         [[ 0.0657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0588]],\n",
      "\n",
      "         [[ 0.0321]],\n",
      "\n",
      "         [[ 0.0419]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045]],\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         [[ 0.1066]]],\n",
      "\n",
      "\n",
      "        [[[-0.0898]],\n",
      "\n",
      "         [[-0.0126]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0318]],\n",
      "\n",
      "         [[ 0.0727]],\n",
      "\n",
      "         [[ 0.0610]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2326]],\n",
      "\n",
      "         [[-0.0248]],\n",
      "\n",
      "         [[ 0.0651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0019]],\n",
      "\n",
      "         [[ 0.0101]],\n",
      "\n",
      "         [[-0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.0115]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0885]],\n",
      "\n",
      "         [[-0.0664]],\n",
      "\n",
      "         [[ 0.0964]]],\n",
      "\n",
      "\n",
      "        [[[-0.0120]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[ 0.0493]]]], device='cuda:0')), ('backbone.model.layer3.0.downsample.1.weight', tensor([1.1918, 2.3943, 1.5797,  ..., 2.6591, 2.2162, 2.5378], device='cuda:0')), ('backbone.model.layer3.0.downsample.1.bias', tensor([2.2924, 0.5938, 0.3299,  ..., 0.7247, 0.5221, 0.7599], device='cuda:0')), ('backbone.model.layer3.1.conv1.weight', tensor([[[[-0.0389]],\n",
      "\n",
      "         [[-0.0129]],\n",
      "\n",
      "         [[ 0.0807]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[ 0.0162]],\n",
      "\n",
      "         [[ 0.0179]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0370]],\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[-0.0544]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0166]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[ 0.0091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0969]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[ 0.1459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[ 0.0031]],\n",
      "\n",
      "         [[ 0.0423]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0683]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         [[-0.1244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0388]],\n",
      "\n",
      "         [[ 0.0106]],\n",
      "\n",
      "         [[ 0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0212]],\n",
      "\n",
      "         [[ 0.1061]],\n",
      "\n",
      "         [[ 0.0178]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0746]],\n",
      "\n",
      "         [[ 0.0533]],\n",
      "\n",
      "         [[-0.0185]]],\n",
      "\n",
      "\n",
      "        [[[-0.1187]],\n",
      "\n",
      "         [[-0.0200]],\n",
      "\n",
      "         [[ 0.0591]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1015]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[-0.1304]]]], device='cuda:0')), ('backbone.model.layer3.1.bn1.weight', tensor([4.5300, 3.6900, 2.9296, 3.1876, 1.9662, 1.5145, 1.7285, 1.9012, 2.6346,\n",
      "        3.2120, 3.0098, 1.6250, 2.4632, 1.6906, 1.3772, 1.8133, 1.5520, 2.3810,\n",
      "        4.4742, 3.8852, 3.9936, 6.1225, 3.8670, 5.1981, 1.7710, 4.9629, 1.5761,\n",
      "        1.5875, 1.5915, 2.1069, 1.2029, 2.0090, 3.4889, 1.9143, 1.5382, 3.1900,\n",
      "        3.6936, 2.7784, 2.0459, 2.0856, 2.8994, 2.5289, 2.7597, 3.1623, 2.9048,\n",
      "        2.9179, 1.5189, 2.2217, 2.4996, 1.5601, 2.2931, 3.2776, 2.0049, 4.1057,\n",
      "        1.5387, 1.4701, 3.7245, 3.5880, 2.0041, 2.3405, 1.5866, 2.8203, 2.3793,\n",
      "        0.8341, 2.8125, 1.5463, 1.7648, 2.5802, 2.4534, 3.0302, 2.2517, 1.5955,\n",
      "        2.5219, 2.5268, 3.7824, 3.2633, 1.5169, 1.5200, 2.9266, 1.5710, 1.7155,\n",
      "        2.0248, 1.8607, 2.0134, 4.2187, 2.0214, 2.7093, 2.0144, 2.3990, 1.9586,\n",
      "        3.2994, 2.2865, 2.0215, 2.8592, 1.8380, 5.6081, 1.8163, 1.7623, 2.4864,\n",
      "        1.1395, 1.7632, 1.6191, 1.7665, 1.7156, 0.1950, 2.8373, 2.9261, 2.1242,\n",
      "        3.1949, 2.8334, 2.6765, 1.9888, 1.6092, 3.1110, 1.9927, 1.4757, 2.3510,\n",
      "        2.2208, 3.0052, 3.0279, 3.5410, 1.9603, 1.9437, 2.2832, 1.8481, 1.7898,\n",
      "        4.0641, 2.3941, 2.4154, 1.5994, 4.0100, 1.8230, 1.7616, 1.5111, 3.4343,\n",
      "        2.8541, 2.5348, 2.7720, 2.2176, 0.8402, 1.9032, 2.2962, 2.8110, 2.8526,\n",
      "        1.6864, 2.9249, 2.3280, 1.5658, 1.7060, 3.0742, 2.3073, 2.5423, 3.8308,\n",
      "        3.4067, 1.7016, 2.2208, 2.4313, 1.9161, 2.2282, 1.5775, 2.4883, 2.6939,\n",
      "        1.8222, 2.0068, 1.6078, 4.6842, 1.6222, 2.2502, 1.5033, 3.3694, 1.3089,\n",
      "        1.4110, 1.9951, 1.6360, 1.9484, 3.4111, 2.0646, 1.6076, 1.7612, 1.7086,\n",
      "        2.4504, 1.8427, 1.6937, 3.5341, 3.7005, 2.0735, 2.2027, 4.0442, 1.8939,\n",
      "        2.3202, 3.5209, 3.2277, 2.0657, 2.4049, 1.6875, 2.3672, 2.5507, 2.6007,\n",
      "        1.2073, 2.4552, 2.3894, 1.4040, 1.8213, 1.7182, 1.6706, 1.7292, 1.5858,\n",
      "        1.6274, 2.0300, 1.7620, 1.7800, 3.2749, 2.2589, 1.9535, 1.5989, 2.1621,\n",
      "        1.9521, 3.0687, 3.1307, 3.1596, 3.0456, 4.4984, 3.2288, 3.0053, 2.8506,\n",
      "        4.3691, 2.9253, 7.9440, 2.4359, 4.0261, 1.3621, 4.1813, 1.5151, 1.6060,\n",
      "        1.8521, 1.5008, 2.1833, 1.9357, 0.8967, 2.2790, 1.2216, 1.9987, 2.2395,\n",
      "        1.2601, 3.2404, 1.8188, 1.5367, 2.8400, 1.3524, 1.9940, 2.2460, 2.9282,\n",
      "        1.6608, 1.7835, 2.0634, 2.4385], device='cuda:0')), ('backbone.model.layer3.1.bn1.bias', tensor([ 0.9421,  0.8397, -3.4965, -2.9692, -1.8407,  0.2488, -1.4208, -0.7138,\n",
      "         0.1937, -0.4340, -1.1457, -2.8745, -0.5557, -2.3838,  0.7473, -0.2034,\n",
      "        -3.3671,  0.6819, -0.0688, -1.9988, -2.4336,  2.2252, -1.2766,  0.7529,\n",
      "        -0.6193, -2.3280, -0.6300, -1.1136, -0.7947, -1.2847,  0.6108, -1.5260,\n",
      "        -2.0036,  1.3701, -1.7486, -1.9711, -2.2222, -0.3757,  0.9813, -2.3573,\n",
      "        -0.7174,  1.0837, -1.0297,  0.0303, -0.9485, -0.8997, -3.5270, -1.0049,\n",
      "        -0.8264, -0.2794, -0.2934, -0.5844, -1.9700, -4.3034, -0.8820, -1.3506,\n",
      "        -0.1121,  0.6029, -3.1291, -0.9815,  0.2157, -1.2558, -3.2197, -0.1760,\n",
      "        -4.0048, -0.0462, -1.3129, -1.7261,  0.2701, -3.7921,  2.6382,  0.0407,\n",
      "        -1.7687, -1.9640, -1.6901, -1.2556,  0.5704,  0.4520, -1.6259, -2.5201,\n",
      "         0.5371, -1.5351, -1.9708, -0.1346, -1.1925, -0.6024,  0.1602,  1.3956,\n",
      "        -0.2852, -0.4891, -1.3662, -0.7344, -3.4432, -0.7095, -0.3152, -3.8438,\n",
      "        -1.1368,  0.0865, -1.1348,  0.7327, -0.3708, -0.4890, -1.3273,  0.2099,\n",
      "        -1.8608, -0.6921, -1.4407,  0.3750, -0.4113, -1.6793, -0.9941, -2.5124,\n",
      "         1.0207, -0.8188, -0.9750, -2.5811, -3.2161, -1.1167, -1.4355,  0.2765,\n",
      "        -3.3413, -2.5954, -2.8465, -0.3784, -0.3922,  0.0774, -0.8125, -0.4636,\n",
      "        -1.9814, -1.4088, -0.6757, -1.3654,  0.6247, -0.4952, -3.1394,  0.4723,\n",
      "        -0.3654,  0.0441, -3.2075, -1.1493, -0.5080, -4.0548, -0.7638, -0.4706,\n",
      "        -1.0187,  1.5847, -0.0820, -1.4575, -3.0014,  1.8440,  1.0416, -0.2418,\n",
      "        -0.2756,  0.1243, -2.0435, -2.6841, -0.2900, -0.0225, -1.4929,  0.9410,\n",
      "        -1.1598,  1.1262, -1.5495, -0.1701, -3.1885,  0.3467, -2.0173,  0.6162,\n",
      "        -0.5305, -1.6219, -0.4629,  1.0916, -0.4269, -0.5441, -1.7776, -2.8325,\n",
      "         0.2596,  0.0433, -1.8619, -4.0128, -0.6599,  0.6147, -1.7202, -1.4808,\n",
      "         0.2645, -2.3819,  0.7695, -0.0388, -2.9107, -0.8483, -0.4905, -0.6892,\n",
      "        -0.4986, -2.8601, -0.6190, -0.2680, -1.1945, -0.6605, -3.5311,  2.3792,\n",
      "        -4.1291, -2.1390,  0.4873, -1.9623, -1.2197, -0.3019, -0.8374, -0.3911,\n",
      "        -3.2980,  0.9244, -2.4552,  0.2345, -0.8460, -0.5764,  1.1694,  0.0164,\n",
      "        -0.1744,  0.0498, -2.3897, -2.5927, -2.4714, -2.0355, -2.2547, -1.7988,\n",
      "        -0.3256,  1.4965,  0.9051, -0.5459, -1.0448, -1.4143, -3.6740, -1.8247,\n",
      "        -1.0343,  0.1974, -0.3890,  0.6471, -2.8056, -0.8956, -3.5039, -0.9700,\n",
      "        -0.6316, -1.2514, -0.6394, -0.8135, -2.1725, -1.8535,  1.5476, -0.8077,\n",
      "         0.0956,  0.0954, -3.5108,  0.4975,  0.0544,  1.4920, -3.6052, -2.3216],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.conv2.weight', tensor([[[[-1.0569e-03, -1.1655e-02, -3.6572e-02],\n",
      "          [ 1.1646e-02,  9.6438e-03, -1.8771e-02],\n",
      "          [ 7.4627e-04, -3.0688e-02, -5.4393e-03]],\n",
      "\n",
      "         [[ 1.9654e-02,  5.3084e-03, -1.1607e-02],\n",
      "          [-1.4723e-02,  5.6322e-02,  3.4617e-02],\n",
      "          [ 3.9644e-02, -1.9067e-02, -2.4182e-02]],\n",
      "\n",
      "         [[ 5.0307e-02, -2.1990e-02, -2.0607e-02],\n",
      "          [ 1.0209e-02,  8.5472e-03, -6.2557e-03],\n",
      "          [-3.0898e-02, -2.1137e-02,  2.6006e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1666e-02,  8.7013e-02, -5.8883e-02],\n",
      "          [-8.7601e-02,  2.4003e-02, -9.2656e-02],\n",
      "          [-4.7234e-02,  8.8015e-02, -3.1330e-02]],\n",
      "\n",
      "         [[-1.1093e-02, -1.9080e-01, -2.4098e-03],\n",
      "          [ 1.7877e-03, -1.0533e-02,  5.9489e-02],\n",
      "          [-3.8988e-02, -1.0955e-01, -1.4830e-02]],\n",
      "\n",
      "         [[ 4.0988e-02, -5.3570e-02,  1.7341e-02],\n",
      "          [ 4.8196e-02,  1.1657e-01, -5.0820e-03],\n",
      "          [-2.6799e-02,  6.5847e-02, -4.1077e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0230e-01,  9.7790e-02,  1.6434e-01],\n",
      "          [ 1.0637e-01,  1.1623e-01,  1.6060e-01],\n",
      "          [ 1.3511e-01,  1.3651e-01,  1.1071e-01]],\n",
      "\n",
      "         [[-8.6343e-02, -1.2224e-02, -4.6275e-02],\n",
      "          [-3.6791e-02, -1.3996e-01, -1.3550e-01],\n",
      "          [-6.5269e-02, -1.4018e-01, -1.0623e-01]],\n",
      "\n",
      "         [[ 8.8904e-02, -4.7713e-02, -4.7310e-02],\n",
      "          [ 1.4144e-02,  2.0591e-02, -3.9764e-02],\n",
      "          [-4.7904e-03, -8.3006e-03, -8.5651e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3430e-02,  9.2219e-03,  7.6635e-03],\n",
      "          [ 3.8118e-05,  1.5663e-02,  3.0218e-02],\n",
      "          [-4.8170e-02,  5.0926e-03,  5.4249e-02]],\n",
      "\n",
      "         [[-7.7045e-04, -1.6486e-02,  4.0103e-02],\n",
      "          [ 7.7251e-02, -4.7895e-02, -4.3376e-02],\n",
      "          [ 1.3619e-01,  5.6413e-02, -5.5296e-02]],\n",
      "\n",
      "         [[ 1.1906e-02,  2.5209e-02, -4.7202e-02],\n",
      "          [ 9.5736e-02, -4.2493e-02, -7.1928e-02],\n",
      "          [ 7.0238e-02, -2.6972e-02, -2.6995e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6621e-03, -4.8902e-03,  2.1102e-03],\n",
      "          [ 1.6529e-02,  1.4903e-04,  3.2087e-02],\n",
      "          [-8.5477e-03,  3.1598e-02,  6.7904e-05]],\n",
      "\n",
      "         [[ 3.3497e-02, -6.8091e-02,  6.8877e-03],\n",
      "          [-4.9523e-02, -6.8322e-02,  3.6292e-02],\n",
      "          [ 5.7529e-02,  7.6780e-02,  3.2050e-02]],\n",
      "\n",
      "         [[-4.0343e-02, -1.0567e-02, -4.2618e-02],\n",
      "          [-2.6565e-02, -7.2162e-04,  3.7221e-03],\n",
      "          [-5.0999e-02, -1.0744e-02,  7.1907e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8216e-02, -1.0470e-01, -4.8870e-04],\n",
      "          [ 5.3481e-02,  4.3966e-02,  4.5232e-02],\n",
      "          [ 2.8394e-02,  5.3989e-02,  3.7584e-02]],\n",
      "\n",
      "         [[ 2.2190e-02,  2.9099e-02,  1.0672e-02],\n",
      "          [ 2.0555e-02,  5.3637e-02,  9.1637e-03],\n",
      "          [ 4.0379e-02,  8.3322e-02, -9.2066e-03]],\n",
      "\n",
      "         [[ 8.1118e-02,  6.8541e-02,  3.7371e-02],\n",
      "          [ 3.2736e-02,  8.0574e-02,  1.9031e-02],\n",
      "          [ 2.8990e-02,  4.4833e-02, -3.8202e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.5831e-01, -5.3489e-01, -2.0015e-01],\n",
      "          [-2.1486e-02, -3.0427e-02, -8.4873e-03],\n",
      "          [ 9.8651e-02,  2.6570e-01,  1.6172e-01]],\n",
      "\n",
      "         [[-1.7151e-02, -4.2496e-02, -9.4475e-02],\n",
      "          [-8.2709e-02, -1.8566e-01, -1.6653e-01],\n",
      "          [-2.1637e-01, -4.7397e-01, -1.9762e-01]],\n",
      "\n",
      "         [[-7.4327e-02, -1.0149e-01, -8.6452e-03],\n",
      "          [-5.5152e-03, -1.4027e-02,  1.0946e-02],\n",
      "          [ 2.5621e-02,  7.2893e-02,  4.4424e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7167e-02,  1.6848e-02, -3.8715e-02],\n",
      "          [ 2.3930e-02,  3.9914e-03,  2.2515e-03],\n",
      "          [ 2.6239e-02,  3.6672e-02,  1.7768e-02]],\n",
      "\n",
      "         [[ 8.1975e-03,  3.7022e-02,  3.0945e-03],\n",
      "          [ 6.0874e-02,  1.9561e-03,  2.8346e-02],\n",
      "          [ 1.5682e-02,  7.4327e-02,  2.2237e-02]],\n",
      "\n",
      "         [[ 4.9202e-02, -3.5579e-02,  8.6280e-03],\n",
      "          [ 2.7047e-03,  3.2184e-02, -3.8047e-03],\n",
      "          [ 1.7404e-02,  8.4329e-02, -2.7709e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4391e-02, -7.5765e-02,  2.9966e-02],\n",
      "          [ 1.7745e-02, -3.0422e-02,  8.7122e-03],\n",
      "          [ 1.1764e-02,  5.9028e-02, -5.5824e-03]],\n",
      "\n",
      "         [[-1.0934e-02, -3.8905e-02, -1.5120e-02],\n",
      "          [-1.2345e-02,  7.8533e-02,  2.1043e-02],\n",
      "          [-8.9506e-02,  1.4922e-02, -3.7050e-03]],\n",
      "\n",
      "         [[-1.0102e-01, -6.5687e-02,  7.1834e-02],\n",
      "          [-5.5488e-02, -1.2850e-01,  1.1294e-01],\n",
      "          [-2.9003e-02,  3.3426e-02,  1.4050e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6458e-02, -2.7955e-02,  9.7322e-02],\n",
      "          [-1.4057e-01,  6.8789e-02,  1.8379e-01],\n",
      "          [-5.9705e-02, -1.7706e-02,  8.9511e-02]],\n",
      "\n",
      "         [[-1.0353e-01, -8.6599e-02,  7.3534e-02],\n",
      "          [-1.5821e-01, -1.4007e-01,  6.6191e-02],\n",
      "          [-7.6835e-02,  3.2054e-02, -1.5866e-02]],\n",
      "\n",
      "         [[-1.9111e-02, -6.8468e-02,  5.9212e-02],\n",
      "          [-7.1382e-02, -2.3609e-02,  2.5433e-02],\n",
      "          [ 5.7754e-02,  5.1761e-03,  4.7541e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1688e-01, -1.1971e-01,  1.0432e-02],\n",
      "          [-7.6365e-02, -3.6069e-02,  7.6260e-02],\n",
      "          [-7.7158e-02,  1.3399e-01,  1.4026e-01]],\n",
      "\n",
      "         [[ 9.3005e-03,  2.5446e-02,  3.4105e-02],\n",
      "          [ 1.0450e-02,  7.1148e-02,  5.1510e-02],\n",
      "          [-1.2792e-01, -1.2857e-01,  9.0199e-02]],\n",
      "\n",
      "         [[-5.8958e-02, -1.4252e-02,  8.1905e-02],\n",
      "          [-1.9989e-01, -4.1554e-02,  7.6283e-02],\n",
      "          [-6.8530e-02,  5.6793e-02,  8.7995e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8941e-02,  4.8438e-02,  6.0868e-02],\n",
      "          [-4.3206e-03, -1.9090e-02,  3.2238e-02],\n",
      "          [ 6.6573e-04, -2.9166e-02,  4.3190e-03]],\n",
      "\n",
      "         [[-5.8334e-02, -2.4546e-02,  3.2194e-03],\n",
      "          [-1.5308e-03, -8.4044e-02,  5.0086e-02],\n",
      "          [ 1.4837e-03, -4.5293e-02, -1.7716e-02]],\n",
      "\n",
      "         [[-5.7946e-02, -5.1299e-02, -2.9962e-02],\n",
      "          [ 1.7641e-02,  5.9575e-03,  3.3371e-03],\n",
      "          [-1.2719e-02,  3.1627e-03, -1.9584e-02]]]], device='cuda:0')), ('backbone.model.layer3.1.bn2.weight', tensor([ 2.0704,  2.1021,  2.3373,  2.4358,  2.3037,  1.7597,  2.2366,  1.9680,\n",
      "         1.7363,  3.3435,  2.6317,  1.4723,  2.3599,  2.0877,  2.3056,  2.7585,\n",
      "         2.8485,  2.1891,  2.0657,  2.8919,  2.2038,  2.3033,  2.3119,  2.1177,\n",
      "         2.5155,  3.4576,  3.7031,  3.9064,  2.0927,  2.5272,  2.5318,  1.8404,\n",
      "         2.9229,  3.0601,  3.1156,  2.2212,  3.1393,  3.1125,  2.9913,  1.9106,\n",
      "         2.5190,  3.1338,  2.1565,  2.1869,  1.9112,  1.9167,  2.5405,  2.1728,\n",
      "         3.5876,  2.5285,  2.3368,  3.3751,  2.5458,  1.9890,  2.4741,  2.1576,\n",
      "         4.6840,  1.3743,  2.3042,  2.8167,  2.9569,  2.2038,  2.9032,  3.3110,\n",
      "         3.0237,  2.4610,  2.7520,  3.1273,  2.4975,  3.1409,  2.5585,  2.4572,\n",
      "         2.0431,  1.9360,  2.1565,  2.2460,  2.5161,  3.3656,  2.7832,  2.3560,\n",
      "         2.5567,  2.8109,  2.7257,  5.1802,  2.8229,  2.6472,  3.4049,  2.7719,\n",
      "         2.1369,  2.0951,  2.3009,  2.1414,  2.3776,  2.0742,  2.2348,  2.7237,\n",
      "         2.5537,  2.0717,  2.6775,  2.1324,  2.7294,  2.5977,  3.3268,  1.9891,\n",
      "         2.5726,  2.9758,  2.5672,  2.5584,  2.2643,  1.8131,  2.2620,  2.5837,\n",
      "         2.7791,  2.2369,  2.2774,  2.2261,  2.7319,  1.7291,  1.8730,  1.7476,\n",
      "         2.3920,  2.4554,  2.0345,  2.2352,  2.3184,  4.5633,  2.1208,  2.0382,\n",
      "         3.2533,  2.4598,  1.8305,  2.9690,  3.3118,  2.8938,  3.0277,  1.8326,\n",
      "         2.0528,  1.8626,  2.2811,  2.1759,  2.7206,  2.0516,  2.2302,  2.4726,\n",
      "         2.3224,  2.9455,  2.3888,  2.5699,  2.5596,  1.5575,  2.4829,  2.6489,\n",
      "         1.8979,  2.3866,  1.7847,  1.5195,  2.0500,  2.1464,  2.2793,  2.0354,\n",
      "         4.3033,  3.9817,  2.4931,  2.1711,  2.3683,  2.4458,  2.7998,  2.8449,\n",
      "         1.8599,  2.5116,  2.3855,  2.3233,  2.5930,  2.7587,  2.0590,  1.8935,\n",
      "         2.2371,  2.0442,  2.4584,  1.5632,  1.9256,  2.4100,  2.0023,  2.2999,\n",
      "         2.4433,  2.8762,  2.1239,  3.1263,  2.3622,  3.6667,  2.2817,  2.0306,\n",
      "         2.0529,  2.4114,  1.9497,  3.0695,  2.1377,  2.4007,  2.7392,  3.0785,\n",
      "         1.9526,  2.6593,  1.7101,  2.2625,  2.6056,  2.3793,  3.1576,  0.8589,\n",
      "         2.1623, 14.2481,  1.7535,  2.3313,  1.8761,  1.8566,  2.4248,  1.9818,\n",
      "         2.0285,  3.5361,  1.4842,  2.5250,  2.4428,  2.0566,  2.0675,  2.8989,\n",
      "         2.4757,  2.2054,  2.6942,  2.2030,  2.2033,  2.2645,  2.5605,  1.6484,\n",
      "         2.2971,  2.0399,  1.7264,  2.1755,  2.4325,  2.0912,  2.4002,  2.2439,\n",
      "         2.0250,  4.6822,  2.2632,  1.6435,  1.9792,  2.0860,  1.9496,  2.2664,\n",
      "         2.8554,  2.6318,  2.6382,  2.0211,  2.4678,  3.2663,  2.5654,  3.5744],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.bn2.bias', tensor([ 0.4520, -0.4894, -2.0719, -1.2573, -2.6730,  0.3730, -2.0945, -1.0438,\n",
      "         0.2009, -0.5452, -1.2855, -1.9986,  0.2818, -0.1265, -1.8576, -1.4840,\n",
      "        -0.5387, -0.6423, -2.9596, -1.8901, -1.0492,  0.2413, -0.0565, -1.4100,\n",
      "        -0.6141,  0.0786, -0.1203, -0.8656, -2.2461, -0.3288, -0.7744, -2.3125,\n",
      "        -0.0073, -1.1720,  0.9114,  0.3772,  0.1431, -0.0524, -0.7505, -4.4793,\n",
      "        -0.7966, -1.0151,  0.2210, -0.2963,  0.2097, -2.0222, -1.3150, -1.0907,\n",
      "        -0.3834, -1.0760, -1.0115, -0.7289, -1.5399,  0.5255, -1.4395, -2.0144,\n",
      "        -2.6826, -2.0150, -3.1710, -0.3500, -0.1949, -1.0819,  0.5823, -0.5840,\n",
      "        -1.7431, -1.2651, -0.4412, -1.2133, -2.8716, -1.4631, -1.4910, -0.1022,\n",
      "        -0.8277, -3.0056,  0.1770, -0.7260, -0.4900, -3.6018, -2.1165, -1.2506,\n",
      "        -0.2349, -1.1076, -1.1559, -0.0342, -0.6436, -3.3886, -0.7755, -0.6793,\n",
      "        -1.3957,  0.0295, -0.2663, -0.2705, -1.3999, -1.7271,  1.0402, -2.9163,\n",
      "         0.1746, -0.2979, -1.5530, -1.5999, -0.4812, -1.7875, -2.3971, -3.0596,\n",
      "        -1.3683, -2.0022, -0.3390, -0.9240, -1.5094, -2.4695,  0.5413, -0.5589,\n",
      "        -1.8215, -0.6415, -0.4869, -0.5313, -1.3063,  0.3372, -1.6285, -0.9261,\n",
      "         0.4363, -1.8500, -2.4031, -1.4148, -2.2996, -2.2445, -1.1888,  0.4441,\n",
      "        -0.5389, -0.4054, -3.0481, -1.2118,  0.7202, -1.5307, -0.4727, -0.4361,\n",
      "        -0.4158, -0.3499, -0.4372, -2.0505, -2.1950,  0.0414, -2.0437, -1.2938,\n",
      "         0.1171,  0.1898,  0.3439, -0.4527,  0.1098, -2.4935, -0.0060, -0.3531,\n",
      "        -0.1576,  0.2071, -0.3281, -1.3501,  0.4831, -1.1355, -0.5586, -0.1566,\n",
      "        -1.3945, -2.3485, -3.2646, -1.1916, -1.1906, -2.1121,  1.8985, -0.7669,\n",
      "        -1.5270, -0.5856, -1.1315, -1.4907, -0.0324, -0.2391, -3.1627,  0.9090,\n",
      "        -0.3843, -0.4619, -0.4379, -1.3238, -0.7553,  0.0658, -1.7907, -1.2325,\n",
      "        -1.4928, -1.3485,  0.4761, -0.4506,  0.1582, -0.4360, -0.4361, -4.4919,\n",
      "        -1.1644, -1.2812, -1.4077, -1.5351,  0.0259, -1.8354,  0.4670, -1.5656,\n",
      "        -1.0174,  0.0614, -1.3280,  0.0949, -3.6344,  0.0190,  0.2467,  0.2575,\n",
      "        -1.3675, -2.6866, -0.5745, -1.1239, -0.3294, -0.6263, -2.4166, -1.7473,\n",
      "        -0.5153, -2.4608, -1.6700, -0.1480,  0.7768, -1.2190, -0.3067, -0.8808,\n",
      "        -0.5287,  1.2746, -1.6345, -1.1948, -2.9572, -1.0837, -0.9019,  0.1721,\n",
      "        -0.3728, -0.0695, -1.6809, -0.8561, -0.1525,  0.0666, -0.2680, -1.8339,\n",
      "        -1.3712, -1.9117, -1.4712,  1.1837, -1.4145, -0.6051, -0.5736, -2.1988,\n",
      "        -0.5839, -0.2765, -0.9376, -3.2155, -0.3959, -0.2802, -1.3275, -0.3025],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.conv3.weight', tensor([[[[ 0.0419]],\n",
      "\n",
      "         [[ 0.0314]],\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[-0.0077]],\n",
      "\n",
      "         [[-0.0401]]],\n",
      "\n",
      "\n",
      "        [[[-0.0612]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[ 0.1090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[ 0.0204]],\n",
      "\n",
      "         [[ 0.0693]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0064]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[-0.0498]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0794]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[-0.1588]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0023]],\n",
      "\n",
      "         [[ 0.1266]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1446]],\n",
      "\n",
      "         [[-0.0223]],\n",
      "\n",
      "         [[-0.0118]]],\n",
      "\n",
      "\n",
      "        [[[-0.0848]],\n",
      "\n",
      "         [[ 0.1269]],\n",
      "\n",
      "         [[ 0.0082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[-0.0570]],\n",
      "\n",
      "         [[-0.0275]]],\n",
      "\n",
      "\n",
      "        [[[-0.0401]],\n",
      "\n",
      "         [[-0.0451]],\n",
      "\n",
      "         [[ 0.0165]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0023]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         [[ 0.0107]]]], device='cuda:0')), ('backbone.model.layer3.1.bn3.weight', tensor([-1.4342, -1.3489,  2.7093,  ..., -3.4957,  3.4555, -2.3019],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.bn3.bias', tensor([-0.4778, -0.4485,  0.5379,  ..., -0.6582, -0.5048, -0.6375],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.conv1.weight', tensor([[[[-0.0999]],\n",
      "\n",
      "         [[-0.0818]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0902]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         [[ 0.0407]]],\n",
      "\n",
      "\n",
      "        [[[-0.0438]],\n",
      "\n",
      "         [[ 0.0117]],\n",
      "\n",
      "         [[-0.0681]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[-0.0144]],\n",
      "\n",
      "         [[ 0.0105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019]],\n",
      "\n",
      "         [[ 0.0221]],\n",
      "\n",
      "         [[ 0.0716]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0614]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[-0.0415]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0570]],\n",
      "\n",
      "         [[-0.0246]],\n",
      "\n",
      "         [[ 0.0607]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0196]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[ 0.0313]]],\n",
      "\n",
      "\n",
      "        [[[-0.0220]],\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0457]],\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         [[-0.0381]]],\n",
      "\n",
      "\n",
      "        [[[-0.0835]],\n",
      "\n",
      "         [[-0.0122]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0072]],\n",
      "\n",
      "         [[ 0.0773]],\n",
      "\n",
      "         [[ 0.0566]]]], device='cuda:0')), ('backbone.model.layer3.2.bn1.weight', tensor([1.5967, 1.9867, 5.9114, 3.3899, 2.3188, 2.5263, 1.7707, 1.6695, 3.8486,\n",
      "        3.1560, 2.1669, 2.1349, 1.7199, 3.3125, 1.8394, 5.1074, 1.4954, 2.7587,\n",
      "        9.3811, 2.9675, 3.2287, 3.3711, 2.1868, 3.5000, 2.3377, 3.2956, 5.4763,\n",
      "        3.3229, 2.4959, 1.7563, 1.3025, 3.4048, 1.3323, 2.0382, 1.9436, 1.5594,\n",
      "        1.8807, 1.7702, 1.7929, 2.1191, 2.6590, 2.5039, 2.1438, 3.4171, 3.3061,\n",
      "        2.2635, 1.6914, 2.2385, 3.7349, 2.0396, 3.2278, 2.1600, 3.1834, 1.1082,\n",
      "        2.7399, 2.9488, 2.3654, 1.7355, 1.7578, 3.5751, 2.0314, 2.0553, 4.6395,\n",
      "        2.1609, 3.8889, 1.6094, 2.5084, 1.9051, 2.1775, 2.5089, 1.6157, 1.9197,\n",
      "        1.6676, 1.8413, 3.2613, 3.7034, 3.3945, 1.7240, 1.8369, 2.5246, 1.7714,\n",
      "        2.1050, 1.7988, 1.9273, 2.1623, 2.4347, 1.4532, 2.1884, 1.5818, 2.3456,\n",
      "        3.1133, 1.8174, 4.1358, 2.1030, 2.4920, 1.4988, 6.5515, 3.0130, 2.9183,\n",
      "        4.2277, 2.4918, 2.3116, 4.1148, 3.1705, 2.7428, 3.3114, 1.9734, 1.5778,\n",
      "        1.6666, 6.1665, 2.2718, 2.3492, 2.5427, 2.4952, 2.4634, 1.5782, 1.6968,\n",
      "        2.6725, 1.8410, 1.9982, 3.9390, 2.6861, 1.5773, 1.8700, 2.3026, 2.3625,\n",
      "        3.5645, 2.1607, 2.8686, 2.6020, 2.2314, 4.0603, 2.1385, 2.5058, 1.6944,\n",
      "        2.0683, 2.3429, 2.2035, 1.7636, 1.8867, 2.3319, 2.9216, 2.2116, 2.1436,\n",
      "        3.8773, 2.1006, 4.1490, 1.7724, 2.1052, 2.2548, 2.6560, 2.4268, 1.5415,\n",
      "        3.5438, 2.1862, 2.5199, 1.8500, 2.3544, 2.8137, 2.1989, 2.8398, 7.9282,\n",
      "        2.2083, 2.4294, 2.0046, 1.0861, 2.3656, 3.0486, 1.3400, 1.7528, 1.6818,\n",
      "        1.5290, 1.6233, 1.6303, 2.3241, 1.9096, 2.0725, 2.2374, 2.3913, 1.8304,\n",
      "        2.5805, 3.4546, 1.9433, 2.4239, 2.1909, 2.3142, 1.4636, 2.8146, 1.5988,\n",
      "        2.3152, 1.5003, 1.6783, 2.0033, 2.2853, 2.3658, 2.6146, 1.5655, 2.8736,\n",
      "        2.0375, 3.7613, 1.7490, 1.8766, 1.3818, 1.4984, 2.6067, 3.1406, 3.5875,\n",
      "        1.8120, 2.1625, 2.6915, 1.5371, 2.8082, 1.7525, 2.2013, 2.5688, 1.7647,\n",
      "        1.0668, 1.5870, 1.0280, 1.0258, 1.4568, 1.3122, 1.6940, 1.6548, 1.4966,\n",
      "        2.0941, 2.3467, 1.9902, 0.6368, 4.1747, 4.9501, 2.1041, 3.0833, 3.8972,\n",
      "        2.7375, 1.7418, 2.8863, 3.7437, 3.1111, 1.3509, 1.4713, 3.1319, 5.3327,\n",
      "        2.1600, 1.4042, 2.9398, 2.3932, 2.1178, 3.3656, 1.4891, 0.8534, 1.9583,\n",
      "        2.2670, 1.2547, 1.7204, 1.4606], device='cuda:0')), ('backbone.model.layer3.2.bn1.bias', tensor([-1.9152e+00,  2.2290e-01, -1.2447e+00, -1.8340e+00, -8.3207e-01,\n",
      "         1.1020e-01, -5.2723e-02, -1.4869e+00, -3.8262e-01,  8.0865e-01,\n",
      "        -2.9824e+00, -6.7831e-01,  1.3020e-02,  7.1310e-01, -1.3254e+00,\n",
      "        -2.3395e+00, -3.0104e+00,  1.1112e-01,  2.6435e+00, -1.0367e+00,\n",
      "         3.6332e-01, -1.0468e+00, -1.1506e+00, -1.1022e+00, -1.3322e+00,\n",
      "         1.4246e+00, -2.4564e+00, -9.1170e-01, -1.2907e+00, -1.9675e+00,\n",
      "        -1.4185e+00, -1.9188e+00, -2.4690e+00, -6.2502e-01,  3.5406e-02,\n",
      "        -1.9871e-01,  3.7515e-01,  5.0573e-01, -9.1372e-01,  1.1642e+00,\n",
      "         2.7319e-01,  2.8035e-01, -2.0674e+00, -6.9401e-01, -1.0094e+00,\n",
      "        -3.8289e+00,  2.1944e-01,  7.1007e-01, -4.2999e+00,  2.8258e-01,\n",
      "        -2.9316e+00,  2.4949e-01, -1.3262e+00, -3.0173e+00, -2.0675e-01,\n",
      "        -1.6922e+00,  2.8603e-01, -3.3530e+00, -1.9905e-01, -2.6368e-01,\n",
      "        -1.9892e+00,  4.7776e-01, -3.3790e+00,  8.4813e-01, -3.6403e-01,\n",
      "        -2.2500e-01, -1.4457e+00,  2.1313e-01, -1.2212e+00, -2.6885e-01,\n",
      "        -1.9574e+00, -6.3878e-01, -2.6062e+00, -1.2133e-02, -1.9388e-01,\n",
      "        -5.9473e-01, -3.9696e-01, -1.3505e+00,  5.3656e-01, -2.9727e+00,\n",
      "         1.2810e+00,  1.0541e+00,  1.1805e+00, -3.2929e-01, -1.6179e+00,\n",
      "        -1.3118e-01, -2.0663e+00, -1.2316e+00, -1.7986e+00, -6.9152e-01,\n",
      "        -1.0090e+00, -1.9192e+00, -1.7283e+00, -2.5961e+00, -8.5511e-01,\n",
      "         1.5235e+00, -1.4780e-01, -1.6104e+00, -3.6279e-01,  2.1868e+00,\n",
      "        -1.3836e+00, -4.1517e+00,  1.9725e-01, -1.0111e+00,  2.8664e-01,\n",
      "        -2.7819e+00, -1.9255e+00,  2.9294e-01, -2.0732e+00, -1.2969e+00,\n",
      "         1.4131e-01, -1.1414e+00,  1.0923e-01, -1.1548e-01, -2.7586e+00,\n",
      "        -9.8461e-01, -6.7238e-01, -1.2984e+00,  1.2161e+00, -1.0253e+00,\n",
      "        -2.4343e+00, -2.6982e-01, -1.7554e-01,  3.6260e-01, -3.5795e+00,\n",
      "         2.7612e-02, -4.5228e-01, -1.9063e+00,  1.7975e-02,  1.1564e-01,\n",
      "        -3.4638e-01, -4.7017e+00, -2.4120e+00, -2.7796e+00, -3.3596e+00,\n",
      "         7.1143e-01,  4.4922e-01, -8.2693e-01, -1.7714e+00, -1.6241e+00,\n",
      "         1.3414e+00, -3.6527e+00,  1.5094e-01,  1.7124e+00, -6.9414e+00,\n",
      "        -1.3995e+00, -4.0581e+00, -3.0568e+00, -1.3540e+00, -2.8832e+00,\n",
      "         2.9670e+00, -2.3142e+00, -2.0605e+00, -2.6776e+00, -1.4220e+00,\n",
      "        -4.7322e-01, -1.5544e+00, -1.8154e+00, -4.4336e-01,  2.8070e-03,\n",
      "         2.2437e-01, -2.4715e+00, -6.2946e-01,  4.1325e-01,  1.1764e-01,\n",
      "        -2.8712e+00,  9.0518e-02,  3.1488e-01, -3.4003e+00, -4.6061e-01,\n",
      "        -8.1940e-01,  1.3713e+00, -1.1252e+00, -1.1979e-01,  4.4928e-02,\n",
      "        -1.3069e+00, -2.9856e+00, -5.6022e-01,  2.9491e-01, -6.2542e-01,\n",
      "        -9.0575e-01,  2.2936e+00, -1.0312e+00, -7.0473e-01, -1.3433e+00,\n",
      "        -2.2080e-01, -1.4166e-01, -4.2973e+00, -1.3394e-01, -7.6027e-02,\n",
      "         4.1910e-01, -3.0279e-01, -1.0107e+00, -1.0132e+00, -8.7094e-01,\n",
      "        -1.2152e+00, -1.1603e+00,  5.1390e+00, -1.4957e+00, -1.4581e+00,\n",
      "        -1.0433e+00,  2.9810e-01,  3.7403e-01, -1.5533e+00, -1.2997e+00,\n",
      "        -1.6096e+00, -6.9629e-01, -2.7859e-02,  8.9123e-01,  2.7504e-01,\n",
      "        -2.2270e+00, -1.4392e+00, -1.0627e-01, -1.6608e+00, -5.3382e-01,\n",
      "        -8.4077e-01,  2.9701e-01,  6.7888e-01, -3.2519e-01, -1.0299e+00,\n",
      "        -8.5510e-01, -3.1546e-01, -2.1187e-01, -9.6136e-01, -6.3044e-02,\n",
      "        -6.5074e-02, -6.6847e-01, -1.2084e-01, -8.4633e-01, -4.3190e+00,\n",
      "        -8.3079e+00, -1.3756e+00,  3.5278e-01,  9.0118e-02, -4.0783e+00,\n",
      "         5.7977e-01,  3.0619e-01, -5.6524e+00, -3.4165e-01,  1.4117e-01,\n",
      "        -8.0940e-01, -5.0793e-01, -2.3183e+00, -5.2178e-02,  1.1649e+00,\n",
      "        -2.0828e+00,  9.1538e-02, -2.6840e+00, -2.5027e+00, -5.1534e-01,\n",
      "        -1.4219e-01, -1.8382e+00,  1.2075e+00, -1.1054e+00, -9.0725e-01,\n",
      "         3.7477e-01], device='cuda:0')), ('backbone.model.layer3.2.conv2.weight', tensor([[[[ 0.0331,  0.0418, -0.0139],\n",
      "          [ 0.0519, -0.0094, -0.1320],\n",
      "          [ 0.0644,  0.0468, -0.0873]],\n",
      "\n",
      "         [[ 0.0129, -0.0053,  0.0077],\n",
      "          [ 0.0084, -0.0667, -0.0136],\n",
      "          [-0.0109, -0.0565, -0.0038]],\n",
      "\n",
      "         [[-0.0970, -0.1211, -0.0122],\n",
      "          [-0.0188, -0.1045, -0.0619],\n",
      "          [ 0.0037, -0.0639, -0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0695, -0.0217, -0.1142],\n",
      "          [ 0.0259,  0.0138, -0.2251],\n",
      "          [ 0.0010, -0.0482, -0.1083]],\n",
      "\n",
      "         [[ 0.0456,  0.0201, -0.0499],\n",
      "          [ 0.0444, -0.0132, -0.1131],\n",
      "          [ 0.0526,  0.0092, -0.0437]],\n",
      "\n",
      "         [[ 0.0130, -0.0368, -0.1599],\n",
      "          [ 0.0306, -0.0721, -0.1296],\n",
      "          [ 0.0102,  0.0220, -0.0780]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045,  0.0063, -0.0658],\n",
      "          [-0.0040,  0.0402, -0.0071],\n",
      "          [-0.0137, -0.0057, -0.0219]],\n",
      "\n",
      "         [[ 0.0518, -0.0084,  0.0694],\n",
      "          [ 0.0136, -0.2061,  0.0372],\n",
      "          [ 0.0178, -0.0036,  0.0671]],\n",
      "\n",
      "         [[-0.0491, -0.0596,  0.0144],\n",
      "          [-0.0795, -0.1470, -0.0110],\n",
      "          [-0.0356, -0.0542, -0.0245]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224, -0.0271,  0.0409],\n",
      "          [-0.0380,  0.1213,  0.0393],\n",
      "          [-0.0193,  0.0296,  0.0298]],\n",
      "\n",
      "         [[-0.0051, -0.0070,  0.0134],\n",
      "          [ 0.0006, -0.0830, -0.0024],\n",
      "          [ 0.0159,  0.0018,  0.0282]],\n",
      "\n",
      "         [[-0.0925, -0.0151,  0.1617],\n",
      "          [-0.1799, -0.0599,  0.2136],\n",
      "          [-0.1298,  0.0680,  0.2019]]],\n",
      "\n",
      "\n",
      "        [[[-0.0407, -0.0726, -0.1071],\n",
      "          [-0.0330, -0.0034, -0.0119],\n",
      "          [ 0.0048, -0.0018,  0.0057]],\n",
      "\n",
      "         [[ 0.0057, -0.0883,  0.0312],\n",
      "          [-0.0012,  0.0233,  0.0385],\n",
      "          [ 0.0449, -0.0622, -0.0469]],\n",
      "\n",
      "         [[ 0.0239, -0.0505,  0.0518],\n",
      "          [ 0.0148, -0.0345,  0.0188],\n",
      "          [ 0.0609, -0.0214,  0.0374]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0109, -0.0356,  0.0143],\n",
      "          [ 0.0057, -0.0317,  0.0092],\n",
      "          [ 0.0352, -0.0475, -0.0204]],\n",
      "\n",
      "         [[-0.0850,  0.0693, -0.0673],\n",
      "          [-0.1355,  0.1037, -0.1019],\n",
      "          [-0.1373,  0.0331, -0.1290]],\n",
      "\n",
      "         [[-0.0588,  0.1091, -0.0087],\n",
      "          [-0.0789,  0.0646, -0.0345],\n",
      "          [-0.0139,  0.0530, -0.0911]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0008,  0.0667,  0.0148],\n",
      "          [-0.0647, -0.0767, -0.0391],\n",
      "          [-0.0719,  0.0296, -0.0386]],\n",
      "\n",
      "         [[ 0.0399,  0.0344,  0.0808],\n",
      "          [-0.0439, -0.0230, -0.0768],\n",
      "          [-0.0085, -0.0245, -0.0083]],\n",
      "\n",
      "         [[ 0.0490,  0.0170,  0.0612],\n",
      "          [ 0.0722,  0.0529,  0.0722],\n",
      "          [ 0.0414, -0.0447, -0.0137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0406, -0.0202, -0.0821],\n",
      "          [-0.0040, -0.0141, -0.0682],\n",
      "          [ 0.0460,  0.0437,  0.0551]],\n",
      "\n",
      "         [[ 0.0023,  0.0866,  0.0411],\n",
      "          [ 0.0163,  0.0637,  0.0285],\n",
      "          [-0.0453, -0.0748, -0.0508]],\n",
      "\n",
      "         [[-0.0203,  0.0309,  0.0882],\n",
      "          [-0.0019,  0.0197, -0.0208],\n",
      "          [ 0.0696,  0.0490, -0.0069]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174,  0.0152,  0.0658],\n",
      "          [-0.0446, -0.1576,  0.0093],\n",
      "          [ 0.0545, -0.0209,  0.0266]],\n",
      "\n",
      "         [[ 0.0022,  0.0970,  0.0531],\n",
      "          [ 0.0565,  0.0766,  0.0586],\n",
      "          [-0.0039, -0.1158, -0.0400]],\n",
      "\n",
      "         [[ 0.0114, -0.0129,  0.0146],\n",
      "          [ 0.0166,  0.0531,  0.0645],\n",
      "          [ 0.0060,  0.0854,  0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0412, -0.0809, -0.0673],\n",
      "          [ 0.0618,  0.0729,  0.0646],\n",
      "          [ 0.1169,  0.1020,  0.1042]],\n",
      "\n",
      "         [[ 0.0062,  0.0938,  0.0114],\n",
      "          [-0.0315,  0.0352, -0.0172],\n",
      "          [-0.0968, -0.0830, -0.1123]],\n",
      "\n",
      "         [[-0.0335,  0.0804,  0.0828],\n",
      "          [-0.0056, -0.0236,  0.0201],\n",
      "          [-0.0287, -0.0148,  0.0223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0234,  0.0267,  0.0167],\n",
      "          [-0.0196, -0.0275, -0.0393],\n",
      "          [-0.0048,  0.0093, -0.0417]],\n",
      "\n",
      "         [[-0.0172, -0.0227, -0.0122],\n",
      "          [ 0.0443,  0.1102,  0.0013],\n",
      "          [-0.0076, -0.0188,  0.0492]],\n",
      "\n",
      "         [[-0.0200,  0.0284, -0.0465],\n",
      "          [-0.1130, -0.0075, -0.0093],\n",
      "          [-0.1139,  0.0449, -0.0232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0151, -0.1071,  0.0088],\n",
      "          [ 0.0140, -0.1309,  0.0088],\n",
      "          [ 0.0290, -0.0731,  0.0271]],\n",
      "\n",
      "         [[ 0.0402,  0.0542,  0.0075],\n",
      "          [ 0.0147,  0.0095,  0.0010],\n",
      "          [ 0.0109,  0.0605, -0.0214]],\n",
      "\n",
      "         [[ 0.0041, -0.0002, -0.0789],\n",
      "          [ 0.0178, -0.0397, -0.0148],\n",
      "          [-0.0408, -0.0922, -0.0017]]]], device='cuda:0')), ('backbone.model.layer3.2.bn2.weight', tensor([ 2.2114,  1.8234,  3.4551,  3.6621,  2.3080,  1.7785,  3.0569,  2.2961,\n",
      "         2.5763,  2.6562,  1.9590,  3.3849,  1.8798,  1.8516,  3.7038,  2.1092,\n",
      "         2.4650,  1.9162,  1.4057,  2.0683,  2.7975,  1.7420,  2.7612,  2.2874,\n",
      "         2.0891,  1.7388,  3.1214,  2.5368,  3.4771,  2.3724,  2.1352,  2.1895,\n",
      "         4.2674,  4.2627,  3.5714,  3.7944,  3.0096,  3.4272,  1.9087,  3.9581,\n",
      "         2.3385,  2.4967,  2.5859,  3.3620,  1.2844,  2.3257,  2.2908,  2.0392,\n",
      "         1.6305,  2.2665,  2.0724,  2.7280,  2.7357,  2.4761,  2.8637,  0.4054,\n",
      "        10.1352,  2.5971,  2.5924,  2.2262,  2.3573,  2.0791,  2.6785,  3.5410,\n",
      "         2.1959,  2.1487,  2.5899,  3.5776,  2.1734,  2.1629,  2.4866,  1.3711,\n",
      "         2.7187,  2.2844,  2.3990,  2.1106,  2.0360,  1.8900,  3.1626,  1.3433,\n",
      "         0.7260,  3.9220,  2.9941,  5.5950,  3.3190,  2.2297,  2.4446,  3.3986,\n",
      "         4.0177,  1.6837,  2.8903,  3.3973,  2.6501,  2.4258,  5.9766,  3.5246,\n",
      "         2.7438,  1.6172,  2.2324,  2.4395,  1.7559,  2.0885,  1.7777,  2.0031,\n",
      "         1.7896,  3.6807,  3.8690,  5.1284,  2.8414,  2.2452,  5.3140,  5.0200,\n",
      "         3.0312,  1.3180,  2.0010,  3.2371,  2.4812,  1.5194,  2.6472,  1.5730,\n",
      "         1.7094,  2.1163,  1.9037,  1.8361,  2.3339,  1.5101,  1.5229,  2.0586,\n",
      "         2.1331,  2.7791,  4.4018,  5.0755,  2.8208,  3.4605,  3.3071,  2.3730,\n",
      "         2.8333,  2.9095,  2.3483,  2.6475,  3.4106,  0.7148,  3.0844,  2.7259,\n",
      "         3.2623,  2.2036,  2.6322,  2.3080,  2.0846,  1.6973,  2.7064,  2.8703,\n",
      "         2.0850,  1.7782,  1.9213,  2.8563,  2.5149,  1.6198,  1.8326,  2.0265,\n",
      "         1.7400,  0.8162,  1.9846,  2.5447,  1.7969,  2.1347,  2.9943,  2.1408,\n",
      "         2.2889,  1.5303,  2.5518,  1.5807,  1.2971,  1.4261,  2.1251,  2.1322,\n",
      "         2.3716,  2.1964,  2.7697,  3.0116,  1.1154,  2.3292,  2.6964,  2.3166,\n",
      "         2.7991,  0.6044,  3.0374,  2.5645,  3.2292,  2.0899,  2.8657,  3.9078,\n",
      "         1.7134,  1.5339,  1.6969,  1.3111,  1.4087,  2.2053,  2.0449,  1.3374,\n",
      "         1.1172,  4.0103,  1.7741,  2.2345,  2.4109,  1.9175,  2.0508,  2.6836,\n",
      "         3.4760,  2.5525,  2.0293,  2.9613,  2.2232,  3.4337,  0.3542,  2.3294,\n",
      "         2.7053,  2.4873,  2.1737,  1.7397,  1.8075,  2.1524,  1.8988,  2.1438,\n",
      "         2.0787,  2.3788,  2.5409,  2.4502,  2.7128,  2.9784,  3.0396,  0.8101,\n",
      "         1.1788,  1.5049,  3.5460,  1.7700,  1.9396,  1.9314,  2.1097,  2.0233,\n",
      "         1.9602,  1.8034,  0.7968,  4.4605,  1.5877,  2.5540,  1.1812,  1.8891,\n",
      "         2.2658,  2.0119,  1.9361,  2.0105,  2.5830,  1.5831,  1.9344,  1.9840],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.bn2.bias', tensor([-8.6385e-01, -8.5536e-01,  9.9707e-01, -1.5402e+00, -9.2505e-01,\n",
      "        -7.0372e-01, -1.0793e+00, -2.8655e+00, -2.7758e-01, -2.0144e+00,\n",
      "        -8.1449e-01, -2.5370e+00, -9.3481e-01, -2.2524e+00, -9.9988e-01,\n",
      "         5.1532e-01,  2.1786e-01, -1.0188e-01, -1.8093e+00, -1.9103e-02,\n",
      "        -4.5471e+00, -7.0738e-01, -3.5246e-01, -2.9847e-01, -7.1803e-01,\n",
      "        -2.9809e+00, -9.4203e-01,  3.9010e-01, -1.7040e+00, -2.0974e+00,\n",
      "        -1.1470e+00, -6.4060e-01, -5.6347e-02, -4.0235e-01, -1.3066e+00,\n",
      "         5.9484e-01, -1.1488e+00,  4.1666e-01, -4.2246e+00, -8.8511e-02,\n",
      "        -9.5039e-01, -3.6596e-01, -8.4671e-01,  3.5237e-01, -2.1283e+00,\n",
      "         6.4229e-01, -5.4780e-01, -1.1855e+00,  4.0563e-02, -3.0927e-01,\n",
      "        -3.6849e-01, -1.0915e+00, -5.5338e-01, -3.2706e+00, -6.3695e-01,\n",
      "        -6.4578e-01,  2.1274e+00, -1.0564e+00, -8.1495e-01, -1.7562e+00,\n",
      "        -1.0060e+00, -2.8071e+00, -3.2226e-01, -1.3274e+00, -2.6083e+00,\n",
      "        -2.1833e+00, -1.6045e+00, -1.7173e+00, -1.9531e-01,  4.2121e-01,\n",
      "        -1.7421e+00,  2.1873e+00, -1.1494e+00, -7.1118e-01, -7.1582e-01,\n",
      "        -3.6665e-01, -3.0770e+00,  2.8523e-01, -1.0095e+00,  8.2216e-01,\n",
      "        -1.2567e+00,  6.8165e-02,  5.3905e-01, -1.2914e-02, -4.2182e+00,\n",
      "         3.2094e-01,  3.9842e-01, -1.8414e+00, -1.1959e+00, -3.4893e+00,\n",
      "        -3.9697e-01, -2.2651e+00, -3.6949e-01, -2.3067e+00,  5.5120e-01,\n",
      "        -1.7620e+00, -1.1803e+00,  1.4113e-01,  6.6054e-02, -5.3550e-01,\n",
      "        -2.3350e+00, -1.1034e+00, -8.8504e-01,  2.1226e-01, -1.5752e+00,\n",
      "        -2.3512e+00, -1.6811e+00, -2.7827e+00, -1.8326e+00, -6.9080e+00,\n",
      "        -2.9731e+00, -1.2168e+00, -1.4364e+00, -2.3539e+00, -5.4533e-01,\n",
      "        -1.6113e+00,  5.0683e-01,  1.4345e+00,  2.4934e-01,  1.0699e+00,\n",
      "        -1.1428e+00, -1.2276e+00, -1.0392e+00, -1.4418e+00, -1.6111e-01,\n",
      "        -2.1592e+00, -4.3404e-01, -5.7372e-02, -3.8764e+00, -8.0532e-01,\n",
      "        -1.0520e+00, -1.8280e+00, -1.0473e+00, -9.5436e-01, -6.7673e-01,\n",
      "         6.0775e-01, -1.8615e+00,  4.4003e-01, -1.1594e+00, -2.5750e+00,\n",
      "         6.3509e-01, -1.3786e+00, -1.0941e-01,  5.4422e-01, -2.5117e+00,\n",
      "        -1.4445e+00,  4.4561e-01,  2.6968e-03, -1.6087e+00, -1.2898e+00,\n",
      "        -2.2910e+00, -9.5554e-01, -2.2368e-01, -1.4648e+00, -5.7100e-01,\n",
      "        -1.5640e+00,  1.7462e-01, -2.3592e+00,  1.3310e-01,  4.8467e-01,\n",
      "        -3.3732e-01, -9.6936e-01, -7.6785e-01, -8.5709e-01, -3.7301e-01,\n",
      "         2.9892e-01, -5.3028e+00, -6.8952e-01, -3.7028e-01, -1.4517e+00,\n",
      "         5.8756e-01,  1.7619e-01, -6.7631e-01,  4.9183e-01, -8.5907e-01,\n",
      "        -6.2667e-01,  6.3926e-01, -4.9601e-01, -3.2602e+00, -1.0221e-01,\n",
      "        -1.9155e+00, -8.8528e-02, -3.9977e-01, -1.4764e-01, -7.4585e-01,\n",
      "        -1.7808e+00,  5.6698e-01, -1.2400e+00, -3.7373e-01,  8.0457e-01,\n",
      "         3.9185e-02, -3.7872e+00,  2.7406e-01,  1.1608e+00, -1.5581e+00,\n",
      "        -1.2495e+00, -4.1120e-01,  1.4069e-01,  3.3666e-01, -1.8348e+00,\n",
      "         8.1452e-02, -1.6466e+00, -2.0453e+00, -8.4152e-01, -2.9240e-01,\n",
      "        -3.7709e+00,  5.1774e-01, -8.8879e-01, -1.6874e+00, -3.0544e+00,\n",
      "        -5.0994e-01,  7.7300e-02,  1.3724e-02, -1.8293e+00, -2.7562e-01,\n",
      "         1.5900e-01, -4.6189e-01,  3.0437e-01,  3.9932e-01,  3.8440e-01,\n",
      "        -1.8998e+00, -2.9886e-01, -2.3943e+00, -2.3243e+00,  3.2090e-01,\n",
      "        -1.6544e+00,  4.8807e-01, -3.2396e-02, -3.4129e+00,  5.0152e-01,\n",
      "         4.6202e-02, -1.9897e+00, -1.6692e+00, -1.2055e+00, -2.5518e+00,\n",
      "         4.7206e-01, -5.8983e-01, -4.3595e-01, -3.3862e-01, -1.3538e-01,\n",
      "         6.2380e-02, -4.2555e-01,  2.7785e-01, -3.0015e+00, -1.1723e-01,\n",
      "         7.7730e-01, -1.4479e+00, -2.2072e+00, -6.3080e-01, -6.7254e-01,\n",
      "        -2.5154e+00, -2.6630e-01, -1.7835e+00, -2.6663e-01,  8.1486e-01,\n",
      "        -7.9629e-01], device='cuda:0')), ('backbone.model.layer3.2.conv3.weight', tensor([[[[ 0.1302]],\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         [[ 0.0721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0035]],\n",
      "\n",
      "         [[ 0.0824]],\n",
      "\n",
      "         [[ 0.0076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0406]],\n",
      "\n",
      "         [[ 0.1592]],\n",
      "\n",
      "         [[-0.3507]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[ 0.1111]],\n",
      "\n",
      "         [[-0.0046]]],\n",
      "\n",
      "\n",
      "        [[[-0.0281]],\n",
      "\n",
      "         [[-0.0708]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[-0.1116]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0523]],\n",
      "\n",
      "         [[ 0.1724]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0005]],\n",
      "\n",
      "         [[ 0.0912]],\n",
      "\n",
      "         [[-0.0426]]],\n",
      "\n",
      "\n",
      "        [[[-0.0504]],\n",
      "\n",
      "         [[ 0.0302]],\n",
      "\n",
      "         [[ 0.1641]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0873]]],\n",
      "\n",
      "\n",
      "        [[[-0.0480]],\n",
      "\n",
      "         [[ 0.0078]],\n",
      "\n",
      "         [[ 0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[-0.0667]]]], device='cuda:0')), ('backbone.model.layer3.2.bn3.weight', tensor([ 1.4139,  1.6582,  1.5830,  ...,  1.2578, -2.6621,  1.8908],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.bn3.bias', tensor([-0.3329, -0.6438, -0.3667,  ..., -0.5458,  0.2469, -0.6319],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv1.weight', tensor([[[[ 0.0279]],\n",
      "\n",
      "         [[-0.1005]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         [[ 0.0705]],\n",
      "\n",
      "         [[-0.0016]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0480]],\n",
      "\n",
      "         [[ 0.0446]],\n",
      "\n",
      "         [[ 0.0850]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[ 0.0828]],\n",
      "\n",
      "         [[-0.0328]]],\n",
      "\n",
      "\n",
      "        [[[-0.0046]],\n",
      "\n",
      "         [[-0.1167]],\n",
      "\n",
      "         [[-0.0624]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[-0.0149]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0443]],\n",
      "\n",
      "         [[ 0.0818]],\n",
      "\n",
      "         [[ 0.1084]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[ 0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.0445]],\n",
      "\n",
      "         [[ 0.1481]],\n",
      "\n",
      "         [[-0.2798]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0206]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[ 0.0026]]],\n",
      "\n",
      "\n",
      "        [[[-0.0015]],\n",
      "\n",
      "         [[ 0.0476]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0471]],\n",
      "\n",
      "         [[ 0.1067]],\n",
      "\n",
      "         [[ 0.0620]]]], device='cuda:0')), ('backbone.model.layer3.3.bn1.weight', tensor([2.0251, 1.8809, 1.7625, 2.7906, 2.6572, 5.0392, 1.8324, 1.8810, 2.5099,\n",
      "        1.5392, 2.1742, 2.1923, 3.0884, 3.0851, 2.7540, 1.9236, 2.0051, 1.4511,\n",
      "        2.3482, 1.5532, 1.9655, 1.9130, 1.6397, 1.6202, 2.7161, 2.4579, 3.7488,\n",
      "        2.4746, 2.4112, 3.5530, 1.3056, 2.3672, 3.4150, 2.4398, 2.7394, 2.5005,\n",
      "        1.8930, 3.3475, 2.1898, 1.7604, 0.8535, 1.3806, 2.6919, 1.9333, 1.4608,\n",
      "        3.6962, 2.3909, 2.3114, 1.9841, 2.0179, 1.6332, 1.6751, 2.1203, 2.2803,\n",
      "        2.8138, 2.1805, 2.9055, 2.1205, 2.9197, 2.6061, 2.7021, 1.8130, 1.9716,\n",
      "        3.0859, 2.7044, 3.0162, 2.1844, 2.1982, 1.1326, 1.8474, 1.9675, 2.0604,\n",
      "        2.3837, 2.4233, 1.7364, 2.5055, 1.8963, 2.1524, 1.9387, 2.4282, 2.6394,\n",
      "        3.0244, 3.2893, 3.4896, 3.0607, 2.8379, 4.7873, 1.7532, 1.8957, 1.9292,\n",
      "        1.8617, 1.4848, 2.5731, 2.7100, 2.3708, 2.8270, 2.0072, 2.2393, 2.9412,\n",
      "        2.2667, 2.7462, 2.6758, 2.2384, 2.4532, 3.0513, 0.9884, 5.7068, 1.8863,\n",
      "        2.7959, 1.9709, 1.7511, 4.3736, 3.2079, 3.7021, 0.9385, 1.5273, 2.3192,\n",
      "        3.3762, 2.8657, 2.1469, 2.9676, 1.5118, 1.9489, 2.0899, 1.7240, 1.7952,\n",
      "        2.8250, 1.8794, 2.5240, 4.5620, 5.0192, 2.2860, 1.4832, 2.3578, 2.5261,\n",
      "        0.9024, 1.6188, 2.6627, 2.5296, 2.5743, 3.5487, 1.9723, 2.1560, 2.8135,\n",
      "        3.3425, 2.5049, 4.2823, 0.8482, 1.5671, 2.3198, 2.9131, 3.6528, 2.3021,\n",
      "        1.8122, 2.2246, 1.3795, 1.9976, 2.5580, 2.7598, 2.4612, 1.5261, 1.8389,\n",
      "        1.6784, 2.6473, 1.9688, 1.6232, 2.8958, 2.4750, 1.5876, 3.4259, 3.0292,\n",
      "        1.4883, 3.0065, 2.2181, 2.2970, 2.4602, 1.6177, 1.9787, 2.3687, 2.2122,\n",
      "        1.9708, 3.9495, 2.0521, 2.4645, 2.2132, 1.8230, 2.7467, 2.4033, 2.1148,\n",
      "        1.3131, 1.6341, 2.3585, 1.8505, 2.0089, 1.7480, 2.5520, 2.2535, 2.7343,\n",
      "        1.4156, 1.9969, 1.8893, 3.0938, 2.6218, 2.3367, 2.1864, 2.6654, 1.7374,\n",
      "        1.8534, 2.8028, 6.2646, 3.0720, 2.5940, 1.5143, 3.4338, 4.5743, 2.4128,\n",
      "        2.8783, 3.4975, 2.4802, 3.1599, 2.4282, 2.6618, 1.6456, 3.2576, 2.2372,\n",
      "        1.9593, 3.1104, 1.6926, 2.6422, 1.7485, 1.7822, 3.6544, 2.0454, 2.3340,\n",
      "        1.6940, 2.4581, 2.2521, 2.4984, 1.6489, 1.6929, 1.6040, 1.8723, 2.3025,\n",
      "        1.5423, 2.2272, 2.3838, 2.3770, 2.7409, 2.0534, 1.8753, 1.6720, 2.7472,\n",
      "        1.6015, 1.7609, 1.0752, 2.0290], device='cuda:0')), ('backbone.model.layer3.3.bn1.bias', tensor([-2.7309, -4.2231, -0.3822, -1.4181, -0.3771, -4.6080,  0.0793, -0.3473,\n",
      "        -2.7307,  0.8960, -0.0564, -3.1220, -3.0602, -2.5107, -1.9342, -1.5050,\n",
      "        -0.0869, -1.5037, -1.1617, -0.4407, -0.4391, -0.2395, -0.4566, -1.0291,\n",
      "        -0.4488, -1.2474, -1.7212, -1.4813,  0.0851, -1.1032, -2.7400, -1.3286,\n",
      "         0.2047, -0.6152, -0.8739, -1.0081, -2.6574, -0.4942, -0.2621, -1.2695,\n",
      "        -1.0830, -0.0478, -3.9401,  0.0601, -0.3792, -1.5476, -0.5399, -0.2371,\n",
      "        -0.1686, -0.0981, -0.6775, -0.9537, -0.9847, -1.8533, -0.0248, -1.5263,\n",
      "        -3.1093,  0.4977,  0.6404, -2.1630, -2.3214, -1.0829, -2.4209,  1.5256,\n",
      "        -0.2747, -1.6809, -1.6630, -0.4149,  1.0645, -1.7861, -1.5919, -1.4597,\n",
      "        -0.6602, -0.7151, -0.0231, -2.7275, -0.1831, -0.2926, -2.6958, -3.6038,\n",
      "         0.1082, -3.2176, -0.5337, -0.6667, -1.2963, -0.2633, -1.5826, -3.8865,\n",
      "        -2.1124, -0.8448, -2.3476, -0.6015, -0.7047, -1.6587, -0.3061, -0.5763,\n",
      "        -1.0523, -3.2848,  0.5210, -3.5836, -1.6048, -1.0733, -1.1334, -0.1717,\n",
      "        -0.8983,  0.4227, -4.0163, -1.1170, -1.3133, -0.8799, -1.8417, -3.6682,\n",
      "        -1.5710, -2.0928, -2.3890, -0.9547, -0.9412, -0.9506, -4.4159, -0.8818,\n",
      "        -1.7585, -0.9128, -1.0019,  1.1641, -0.8857, -1.0387, -0.3268, -2.0396,\n",
      "        -3.5010, -2.2731, -2.7511, -0.8954, -1.7581, -0.9919, -0.7532, -3.4816,\n",
      "        -2.3124, -2.5041, -0.6557,  1.2661, -1.5271, -0.6400, -0.6124, -1.2055,\n",
      "        -2.2914, -0.5305, -2.2775, -0.3130, -1.7026, -0.5606,  0.2622, -0.5855,\n",
      "        -0.6762, -1.8129, -0.2458,  1.6469, -1.4153, -1.9691, -2.8367, -1.0005,\n",
      "        -1.6974, -1.0173, -0.0803, -1.1458, -0.8263,  0.3574, -1.8013, -0.5931,\n",
      "         0.0705, -1.2705, -2.2151, -1.9519, -2.3198, -2.7771, -1.0320, -0.3339,\n",
      "        -2.8740, -0.1641, -1.0510, -0.8072, -1.5758, -3.8578,  0.0502,  0.0720,\n",
      "        -1.1570, -0.9379, -1.1480, -3.1333, -0.4494, -0.1676, -3.3634, -4.9689,\n",
      "        -0.3228,  1.8818,  0.2609, -2.1624, -2.8534, -1.4591, -0.5188, -0.4893,\n",
      "        -1.8880, -1.5817, -1.6280,  1.5983, -2.2254, -0.7276, -0.8501, -1.9850,\n",
      "        -0.0519, -0.3877,  0.5435, -1.3328, -3.1834, -1.0089,  0.2022, -2.5690,\n",
      "         0.6607, -1.1041, -2.2819, -1.0129, -1.8393, -1.2940, -3.6075, -1.0751,\n",
      "        -1.7061, -0.5562, -2.4310, -0.4458, -2.5563,  0.2818, -3.4883, -1.3806,\n",
      "        -3.8902, -1.1514, -0.3811, -1.8396, -0.9157, -0.8499, -0.3542, -0.7183,\n",
      "        -0.6341, -1.9142, -1.6655, -1.5621,  0.5175, -0.2883, -1.7883, -0.9062,\n",
      "        -0.7977,  0.0078, -1.3303, -0.8899, -1.6441, -2.2552,  0.9061, -0.4219],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv2.weight', tensor([[[[-0.0535, -0.1016, -0.0928],\n",
      "          [-0.0424, -0.0986, -0.1171],\n",
      "          [-0.0573, -0.0095, -0.0996]],\n",
      "\n",
      "         [[-0.0654, -0.0573,  0.0255],\n",
      "          [-0.1014, -0.0125, -0.0278],\n",
      "          [ 0.0176,  0.0754, -0.0167]],\n",
      "\n",
      "         [[ 0.1417,  0.1646,  0.1362],\n",
      "          [ 0.0264,  0.0184,  0.0015],\n",
      "          [-0.0232, -0.0894, -0.0296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0493,  0.0253,  0.0602],\n",
      "          [ 0.0271, -0.0336,  0.0258],\n",
      "          [ 0.0340, -0.0647, -0.0088]],\n",
      "\n",
      "         [[-0.0039, -0.0386,  0.0362],\n",
      "          [ 0.0073, -0.0479,  0.0785],\n",
      "          [ 0.0571,  0.0636,  0.0905]],\n",
      "\n",
      "         [[ 0.0305, -0.0217,  0.0064],\n",
      "          [-0.0037, -0.0415, -0.0596],\n",
      "          [-0.0280, -0.0258, -0.0720]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0511,  0.0476,  0.1099],\n",
      "          [ 0.0134,  0.0055,  0.0510],\n",
      "          [ 0.0748, -0.0144,  0.0283]],\n",
      "\n",
      "         [[ 0.1086,  0.0456,  0.0779],\n",
      "          [ 0.0142, -0.0542, -0.0574],\n",
      "          [ 0.0071, -0.0213, -0.0005]],\n",
      "\n",
      "         [[ 0.0614,  0.1213,  0.0935],\n",
      "          [-0.0240,  0.1253,  0.0389],\n",
      "          [-0.0093,  0.0376, -0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0416,  0.0681,  0.0391],\n",
      "          [ 0.0165,  0.0473,  0.0109],\n",
      "          [ 0.0177,  0.0157,  0.0210]],\n",
      "\n",
      "         [[-0.1266, -0.1044, -0.0993],\n",
      "          [-0.0901, -0.0724, -0.1092],\n",
      "          [-0.1053, -0.0810, -0.0756]],\n",
      "\n",
      "         [[-0.0254,  0.0526,  0.0647],\n",
      "          [-0.0006,  0.1294,  0.0567],\n",
      "          [ 0.0731,  0.1036,  0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.0487, -0.0999, -0.0500],\n",
      "          [ 0.0006, -0.0575, -0.0331],\n",
      "          [-0.0110,  0.0112, -0.0223]],\n",
      "\n",
      "         [[-0.0361, -0.0245, -0.0140],\n",
      "          [-0.0538, -0.0378, -0.0442],\n",
      "          [-0.0093, -0.0032, -0.0273]],\n",
      "\n",
      "         [[ 0.0760,  0.0450,  0.0259],\n",
      "          [ 0.0428,  0.0951,  0.0663],\n",
      "          [ 0.0627,  0.1137,  0.0686]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0379, -0.0079, -0.0287],\n",
      "          [ 0.0037,  0.1699,  0.0165],\n",
      "          [-0.0146,  0.0286, -0.0309]],\n",
      "\n",
      "         [[ 0.0570, -0.0027,  0.0419],\n",
      "          [ 0.0497, -0.0351,  0.0212],\n",
      "          [-0.0162,  0.0050, -0.0156]],\n",
      "\n",
      "         [[ 0.0130, -0.0366, -0.0092],\n",
      "          [ 0.0086, -0.1675,  0.0026],\n",
      "          [-0.0042, -0.0734,  0.0107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0268, -0.1280, -0.0320],\n",
      "          [-0.1358, -0.1360, -0.1045],\n",
      "          [-0.1202, -0.1445, -0.1195]],\n",
      "\n",
      "         [[ 0.0048, -0.0022,  0.0097],\n",
      "          [ 0.0380,  0.1193,  0.0752],\n",
      "          [ 0.0319,  0.0769,  0.0529]],\n",
      "\n",
      "         [[-0.0569, -0.0104, -0.0470],\n",
      "          [-0.0153,  0.0938,  0.0517],\n",
      "          [ 0.0265, -0.0079, -0.0424]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0632,  0.0369, -0.0566],\n",
      "          [-0.0135,  0.0976, -0.0402],\n",
      "          [-0.0354,  0.0326, -0.0279]],\n",
      "\n",
      "         [[ 0.0038,  0.0598,  0.0075],\n",
      "          [ 0.0101,  0.0224, -0.0031],\n",
      "          [-0.0152,  0.0041,  0.0195]],\n",
      "\n",
      "         [[-0.0171,  0.1029, -0.0021],\n",
      "          [-0.0003,  0.1424,  0.0037],\n",
      "          [-0.0005,  0.1443,  0.0146]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0644,  0.0386,  0.1052],\n",
      "          [-0.0046, -0.0639,  0.0230],\n",
      "          [ 0.0084, -0.0557,  0.0277]],\n",
      "\n",
      "         [[-0.0103,  0.0619,  0.0415],\n",
      "          [ 0.0210,  0.0165,  0.0377],\n",
      "          [ 0.0444,  0.0283,  0.0639]],\n",
      "\n",
      "         [[ 0.0355, -0.0052,  0.0365],\n",
      "          [ 0.0975,  0.0423,  0.0425],\n",
      "          [ 0.0310,  0.0480, -0.0021]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0800, -0.0783, -0.0659],\n",
      "          [-0.0829, -0.0948, -0.0906],\n",
      "          [-0.0658, -0.0362, -0.0773]],\n",
      "\n",
      "         [[ 0.0467,  0.0454,  0.0558],\n",
      "          [ 0.0468, -0.0047,  0.0681],\n",
      "          [ 0.0231,  0.0833,  0.0589]],\n",
      "\n",
      "         [[ 0.0019, -0.0243, -0.0162],\n",
      "          [ 0.0125,  0.0291, -0.0249],\n",
      "          [ 0.0021, -0.0467, -0.0082]]],\n",
      "\n",
      "\n",
      "        [[[-0.0579, -0.0519, -0.0110],\n",
      "          [ 0.0150, -0.0848, -0.0605],\n",
      "          [ 0.0628,  0.0420,  0.0457]],\n",
      "\n",
      "         [[-0.0591, -0.0986, -0.1060],\n",
      "          [ 0.0035, -0.0491, -0.0141],\n",
      "          [-0.0328,  0.0301, -0.0373]],\n",
      "\n",
      "         [[-0.0108,  0.0013, -0.0206],\n",
      "          [-0.0105, -0.0725,  0.0254],\n",
      "          [-0.0129, -0.1521, -0.0966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0409,  0.0086,  0.0195],\n",
      "          [ 0.0419,  0.0125,  0.0767],\n",
      "          [-0.0020,  0.0002,  0.0304]],\n",
      "\n",
      "         [[ 0.0068,  0.0780,  0.0361],\n",
      "          [-0.0331,  0.0087, -0.0843],\n",
      "          [-0.0859, -0.0229, -0.0703]],\n",
      "\n",
      "         [[-0.0290, -0.1350, -0.0530],\n",
      "          [-0.0006, -0.0174, -0.0010],\n",
      "          [ 0.0169,  0.0983,  0.0600]]]], device='cuda:0')), ('backbone.model.layer3.3.bn2.weight', tensor([2.7639, 2.3606, 4.5588, 3.4224, 1.5517, 3.2295, 2.2590, 2.5699, 2.3219,\n",
      "        2.7078, 1.3042, 3.7578, 2.3774, 2.1916, 2.5174, 3.3032, 1.2413, 2.2071,\n",
      "        2.2611, 2.5218, 2.5807, 2.1787, 3.2626, 2.3614, 3.4540, 2.2389, 4.3291,\n",
      "        2.8772, 1.8325, 2.4495, 1.9301, 2.6842, 1.8557, 2.0133, 2.1322, 2.5408,\n",
      "        2.4704, 2.3791, 2.7639, 3.6789, 2.0614, 3.2822, 3.1797, 1.0147, 2.5087,\n",
      "        2.5986, 3.9955, 2.0886, 3.0339, 2.2370, 3.0284, 0.9308, 2.5361, 2.3164,\n",
      "        3.6857, 2.7964, 2.3749, 1.9952, 2.4285, 2.1732, 2.9577, 3.2584, 2.6783,\n",
      "        3.9530, 2.5571, 2.2880, 2.3455, 2.3588, 1.9735, 1.9142, 2.2832, 2.4372,\n",
      "        2.1715, 2.5932, 1.9534, 3.1743, 2.7418, 2.5195, 3.2733, 3.7276, 2.4665,\n",
      "        2.2980, 2.5386, 2.2023, 2.3591, 0.9977, 2.3444, 2.6412, 2.2569, 3.4546,\n",
      "        2.0822, 3.6883, 3.1628, 3.3623, 2.6409, 2.9286, 3.5910, 3.0726, 3.1428,\n",
      "        3.7242, 3.5746, 3.0999, 1.0777, 4.0333, 1.0313, 2.1547, 1.9265, 1.6037,\n",
      "        1.9350, 1.8655, 2.3739, 2.0844, 4.2484, 2.2484, 1.3338, 2.3161, 2.4433,\n",
      "        2.7439, 2.6089, 3.4441, 3.9141, 2.3506, 2.4135, 2.1360, 2.3997, 2.4153,\n",
      "        3.0245, 3.2009, 2.0041, 2.0001, 2.5322, 2.1115, 2.3324, 2.4663, 1.7166,\n",
      "        5.0472, 5.3695, 0.8651, 2.3723, 3.5916, 3.1022, 2.0848, 1.8951, 3.1582,\n",
      "        2.3273, 4.3619, 1.9538, 2.1472, 1.8886, 2.0771, 1.5958, 1.6591, 1.7961,\n",
      "        3.3678, 2.2996, 2.4607, 2.2049, 1.9404, 1.8655, 2.8556, 1.9188, 3.3799,\n",
      "        2.7270, 3.5351, 2.4638, 2.3358, 1.7099, 2.0593, 2.3772, 1.2575, 2.7883,\n",
      "        2.3689, 2.5305, 3.4048, 2.9792, 2.2526, 2.0604, 1.5141, 1.9113, 2.4221,\n",
      "        2.0440, 2.1314, 1.8527, 2.2599, 2.0974, 1.8639, 1.7755, 2.9971, 2.3034,\n",
      "        2.3745, 2.2515, 2.3902, 2.5119, 1.4061, 2.1128, 2.6678, 2.3100, 3.6073,\n",
      "        3.7851, 3.1820, 4.3201, 2.5349, 2.9431, 2.1184, 2.4610, 1.8071, 2.1070,\n",
      "        2.3645, 2.2379, 2.3138, 2.4590, 3.3708, 3.3004, 2.6158, 3.3185, 2.4307,\n",
      "        4.0407, 3.8933, 2.2316, 3.7075, 2.4051, 2.7125, 2.0756, 2.6176, 1.6336,\n",
      "        2.9514, 1.9343, 2.0638, 2.7016, 2.9118, 2.3150, 2.3964, 1.8182, 2.1556,\n",
      "        2.0661, 2.2563, 2.3761, 2.1216, 1.8672, 1.1445, 1.7803, 1.9562, 2.2317,\n",
      "        2.2373, 2.2677, 3.3803, 2.1051, 1.3243, 2.0984, 2.4461, 2.9297, 2.6883,\n",
      "        2.1902, 2.3741, 2.5711, 2.1144], device='cuda:0')), ('backbone.model.layer3.3.bn2.bias', tensor([ 1.3905,  0.0878, -1.2869, -1.8216, -3.6235, -0.1951,  0.8856,  0.2855,\n",
      "         0.4527, -0.1246, -3.1639, -0.4958, -1.1903, -0.0887, -1.0716, -0.1728,\n",
      "        -3.0125, -0.1572, -1.1348, -0.7767,  0.1106, -0.8456,  0.0241, -0.8419,\n",
      "        -0.2798, -0.6629, -0.6408, -0.3818, -2.2609, -0.6976,  0.3403, -1.0903,\n",
      "        -1.7149, -1.2531,  0.4882, -0.7583, -1.3451,  0.0933, -0.5694, -2.4933,\n",
      "         0.0847, -0.2457, -0.3674, -1.8280, -2.2974, -1.0775, -1.0557,  0.1275,\n",
      "         0.0368,  0.4830,  0.2017, -1.9681,  0.2280, -2.1037, -0.1152, -0.5425,\n",
      "        -1.1495, -2.0434,  0.6774, -1.5322, -1.9096, -0.6252,  0.2573, -0.5237,\n",
      "        -0.8142, -0.2125, -0.8077, -1.6420, -2.2967, -1.0171,  0.2974, -1.9495,\n",
      "        -0.7702, -0.5276, -2.9969, -0.7159, -0.0998, -1.1867,  0.3672, -1.2324,\n",
      "        -1.9112,  0.3994,  0.4916,  0.5247,  0.5439, -3.7560,  0.0718, -2.2616,\n",
      "        -3.5205, -1.0975, -2.4059,  0.1220, -0.5945,  0.7933, -0.4821,  0.5015,\n",
      "        -1.0196, -1.2495, -2.8158,  0.1338, -4.1672, -0.4847,  0.8108, -0.8625,\n",
      "        -2.9280, -1.9314,  0.0407,  0.0493, -0.4601,  0.2779, -0.1215, -0.4579,\n",
      "        -2.3348, -1.3769, -0.6968, -0.9739, -0.0695, -1.8355,  0.4939, -1.8967,\n",
      "        -4.4636, -1.0494, -1.2463, -0.5919, -0.9493, -1.1997, -1.5941, -2.2534,\n",
      "        -1.3733, -0.2123,  0.0046, -0.1578, -0.2890, -1.0787, -2.6427, -2.2527,\n",
      "        -2.8004, -0.9377, -0.4066, -1.8280, -2.2637, -0.3701,  2.6953, -0.6290,\n",
      "        -0.6085, -2.8985,  0.0419,  0.4855, -1.3071, -1.8321, -1.1590, -0.2857,\n",
      "         0.7530, -0.3192, -1.4527, -0.7722, -1.8301, -1.1271, -1.1265, -1.4426,\n",
      "        -1.9787, -2.0732, -0.8426, -1.6511, -1.7003, -0.8805,  1.5057, -0.4571,\n",
      "        -0.1198, -3.1307, -0.0140,  0.1780, -0.4249,  0.1165,  0.0262, -0.5343,\n",
      "        -1.4034,  1.0246, -1.9475, -1.2513, -0.1242, -0.3262,  1.4622, -0.4953,\n",
      "        -0.4238,  2.1012, -1.9394, -1.0951,  0.3562, -0.8891, -1.5312, -0.3276,\n",
      "        -1.8324,  1.2905, -0.7081, -0.9715, -1.8951, -0.3372, -1.2994, -1.1907,\n",
      "        -0.8230, -0.0143,  0.0072, -0.0251, -0.7959, -2.4927, -0.3244,  0.4052,\n",
      "        -1.1389, -1.8446, -1.3663, -0.2841, -1.3765, -0.4424, -0.5442, -3.1047,\n",
      "        -4.3386, -2.7227, -1.3698, -1.9908,  0.1740, -1.4143, -1.2714, -1.1291,\n",
      "        -1.5925, -1.0875,  0.0092, -1.7108, -0.5274, -1.1804, -1.0430, -0.6578,\n",
      "         0.2163,  0.4419, -0.0054, -2.5083,  0.7615,  0.3567,  0.3423, -4.2560,\n",
      "        -1.7885, -0.4242, -0.2423, -0.4666, -1.8809, -0.8867, -0.0615,  1.6369,\n",
      "        -1.4073, -0.6959, -0.3606, -0.7385, -1.0913,  0.0235, -1.7620, -1.7633],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv3.weight', tensor([[[[-0.1310]],\n",
      "\n",
      "         [[ 0.0424]],\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[ 0.0274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0554]],\n",
      "\n",
      "         [[ 0.0792]],\n",
      "\n",
      "         [[ 0.0245]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[ 0.0037]]],\n",
      "\n",
      "\n",
      "        [[[-0.0101]],\n",
      "\n",
      "         [[ 0.0160]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0942]],\n",
      "\n",
      "         [[-0.0118]],\n",
      "\n",
      "         [[ 0.0698]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0489]],\n",
      "\n",
      "         [[ 0.0021]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.1299]]],\n",
      "\n",
      "\n",
      "        [[[-0.0268]],\n",
      "\n",
      "         [[ 0.0872]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0707]],\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[-0.0301]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         [[-0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0528]],\n",
      "\n",
      "         [[ 0.0039]],\n",
      "\n",
      "         [[ 0.0372]]]], device='cuda:0')), ('backbone.model.layer3.3.bn3.weight', tensor([ 2.1156, -2.0873, -3.8347,  ..., -3.0713, -6.4074,  2.5510],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.bn3.bias', tensor([-0.3309, -0.2575, -0.0464,  ..., -0.2761, -0.0222, -0.4712],\n",
      "       device='cuda:0')), ('backbone.model.layer3.4.conv1.weight', tensor([[[[ 0.0647]],\n",
      "\n",
      "         [[-0.0823]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[ 0.0323]],\n",
      "\n",
      "         [[ 0.0051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0211]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[ 0.0988]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0335]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174]],\n",
      "\n",
      "         [[-0.0161]],\n",
      "\n",
      "         [[ 0.0617]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         [[ 0.0458]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0070]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         [[ 0.0240]],\n",
      "\n",
      "         [[ 0.0623]]],\n",
      "\n",
      "\n",
      "        [[[-0.0457]],\n",
      "\n",
      "         [[-0.0363]],\n",
      "\n",
      "         [[-0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.0690]],\n",
      "\n",
      "         [[ 0.0495]]],\n",
      "\n",
      "\n",
      "        [[[-0.0425]],\n",
      "\n",
      "         [[-0.0748]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0045]],\n",
      "\n",
      "         [[-0.0798]],\n",
      "\n",
      "         [[-0.0530]]]], device='cuda:0')), ('backbone.model.layer3.4.bn1.weight', tensor([0.9811, 1.7768, 2.5331, 1.8560, 1.9585, 2.3710, 3.7276, 1.9664, 0.6484,\n",
      "        1.9101, 2.5548, 1.4840, 3.2212, 2.3145, 2.1420, 3.2629, 3.8055, 1.8097,\n",
      "        4.1647, 2.8327, 2.5156, 2.3782, 2.7534, 1.5460, 2.2133, 3.3903, 2.3520,\n",
      "        3.5845, 2.1176, 1.4945, 2.3085, 1.4295, 1.7488, 3.2725, 1.6276, 2.6237,\n",
      "        2.1439, 2.0292, 2.4036, 2.8267, 1.8723, 5.5341, 2.4138, 1.4957, 2.5611,\n",
      "        1.4383, 2.0002, 1.4921, 2.4446, 2.3594, 1.1782, 4.3713, 2.6635, 2.5235,\n",
      "        2.0339, 1.8083, 3.2813, 0.5036, 2.1258, 3.1208, 1.9562, 1.7206, 1.8084,\n",
      "        4.2399, 1.9106, 1.9061, 1.8549, 2.4678, 2.3341, 2.7524, 0.4946, 2.1477,\n",
      "        2.3274, 1.3863, 2.1973, 2.4397, 3.2466, 2.3630, 1.6289, 1.5500, 2.0993,\n",
      "        1.7594, 1.7637, 2.4481, 1.7140, 2.2075, 1.7510, 0.7242, 2.5045, 1.6731,\n",
      "        2.5923, 3.0458, 0.7848, 2.4626, 2.7238, 1.7556, 1.7990, 0.7272, 1.1130,\n",
      "        1.6618, 1.5672, 3.9393, 2.5825, 1.8441, 1.8583, 1.4117, 4.6411, 2.0135,\n",
      "        3.9958, 1.8557, 1.2173, 2.5266, 2.2553, 1.6368, 1.9023, 2.1753, 2.0462,\n",
      "        0.5415, 1.4849, 2.0580, 2.3070, 2.5737, 1.4835, 0.6643, 5.8700, 3.0083,\n",
      "        1.7111, 1.7353, 3.6116, 2.7653, 3.8204, 2.0068, 3.4339, 4.0962, 1.8368,\n",
      "        2.1826, 1.4832, 1.3440, 1.5371, 1.6928, 1.7015, 1.5575, 1.1828, 1.8936,\n",
      "        2.6123, 2.4972, 3.1597, 0.5948, 1.7720, 1.2843, 1.8794, 1.8440, 1.3679,\n",
      "        1.9790, 1.6595, 2.5982, 2.7744, 0.5163, 2.0453, 1.6973, 1.4125, 1.1051,\n",
      "        2.5215, 1.9592, 2.4128, 1.9771, 2.4867, 2.4472, 1.9193, 1.6053, 2.4665,\n",
      "        2.0686, 1.2733, 1.3047, 2.3386, 2.1789, 1.5729, 2.9321, 1.4503, 0.7838,\n",
      "        2.1380, 2.5611, 2.1747, 2.9327, 1.5346, 2.0081, 3.1817, 1.4108, 2.6398,\n",
      "        2.3621, 2.4482, 2.0356, 1.4234, 4.0228, 3.2651, 2.4484, 2.7088, 1.3019,\n",
      "        2.3131, 4.4103, 2.2291, 1.6919, 4.8255, 2.1432, 2.0713, 2.2528, 2.4267,\n",
      "        1.9783, 2.6441, 2.3157, 2.9891, 0.8599, 0.5134, 3.4514, 3.1319, 1.8975,\n",
      "        1.3496, 1.6977, 0.6854, 2.5755, 4.4363, 2.7299, 1.8261, 1.8031, 0.6173,\n",
      "        1.5916, 3.4630, 2.2783, 3.4837, 1.5092, 3.6016, 2.0254, 2.4042, 1.5901,\n",
      "        0.9798, 1.4110, 1.4984, 1.7478, 1.8956, 1.4383, 1.5604, 1.8537, 1.3998,\n",
      "        2.0110, 0.9570, 1.7612, 1.6253, 2.2220, 2.0595, 1.9580, 2.3027, 4.8373,\n",
      "        1.8110, 2.9105, 1.1256, 1.4557], device='cuda:0')), ('backbone.model.layer3.4.bn1.bias', tensor([ 2.2361e-01, -4.6058e-01, -2.6824e+00, -2.4042e+00, -1.8751e+00,\n",
      "        -1.2681e+00, -8.7691e-01, -1.0552e+00, -1.6648e+00, -2.0111e+00,\n",
      "        -1.7020e+00, -4.6706e-01, -2.5226e+00, -7.6697e-01, -5.9487e-01,\n",
      "        -1.4510e+00, -2.9641e+00, -1.4937e+00, -2.1500e+00,  1.3701e-01,\n",
      "        -3.3780e-01, -1.8673e+00, -1.1482e+00, -2.9064e+00, -5.0935e-01,\n",
      "        -2.3244e-01, -1.6323e+00, -8.7306e-02, -1.7315e+00, -1.3410e-01,\n",
      "        -1.0151e+00, -3.0012e+00, -2.5833e+00, -1.0621e+00, -9.0457e-01,\n",
      "        -2.1042e+00, -1.3664e+00, -2.8663e+00, -3.2947e-01, -8.6316e-01,\n",
      "        -2.3305e+00, -7.5817e-01, -1.0946e+00, -2.5593e+00, -1.0819e+00,\n",
      "        -1.0561e+00, -1.1033e+00, -3.3896e-01, -1.0084e-01,  7.4042e-01,\n",
      "        -7.7511e-02, -1.0469e+00, -1.1859e+00, -1.4533e+00, -2.4127e+00,\n",
      "        -1.2087e+00, -1.4010e+00, -1.8598e-01, -1.1328e-01, -3.7885e+00,\n",
      "        -4.4579e-01, -7.9415e-01,  5.3732e-02, -1.3550e+00, -2.0279e+00,\n",
      "        -1.4162e+00, -1.5829e+00, -1.2672e+00, -1.5707e+00, -2.1050e+00,\n",
      "         4.4760e-01, -8.1413e-01, -2.1103e+00,  7.0843e-01, -1.5332e+00,\n",
      "        -7.5547e-01, -2.4887e+00, -2.6343e+00, -7.1872e-01, -6.5421e-01,\n",
      "        -6.0591e-01, -1.9484e+00, -5.7475e-01, -1.9577e+00, -9.1715e-01,\n",
      "        -1.8235e+00, -1.2163e+00, -8.2261e-01, -1.3578e+00, -1.3154e+00,\n",
      "        -1.7110e+00, -1.7216e+00, -1.8547e+00, -1.0424e+00, -1.6252e+00,\n",
      "        -1.8544e+00, -1.2316e+00, -1.7791e+00, -3.3839e-01, -1.4712e+00,\n",
      "        -1.0906e+00, -1.9979e+00, -2.2611e+00, -1.0293e+00, -2.2198e+00,\n",
      "        -4.5631e-01, -2.6765e+00, -4.5535e+00, -3.5602e+00, -9.3913e-01,\n",
      "        -1.1238e+00, -2.5213e+00, -1.9452e+00, -2.0555e+00, -5.0498e-02,\n",
      "        -9.3776e-01, -1.4841e+00,  5.8358e-01, -1.7793e+00, -7.4832e-01,\n",
      "        -8.7303e-01, -9.2144e-01, -5.4390e-01, -2.9743e-01, -4.1117e+00,\n",
      "        -1.1043e+00, -1.5423e+00, -1.8544e+00, -1.8407e+00, -2.4634e+00,\n",
      "        -8.3598e-02, -1.2864e+00, -1.9898e+00, -1.3730e+00, -4.1070e+00,\n",
      "        -1.7401e+00,  3.1828e-01, -1.7661e+00, -8.8020e-01, -1.9326e+00,\n",
      "        -1.0160e+00, -6.4942e-01,  1.1963e-01, -9.5541e-01, -8.7678e-01,\n",
      "        -1.2093e+00, -1.9996e+00,  4.7022e-01, -1.0080e+00, -1.8550e+00,\n",
      "        -1.1948e+00, -1.6949e+00, -2.0962e+00, -1.3768e-01, -1.8325e+00,\n",
      "        -1.1180e+00, -3.0254e-01,  8.3341e-01, -1.9903e+00, -1.2238e+00,\n",
      "        -2.1529e-01, -3.0708e-01, -7.3461e-01, -1.2328e+00, -8.3309e-01,\n",
      "        -2.7623e+00, -1.1257e-01, -1.8736e+00, -2.7357e+00, -5.4090e-01,\n",
      "        -1.4034e+00, -1.4390e+00, -2.1604e-01, -9.6673e-01, -2.1324e+00,\n",
      "        -2.7892e+00, -8.4611e-01, -3.4260e+00,  8.7944e-01,  2.6984e-02,\n",
      "        -2.1774e+00, -2.9790e+00, -1.3923e+00, -2.9432e+00, -1.7203e+00,\n",
      "        -1.3678e-01, -2.0907e+00, -2.8682e+00, -7.8128e-01, -2.2239e+00,\n",
      "        -1.4172e+00,  1.0452e-01, -1.4970e+00, -2.8421e+00,  1.1715e-01,\n",
      "        -1.1027e+00, -1.7161e+00, -1.7448e+00, -1.7506e+00, -1.7790e+00,\n",
      "         9.0025e-01, -1.5187e-01, -2.2429e+00, -1.2350e+00, -2.5084e+00,\n",
      "        -2.1854e+00,  5.9658e-03, -2.3713e+00, -7.5699e-01, -6.1564e-01,\n",
      "        -1.0064e+00, -2.4404e-01, -4.1012e-01, -4.4675e+00, -1.7143e+00,\n",
      "        -4.4617e-01, -1.3628e+00, -3.5797e-01,  6.6170e-01, -4.4024e+00,\n",
      "        -2.9766e+00, -2.6048e+00, -1.4960e+00, -9.4736e-01, -5.3321e-01,\n",
      "         1.9630e-03, -4.5596e+00, -6.8299e-01, -1.0456e+00, -4.5833e-01,\n",
      "        -1.6728e+00, -6.4019e-01, -2.6178e+00, -2.0655e-01,  2.4236e-02,\n",
      "        -8.9706e-01, -7.5929e-01, -3.0596e+00, -1.2371e+00, -8.5828e-01,\n",
      "        -1.8885e+00, -1.4650e+00,  4.6326e-01, -1.0624e+00,  1.6064e-01,\n",
      "        -6.6607e-01, -3.4341e-01, -1.6811e+00, -2.4426e+00, -8.5105e-01,\n",
      "        -1.9691e+00, -3.0985e+00,  7.7847e-02, -2.6881e+00, -1.9581e-01,\n",
      "        -1.7749e+00], device='cuda:0')), ('backbone.model.layer3.4.conv2.weight', tensor([[[[ 1.8140e-02, -2.6086e-03,  6.6929e-02],\n",
      "          [ 2.8736e-02, -6.0018e-02,  6.2548e-02],\n",
      "          [ 5.5545e-02,  5.9051e-02,  7.6355e-02]],\n",
      "\n",
      "         [[ 2.6958e-02,  7.1472e-03, -2.3798e-03],\n",
      "          [ 3.1295e-02, -4.1986e-02, -5.0167e-03],\n",
      "          [-4.5553e-03, -1.1798e-02, -8.4402e-04]],\n",
      "\n",
      "         [[-2.0592e-02,  2.8173e-02,  1.7024e-02],\n",
      "          [ 2.2506e-02,  1.2637e-01, -6.9830e-04],\n",
      "          [ 3.1603e-02, -1.3422e-02, -7.0186e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.2971e-03, -1.4774e-02,  7.4050e-03],\n",
      "          [ 1.7234e-02, -5.8618e-02, -2.5721e-03],\n",
      "          [-1.3136e-02, -1.7336e-02, -8.7691e-03]],\n",
      "\n",
      "         [[-7.3823e-03,  8.4137e-02,  1.0698e-02],\n",
      "          [ 2.2604e-02,  1.3317e-01,  3.2720e-02],\n",
      "          [-1.6691e-02,  3.6824e-02, -1.3394e-02]],\n",
      "\n",
      "         [[ 2.3134e-02,  2.5383e-02, -2.4284e-02],\n",
      "          [ 2.7154e-02,  2.4281e-02,  1.4011e-02],\n",
      "          [ 5.8671e-02,  8.4261e-02,  5.6262e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8811e-02, -1.8866e-02,  4.9950e-03],\n",
      "          [-2.4695e-02, -9.1323e-02, -1.5253e-02],\n",
      "          [ 5.4611e-03, -2.6243e-02,  1.4090e-02]],\n",
      "\n",
      "         [[ 4.3014e-03,  1.1311e-02, -4.1108e-03],\n",
      "          [-3.9374e-02, -1.8267e-02, -2.2069e-02],\n",
      "          [-3.1973e-02, -3.3089e-02, -2.2971e-02]],\n",
      "\n",
      "         [[-5.2621e-02, -1.2648e-01, -1.3176e-01],\n",
      "          [-1.1325e-01, -2.9524e-02, -9.2501e-02],\n",
      "          [-1.2166e-01, -7.4600e-02, -6.1615e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5124e-01,  1.0636e-01,  1.0248e-01],\n",
      "          [ 9.7364e-02,  5.9213e-02,  1.3638e-01],\n",
      "          [ 1.0223e-01,  7.9154e-02,  1.3023e-01]],\n",
      "\n",
      "         [[-3.5635e-02,  7.2200e-02,  2.4543e-03],\n",
      "          [-2.8691e-02,  3.7437e-02,  2.5827e-02],\n",
      "          [-7.3487e-02, -1.2518e-01, -8.0598e-02]],\n",
      "\n",
      "         [[-1.4779e-02,  2.4710e-03,  5.8145e-02],\n",
      "          [-3.2347e-02, -4.2256e-02,  2.3597e-03],\n",
      "          [-1.8044e-02,  9.0669e-03,  1.6541e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9954e-02, -4.1353e-02, -4.7041e-02],\n",
      "          [-1.6542e-04,  1.0306e-02, -4.7985e-02],\n",
      "          [-5.1466e-02, -5.2893e-02, -3.2822e-02]],\n",
      "\n",
      "         [[-1.8844e-02,  7.0999e-02, -1.6633e-02],\n",
      "          [ 6.6434e-02,  8.8203e-02,  3.7508e-02],\n",
      "          [-1.2501e-02,  4.4026e-02, -9.2774e-03]],\n",
      "\n",
      "         [[ 1.0916e-02,  7.9476e-02,  7.4798e-02],\n",
      "          [ 1.1541e-01,  1.7052e-01,  1.2300e-01],\n",
      "          [ 9.1711e-02,  9.6325e-02,  1.0526e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9177e-02, -1.5282e-02, -3.2761e-02],\n",
      "          [-3.9921e-02, -5.1642e-02, -7.2191e-03],\n",
      "          [-3.9609e-02, -2.2482e-02,  7.7511e-04]],\n",
      "\n",
      "         [[-5.1433e-02,  4.2668e-03, -1.1063e-02],\n",
      "          [ 3.0865e-02,  1.9307e-02,  4.3768e-02],\n",
      "          [ 1.1100e-01,  1.1147e-01,  6.8598e-02]],\n",
      "\n",
      "         [[ 4.8214e-02,  2.8349e-02,  2.8280e-02],\n",
      "          [ 1.0520e-03, -1.7737e-02,  3.7326e-02],\n",
      "          [-1.9914e-02, -1.5938e-02, -1.0017e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.9145e-02,  1.4109e-03, -3.3609e-02],\n",
      "          [-2.1361e-02,  6.8451e-02,  3.2799e-03],\n",
      "          [-3.3754e-02, -1.6053e-02, -5.8114e-02]],\n",
      "\n",
      "         [[-3.1362e-02,  6.6829e-03,  7.5565e-03],\n",
      "          [ 1.1497e-02, -2.8175e-02,  2.1480e-02],\n",
      "          [-1.9236e-02,  4.1040e-02,  1.9722e-02]],\n",
      "\n",
      "         [[ 5.0385e-02,  1.4112e-02, -7.0977e-03],\n",
      "          [ 2.1889e-02, -2.7482e-02, -3.5083e-02],\n",
      "          [ 6.5584e-02,  2.0226e-02,  2.4599e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8683e-02, -1.1277e-02, -7.5367e-02],\n",
      "          [-1.3404e-02,  8.2810e-02, -1.6131e-02],\n",
      "          [-2.3790e-02, -3.5086e-02,  1.7072e-02]],\n",
      "\n",
      "         [[ 9.1211e-02,  1.0177e-01,  1.0837e-01],\n",
      "          [ 6.8752e-02,  5.1684e-02,  4.3344e-02],\n",
      "          [ 1.4962e-02, -2.4700e-02,  6.0771e-04]],\n",
      "\n",
      "         [[-6.3720e-02,  4.8304e-02, -4.7461e-03],\n",
      "          [ 1.2779e-02,  1.3370e-01,  4.4559e-02],\n",
      "          [ 5.6954e-02,  1.1786e-01,  1.0025e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0918e-02,  6.9099e-02,  8.1389e-02],\n",
      "          [ 5.0196e-02,  3.1642e-02,  9.4789e-02],\n",
      "          [ 7.1946e-02,  1.0068e-01,  8.5690e-02]],\n",
      "\n",
      "         [[ 2.6799e-02,  2.2325e-02,  2.5380e-02],\n",
      "          [ 5.9743e-02,  7.8886e-02,  7.6196e-02],\n",
      "          [ 4.5154e-02,  8.5179e-02,  2.9177e-02]],\n",
      "\n",
      "         [[ 8.3024e-02,  9.1377e-02,  7.6623e-02],\n",
      "          [ 2.3921e-02, -3.1292e-02,  1.0035e-03],\n",
      "          [ 1.2961e-02, -2.7635e-02, -2.9030e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0119e-02,  7.1703e-02,  5.8624e-02],\n",
      "          [ 6.0473e-02,  1.0788e-01,  5.5130e-02],\n",
      "          [ 3.8647e-02,  3.7009e-02,  2.1933e-03]],\n",
      "\n",
      "         [[ 8.7974e-02,  1.0982e-01,  1.0474e-01],\n",
      "          [-2.4784e-02,  1.1921e-02,  8.4665e-03],\n",
      "          [-9.9177e-02, -1.2162e-01, -1.0429e-01]],\n",
      "\n",
      "         [[-1.6711e-03,  2.6631e-02, -2.4397e-02],\n",
      "          [ 1.8112e-02,  8.7959e-02,  3.2298e-02],\n",
      "          [ 5.7830e-02,  2.6568e-02,  3.8244e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5823e-03, -2.9764e-02, -4.7938e-02],\n",
      "          [-1.0072e-02, -7.2116e-02, -3.0204e-02],\n",
      "          [-7.5273e-02, -9.7038e-02, -2.2118e-02]],\n",
      "\n",
      "         [[-1.8962e-02,  2.1812e-02,  5.5825e-02],\n",
      "          [-5.8356e-03, -1.1711e-01,  2.4683e-02],\n",
      "          [ 4.6609e-02,  3.5208e-02,  2.4785e-02]],\n",
      "\n",
      "         [[-4.2896e-02, -3.2712e-02, -2.0775e-02],\n",
      "          [-3.2385e-03, -2.9722e-03, -3.8690e-03],\n",
      "          [-2.5180e-02,  3.3076e-02, -2.3967e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9441e-02, -4.5364e-02, -6.7747e-02],\n",
      "          [-7.5667e-02, -2.0519e-02, -7.1823e-02],\n",
      "          [-2.5942e-02, -2.9972e-02, -4.9426e-02]],\n",
      "\n",
      "         [[ 2.6062e-02,  7.3205e-02,  3.0382e-02],\n",
      "          [-1.5172e-02,  3.8145e-02,  2.3917e-02],\n",
      "          [-2.9080e-02, -8.8450e-02, -5.5209e-02]],\n",
      "\n",
      "         [[ 3.1703e-02, -8.4651e-02,  1.1714e-03],\n",
      "          [-8.1188e-03, -1.3053e-01,  2.0090e-02],\n",
      "          [ 2.3417e-02, -1.4205e-02,  3.3489e-02]]]], device='cuda:0')), ('backbone.model.layer3.4.bn2.weight', tensor([1.9290, 2.4255, 2.5252, 0.8865, 1.9299, 2.3757, 2.5152, 2.0861, 1.9553,\n",
      "        4.1051, 1.1203, 1.6310, 2.6746, 3.7818, 3.4806, 3.0890, 3.0537, 2.2651,\n",
      "        2.5755, 2.4762, 2.4925, 2.3508, 2.7319, 0.7892, 2.3404, 3.0376, 2.9579,\n",
      "        2.6918, 2.1613, 3.2484, 0.5870, 2.5505, 2.1361, 1.7258, 1.9454, 2.2069,\n",
      "        2.0240, 1.1737, 1.7833, 2.5166, 6.8966, 3.0495, 2.4641, 2.3275, 2.3831,\n",
      "        3.3775, 3.2870, 0.1087, 2.0761, 2.3513, 2.3371, 2.2121, 2.1056, 2.5797,\n",
      "        2.0454, 2.1422, 1.7339, 3.7512, 3.4558, 3.1127, 3.4774, 2.6602, 2.6446,\n",
      "        2.7174, 2.1924, 3.1256, 4.2610, 2.4023, 3.3221, 2.4156, 0.6995, 2.6778,\n",
      "        4.5860, 2.4556, 2.9951, 1.7149, 4.8925, 1.3954, 2.1221, 1.8355, 0.0880,\n",
      "        2.7868, 3.8271, 2.3304, 3.3918, 3.1071, 2.2688, 2.6871, 1.5723, 2.6178,\n",
      "        2.8730, 0.5923, 2.9653, 3.8934, 1.9961, 3.2751, 1.5751, 1.2487, 1.9714,\n",
      "        2.1913, 2.3058, 1.7468, 1.6014, 1.7885, 1.3847, 2.1941, 2.7449, 2.1484,\n",
      "        2.4054, 2.4391, 2.5487, 2.9612, 1.7720, 2.2719, 2.6942, 1.1956, 2.3910,\n",
      "        1.9490, 2.5320, 1.8875, 3.3474, 2.7268, 2.9485, 3.5251, 3.2196, 2.3550,\n",
      "        3.5090, 0.8551, 3.3857, 2.9552, 2.4704, 2.6955, 3.4489, 3.3440, 0.8285,\n",
      "        2.8681, 2.7577, 3.0562, 2.4479, 3.2497, 2.9586, 2.1036, 0.1329, 3.1004,\n",
      "        1.5588, 1.7759, 1.7151, 2.2890, 2.1174, 2.0902, 1.5680, 1.6566, 2.1091,\n",
      "        2.4494, 0.6306, 2.2976, 2.2932, 1.9891, 2.3533, 1.8465, 2.7912, 2.0073,\n",
      "        2.4601, 2.4576, 2.4487, 0.6193, 4.0501, 2.2433, 3.8947, 3.9711, 2.6132,\n",
      "        0.6959, 2.7668, 2.6888, 2.3749, 2.6862, 0.6248, 3.1749, 2.9733, 1.7809,\n",
      "        2.0531, 2.4193, 2.4428, 2.0037, 4.4606, 0.6287, 2.9893, 2.6910, 2.1164,\n",
      "        3.3002, 2.0468, 2.3962, 2.4968, 3.5663, 3.8215, 0.7546, 3.9234, 2.2336,\n",
      "        2.3234, 2.1119, 0.8242, 1.8214, 2.1910, 1.7195, 0.8259, 2.7337, 1.7051,\n",
      "        1.7858, 2.3198, 2.3169, 2.5771, 2.5112, 1.9956, 1.9412, 2.8340, 0.9196,\n",
      "        2.6229, 3.1240, 1.5082, 3.7519, 2.2913, 3.3674, 2.4901, 2.6815, 2.4211,\n",
      "        2.9299, 3.4285, 2.5771, 2.8118, 4.1705, 2.2008, 1.0541, 2.8602, 0.5227,\n",
      "        2.9913, 3.6602, 2.3902, 4.2844, 2.6789, 2.5994, 1.7902, 2.0175, 1.6550,\n",
      "        1.7564, 2.2612, 1.9094, 1.7470, 1.8108, 2.6239, 3.5324, 3.8796, 2.0647,\n",
      "        2.1338, 1.2718, 2.9272, 5.2911], device='cuda:0')), ('backbone.model.layer3.4.bn2.bias', tensor([-1.1955e+00,  6.3973e-01, -1.3037e+00, -3.4076e+00,  2.2941e-01,\n",
      "         3.0766e-02, -3.6681e-04,  8.4713e-01, -1.4215e+00, -2.0285e+00,\n",
      "         8.3753e-01, -1.7212e+00,  3.3877e-01, -1.2257e-01, -1.3774e+00,\n",
      "        -1.3490e+00, -2.5885e+00, -4.1985e-02,  5.4244e-01,  5.3622e-02,\n",
      "         6.1403e-01, -1.6528e+00,  1.7452e-01, -3.4579e+00,  1.0263e-01,\n",
      "        -2.2546e+00,  6.0808e-01,  2.4394e-01,  8.1183e-01,  5.7884e-01,\n",
      "        -1.5534e+00, -1.0607e+00, -9.1018e-01, -6.4525e-01, -2.7474e+00,\n",
      "        -4.9070e-01,  7.6437e-03,  7.2263e-01, -1.4541e-02, -2.3515e+00,\n",
      "        -5.3183e+00, -1.1967e-01,  8.4578e-01,  6.0127e-01,  1.1511e+00,\n",
      "        -3.0282e-01, -3.0477e-01, -1.9239e+00, -9.0128e-01,  6.5976e-01,\n",
      "        -4.9639e-01, -9.0740e-01, -6.3639e-01, -1.5681e-01, -1.1309e+00,\n",
      "         4.4899e-01, -4.1025e-01, -2.8241e-01, -1.2877e+00, -1.4863e+00,\n",
      "        -2.8485e-01,  1.7526e-01, -2.8499e+00,  3.7728e-02,  7.3946e-01,\n",
      "        -1.2683e+00, -1.0289e+00, -2.7257e-01, -2.4180e+00,  4.4257e-01,\n",
      "        -2.5064e+00, -6.9685e-01, -8.5306e-01,  6.4934e-01,  7.9965e-01,\n",
      "        -6.2696e-01, -2.6494e+00, -2.3892e+00, -9.3735e-01, -5.9820e-01,\n",
      "        -2.2903e+00, -1.5885e+00,  2.1729e-01, -8.4068e-01, -2.4901e+00,\n",
      "         9.4570e-01,  1.4371e+00,  4.2790e-01,  1.0903e+00,  4.4365e-01,\n",
      "        -7.0604e-01, -1.6628e+00, -2.5014e+00, -1.8074e+00,  4.6492e-01,\n",
      "         3.9399e-01, -1.9353e-02, -4.2532e+00, -1.7325e+00,  8.0509e-01,\n",
      "        -4.7113e-01,  1.1786e-01,  3.0690e-01,  4.0461e-01, -1.5335e-01,\n",
      "         1.5426e-01,  1.0358e-01, -2.7037e+00, -5.0353e-01,  1.4703e-01,\n",
      "        -8.3110e-01, -7.5133e-01,  6.8041e-01,  1.4968e-01, -4.6977e-01,\n",
      "        -1.3784e+00,  7.2129e-02,  8.1630e-02, -1.7297e-01, -7.0310e-01,\n",
      "        -1.5538e+00,  8.0178e-01,  4.9972e-01,  4.4901e-01, -1.2734e+00,\n",
      "         1.1829e+00,  7.7164e-01, -1.2089e+00,  2.2305e-01, -1.6507e+00,\n",
      "         1.7434e-01,  3.0537e-01, -3.4401e+00, -1.4057e+00,  5.6580e-01,\n",
      "        -2.5385e-02, -1.6409e+00,  5.6369e-01, -4.2325e-01,  6.5271e-01,\n",
      "        -1.7023e+00,  8.0605e-01, -2.5662e+00, -1.8117e+00, -5.8010e-01,\n",
      "        -5.3247e-01,  1.8369e-01,  5.3969e-01, -1.1742e+00, -1.6574e-01,\n",
      "        -3.1033e-02, -8.3403e-01,  1.0960e+00,  4.2159e-01, -1.9127e+00,\n",
      "        -1.9340e+00, -6.0610e-01,  2.9684e-01,  5.4347e-01,  3.1736e-01,\n",
      "        -1.8422e+00,  3.8241e-01, -1.4477e+00,  5.2591e-01,  3.5263e-02,\n",
      "        -1.9550e+00,  5.4599e-01,  4.9164e-01, -2.5100e-01,  2.4994e-01,\n",
      "        -1.1611e+00, -1.0899e+00,  8.0953e-01, -5.1110e-01, -6.9468e-01,\n",
      "         2.6172e-01, -1.8109e+00, -1.1795e+00, -1.5197e+00,  1.2306e+00,\n",
      "        -9.0728e-02, -1.8065e+00,  9.0069e-01,  5.1133e-01, -8.9310e-01,\n",
      "        -2.4714e+00,  7.8763e-01,  1.3808e+00, -9.0965e-01, -1.9256e+00,\n",
      "         6.8808e-01, -6.1421e-01, -1.0327e+00, -3.1657e+00, -9.0986e-01,\n",
      "        -2.9769e+00,  1.0624e+00,  1.7892e-01,  9.6649e-01,  2.3145e-01,\n",
      "         3.8304e-01,  9.4275e-02, -7.2399e-01,  6.9849e-01, -3.2713e+00,\n",
      "        -1.8229e+00,  1.1741e+00,  9.1032e-01, -1.7291e+00,  2.7987e-01,\n",
      "         1.1834e+00, -1.1344e-01,  3.6593e-01,  1.9172e-01,  5.2725e-02,\n",
      "        -3.9177e+00,  1.9198e-01, -2.8869e-01, -2.3317e+00, -1.4453e+00,\n",
      "         1.6185e-01, -9.2478e-01,  8.7348e-01,  6.6765e-01, -2.6453e-01,\n",
      "         1.9214e-01, -7.3259e-01,  2.0441e-01,  3.0331e-01,  3.0444e-01,\n",
      "        -1.4018e-01, -2.4385e+00, -1.5899e+00, -3.0488e-01,  7.7978e-02,\n",
      "         3.2551e-01,  3.7460e-01, -4.2562e+00,  3.2517e-01,  1.6387e-01,\n",
      "        -1.4512e+00, -4.6640e-01, -3.7860e-01, -7.7987e-02,  2.6581e-01,\n",
      "        -8.2066e-01,  1.0645e-01,  4.1374e-02,  7.3963e-03,  5.7340e-01,\n",
      "        -1.3235e+00,  7.7334e-01, -8.5641e-01, -2.8370e+00, -2.6535e-01,\n",
      "        -8.7873e-01], device='cuda:0')), ('backbone.model.layer3.4.conv3.weight', tensor([[[[-0.0623]],\n",
      "\n",
      "         [[ 0.0902]],\n",
      "\n",
      "         [[-0.0533]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1081]],\n",
      "\n",
      "         [[ 0.0874]],\n",
      "\n",
      "         [[ 0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.0680]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[ 0.1057]],\n",
      "\n",
      "         [[-0.0134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0283]],\n",
      "\n",
      "         [[ 0.0917]],\n",
      "\n",
      "         [[ 0.0053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1976]],\n",
      "\n",
      "         [[ 0.1372]],\n",
      "\n",
      "         [[-0.0512]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1032]],\n",
      "\n",
      "         [[ 0.2105]],\n",
      "\n",
      "         [[ 0.0602]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0236]],\n",
      "\n",
      "         [[ 0.1348]],\n",
      "\n",
      "         [[-0.0273]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0308]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.1571]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0976]],\n",
      "\n",
      "         [[-0.0335]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0226]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0575]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.0873]]]], device='cuda:0')), ('backbone.model.layer3.4.bn3.weight', tensor([ 0.2602, -5.0849,  0.0143,  ..., -0.4597,  1.0728,  1.1504],\n",
      "       device='cuda:0')), ('backbone.model.layer3.4.bn3.bias', tensor([ 0.0742,  1.7853,  0.0035,  ..., -0.0539, -0.4612, -0.2921],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.conv1.weight', tensor([[[[-0.0050]],\n",
      "\n",
      "         [[-0.0752]],\n",
      "\n",
      "         [[ 0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[ 0.0554]]],\n",
      "\n",
      "\n",
      "        [[[-0.0449]],\n",
      "\n",
      "         [[ 0.0942]],\n",
      "\n",
      "         [[-0.0138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0554]],\n",
      "\n",
      "         [[-0.0189]],\n",
      "\n",
      "         [[-0.0583]]],\n",
      "\n",
      "\n",
      "        [[[-0.0974]],\n",
      "\n",
      "         [[ 0.1456]],\n",
      "\n",
      "         [[ 0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0288]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         [[ 0.0783]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0233]],\n",
      "\n",
      "         [[ 0.0208]],\n",
      "\n",
      "         [[-0.1489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         [[-0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444]],\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         [[-0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0824]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         [[ 0.0387]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0007]],\n",
      "\n",
      "         [[-0.0665]],\n",
      "\n",
      "         [[-0.0839]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1080]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[ 0.0531]]]], device='cuda:0')), ('backbone.model.layer3.5.bn1.weight', tensor([1.4852, 3.2729, 3.1057, 2.0673, 0.5763, 2.4739, 2.4893, 1.4658, 3.1462,\n",
      "        1.6880, 1.5507, 1.6862, 1.3080, 2.4553, 0.6846, 1.8578, 1.2479, 1.1687,\n",
      "        2.0758, 2.2189, 2.2338, 1.9127, 1.9356, 1.4173, 1.7582, 4.9320, 3.5042,\n",
      "        1.8160, 3.7318, 2.7672, 1.0707, 4.1777, 2.3917, 1.7488, 3.0752, 2.8819,\n",
      "        1.4444, 2.3230, 2.7860, 2.2147, 2.0825, 2.5044, 1.2726, 1.7923, 2.7466,\n",
      "        4.7087, 1.4169, 4.1317, 3.2424, 3.4752, 1.3938, 1.6169, 3.5631, 3.5693,\n",
      "        1.7766, 4.9925, 2.1264, 1.1651, 1.5308, 1.9155, 2.7575, 2.6886, 4.1637,\n",
      "        1.6208, 1.5765, 4.7049, 2.2442, 2.3855, 2.2063, 3.3629, 3.2180, 2.6590,\n",
      "        3.1060, 1.8445, 2.1367, 4.7130, 2.3400, 3.3061, 3.3906, 1.6378, 1.4307,\n",
      "        2.2192, 2.1112, 0.6146, 3.6153, 1.9711, 4.0864, 1.8594, 0.8910, 0.8875,\n",
      "        2.4554, 3.4581, 2.5861, 1.3246, 3.0670, 1.6468, 0.9281, 1.8438, 1.6273,\n",
      "        2.2884, 1.7332, 0.8801, 1.9482, 3.3921, 2.5850, 2.1514, 1.5718, 1.8127,\n",
      "        4.2581, 3.1335, 2.8837, 0.8873, 2.0166, 2.4763, 1.3620, 2.3134, 0.7275,\n",
      "        2.1851, 1.5166, 1.3425, 3.0358, 1.4815, 3.1026, 1.6465, 5.2060, 2.0161,\n",
      "        3.8185, 2.6601, 1.5144, 1.7694, 2.0594, 2.9870, 2.7636, 5.1804, 2.0347,\n",
      "        1.8708, 1.0707, 2.9827, 2.4023, 1.8565, 7.2270, 3.5273, 2.2581, 5.1927,\n",
      "        2.5270, 1.1333, 3.4341, 2.0126, 2.7409, 2.0246, 1.9832, 2.2076, 1.6627,\n",
      "        2.7495, 1.4019, 1.0664, 3.8186, 1.9650, 1.3981, 1.9548, 1.6031, 1.4304,\n",
      "        3.2129, 4.4563, 1.8792, 1.4943, 2.2476, 2.3710, 3.5282, 1.1253, 2.8602,\n",
      "        1.9554, 4.3865, 2.9684, 2.1124, 2.2242, 1.4172, 2.8978, 2.6657, 1.6584,\n",
      "        2.7679, 2.4428, 1.1472, 2.7886, 2.0316, 2.3835, 3.8681, 1.7310, 1.4127,\n",
      "        1.9266, 1.5777, 4.0280, 5.1983, 1.7159, 2.2629, 0.4568, 3.0747, 2.3366,\n",
      "        3.3699, 2.2933, 1.2367, 1.5433, 1.8904, 1.8471, 2.5921, 0.8374, 1.4323,\n",
      "        1.7395, 4.0891, 1.8250, 3.4978, 1.6632, 2.3644, 1.8024, 2.2218, 5.7029,\n",
      "        3.1383, 5.6155, 1.7813, 3.1792, 1.0622, 6.0300, 1.4698, 2.1041, 0.8673,\n",
      "        1.6361, 1.9967, 1.7760, 1.9182, 1.9811, 2.2388, 1.1072, 2.6161, 0.8813,\n",
      "        1.9870, 1.9682, 5.2035, 3.1700, 1.8749, 1.5456, 2.5078, 4.2062, 2.1083,\n",
      "        1.9336, 3.2969, 3.0115, 1.5607, 2.3117, 1.9631, 1.9631, 1.9776, 1.1555,\n",
      "        2.1286, 2.3548, 1.6868, 0.6115], device='cuda:0')), ('backbone.model.layer3.5.bn1.bias', tensor([-1.3011, -0.4200, -1.7635, -2.7558, -0.0386, -0.7511, -1.1376, -0.0079,\n",
      "        -4.9134, -0.6461,  0.1099, -0.9773, -0.2172, -0.2028, -0.0964, -0.7478,\n",
      "        -0.0266, -1.0643, -0.2969, -0.0819, -0.7602, -0.6540, -2.2234, -2.2738,\n",
      "        -1.2207, -1.3956, -1.1124, -1.0210, -1.7614, -1.1829, -2.5973, -0.8573,\n",
      "        -0.7110,  0.4253, -0.8747, -0.9150, -3.4887, -0.6927, -1.0752,  0.0682,\n",
      "        -1.8815, -1.2622, -0.7859, -0.0974, -2.4963, -4.1108, -1.4570, -1.8094,\n",
      "        -1.0895, -0.6166, -3.0493, -0.8116, -0.2453, -1.4946, -0.4241, -1.6790,\n",
      "        -0.4582, -1.5803, -0.4813, -1.0263, -1.7170, -1.5509, -0.1079, -1.0063,\n",
      "        -2.2815, -0.8797, -2.4329, -1.5968,  1.3513, -1.1854, -0.5786, -1.6700,\n",
      "        -1.4094, -7.3654, -0.5131, -2.0949, -0.9268, -1.0390, -1.6291, -0.0231,\n",
      "        -1.8025, -0.4152, -2.2173,  0.6338, -1.0412, -1.0602, -0.0989, -2.6227,\n",
      "         0.7320, -0.3800, -1.8882, -2.3759, -1.7956,  0.1959, -1.7078, -1.3450,\n",
      "        -0.2012, -0.8362,  0.1634, -1.2316, -1.9372, -2.0719, -0.9756, -1.5415,\n",
      "        -0.8276, -0.1411,  0.4428,  0.7902, -0.1715, -3.0367, -1.1475, -1.4936,\n",
      "        -0.5255, -1.1886, -0.6822, -1.7831, -0.3783, -2.3747,  0.5676,  1.2604,\n",
      "        -1.0312, -3.7591, -1.7766, -1.0339, -2.5566,  0.0553, -1.1926, -0.5420,\n",
      "         1.7146, -2.3438, -0.8320, -1.8776, -1.1313, -1.9702, -0.5734, -1.5204,\n",
      "        -2.1112, -3.6120, -1.8749, -0.1960, -3.0090, -0.7552, -1.3546, -2.6739,\n",
      "        -1.2191, -1.9526, -2.3310,  0.3074, -2.0417, -0.6787, -0.6221, -1.5687,\n",
      "         0.0313, -1.4623,  0.5506, -2.5682, -1.7528, -1.0403,  0.2314,  0.0711,\n",
      "        -1.9606, -1.0876, -0.3547, -1.7235, -0.1592, -1.3793, -1.0379, -1.6690,\n",
      "        -0.7828, -2.5104, -0.7588, -0.3562, -1.3058, -0.4313, -0.4636, -3.0468,\n",
      "        -2.2424, -4.5501, -3.0423, -0.7692, -2.9243, -3.7350, -0.1591, -3.6920,\n",
      "        -0.5812, -1.6842, -0.0248, -0.1319, -1.7735, -2.1610, -1.8762,  0.2511,\n",
      "        -2.5514, -1.4371, -2.3948,  0.8969, -1.8835, -1.9166, -2.8857, -2.4437,\n",
      "        -0.5069, -0.5561, -1.4166, -1.9953, -1.3496, -3.4709, -1.0109, -0.1024,\n",
      "        -2.0271, -2.8026, -2.6857, -0.2108,  0.4512, -2.3966, -1.6891, -1.6206,\n",
      "        -2.7224, -3.5393, -0.9481, -1.4672, -2.5998, -3.7795, -0.6627, -1.1810,\n",
      "        -2.8528, -0.4377, -2.3358, -0.2613, -0.6080, -1.1598, -0.8126, -0.7563,\n",
      "        -1.4620, -1.5391, -0.2947, -1.6043, -1.8136, -1.6179, -1.5761, -0.4663,\n",
      "        -0.0732, -1.8601,  0.4953, -0.4401, -1.0396, -1.5020, -4.6421, -0.4417,\n",
      "        -0.3447, -1.1976, -1.6017, -1.0919, -1.3272, -1.4845, -0.3436, -1.4302],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.conv2.weight', tensor([[[[-3.0126e-02, -6.5069e-02, -8.0060e-02],\n",
      "          [-3.1927e-02,  2.2007e-03, -3.3761e-02],\n",
      "          [-1.0773e-02, -1.9440e-02, -1.0206e-03]],\n",
      "\n",
      "         [[-1.6157e-01, -1.8362e-01, -1.4388e-01],\n",
      "          [-1.1685e-01, -8.8171e-02, -7.8696e-02],\n",
      "          [ 7.1360e-03,  1.6532e-02, -5.5012e-02]],\n",
      "\n",
      "         [[-8.8899e-03,  5.2452e-02,  2.0718e-02],\n",
      "          [-3.4356e-02, -3.1858e-02, -5.1448e-03],\n",
      "          [-4.6568e-02, -5.0200e-02, -2.9930e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1549e-01, -5.6381e-02, -1.4566e-01],\n",
      "          [-1.2336e-01, -6.9266e-02, -1.5765e-01],\n",
      "          [-1.1674e-01, -1.1551e-01, -1.6064e-01]],\n",
      "\n",
      "         [[-1.5494e-02,  4.2709e-04, -6.7384e-03],\n",
      "          [-4.4397e-02,  1.1598e-03, -6.7877e-02],\n",
      "          [-9.9168e-02, -6.8193e-02, -2.7521e-03]],\n",
      "\n",
      "         [[-4.5342e-02, -1.1574e-01, -6.2240e-02],\n",
      "          [-7.2096e-02, -1.0811e-01, -5.4723e-02],\n",
      "          [-6.3851e-02, -4.5152e-02, -4.0025e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5849e-02, -4.8172e-02, -2.9536e-02],\n",
      "          [-4.8661e-02, -1.2134e-02, -6.8635e-02],\n",
      "          [-5.5971e-02, -4.9053e-02, -7.5355e-02]],\n",
      "\n",
      "         [[ 3.9963e-02,  4.1310e-02,  4.1324e-03],\n",
      "          [ 3.8826e-02,  1.8669e-02, -7.9041e-03],\n",
      "          [ 3.2591e-02,  1.8356e-02,  1.7128e-02]],\n",
      "\n",
      "         [[ 8.9516e-02, -1.5888e-02,  3.1086e-03],\n",
      "          [ 7.8388e-02,  3.6714e-02, -3.1601e-02],\n",
      "          [-8.9336e-03, -6.2775e-02, -3.8521e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5712e-02,  5.2993e-02,  6.0687e-02],\n",
      "          [ 9.8716e-02,  2.0923e-02,  8.8699e-02],\n",
      "          [ 1.1588e-01,  3.5768e-02,  1.2685e-01]],\n",
      "\n",
      "         [[-2.4788e-03, -1.1887e-01, -1.9854e-02],\n",
      "          [ 2.7485e-02, -2.0704e-02,  1.0353e-01],\n",
      "          [-5.8462e-03, -8.0393e-02,  3.4710e-02]],\n",
      "\n",
      "         [[-9.6639e-02, -1.0985e-01, -4.9067e-02],\n",
      "          [-1.0496e-01, -1.1225e-01, -4.3896e-02],\n",
      "          [-2.6408e-02, -7.4459e-02, -1.7601e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1364e-02, -2.5501e-02, -8.9831e-02],\n",
      "          [-5.8042e-02,  3.6634e-02, -6.8997e-02],\n",
      "          [-2.2065e-02,  6.2276e-02, -4.9969e-02]],\n",
      "\n",
      "         [[-4.9758e-03,  3.8400e-02,  6.1597e-02],\n",
      "          [ 8.7954e-02, -8.9322e-02,  8.5414e-02],\n",
      "          [ 9.2924e-02,  1.3012e-02,  1.1699e-01]],\n",
      "\n",
      "         [[-2.3428e-02,  4.3617e-02,  5.7583e-03],\n",
      "          [-5.9888e-03,  4.0091e-02,  1.2352e-02],\n",
      "          [ 3.4128e-03,  5.6933e-02, -7.1737e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7714e-02,  1.0159e-01,  3.5127e-02],\n",
      "          [ 2.1783e-02,  7.0243e-02,  4.0840e-05],\n",
      "          [-4.3435e-02, -1.1688e-02, -7.3202e-03]],\n",
      "\n",
      "         [[-3.6998e-02,  6.4952e-02, -4.6540e-03],\n",
      "          [ 5.6243e-03,  9.6173e-02, -4.0238e-02],\n",
      "          [-2.9651e-02,  1.9965e-02, -7.9273e-02]],\n",
      "\n",
      "         [[ 1.3311e-02, -5.3085e-02, -9.0291e-03],\n",
      "          [ 1.0910e-02, -6.1567e-03,  1.0043e-02],\n",
      "          [ 1.7020e-02, -1.4619e-02,  2.3666e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.3398e-02,  2.4225e-03, -9.0272e-03],\n",
      "          [ 1.4635e-02,  3.7916e-02,  4.9440e-02],\n",
      "          [ 1.3614e-02,  7.4133e-02,  5.4323e-02]],\n",
      "\n",
      "         [[-1.7996e-01, -2.0380e-01, -1.9599e-01],\n",
      "          [-1.5283e-01, -1.8972e-01, -1.8129e-01],\n",
      "          [-7.6927e-02, -9.8908e-02, -8.3891e-02]],\n",
      "\n",
      "         [[ 1.3492e-01,  1.6927e-01,  1.0088e-01],\n",
      "          [ 1.8733e-01,  2.8159e-01,  1.5529e-01],\n",
      "          [ 2.2825e-01,  2.8839e-01,  1.7665e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3918e-02, -4.4265e-02,  1.1248e-02],\n",
      "          [-2.6011e-02, -9.7481e-02, -1.6946e-02],\n",
      "          [ 3.3598e-02, -1.9091e-02,  2.6880e-02]],\n",
      "\n",
      "         [[ 9.6960e-04, -1.3991e-02,  2.1728e-02],\n",
      "          [ 4.5186e-02,  1.2742e-02,  5.6722e-02],\n",
      "          [-4.7513e-02, -1.8959e-02, -4.7290e-02]],\n",
      "\n",
      "         [[-2.0960e-01, -1.9724e-01, -2.3245e-01],\n",
      "          [-1.8212e-01, -2.1160e-01, -2.1926e-01],\n",
      "          [-2.0964e-01, -2.5554e-01, -2.7705e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1724e-02, -5.0829e-02, -4.5687e-02],\n",
      "          [-3.4457e-02, -1.3143e-01, -8.5314e-02],\n",
      "          [-2.4859e-02, -1.0578e-01, -3.4198e-02]],\n",
      "\n",
      "         [[ 3.9407e-02,  1.2718e-02, -4.3295e-02],\n",
      "          [ 2.6507e-02,  1.6522e-01,  1.2198e-02],\n",
      "          [ 4.6081e-02,  4.1927e-03,  1.4933e-02]],\n",
      "\n",
      "         [[-2.2432e-02,  3.1649e-02, -2.8396e-02],\n",
      "          [ 4.2371e-02, -1.9659e-02,  2.9343e-02],\n",
      "          [ 7.5689e-03,  3.0675e-02,  3.9486e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3335e-02, -1.3251e-02, -1.1222e-02],\n",
      "          [-1.5473e-02,  1.2936e-01,  3.7815e-02],\n",
      "          [-3.7278e-02,  6.8900e-03, -6.4999e-02]],\n",
      "\n",
      "         [[-1.8300e-02, -2.5131e-02, -1.3673e-02],\n",
      "          [-2.6743e-03,  4.0869e-02, -1.9581e-02],\n",
      "          [ 2.6616e-02,  2.6624e-03,  3.4260e-02]],\n",
      "\n",
      "         [[ 5.9158e-02,  6.2257e-02,  5.3467e-02],\n",
      "          [ 3.1171e-02,  7.9780e-02,  3.2978e-02],\n",
      "          [ 3.0387e-02,  7.7567e-02,  4.4266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2663e-02,  1.2158e-02, -4.8785e-03],\n",
      "          [-4.7927e-03,  1.8207e-02, -7.5964e-03],\n",
      "          [-3.4807e-02, -1.6773e-02, -8.7812e-03]],\n",
      "\n",
      "         [[ 2.4696e-02,  3.4358e-02,  5.6985e-03],\n",
      "          [ 1.4231e-02, -2.7495e-02, -1.7663e-03],\n",
      "          [-5.4913e-02, -2.3215e-02, -2.5171e-02]],\n",
      "\n",
      "         [[ 9.2285e-03,  3.2782e-02, -1.9081e-02],\n",
      "          [-4.1236e-02,  3.9687e-02, -3.2634e-02],\n",
      "          [-5.3521e-02, -3.5577e-02, -6.4801e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8010e-02, -1.4536e-02,  9.0045e-03],\n",
      "          [-4.0036e-02, -4.9584e-02, -2.0707e-02],\n",
      "          [-8.7691e-03, -4.4960e-02, -4.5329e-02]],\n",
      "\n",
      "         [[-2.7639e-02,  3.5597e-02,  8.2298e-04],\n",
      "          [-2.9570e-02,  2.8251e-02,  2.6092e-04],\n",
      "          [-4.8411e-02, -3.7837e-02, -1.6720e-02]],\n",
      "\n",
      "         [[-3.7951e-02,  2.3490e-02, -2.4559e-02],\n",
      "          [-3.3889e-03, -7.6114e-02, -5.0305e-02],\n",
      "          [-4.5863e-02, -6.1375e-03, -7.1011e-02]]]], device='cuda:0')), ('backbone.model.layer3.5.bn2.weight', tensor([1.9716, 0.8850, 2.4005, 2.1577, 2.1308, 2.9592, 3.4524, 2.7000, 2.8562,\n",
      "        2.8370, 3.1491, 2.5477, 2.0466, 2.1160, 0.6116, 3.0788, 2.3723, 1.3448,\n",
      "        0.6304, 3.9090, 3.6329, 1.9093, 4.2062, 5.0781, 1.7409, 1.9834, 2.0901,\n",
      "        0.9367, 1.9504, 1.8760, 2.4362, 1.3753, 2.6462, 3.9181, 3.4102, 0.6655,\n",
      "        2.7020, 2.0169, 3.0613, 3.5904, 1.7606, 0.7473, 2.2563, 1.7484, 1.9070,\n",
      "        1.8505, 1.7893, 2.7985, 1.7277, 1.2846, 1.0214, 2.1889, 2.8349, 3.0310,\n",
      "        2.2443, 2.9965, 3.4888, 2.0211, 7.5969, 2.2658, 2.2603, 2.2425, 2.1839,\n",
      "        1.5883, 2.0338, 2.1365, 1.8545, 2.0660, 2.4273, 2.6135, 1.5769, 1.8998,\n",
      "        1.6622, 1.5335, 2.9984, 0.8109, 1.4246, 2.2967, 1.7134, 1.5401, 2.7018,\n",
      "        1.6863, 3.4730, 2.1620, 2.5948, 2.5300, 1.9416, 1.9725, 1.4079, 3.4798,\n",
      "        1.9092, 0.7117, 4.1393, 0.9295, 2.9246, 4.9912, 2.0959, 0.6856, 2.1821,\n",
      "        1.6401, 1.7920, 2.7133, 1.4849, 2.1308, 0.4994, 2.6308, 3.8449, 3.1174,\n",
      "        2.4238, 2.9080, 4.1311, 3.1961, 2.4871, 1.9249, 2.0504, 1.9636, 1.7953,\n",
      "        2.0862, 2.1926, 1.1073, 1.8730, 1.9233, 2.0000, 1.4451, 1.7231, 1.4514,\n",
      "        2.4742, 1.8367, 1.4912, 1.7367, 1.6923, 2.0633, 1.3427, 2.7889, 1.7591,\n",
      "        2.1824, 3.2854, 1.9389, 1.9780, 2.5121, 2.7075, 1.8072, 0.5674, 3.2855,\n",
      "        0.4559, 2.2576, 1.7730, 1.8034, 2.1724, 2.0259, 1.6632, 2.8649, 2.5535,\n",
      "        2.4252, 3.2703, 3.4505, 3.1492, 2.4660, 3.0812, 1.8216, 1.6820, 2.2678,\n",
      "        3.3482, 2.6256, 2.9110, 1.1086, 3.7212, 1.9233, 3.1388, 2.6216, 2.7718,\n",
      "        0.6663, 2.1705, 2.0879, 4.8184, 2.7556, 2.5098, 2.4917, 0.7492, 2.6312,\n",
      "        1.5703, 2.4590, 1.6485, 1.5919, 1.0458, 2.6056, 2.3944, 2.2940, 3.5769,\n",
      "        3.0304, 3.5413, 2.0056, 3.5789, 3.4389, 3.9773, 2.5269, 4.9488, 5.9673,\n",
      "        2.6218, 3.2439, 3.8605, 1.8095, 2.0449, 2.3099, 1.7797, 1.7532, 1.5025,\n",
      "        2.2445, 2.4861, 2.3791, 1.5928, 1.1528, 2.4567, 2.5132, 1.8339, 3.5058,\n",
      "        1.9978, 0.7220, 2.7285, 2.2432, 1.9329, 2.4716, 2.4272, 3.3063, 3.1722,\n",
      "        1.7404, 1.9045, 1.9482, 2.8016, 2.3476, 1.3035, 2.0206, 2.2605, 1.8333,\n",
      "        1.9360, 1.2660, 1.3409, 1.7566, 2.7977, 1.7741, 1.6394, 1.9602, 1.9277,\n",
      "        1.2702, 1.7798, 3.1350, 1.4802, 1.9416, 3.2474, 2.2052, 2.5035, 2.0894,\n",
      "        2.1459, 0.4560, 2.1976, 2.3609], device='cuda:0')), ('backbone.model.layer3.5.bn2.bias', tensor([-1.3165e+00,  2.2318e-01, -1.6689e+00, -1.5092e+00, -4.8535e-01,\n",
      "        -2.6391e+00, -2.8729e+00, -1.9792e+00, -8.9919e-01, -1.2269e+00,\n",
      "        -3.0718e+00,  5.1775e-01, -2.4929e-02,  5.1377e-01, -2.7939e+00,\n",
      "         1.5244e+00, -6.1665e-01,  1.5803e+00, -2.6272e-01, -3.4205e+00,\n",
      "        -4.3886e-01, -1.3925e+00, -4.7507e-01, -3.9720e+00,  1.5097e-01,\n",
      "        -4.5149e-01, -1.3196e+00,  1.1570e+00, -7.8038e-01, -4.1751e-02,\n",
      "        -2.0460e+00,  1.0115e+00,  2.1132e-01,  1.0211e+00, -2.6322e+00,\n",
      "        -4.3816e+00, -1.2400e+00,  1.0533e+00, -1.8279e+00, -3.0849e-01,\n",
      "         2.7327e-01, -2.3425e+00, -2.0411e+00,  3.8753e-01,  5.6912e-01,\n",
      "         5.0206e-01,  5.0193e-01, -2.5296e+00,  1.2367e-02, -2.3946e+00,\n",
      "        -1.6855e-02,  3.5280e-02,  1.5241e-01, -2.9044e+00, -3.3994e-01,\n",
      "        -3.4728e+00, -1.2121e+00, -2.3263e-01, -3.4758e+00, -5.6429e-01,\n",
      "        -1.7093e-01, -5.5346e-01, -6.5603e-01, -1.8963e+00, -2.2978e+00,\n",
      "        -2.4029e-01, -2.8399e-01, -9.7270e-01, -5.0282e-02, -2.6674e+00,\n",
      "         2.4178e-01,  1.0645e-01,  4.1376e-01,  5.0739e-01, -3.0469e+00,\n",
      "        -2.7392e+00, -6.5667e-01, -1.3054e+00,  6.1450e-01, -4.7044e-01,\n",
      "        -2.2291e-02, -3.0717e+00, -1.0963e-01,  7.5828e-02,  9.7700e-01,\n",
      "        -1.2450e-01,  5.9078e-02, -1.1448e+00, -5.6379e-01, -2.1466e+00,\n",
      "         5.8848e-01,  6.5726e-02, -2.8028e+00,  1.6023e+00, -1.0356e+00,\n",
      "        -2.9682e+00, -1.2291e+00, -2.3175e+00, -1.9020e+00, -2.5840e-01,\n",
      "         4.2517e-01, -3.0418e+00,  5.8659e-01,  1.4699e-01, -1.8848e+00,\n",
      "        -1.1028e+00, -7.0594e-01, -1.5908e-01,  4.2562e-02, -1.6007e+00,\n",
      "        -8.1654e-01, -2.7698e+00, -4.1602e-01, -1.4384e+00, -6.7993e-01,\n",
      "        -1.4509e+00,  1.5605e+00, -9.4451e-01, -1.0835e+00,  1.4008e+00,\n",
      "        -7.5101e-01,  3.7958e-02,  3.3173e-01,  6.7474e-01, -4.5415e-03,\n",
      "        -1.6641e+00,  9.2552e-01, -5.5846e-01, -4.1334e-01,  2.3719e-01,\n",
      "        -8.3572e-02,  3.3919e-01, -1.4241e+00, -2.6221e-01, -9.0352e-04,\n",
      "        -1.1351e-01, -3.5175e+00, -1.2253e-01, -9.2757e-02, -3.4333e-01,\n",
      "         2.5557e+00, -4.3171e-01, -5.6967e-01, -1.3110e+00, -1.0946e+00,\n",
      "        -9.8360e-01,  5.0809e-01,  3.8682e-01, -9.2565e-01, -1.7086e-02,\n",
      "         6.2748e-01, -3.2442e+00, -9.2144e-01, -4.7022e-01, -1.3433e+00,\n",
      "        -3.1152e+00, -8.6758e-01, -1.4625e+00, -2.5709e+00, -6.0150e-01,\n",
      "         1.1150e+00, -1.0314e+00, -3.6409e-01,  2.9245e-01, -1.4177e-01,\n",
      "        -3.0291e+00, -7.1323e-02, -7.7640e-01,  1.7797e-01,  2.0093e-01,\n",
      "         3.6102e-02, -1.7498e+00, -1.7112e+00, -1.1967e+00, -6.6925e-01,\n",
      "        -6.0700e-01, -1.3839e+00, -3.4458e-01, -3.3541e+00, -2.3471e+00,\n",
      "         8.4141e-01, -1.3958e+00, -5.0922e-01,  3.9804e-01, -5.0559e+00,\n",
      "        -1.0625e+00, -2.0402e+00, -2.9972e-01, -1.5043e+00, -1.2087e-01,\n",
      "        -2.5172e+00,  5.1895e-02, -3.5585e-01, -1.0090e+00,  2.9288e-01,\n",
      "        -1.4386e+00, -6.5191e-01, -9.5416e-01, -1.1769e+01, -8.9258e-01,\n",
      "        -3.5519e+00, -7.5470e-01, -5.1281e-01,  2.5805e-01, -1.4448e+00,\n",
      "         4.0360e-02, -3.8366e-01, -1.1949e+00, -5.4725e-01, -3.6571e-02,\n",
      "         7.4343e-01, -1.3566e+00, -7.1655e-02, -2.7119e-01, -1.8157e+00,\n",
      "        -1.0947e+00, -1.6670e+00,  7.1653e-01, -1.1437e+00, -7.1718e-01,\n",
      "        -1.4069e+00, -3.9423e-01, -1.3482e+00, -1.6565e+00, -5.8425e-01,\n",
      "         4.1286e-01, -4.6118e-01, -1.9203e-01,  2.5514e-01, -7.5685e-01,\n",
      "        -1.2014e+00, -9.9569e-01, -1.6138e-01, -2.4467e-01,  3.2915e-01,\n",
      "        -1.0208e+00,  5.4656e-02, -1.2629e+00, -1.4422e+00, -6.5830e-01,\n",
      "        -3.0722e-01, -4.5640e-01, -1.0746e+00, -7.2899e-01,  6.9016e-02,\n",
      "        -1.7230e+00,  1.3864e+00, -9.7743e-01, -5.4000e-01,  1.2462e-02,\n",
      "        -1.0586e+00,  4.6164e-01,  7.8305e-01, -9.1481e-01,  5.3722e-01,\n",
      "        -1.5637e+00], device='cuda:0')), ('backbone.model.layer3.5.conv3.weight', tensor([[[[-0.0103]],\n",
      "\n",
      "         [[-0.0527]],\n",
      "\n",
      "         [[-0.0538]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0881]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         [[ 0.0730]]],\n",
      "\n",
      "\n",
      "        [[[-0.0782]],\n",
      "\n",
      "         [[-0.0232]],\n",
      "\n",
      "         [[-0.0668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         [[-0.0895]]],\n",
      "\n",
      "\n",
      "        [[[-0.0920]],\n",
      "\n",
      "         [[ 0.0452]],\n",
      "\n",
      "         [[-0.0893]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0923]],\n",
      "\n",
      "         [[ 0.0317]],\n",
      "\n",
      "         [[-0.0037]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0035]],\n",
      "\n",
      "         [[-0.1572]],\n",
      "\n",
      "         [[ 0.0276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1122]],\n",
      "\n",
      "         [[ 0.1002]],\n",
      "\n",
      "         [[ 0.0473]]],\n",
      "\n",
      "\n",
      "        [[[-0.0277]],\n",
      "\n",
      "         [[-0.1220]],\n",
      "\n",
      "         [[ 0.0486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[-0.1139]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0444]],\n",
      "\n",
      "         [[ 0.0152]],\n",
      "\n",
      "         [[ 0.1128]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1084]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[ 0.0568]]]], device='cuda:0')), ('backbone.model.layer3.5.bn3.weight', tensor([-2.1412, -2.1685,  1.8625,  ..., -1.5707,  4.1138,  2.2215],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.bn3.bias', tensor([-0.5192, -0.7654, -0.0873,  ..., -0.5757,  0.3450,  0.0365],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv1.weight', tensor([[[[-0.0126]],\n",
      "\n",
      "         [[ 0.0001]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         [[-0.0609]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0252]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[-0.0965]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[ 0.0572]],\n",
      "\n",
      "         [[ 0.1200]]],\n",
      "\n",
      "\n",
      "        [[[-0.0309]],\n",
      "\n",
      "         [[ 0.0305]],\n",
      "\n",
      "         [[-0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         [[ 0.0323]],\n",
      "\n",
      "         [[-0.0071]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0532]],\n",
      "\n",
      "         [[-0.0129]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1097]],\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[ 0.0338]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1183]],\n",
      "\n",
      "         [[ 0.0992]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[ 0.0656]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[ 0.0039]],\n",
      "\n",
      "         [[ 0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0385]],\n",
      "\n",
      "         [[-0.0714]],\n",
      "\n",
      "         [[-0.0344]]]], device='cuda:0')), ('backbone.model.layer4.0.bn1.weight', tensor([1.8314, 1.8578, 1.8644, 1.8421, 2.5610, 2.2845, 1.9866, 2.0912, 2.4900,\n",
      "        1.9306, 2.4838, 1.6676, 3.1620, 1.6694, 1.9133, 1.8298, 3.1592, 2.5286,\n",
      "        1.3591, 1.5647, 1.5075, 1.9385, 3.1072, 1.4559, 2.7022, 1.5187, 2.1546,\n",
      "        1.8905, 2.0389, 1.7594, 2.4878, 2.1003, 2.1269, 1.6262, 1.6843, 1.7931,\n",
      "        1.7669, 1.1859, 1.5551, 2.0436, 2.6605, 1.7884, 1.7126, 1.9043, 1.5090,\n",
      "        2.0073, 2.3540, 1.5896, 3.5884, 2.6517, 1.8038, 2.6024, 1.8707, 2.3828,\n",
      "        1.8685, 2.4474, 2.4184, 2.0196, 2.1073, 2.4320, 1.9161, 2.2337, 2.3814,\n",
      "        2.0207, 2.1428, 1.9140, 1.9442, 2.4179, 2.7146, 2.6323, 1.8672, 1.9782,\n",
      "        2.2749, 1.9353, 1.9229, 1.8198, 1.9148, 1.5088, 2.0675, 2.1521, 2.1486,\n",
      "        1.8737, 3.9593, 2.0368, 1.5336, 2.4615, 1.8532, 2.0170, 2.1321, 1.9281,\n",
      "        1.6959, 2.0400, 1.7028, 2.2858, 2.0788, 3.6004, 2.2095, 1.8256, 1.9783,\n",
      "        2.2759, 1.6419, 1.7615, 1.9471, 3.1555, 1.8462, 2.0394, 2.0404, 2.4591,\n",
      "        1.5498, 2.6800, 2.1380, 2.0328, 2.2833, 1.7968, 2.2967, 2.7662, 1.8850,\n",
      "        1.8883, 2.0772, 1.8388, 2.0843, 1.8748, 2.6824, 2.5188, 1.7922, 2.0672,\n",
      "        1.9006, 1.5658, 2.2571, 1.8768, 2.8949, 2.4737, 1.8489, 4.9384, 2.0425,\n",
      "        2.4711, 4.3078, 2.2489, 2.5794, 2.2345, 2.5843, 2.0575, 3.0014, 1.4252,\n",
      "        1.8560, 2.1284, 3.0941, 2.0184, 2.5503, 1.5414, 1.9831, 1.5442, 2.2784,\n",
      "        2.2006, 1.8038, 1.9068, 1.4567, 2.3943, 2.5676, 2.3289, 1.7855, 2.3405,\n",
      "        1.7952, 2.3015, 1.8924, 1.9592, 1.9769, 1.9527, 1.9840, 2.4929, 1.7957,\n",
      "        2.3109, 1.8725, 2.4707, 1.9381, 1.7869, 1.8255, 1.9971, 2.1971, 2.1447,\n",
      "        2.5156, 1.8655, 1.5970, 1.8435, 2.0856, 1.9169, 2.9520, 1.5969, 2.0474,\n",
      "        1.9100, 2.2173, 2.0582, 1.8154, 1.9895, 1.6014, 2.1971, 1.8524, 1.9345,\n",
      "        1.8561, 2.3063, 1.2572, 2.4697, 1.5770, 2.1728, 1.9229, 1.7117, 1.8611,\n",
      "        1.4461, 2.1610, 2.1258, 2.7123, 2.4184, 1.6011, 3.2742, 2.0722, 2.1850,\n",
      "        1.5767, 1.9229, 1.8494, 1.5368, 2.3461, 2.0585, 1.8891, 1.7523, 2.4773,\n",
      "        1.7997, 2.0862, 1.9603, 1.9888, 2.7592, 2.4955, 1.1006, 3.4028, 2.8508,\n",
      "        2.4656, 2.9904, 2.6301, 3.2798, 1.9367, 2.5565, 1.8639, 2.3303, 1.5951,\n",
      "        1.7917, 2.0518, 2.1212, 1.7452, 1.7090, 2.8612, 1.6223, 3.3167, 2.2376,\n",
      "        2.3363, 2.5157, 2.3670, 2.3206, 1.9170, 2.2345, 2.7256, 2.5249, 1.8755,\n",
      "        1.4393, 1.6177, 1.5042, 1.8595, 1.7563, 1.9009, 2.2058, 1.7995, 2.0034,\n",
      "        1.7491, 1.8657, 1.8666, 1.7867, 1.6263, 2.0607, 2.2113, 1.7739, 2.0815,\n",
      "        1.9199, 1.5168, 2.1859, 2.8054, 2.2436, 1.8102, 2.2178, 1.7972, 1.6173,\n",
      "        2.9415, 2.0863, 1.8028, 1.8486, 2.6507, 1.8701, 1.5540, 1.9667, 1.8125,\n",
      "        1.8773, 1.5193, 2.7824, 1.3550, 1.8569, 2.8391, 2.3180, 1.3525, 1.8346,\n",
      "        1.7437, 1.9632, 2.2668, 2.0131, 2.8853, 2.2676, 2.1468, 1.7671, 2.1995,\n",
      "        2.3387, 2.3026, 1.7962, 1.9896, 1.3652, 1.9478, 2.1477, 1.9074, 2.1422,\n",
      "        2.1081, 1.7641, 1.7447, 1.7464, 2.5415, 1.9353, 1.7740, 1.9930, 2.3945,\n",
      "        2.0018, 1.8538, 1.9348, 1.8505, 2.1438, 1.9251, 1.9409, 1.4635, 1.7011,\n",
      "        1.7805, 1.6285, 1.6307, 1.5744, 1.6255, 2.5114, 2.0965, 1.4512, 1.6409,\n",
      "        2.2474, 2.0258, 2.2130, 1.5051, 1.9196, 1.6749, 2.5703, 1.8729, 1.7775,\n",
      "        3.6745, 1.9105, 2.7890, 2.4215, 2.6347, 2.2251, 1.9016, 2.0337, 1.9324,\n",
      "        1.9366, 1.8875, 1.7551, 1.9830, 1.7689, 1.5918, 1.7217, 1.6096, 1.5541,\n",
      "        1.6147, 1.7155, 1.8565, 1.7410, 1.6995, 1.8018, 2.4317, 1.6919, 1.7526,\n",
      "        1.9427, 2.1415, 2.2336, 2.2679, 1.3602, 2.9309, 2.7840, 1.9139, 2.3315,\n",
      "        1.8691, 2.4040, 1.9170, 2.3854, 1.5574, 1.7801, 1.7688, 1.8833, 4.1351,\n",
      "        2.0465, 2.5695, 1.3451, 1.6086, 1.3129, 2.4328, 1.4821, 2.5019, 1.7801,\n",
      "        1.6211, 2.2805, 1.9870, 2.5951, 1.9765, 1.9525, 1.8773, 1.6152, 3.5596,\n",
      "        1.7139, 2.0210, 1.6348, 2.2839, 2.1681, 2.8953, 2.0880, 2.4774, 1.7921,\n",
      "        2.2298, 2.1537, 2.5972, 1.8556, 2.4781, 2.3579, 2.3878, 2.5347, 2.5064,\n",
      "        2.9794, 1.7614, 0.9382, 3.2732, 1.7949, 2.3715, 1.6634, 2.1491, 1.9381,\n",
      "        1.8417, 3.3854, 2.0239, 2.4697, 1.9213, 2.2826, 1.9782, 1.7698, 1.7586,\n",
      "        1.8418, 1.7916, 1.5048, 1.9105, 2.0612, 2.2690, 3.1478, 2.2929, 2.0902,\n",
      "        2.3192, 2.2000, 2.4909, 2.5873, 2.6669, 1.5663, 2.1689, 2.3390, 2.3304,\n",
      "        1.6171, 1.5972, 2.2684, 2.2715, 2.6314, 1.5208, 2.1472, 1.8234, 2.0982,\n",
      "        2.1537, 1.5031, 2.4025, 2.0963, 2.1757, 2.3896, 2.4387, 2.2195, 1.8717,\n",
      "        2.0777, 1.7244, 2.7924, 2.7047, 1.9274, 1.7062, 1.9884, 1.7632, 2.7799,\n",
      "        2.2695, 2.0700, 2.0162, 2.5286, 2.2320, 1.8121, 0.9934, 2.2532],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn1.bias', tensor([-0.9996, -2.7897, -1.4111, -1.9773, -3.0503, -4.4743, -2.3001, -1.9981,\n",
      "        -2.7169, -1.6225, -3.0258, -0.5046, -2.8504, -2.1793, -1.4652, -1.2736,\n",
      "        -3.4100, -2.9174, -0.5999, -0.8509, -1.6865, -1.4168, -3.4186, -0.6015,\n",
      "        -3.5196, -3.5888, -2.1448, -2.3278, -1.8925, -1.3916, -2.5137, -1.6461,\n",
      "        -2.1925, -1.3213, -0.9442, -1.5646, -1.2388, -0.5977, -1.9568, -1.4014,\n",
      "        -2.0915, -2.4112, -1.3068, -1.7585, -0.5639, -2.2673, -3.3161, -2.5145,\n",
      "        -4.3761, -4.5281, -2.0090, -2.1996, -1.9778, -2.4119, -3.4784, -2.1598,\n",
      "        -3.4804, -2.0425, -3.1701, -1.6180, -2.8418, -2.3062, -2.9641, -1.4605,\n",
      "        -2.2890, -1.0965, -1.9730, -2.3220, -4.0837, -2.7054, -2.2302, -1.2831,\n",
      "        -2.0168, -2.1770, -2.9113, -1.0169, -2.0106, -1.7529, -2.5533, -2.0664,\n",
      "        -2.1710, -1.5145, -3.7775, -2.1574, -0.8421, -1.8253, -1.4936, -2.5463,\n",
      "        -2.3034, -1.5163, -4.5540, -1.4503, -1.4212, -2.2556, -1.9856, -2.7003,\n",
      "        -1.7085, -1.6773, -1.5688, -1.9198, -1.2569, -1.1628, -1.7710, -3.6606,\n",
      "        -1.4089, -1.4689, -1.8231, -2.9187, -3.7592, -3.2089, -2.0444, -1.4620,\n",
      "        -1.9147, -1.3590, -2.1241, -2.7468, -1.3691, -0.8564, -1.8088, -4.8912,\n",
      "        -1.4001, -1.9613, -3.5689, -1.6877, -1.3543, -1.1691, -2.1712, -0.9511,\n",
      "        -1.7271, -1.2590, -2.1970, -1.9712, -1.1546, -3.3205, -1.9197, -3.0246,\n",
      "        -4.7700, -1.9730, -2.8411, -1.6436, -2.3231, -1.5342, -2.4796, -3.7443,\n",
      "        -1.3863, -1.2541, -3.0104, -1.5383, -1.4760, -1.4337, -1.7635, -1.5664,\n",
      "        -1.7771, -2.2309, -0.9700, -1.8766, -2.9835, -2.3372, -2.7448, -2.1365,\n",
      "        -1.4536, -1.6375, -4.3185, -2.4854, -1.7552, -1.4736, -2.4015, -1.7439,\n",
      "        -1.4407, -2.5833, -1.7576, -1.4228, -0.9792, -1.5062, -1.6849, -1.5587,\n",
      "        -1.9200, -2.4084, -2.0131, -2.1149, -4.4426, -1.2813, -1.2274, -1.6428,\n",
      "        -1.8997, -2.7946, -3.1332, -1.1866, -2.6902, -1.6114, -2.1983, -1.3523,\n",
      "        -1.8820, -1.7795, -2.3846, -1.8765, -0.8388, -2.7834, -1.7199, -2.9028,\n",
      "        -0.5351, -1.9636, -0.9870, -1.1937, -2.0692, -1.7437, -1.6618, -0.9387,\n",
      "        -2.3412, -1.6485, -4.5582, -2.3570, -1.0143, -4.5586, -1.7861, -2.8052,\n",
      "        -1.3858, -4.6378, -1.5622, -0.6853, -2.4886, -1.0759, -1.3230, -1.7649,\n",
      "        -2.3319, -1.1820, -1.4666, -1.5672, -1.4049, -1.4685, -1.9107, -4.0571,\n",
      "        -3.0346, -2.3134, -2.0295, -2.7964, -1.8417, -3.0239, -0.9414, -1.8925,\n",
      "        -3.0376, -2.4380, -1.7529, -1.7097, -2.8165, -2.8836, -1.2707, -2.4509,\n",
      "        -3.2547, -0.9159, -3.6097, -2.6197, -2.5649, -2.0400, -2.5179, -2.1893,\n",
      "        -1.1007, -2.6401, -2.1536, -2.8813, -2.1624, -1.5842, -1.8486, -1.4313,\n",
      "        -1.7199, -1.3520, -1.2691, -1.8783, -1.5091, -3.7203, -1.9581, -1.5244,\n",
      "        -0.9413, -1.7772, -1.1936, -2.0990, -1.4496, -1.3994, -1.4893, -1.3456,\n",
      "        -3.4333, -1.9926, -1.7385, -2.4689, -0.9465, -1.7723, -1.4997, -0.7370,\n",
      "        -2.3799, -1.8979, -2.1280, -1.5151, -2.4297, -1.5188, -0.8447, -1.4088,\n",
      "        -1.8775, -1.6823, -3.9736, -2.1858, -0.8676, -0.8698, -2.1820, -1.6921,\n",
      "        -0.5586, -2.2900, -1.2983, -1.1886, -1.8446, -1.9717, -4.2489, -2.3368,\n",
      "        -2.7022, -2.5910, -1.9128, -3.4884, -2.1776, -2.4763, -1.8258, -0.5132,\n",
      "        -1.3820, -1.9450, -2.2405, -1.9205, -2.1902, -1.3270, -1.8252, -1.8218,\n",
      "        -2.3352, -1.3971, -0.7591, -1.2263, -3.5390, -3.8310, -1.1625, -2.9750,\n",
      "        -0.7808, -1.8728, -2.2380, -2.0794, -0.7895, -1.5877, -1.4692, -1.2173,\n",
      "        -0.9221, -1.2760, -1.4300, -2.9037, -1.7739, -2.3257, -0.6235, -2.0484,\n",
      "        -5.6271, -1.9085, -0.6323, -1.5295, -2.1286, -2.4066, -1.6659, -1.3136,\n",
      "        -3.9707, -0.9420, -1.9828, -1.2241, -1.6177, -1.7659, -1.8740, -1.8131,\n",
      "        -1.8302, -1.1093, -1.4529, -1.4931, -1.6485, -1.2036, -1.1922, -1.3290,\n",
      "        -1.8219, -1.7314, -1.8881, -1.5410, -1.2840, -1.7799, -1.7026, -1.2010,\n",
      "        -1.7169, -1.3615, -0.7786, -1.4123, -1.1086, -1.5306, -1.5485, -4.4795,\n",
      "        -2.8989, -2.0128, -1.1817, -1.8502, -1.1236, -1.5203, -1.0748, -2.2740,\n",
      "        -0.9860, -1.1201, -0.9258, -0.9914, -4.1147, -1.1996, -2.1968, -0.9262,\n",
      "        -1.3893,  0.1650, -2.2997, -2.4551, -2.1241, -1.7755, -1.3939, -1.7161,\n",
      "        -1.7027, -2.7230, -2.4250, -1.5989, -1.6886, -0.9546, -4.0159, -1.7227,\n",
      "        -2.5392, -1.9205, -2.8345, -4.2425, -2.8568, -1.4851, -4.1609, -1.5756,\n",
      "        -1.8110, -1.6828, -1.6214, -1.0412, -1.8232, -1.7326, -1.4321, -2.0069,\n",
      "        -1.8666, -2.5186, -0.9819, -3.3991, -2.8215, -1.0657, -1.3230, -1.7244,\n",
      "        -2.3584, -1.6072, -2.3355, -2.4545, -1.8892, -1.8637, -1.2456, -2.4801,\n",
      "        -1.9379, -2.0503, -2.5482, -1.6926, -3.1150, -1.2299, -1.9126, -2.2311,\n",
      "        -2.1050, -4.0005, -3.3858, -1.6611, -1.6839, -2.5462, -2.2086, -3.1975,\n",
      "        -4.9379, -1.4284, -2.0111, -2.3941, -2.5925, -0.9196, -2.7926, -3.5658,\n",
      "        -2.8009, -3.3402,  0.4292, -1.3237, -1.5337, -1.6235, -2.1949, -1.2839,\n",
      "        -3.1588, -3.1008, -2.7125, -2.4858, -2.5434, -2.9623, -2.1293, -2.0988,\n",
      "        -0.9947, -1.6477, -1.1928, -1.1239, -0.7619, -0.9237, -1.0089, -1.6383,\n",
      "        -2.1638, -0.9397, -1.1070, -1.6755, -1.4056, -1.1982, -3.3102, -1.5928],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv2.weight', tensor([[[[-0.0351,  0.0303, -0.0548],\n",
      "          [-0.0362,  0.0306,  0.0086],\n",
      "          [-0.0021,  0.0081, -0.0500]],\n",
      "\n",
      "         [[-0.0217, -0.0146, -0.0190],\n",
      "          [-0.0187, -0.0571, -0.0519],\n",
      "          [-0.0672, -0.0573, -0.0648]],\n",
      "\n",
      "         [[ 0.0260, -0.0324, -0.0193],\n",
      "          [-0.0337, -0.0042,  0.0074],\n",
      "          [ 0.0002,  0.0722,  0.0406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0171,  0.0140,  0.0487],\n",
      "          [-0.0056, -0.0172,  0.0419],\n",
      "          [ 0.0009, -0.0308, -0.0478]],\n",
      "\n",
      "         [[-0.0013, -0.0524,  0.0210],\n",
      "          [-0.0114, -0.0642, -0.0532],\n",
      "          [ 0.0759, -0.0228,  0.0390]],\n",
      "\n",
      "         [[-0.0647, -0.0338, -0.0509],\n",
      "          [-0.1104, -0.1053, -0.1478],\n",
      "          [-0.0867, -0.0835, -0.1230]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1026,  0.0995,  0.1088],\n",
      "          [ 0.1158,  0.0779,  0.1169],\n",
      "          [ 0.0924,  0.0955,  0.0800]],\n",
      "\n",
      "         [[ 0.0893,  0.0746,  0.0379],\n",
      "          [ 0.0761,  0.0253,  0.0727],\n",
      "          [ 0.0862,  0.1329,  0.0718]],\n",
      "\n",
      "         [[ 0.0365,  0.0136,  0.0276],\n",
      "          [ 0.0206,  0.1414,  0.0382],\n",
      "          [ 0.0077,  0.0414,  0.0552]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0146,  0.0299,  0.0347],\n",
      "          [-0.0230, -0.0207,  0.0031],\n",
      "          [-0.0045, -0.0235, -0.0055]],\n",
      "\n",
      "         [[ 0.0615,  0.0012,  0.0842],\n",
      "          [ 0.1011,  0.0756,  0.1252],\n",
      "          [ 0.0542,  0.0405,  0.0940]],\n",
      "\n",
      "         [[-0.0441, -0.0362, -0.0301],\n",
      "          [-0.0462, -0.1070, -0.0869],\n",
      "          [-0.0378, -0.0917, -0.0617]]],\n",
      "\n",
      "\n",
      "        [[[-0.0207, -0.0558, -0.0224],\n",
      "          [-0.0005, -0.0081, -0.0142],\n",
      "          [-0.0262, -0.0108, -0.0461]],\n",
      "\n",
      "         [[ 0.0085,  0.0309, -0.0150],\n",
      "          [ 0.0486,  0.0471, -0.0045],\n",
      "          [ 0.0243,  0.0875,  0.0048]],\n",
      "\n",
      "         [[ 0.0268,  0.0351,  0.0100],\n",
      "          [ 0.0169, -0.0034,  0.0321],\n",
      "          [ 0.0531,  0.0951,  0.0313]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0517,  0.0463,  0.0427],\n",
      "          [ 0.0076,  0.0274,  0.0184],\n",
      "          [ 0.0444,  0.0223,  0.0057]],\n",
      "\n",
      "         [[-0.0644, -0.0241, -0.0240],\n",
      "          [ 0.0019, -0.0936, -0.0199],\n",
      "          [ 0.0394,  0.0254,  0.0617]],\n",
      "\n",
      "         [[-0.0135, -0.0515, -0.0114],\n",
      "          [-0.0695, -0.0683, -0.0621],\n",
      "          [-0.0277, -0.1349, -0.0220]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0409,  0.1068,  0.1475],\n",
      "          [ 0.1104,  0.0972,  0.1054],\n",
      "          [ 0.0891,  0.0944,  0.0828]],\n",
      "\n",
      "         [[ 0.0262,  0.0263,  0.0691],\n",
      "          [ 0.0207,  0.0082, -0.0351],\n",
      "          [-0.0084, -0.0622, -0.0207]],\n",
      "\n",
      "         [[-0.0057,  0.1236,  0.0769],\n",
      "          [ 0.0344,  0.0663,  0.0020],\n",
      "          [ 0.0211,  0.0294,  0.0225]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0764, -0.0281, -0.0439],\n",
      "          [-0.0531, -0.0035, -0.0549],\n",
      "          [-0.0457, -0.0618, -0.0774]],\n",
      "\n",
      "         [[ 0.0305, -0.1280, -0.0603],\n",
      "          [-0.0326, -0.1136, -0.1351],\n",
      "          [-0.0856, -0.0791, -0.1000]],\n",
      "\n",
      "         [[ 0.0929,  0.0847,  0.0672],\n",
      "          [ 0.1049,  0.1314,  0.1101],\n",
      "          [ 0.0897,  0.1426,  0.1459]]],\n",
      "\n",
      "\n",
      "        [[[-0.0370, -0.0300, -0.0697],\n",
      "          [-0.0541, -0.0205, -0.0892],\n",
      "          [-0.0847, -0.1028, -0.0414]],\n",
      "\n",
      "         [[-0.0779, -0.1249, -0.1001],\n",
      "          [-0.1006, -0.1459, -0.1090],\n",
      "          [-0.1054, -0.0939, -0.1360]],\n",
      "\n",
      "         [[ 0.0150,  0.0026, -0.0144],\n",
      "          [-0.0122, -0.0205,  0.0189],\n",
      "          [ 0.0343,  0.0362,  0.0530]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0071,  0.0162,  0.0470],\n",
      "          [-0.0078,  0.0285,  0.0559],\n",
      "          [-0.0086,  0.0612,  0.0189]],\n",
      "\n",
      "         [[ 0.0180,  0.0663,  0.0420],\n",
      "          [ 0.0252,  0.0165,  0.0828],\n",
      "          [ 0.0569,  0.1275,  0.0522]],\n",
      "\n",
      "         [[-0.0009,  0.0152,  0.0649],\n",
      "          [ 0.0772,  0.0518,  0.0954],\n",
      "          [ 0.0677,  0.1427,  0.1512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0967,  0.1483,  0.1771],\n",
      "          [ 0.1083,  0.0994,  0.1345],\n",
      "          [ 0.1165,  0.1563,  0.1115]],\n",
      "\n",
      "         [[ 0.0970,  0.1156,  0.0903],\n",
      "          [ 0.0846,  0.1106,  0.0894],\n",
      "          [ 0.0721,  0.0801,  0.0336]],\n",
      "\n",
      "         [[-0.0065,  0.0015,  0.0220],\n",
      "          [ 0.0294,  0.0219,  0.0025],\n",
      "          [-0.0140, -0.0018,  0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0336,  0.0169,  0.0653],\n",
      "          [ 0.0205,  0.0432,  0.0483],\n",
      "          [ 0.0315,  0.0314,  0.0062]],\n",
      "\n",
      "         [[-0.0580, -0.1349, -0.0763],\n",
      "          [-0.1236, -0.0209, -0.0890],\n",
      "          [-0.1184, -0.1413, -0.1080]],\n",
      "\n",
      "         [[ 0.0453,  0.0628,  0.0480],\n",
      "          [ 0.0500,  0.0030,  0.0290],\n",
      "          [ 0.0590,  0.0263, -0.0064]]]], device='cuda:0')), ('backbone.model.layer4.0.bn2.weight', tensor([2.5348, 2.3447, 2.0033, 2.0314, 2.5776, 2.4908, 1.8956, 2.3614, 2.3521,\n",
      "        2.1670, 2.2263, 2.3317, 2.4407, 1.9646, 1.8071, 2.1475, 3.0960, 3.9641,\n",
      "        2.8229, 2.7850, 0.8820, 3.0654, 3.6467, 3.0639, 2.9901, 3.0124, 2.8475,\n",
      "        3.2683, 3.2007, 2.8840, 3.0533, 3.1059, 2.2590, 2.2039, 2.0652, 2.7271,\n",
      "        2.0144, 3.2792, 1.9420, 2.1105, 2.4109, 2.3264, 2.2552, 2.6191, 2.0144,\n",
      "        2.6368, 2.9921, 2.5541, 1.8699, 2.3123, 2.3344, 1.9881, 2.0423, 1.9334,\n",
      "        2.0522, 1.9814, 2.3799, 3.3159, 2.2704, 2.5003, 2.4687, 2.0015, 2.1468,\n",
      "        2.0613, 4.1725, 2.9301, 3.7826, 3.6878, 4.3583, 3.1253, 3.4494, 0.8388,\n",
      "        2.9495, 3.6991, 3.2246, 3.2706, 3.0442, 2.9915, 3.6594, 3.9195, 2.8512,\n",
      "        3.2470, 3.1185, 3.5035, 3.6425, 3.4040, 3.0764, 3.0781, 3.1151, 3.1446,\n",
      "        3.0097, 3.9437, 2.9593, 3.4013, 3.6873, 0.7473, 2.9561, 2.5561, 2.9431,\n",
      "        3.0051, 3.2377, 2.5567, 2.9987, 2.8816, 3.0106, 2.6325, 2.8410, 0.8951,\n",
      "        3.4704, 2.8539, 2.5856, 3.4866, 3.0773, 3.9844, 2.7481, 3.7198, 3.3012,\n",
      "        5.2067, 3.5440, 0.0691, 3.0979, 3.4952, 3.8911, 3.4236, 3.3386, 3.9671,\n",
      "        3.1791, 3.5892, 1.9341, 2.5307, 1.9174, 2.3888, 1.9823, 3.7027, 2.2240,\n",
      "        2.5999, 2.8676, 2.2963, 3.4012, 2.0340, 2.3797, 2.7386, 2.8120, 1.7316,\n",
      "        3.7279, 3.5032, 4.0268, 0.7768, 3.0464, 3.8496, 4.6632, 3.5624, 3.9630,\n",
      "        3.5212, 3.6343, 3.7650, 5.5648, 3.4471, 3.9345, 3.6952, 3.4944, 5.5411,\n",
      "        3.4262, 3.5853, 3.7916, 3.9809, 3.1936, 3.8035, 3.5380, 3.0577, 3.5062,\n",
      "        3.0743, 0.0465, 3.5290, 2.9848, 3.0803, 2.7934, 2.8627, 3.1504, 3.2252,\n",
      "        2.9850, 0.8654, 3.2313, 4.4704, 2.8715, 3.0273, 3.1422, 2.8227, 2.9969,\n",
      "        3.6665, 3.2751, 3.0394, 3.0968, 2.8980, 2.9241, 2.9975, 3.1332, 2.7664,\n",
      "        2.4324, 2.6101, 2.7444, 2.6029, 2.4217, 2.5410, 2.9128, 2.6102, 3.3068,\n",
      "        0.8750, 2.1604, 2.8228, 2.7268, 2.4672, 2.8601, 2.4507, 2.2043, 2.0106,\n",
      "        2.2348, 2.6372, 2.1206, 2.2260, 2.4786, 2.2714, 2.1088, 2.3551, 3.1469,\n",
      "        0.0669, 3.4781, 4.0842, 3.7326, 3.1222, 3.4043, 3.8470, 4.0010, 3.4922,\n",
      "        3.4541, 3.7219, 3.7004, 3.3638, 3.2784, 3.7137, 2.3365, 2.0552, 2.4059,\n",
      "        1.9499, 2.2557, 2.4693, 3.1659, 2.8186, 2.3019, 2.2419, 2.0412, 2.0610,\n",
      "        2.4013, 2.3580, 2.1255, 2.0197, 3.0612, 2.5078, 2.6525, 3.0730, 3.3219,\n",
      "        2.8339, 2.8784, 2.6540, 2.7914, 2.5504, 2.7326, 2.8662, 3.0708, 2.2504,\n",
      "        0.9427, 2.8593, 2.9167, 2.7074, 3.1012, 3.0496, 3.1539, 3.0545, 2.6452,\n",
      "        2.6230, 2.8026, 2.7809, 2.7227, 1.0998, 2.9379, 3.2662, 2.6948, 2.6886,\n",
      "        2.0090, 2.0987, 2.8491, 2.2035, 1.8679, 2.5925, 2.3490, 2.1789, 2.8924,\n",
      "        2.1531, 2.5898, 2.5709, 2.2514, 2.2794, 2.0887, 2.3079, 3.2238, 3.1588,\n",
      "        3.6737, 3.3604, 2.8046, 3.6042, 3.4309, 3.4933, 3.1338, 2.9667, 3.5088,\n",
      "        2.8406, 4.3427, 0.7924, 3.7095, 3.8465, 2.8989, 3.1205, 2.7959, 3.1491,\n",
      "        2.4951, 2.8564, 3.3901, 3.4197, 2.7984, 0.9304, 3.0155, 3.1426, 2.6438,\n",
      "        2.6778, 2.9128, 2.8521, 2.8072, 3.3848, 3.4417, 3.0172, 2.9333, 3.5360,\n",
      "        3.1527, 3.4204, 2.6315, 3.0389, 3.0747, 2.9496, 0.8313, 3.2911, 3.4127,\n",
      "        3.3973, 2.9125, 1.9133, 2.4203, 2.9096, 2.9374, 2.4704, 1.8373, 2.1278,\n",
      "        3.2718, 2.1398, 2.4610, 1.9109, 3.0565, 2.6065, 2.5745, 2.4759, 2.2937,\n",
      "        3.4456, 2.1446, 2.3480, 2.2236, 2.5306, 2.0083, 2.0663, 2.3990, 1.9612,\n",
      "        2.7240, 2.8435, 2.7655, 2.0734, 2.5438, 2.0046, 3.5161, 3.3411, 2.9278,\n",
      "        3.7273, 2.4800, 2.4765, 1.0458, 2.9934, 2.8711, 3.6068, 3.0336, 2.6521,\n",
      "        2.9305, 2.7865, 2.8600, 3.1801, 2.3531, 2.0834, 3.4561, 2.7511, 2.1852,\n",
      "        2.2029, 2.6559, 2.0196, 2.7689, 2.7792, 2.0936, 2.5012, 2.6113, 2.7676,\n",
      "        2.5128, 2.2967, 2.0147, 2.2018, 2.4062, 3.3085, 2.6661, 2.1879, 2.4057,\n",
      "        2.4783, 2.4399, 2.5898, 2.4493, 2.5509, 2.2552, 1.9356, 2.3371, 2.4797,\n",
      "        2.3170, 3.5704, 2.1519, 1.9309, 2.9361, 2.2527, 2.6678, 2.0314, 2.1913,\n",
      "        3.2419, 3.5262, 2.3497, 1.9281, 2.0828, 2.1785, 2.0414, 3.3933, 4.1416,\n",
      "        3.5085, 3.3177, 2.8395, 0.7920, 3.2675, 4.7876, 3.3158, 3.1851, 3.1935,\n",
      "        2.7493, 3.0195, 3.5091, 3.1858, 3.0499, 2.7935, 3.0371, 2.7859, 3.3021,\n",
      "        2.6417, 2.7111, 3.7549, 3.1178, 3.0392, 3.2865, 3.5454, 3.0530, 2.9080,\n",
      "        0.7493, 4.6898, 2.8869, 2.7874, 2.9684, 2.7963, 0.8702, 3.0165, 2.6629,\n",
      "        4.0718, 3.1877, 3.4334, 3.1840, 3.3018, 3.1303, 3.3862, 3.1479, 2.9812,\n",
      "        2.8498, 3.0441, 3.7133, 3.4395, 3.1894, 2.9481, 2.9327, 3.1152, 3.7516,\n",
      "        3.5204, 3.9538, 0.8711, 2.9599, 3.2466, 3.7338, 3.7428, 3.2154],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn2.bias', tensor([-1.7765, -0.8833, -1.0429, -1.4926, -2.4476, -1.6161, -0.8783, -0.6644,\n",
      "        -1.0538, -0.5843, -1.0836, -0.4260, -1.5425, -0.4182, -1.1482, -1.6096,\n",
      "        -0.7188, -1.2788, -0.6816, -0.6130, -4.5884, -0.7414, -0.7272, -0.9410,\n",
      "        -0.7843, -0.4868, -0.7728, -0.5505, -1.1632, -0.5114, -0.8480, -0.6789,\n",
      "        -0.8473, -1.0260, -1.1601, -1.3010, -0.9098, -1.3574, -2.2023, -1.0929,\n",
      "        -0.5289, -0.4999, -0.6194, -0.6962, -1.2396, -0.9654, -1.0119, -0.9156,\n",
      "        -1.2372, -1.9056, -1.1444, -1.2510, -0.7821, -1.3725, -0.5733, -1.1924,\n",
      "        -1.1904, -1.1211, -1.4374, -1.4232, -0.8382, -0.8730, -1.1935, -0.8223,\n",
      "        -1.1133, -0.3390, -0.6807, -0.6417, -1.2532, -0.3931, -0.7146, -3.3881,\n",
      "        -0.8703, -0.6067, -0.7796, -0.7652, -0.9643, -0.8355, -0.9055, -0.8956,\n",
      "        -0.5817, -0.8879, -0.8521, -0.9648, -0.6684, -0.7892, -0.7534, -0.5815,\n",
      "        -0.6385, -0.9478, -0.6663, -1.2679, -0.5957, -1.1935, -0.5942, -3.0708,\n",
      "        -0.6506, -0.5788, -0.4806, -0.4024, -0.6019, -0.2544, -0.3840, -0.4847,\n",
      "        -0.7998, -0.6041, -0.7725, -4.1187, -1.4985, -0.8494, -0.4149, -0.4486,\n",
      "        -0.9088, -0.9069, -0.8334, -0.9912, -1.0669, -1.7130, -1.0474, -1.5351,\n",
      "        -0.7441, -1.1434, -1.3014, -1.0752, -0.8347, -0.9586, -0.7930, -0.7564,\n",
      "        -1.3234, -0.9501, -0.6626, -1.5999, -0.7811, -1.5318, -1.4742, -1.5518,\n",
      "        -1.3045, -1.0811, -2.0722, -1.2624, -0.4534, -1.5879, -1.5301, -1.6608,\n",
      "        -0.3605, -0.4000, -0.2853, -4.2169, -0.2619, -0.2796, -0.8397, -0.1366,\n",
      "        -0.3485, -0.2976,  0.0532, -0.6401, -1.3516, -0.2932, -0.1957, -0.6688,\n",
      "        -0.7061, -1.5037, -0.6724, -0.6276, -0.9271, -0.8460, -0.7433, -0.6545,\n",
      "        -0.7817, -0.9931, -0.8928, -0.8371, -2.0725, -0.6511, -0.6252, -0.5136,\n",
      "        -0.9985, -0.7484, -0.5647, -0.6921, -0.7053, -4.0568, -0.9097, -1.0733,\n",
      "        -1.0500, -0.7646, -0.7770, -0.7330, -1.1969, -0.9122, -1.5775, -0.7106,\n",
      "        -0.9920, -1.0563, -0.8650, -1.1305, -0.8775, -0.5451, -0.5251, -0.9636,\n",
      "        -1.0972, -0.6786, -0.7091, -0.5624, -0.9358, -0.3864, -1.0273, -3.1687,\n",
      "        -1.4106, -1.7563, -1.4817, -0.5543, -1.8609, -1.7239, -0.6428, -1.4874,\n",
      "        -1.0508, -1.8188, -1.2512,  0.2032, -1.0135, -1.3166, -1.3863, -1.0823,\n",
      "        -0.9141, -1.9460, -0.9861, -1.0010, -0.5974, -0.5805, -0.5333, -0.7243,\n",
      "        -0.8451, -0.4753, -0.7196, -0.6115, -0.5541, -0.6587, -1.3612, -1.2031,\n",
      "        -1.2774, -0.9909, -0.8991, -0.9019, -1.8300, -1.3299, -0.8568, -1.6682,\n",
      "        -0.7938, -1.3533, -0.4450, -1.3978, -1.2952, -1.7635, -0.6237, -1.2229,\n",
      "        -1.2598, -0.6866, -0.4795, -1.2004, -1.3276, -0.7965, -0.8052, -1.0104,\n",
      "        -1.0351, -1.0152, -0.8419, -0.9534, -1.0798, -0.5044, -3.0359, -0.9749,\n",
      "        -0.6472, -0.7001, -1.1619, -0.9981, -0.9258, -1.2552, -0.5678, -1.1774,\n",
      "        -0.6152, -0.6631, -0.4474, -3.4435, -0.7755, -1.0101, -0.7191, -0.8182,\n",
      "        -1.1374, -0.2981, -1.8010, -1.1023, -1.1211, -1.6068, -1.5230, -1.6246,\n",
      "        -1.4016, -0.8934, -1.1917, -1.6265, -0.6809, -1.2182, -0.5447, -1.9627,\n",
      "        -0.7972, -0.5583, -0.7175, -0.6731, -0.5393, -0.6287, -0.9542, -0.8897,\n",
      "        -1.1055, -0.1640, -0.6660, -0.5313, -0.4071, -3.4776, -0.9390, -0.7041,\n",
      "        -0.8802, -0.8632, -1.0301, -1.0596, -0.4794, -0.9029, -0.8088, -1.2818,\n",
      "        -0.5894, -3.3695, -0.8199, -0.5208, -0.6516, -0.6640, -1.0299, -0.7393,\n",
      "        -0.7803, -1.0080, -0.7222, -0.5773, -0.6805, -0.8214, -1.1469, -0.9629,\n",
      "        -0.5374, -0.6859, -0.7537, -0.6814, -2.6941, -0.5167, -0.7797, -0.6886,\n",
      "        -1.3474, -1.0532, -2.5460, -1.4179, -1.5901, -1.4046, -1.3458, -1.7044,\n",
      "        -1.4336, -0.9493, -1.4705, -1.6837, -1.5287, -2.2345, -1.6561, -1.5207,\n",
      "        -1.0233, -1.6471, -1.0863, -0.6190, -1.4483, -1.1910, -0.7599, -0.8654,\n",
      "        -1.6294, -1.3995, -1.5697, -1.4568, -1.7439, -1.4516, -0.7167, -0.9567,\n",
      "        -1.5004, -1.1372, -0.7469, -1.1204, -0.8216, -0.6722, -4.7611, -0.5636,\n",
      "        -1.0150, -1.5465, -1.1942, -0.6005, -0.9141, -0.6436, -0.9489, -0.6173,\n",
      "        -0.8744, -1.6971, -1.6910, -0.9322, -1.0892, -0.2637, -2.3178, -2.0867,\n",
      "        -1.1232, -1.6409, -1.6167, -1.2349, -1.3580, -1.2897, -1.4566, -0.9762,\n",
      "        -0.4539, -1.0271, -0.2994, -1.4674, -0.8276, -1.7204, -1.6303, -1.1458,\n",
      "        -1.1930, -1.1318, -1.2072, -1.5621, -1.4367, -1.2828, -1.6344, -1.0117,\n",
      "        -0.3716, -1.1085, -1.0510, -0.7881, -1.4860, -1.4116, -0.3242, -1.2438,\n",
      "        -1.2422, -1.9109, -2.2078, -1.3432, -1.3035, -1.1173, -1.0982, -1.1951,\n",
      "        -1.1862, -1.1692, -0.8714, -0.8877, -0.6640, -3.3223, -0.9404, -1.4355,\n",
      "        -1.1263, -0.8925, -1.1889, -0.8066, -0.8860, -0.7776, -1.2517, -1.1408,\n",
      "        -0.8114, -0.5888, -0.5430, -1.0475, -0.6138, -0.9081, -1.0296, -1.1186,\n",
      "        -1.2764, -1.0699, -0.7722, -0.8573, -0.8410, -3.3895, -1.2882, -0.8511,\n",
      "        -0.7552, -0.6611, -0.9950, -3.4016, -0.7258, -0.6359, -2.0727, -1.5242,\n",
      "        -1.4238, -1.0857, -1.2631, -1.2010, -0.9616, -0.9182, -0.8008, -0.4650,\n",
      "        -0.7754, -1.1708, -0.6139, -0.5375, -0.6357, -0.7016, -0.5916, -0.6461,\n",
      "        -0.9640, -1.6404, -4.4988, -0.3682, -0.4919, -1.1425, -0.6332, -1.4307],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv3.weight', tensor([[[[-1.1125e-01]],\n",
      "\n",
      "         [[-3.9483e-02]],\n",
      "\n",
      "         [[ 7.4000e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7045e-02]],\n",
      "\n",
      "         [[ 5.2433e-02]],\n",
      "\n",
      "         [[-3.2876e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.2342e-02]],\n",
      "\n",
      "         [[-4.5983e-02]],\n",
      "\n",
      "         [[ 1.8164e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7445e-02]],\n",
      "\n",
      "         [[ 6.1139e-02]],\n",
      "\n",
      "         [[ 1.5066e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1137e-02]],\n",
      "\n",
      "         [[ 5.3812e-02]],\n",
      "\n",
      "         [[ 1.7362e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3272e-04]],\n",
      "\n",
      "         [[-1.1901e-01]],\n",
      "\n",
      "         [[ 2.4371e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.1120e-02]],\n",
      "\n",
      "         [[ 4.4639e-02]],\n",
      "\n",
      "         [[-1.0469e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5344e-02]],\n",
      "\n",
      "         [[-2.0878e-02]],\n",
      "\n",
      "         [[ 1.0435e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3318e-03]],\n",
      "\n",
      "         [[-4.0739e-02]],\n",
      "\n",
      "         [[-1.2891e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7942e-03]],\n",
      "\n",
      "         [[ 1.6873e-02]],\n",
      "\n",
      "         [[-1.8642e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2573e-02]],\n",
      "\n",
      "         [[ 2.7993e-02]],\n",
      "\n",
      "         [[ 4.5955e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6195e-02]],\n",
      "\n",
      "         [[-3.0345e-03]],\n",
      "\n",
      "         [[-6.6719e-02]]]], device='cuda:0')), ('backbone.model.layer4.0.bn3.weight', tensor([ 3.0456, -2.1132, -3.0351,  ..., -3.5985, -2.3328,  2.8157],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn3.bias', tensor([-0.2181,  0.0491,  0.3907,  ...,  0.3867,  0.2487,  0.1650],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.downsample.0.weight', tensor([[[[-2.5743e-02]],\n",
      "\n",
      "         [[ 2.0493e-02]],\n",
      "\n",
      "         [[-1.1936e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6353e-01]],\n",
      "\n",
      "         [[-2.6518e-02]],\n",
      "\n",
      "         [[-1.5096e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5896e-04]],\n",
      "\n",
      "         [[ 2.9651e-03]],\n",
      "\n",
      "         [[-8.6959e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0906e-02]],\n",
      "\n",
      "         [[-3.0955e-02]],\n",
      "\n",
      "         [[-2.0388e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8118e-02]],\n",
      "\n",
      "         [[ 2.1359e-02]],\n",
      "\n",
      "         [[-1.0336e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1156e-02]],\n",
      "\n",
      "         [[ 1.4221e-01]],\n",
      "\n",
      "         [[ 6.1775e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.0722e-02]],\n",
      "\n",
      "         [[-6.2133e-02]],\n",
      "\n",
      "         [[-3.2831e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3882e-03]],\n",
      "\n",
      "         [[-6.7392e-02]],\n",
      "\n",
      "         [[-1.8883e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2286e-02]],\n",
      "\n",
      "         [[-1.2046e-01]],\n",
      "\n",
      "         [[-3.2034e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2632e-01]],\n",
      "\n",
      "         [[-4.7911e-02]],\n",
      "\n",
      "         [[-8.9775e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6833e-02]],\n",
      "\n",
      "         [[-6.2321e-02]],\n",
      "\n",
      "         [[-6.3908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6825e-01]],\n",
      "\n",
      "         [[-4.6186e-02]],\n",
      "\n",
      "         [[ 9.1116e-03]]]], device='cuda:0')), ('backbone.model.layer4.0.downsample.1.weight', tensor([2.2027, 1.8375, 2.3178,  ..., 2.3435, 1.7922, 2.8509], device='cuda:0')), ('backbone.model.layer4.0.downsample.1.bias', tensor([-1.4447, -0.9765, -1.5430,  ..., -1.8776, -0.7044, -1.5631],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv1.weight', tensor([[[[ 0.0659]],\n",
      "\n",
      "         [[-0.0184]],\n",
      "\n",
      "         [[ 0.0104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[-0.1383]],\n",
      "\n",
      "         [[-0.0099]]],\n",
      "\n",
      "\n",
      "        [[[-0.0306]],\n",
      "\n",
      "         [[-0.0382]],\n",
      "\n",
      "         [[ 0.0438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         [[-0.1581]],\n",
      "\n",
      "         [[ 0.0711]]],\n",
      "\n",
      "\n",
      "        [[[-0.0321]],\n",
      "\n",
      "         [[ 0.0678]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0696]],\n",
      "\n",
      "         [[-0.0562]],\n",
      "\n",
      "         [[-0.0355]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0007]],\n",
      "\n",
      "         [[-0.0214]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         [[-0.0938]],\n",
      "\n",
      "         [[ 0.1091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0063]],\n",
      "\n",
      "         [[ 0.0725]],\n",
      "\n",
      "         [[ 0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0077]],\n",
      "\n",
      "         [[ 0.0530]],\n",
      "\n",
      "         [[ 0.0106]]],\n",
      "\n",
      "\n",
      "        [[[-0.0526]],\n",
      "\n",
      "         [[ 0.0758]],\n",
      "\n",
      "         [[-0.0616]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.0387]],\n",
      "\n",
      "         [[-0.0376]]]], device='cuda:0')), ('backbone.model.layer4.1.bn1.weight', tensor([3.5802, 3.0815, 3.6061, 2.5156, 2.6140, 2.5180, 2.5625, 2.2622, 3.1301,\n",
      "        2.5879, 0.7952, 2.3449, 6.2648, 2.7186, 3.1997, 3.7691, 3.0661, 2.3174,\n",
      "        2.3623, 2.1085, 2.1533, 2.4128, 2.5667, 2.3366, 3.4406, 2.6268, 2.3390,\n",
      "        3.8522, 3.2979, 2.4012, 3.8371, 0.6469, 0.5874, 2.3534, 2.7144, 2.7434,\n",
      "        2.5910, 2.1433, 2.0997, 2.6050, 2.1462, 3.0212, 4.2486, 2.4258, 1.9761,\n",
      "        2.4585, 2.5520, 2.3704, 2.6984, 5.0215, 2.3042, 2.7667, 2.8113, 2.3687,\n",
      "        2.5293, 2.7474, 3.3481, 3.3394, 2.3388, 2.1294, 0.6256, 2.3908, 2.4416,\n",
      "        2.6193, 3.1818, 3.5457, 3.1039, 3.5465, 3.1677, 2.7209, 3.1761, 1.0530,\n",
      "        3.5315, 3.8737, 4.8387, 4.3558, 2.7072, 4.7335, 2.9562, 3.1265, 2.9000,\n",
      "        2.5391, 2.2087, 2.1093, 2.1717, 2.2170, 2.9801, 2.5762, 2.6718, 2.1156,\n",
      "        3.8921, 2.3381, 2.9445, 0.6288, 2.3926, 3.8924, 2.9517, 2.3458, 2.8235,\n",
      "        2.8528, 3.1002, 4.1061, 0.7297, 3.9795, 3.1865, 3.3063, 2.6355, 2.2614,\n",
      "        2.4635, 3.3568, 2.6316, 2.9907, 2.5144, 2.3129, 2.4004, 2.6545, 3.6656,\n",
      "        2.4478, 0.7527, 2.4536, 5.6691, 3.5236, 2.7316, 3.6511, 4.1919, 3.4528,\n",
      "        2.6223, 2.4218, 2.6517, 3.7746, 4.0089, 2.8248, 3.5227, 3.8196, 2.5849,\n",
      "        4.1667, 2.7041, 0.1302, 2.4949, 4.1402, 2.5772, 2.9518, 5.4739, 4.8536,\n",
      "        3.1272, 2.2508, 3.7294, 2.7383, 2.4029, 3.9913, 4.4109, 0.6043, 3.0391,\n",
      "        3.0839, 2.5032, 2.4291, 2.5322, 2.1877, 2.2171, 3.0718, 2.0884, 1.9518,\n",
      "        1.9411, 1.5749, 1.9666, 1.8881, 1.6873, 1.6478, 1.6923, 2.4635, 1.7089,\n",
      "        1.7686, 2.1087, 1.9884, 1.4891, 2.1309, 0.5877, 2.2345, 4.7271, 2.5175,\n",
      "        2.8035, 3.6245, 5.7142, 2.9057, 3.2237, 2.8029, 2.2418, 2.8769, 2.9279,\n",
      "        2.6265, 2.4017, 2.9831, 2.4729, 3.1174, 3.0339, 2.4911, 2.6573, 0.6334,\n",
      "        2.3942, 2.4668, 2.4990, 4.7815, 3.0491, 2.4758, 2.2980, 2.8786, 2.5915,\n",
      "        2.3564, 2.5679, 3.4073, 3.1276, 2.8228, 5.7291, 2.5399, 4.0181, 3.9819,\n",
      "        4.6618, 7.7891, 3.1846, 0.6949, 2.5325, 5.2135, 4.6511, 2.2663, 1.8374,\n",
      "        2.7572, 2.4612, 2.2675, 2.4944, 2.1218, 3.9863, 2.5309, 0.6740, 3.6435,\n",
      "        3.3575, 2.5054, 4.3865, 2.2826, 2.0239, 2.0304, 2.6475, 2.8781, 2.6938,\n",
      "        3.5689, 3.3721, 5.2899, 3.7332, 2.7735, 3.4759, 2.8386, 2.3073, 0.7349,\n",
      "        2.8215, 2.3779, 3.4438, 3.1583, 5.2803, 0.7758, 3.2736, 3.2201, 3.4679,\n",
      "        3.9977, 2.0007, 3.1021, 2.3786, 2.5721, 2.8421, 3.4092, 4.0832, 2.7113,\n",
      "        3.8935, 4.9442, 2.6808, 3.1142, 4.1257, 4.4653, 3.3262, 3.5853, 4.5352,\n",
      "        3.5589, 2.8728, 2.6997, 2.8411, 2.5505, 2.9675, 3.2327, 2.7834, 0.7200,\n",
      "        2.8850, 3.0212, 2.6504, 5.4159, 3.6905, 3.2329, 2.9148, 2.3823, 4.2825,\n",
      "        4.3233, 3.9903, 3.0417, 2.4439, 0.1034, 4.1674, 2.8764, 2.3225, 1.9279,\n",
      "        2.5508, 2.8952, 3.1378, 1.8914, 2.2177, 3.8885, 2.2813, 2.8811, 2.6381,\n",
      "        2.2784, 0.6753, 6.2899, 1.7229, 2.2095, 2.9464, 2.7580, 3.5550, 2.7004,\n",
      "        3.2913, 3.0061, 2.5952, 3.8766, 2.0457, 5.4649, 4.2876, 2.8553, 0.6453,\n",
      "        2.7629, 4.0856, 2.8048, 0.6775, 3.4056, 3.1417, 2.8293, 2.6468, 2.1787,\n",
      "        2.5710, 2.3920, 2.1565, 2.1037, 2.4901, 3.0357, 2.3005, 2.6247, 2.8475,\n",
      "        1.7551, 4.2764, 2.4583, 2.6584, 1.9858, 5.0535, 2.1835, 3.1437, 2.6678,\n",
      "        2.7100, 2.3720, 4.0244, 2.5495, 2.5212, 3.1025, 0.6173, 3.0154, 0.6979,\n",
      "        3.6917, 2.8196, 5.4145, 2.7806, 2.1054, 3.1164, 2.1305, 2.1858, 2.2415,\n",
      "        3.4135, 3.0992, 2.8257, 2.5266, 2.6979, 1.8916, 3.0710, 4.0214, 2.9640,\n",
      "        2.8196, 0.6244, 2.9456, 2.5951, 2.5475, 3.6980, 2.7166, 2.2442, 3.7081,\n",
      "        2.7488, 3.8089, 2.5763, 3.1494, 2.3528, 2.1062, 2.1359, 2.3939, 0.6767,\n",
      "        2.8449, 4.6315, 2.0835, 1.9049, 1.9343, 1.8235, 2.1967, 2.3233, 1.8368,\n",
      "        8.8802, 3.8322, 2.2930, 2.3682, 3.2962, 2.2887, 2.1632, 1.9851, 0.5960,\n",
      "        2.2588, 1.8282, 2.5226, 2.2499, 2.0641, 2.4520, 2.4219, 2.4248, 2.6924,\n",
      "        3.3690, 2.2081, 7.8368, 2.9351, 0.6620, 2.4396, 3.7949, 2.8026, 2.9480,\n",
      "        3.3543, 3.6182, 4.2425, 3.4175, 2.2707, 3.9314, 4.5351, 4.7103, 4.3448,\n",
      "        2.5064, 2.3644, 3.0797, 1.3196, 0.9019, 2.5401, 2.4541, 2.5652, 2.6415,\n",
      "        2.2345, 1.6491, 2.1195, 1.8726, 2.3335, 2.1493, 4.3363, 4.4295, 3.1952,\n",
      "        2.3628, 2.8939, 2.1546, 2.8146, 2.3845, 2.7543, 1.8018, 3.2521, 0.6032,\n",
      "        2.1992, 2.7949, 3.8290, 4.0590, 2.3760, 2.7911, 2.9403, 3.8818, 4.2112,\n",
      "        2.5820, 2.4390, 3.0768, 3.1249, 3.0577, 2.6909, 0.6911, 2.8674, 2.6149,\n",
      "        5.2874, 3.8124, 3.1055, 3.5933, 0.7554, 2.8523, 2.1884, 2.8063, 2.8299,\n",
      "        2.2038, 4.3653, 3.1036, 4.2710, 3.8129, 2.6147, 2.9479, 3.5189],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn1.bias', tensor([-1.3066, -1.0343, -1.0440, -0.8812, -0.8340, -0.6520, -1.0145, -0.8190,\n",
      "        -1.0969, -0.5424, -3.0376, -0.9152, -3.1128, -0.7843, -0.9736, -1.2407,\n",
      "        -1.0977, -0.6157, -0.7340, -0.6171, -0.6788, -0.2581, -1.0163, -0.6366,\n",
      "        -1.0370, -0.5282, -1.2311, -1.0522, -1.0267, -1.0475, -1.1342, -2.5035,\n",
      "        -2.7653, -1.0539, -1.3448, -0.8629, -1.0912, -0.6318, -0.4191, -0.9962,\n",
      "        -1.6530, -1.1555, -1.4059, -1.2566, -0.3118, -1.0034, -0.9571, -0.6243,\n",
      "        -1.2140, -1.9096, -0.9028, -0.7752, -0.7955, -0.5370, -0.7218, -0.8365,\n",
      "        -1.3929, -1.0514, -0.3167, -0.9347, -2.2207, -0.7868, -0.5280, -0.7880,\n",
      "        -0.6300, -0.7821, -0.8443, -0.9563, -4.3106, -0.6163, -0.7798, -3.0029,\n",
      "        -0.4262, -1.0221, -1.5025, -0.7061, -0.4077, -1.5685, -0.6600, -0.6718,\n",
      "        -1.2649, -0.9545, -0.8267, -0.9299, -0.7750, -0.7181, -1.2141, -1.0055,\n",
      "        -1.6199, -0.7026, -1.6682, -0.8461, -1.8095, -1.9028, -0.6619, -1.2936,\n",
      "        -1.0218, -0.4410, -1.3485, -0.5657, -0.6866, -0.5320, -4.4934, -1.3317,\n",
      "        -1.0644, -1.0736, -0.9863, -1.9052, -0.4413, -0.9260, -0.6377, -0.9009,\n",
      "        -0.8565, -0.5617, -2.0629, -0.7526, -1.3763, -0.8613, -4.7778, -0.7027,\n",
      "        -2.2219, -1.2074, -1.0725, -1.4510, -1.2727, -1.4022, -0.5888, -0.5701,\n",
      "        -0.9651, -0.7652, -1.3435, -0.9693, -1.5639, -1.3436, -0.8142, -1.1971,\n",
      "        -0.9643, -3.8843, -2.7559, -0.9250, -0.8450, -0.8957, -2.3845, -1.9991,\n",
      "        -1.2474, -0.5727, -1.6655, -0.7360, -0.4633, -1.0483, -1.1817, -2.8612,\n",
      "        -0.9503, -0.9522, -1.2512, -1.0526, -1.1126, -0.6298, -0.6665, -1.0615,\n",
      "        -0.7277, -0.8016, -1.0186, -0.5989, -0.7876, -0.8993, -0.7824, -2.3743,\n",
      "        -1.5602, -1.2338, -0.5364, -0.6277, -1.0744, -1.2248, -0.3731, -1.2312,\n",
      "        -3.2187, -0.5264, -1.4521, -0.6441, -0.7017, -1.2262, -1.8288, -0.7549,\n",
      "        -1.3500, -0.7576, -0.8904, -0.8110, -0.8437, -0.7747, -0.7543, -0.6900,\n",
      "        -1.1013, -1.0689, -1.1914, -0.8680, -1.1080, -3.6125, -1.0543, -0.8177,\n",
      "        -0.8271, -2.4493, -1.2472, -0.7769, -0.9473, -1.3836, -0.6889, -0.8100,\n",
      "        -0.8334, -0.9851, -1.1922, -0.8343, -2.5154, -0.9577, -1.1707, -1.8766,\n",
      "        -1.4298, -3.8945, -1.1068, -4.4121, -0.7969, -1.9158, -1.7364, -0.4177,\n",
      "        -0.8293, -1.1174, -0.7598, -0.8918, -0.9324, -0.6643, -1.7760, -1.0923,\n",
      "        -1.8881, -1.7088, -2.0812, -1.1467, -1.4481, -1.0584, -0.6662, -0.7049,\n",
      "        -0.7444, -1.0055, -1.0364, -1.1320, -2.0287, -1.5461, -1.5044, -0.8821,\n",
      "        -0.7887, -0.7882, -1.1781, -3.9932, -0.7455, -0.7884, -1.0557, -0.9361,\n",
      "        -1.7897, -4.6601, -0.7765, -1.3787, -1.3301, -1.3985, -2.1939, -0.8464,\n",
      "        -0.5764, -0.8972, -0.4457, -0.9902, -1.3131, -0.7386, -1.4863, -1.8584,\n",
      "        -0.6894, -1.0094, -1.3773, -2.3793, -1.3608, -1.4994, -1.4696, -1.5360,\n",
      "        -0.5111, -0.8377, -1.0052, -0.6077, -1.2265, -0.8819, -0.9158, -4.0952,\n",
      "        -0.7662, -0.8325, -0.9448, -2.3880, -1.9977, -1.2267, -0.6557, -0.4781,\n",
      "        -1.0066, -1.9372, -1.3572, -1.0636, -0.7886, -2.5106, -1.1766, -0.6773,\n",
      "        -1.4443, -0.2602, -1.0402, -1.4859, -1.8195, -0.6495, -0.7158, -1.3494,\n",
      "        -0.8267, -1.4814, -0.8903, -0.9434, -3.3417, -2.3511, -0.6962, -1.0364,\n",
      "        -0.9862, -0.6891, -1.7284, -0.7128, -1.5244, -0.9383, -0.8123, -1.5912,\n",
      "        -0.7778, -2.6068, -1.1515, -1.0040, -3.5144, -0.7202, -1.9008, -1.1794,\n",
      "        -3.1138, -0.8144, -0.8847, -0.7155, -0.9456, -0.5780, -0.7691, -0.8922,\n",
      "        -0.5416, -0.5780, -0.7326, -1.3682, -0.7898, -1.0313, -0.7490, -1.0464,\n",
      "        -1.8314, -0.5334, -0.8413, -0.5646, -1.8407, -0.6052, -0.8657, -1.0110,\n",
      "        -0.8260, -1.1981, -1.5060, -0.7894, -1.0614, -0.9075, -3.0117, -1.1137,\n",
      "        -3.7366, -1.4148, -0.3166, -1.8581, -0.7616, -0.3516, -1.0344, -0.6740,\n",
      "        -0.3506, -0.4924, -1.1083, -1.2293, -0.8462, -0.6827, -1.1244, -1.5409,\n",
      "        -1.1150, -1.2337, -0.8269, -0.9751, -3.3032, -0.6633, -0.7963, -0.8292,\n",
      "        -1.4751, -0.9243, -0.5353, -0.5744, -1.0372, -1.3509, -0.7507, -1.0184,\n",
      "        -0.8934, -0.8065, -0.6539, -0.7287, -2.9527, -0.9650, -1.5301, -0.5646,\n",
      "        -0.5568, -0.3950, -0.5643, -0.6403, -1.0975, -0.9927, -3.9110, -1.5360,\n",
      "        -0.8617, -0.6989, -1.3792, -0.7029, -0.6922, -0.4327, -2.1103, -0.4887,\n",
      "        -0.8029, -1.3854, -0.6307, -0.7792, -0.7910, -0.9072, -0.7871, -0.8986,\n",
      "        -1.0854, -0.5726, -3.8156, -0.9734, -3.9074, -0.7324, -1.5568, -1.2896,\n",
      "        -1.0326, -1.4942, -1.0142, -1.3678, -0.9438, -0.6537, -1.4423, -1.6607,\n",
      "        -1.1805, -2.3200, -0.6120, -0.8011, -1.6398,  0.7714, -6.5013, -0.7158,\n",
      "        -0.6711, -0.8156, -0.7555, -0.6955,  1.6232,  0.7877,  1.1923, -0.1952,\n",
      "        -0.3705, -1.1081, -1.5651, -0.8247, -1.0604, -0.9834, -0.7491, -0.9401,\n",
      "        -1.1005, -0.9798, -1.4937, -0.9931, -2.4113, -0.3427, -0.6384, -1.1996,\n",
      "        -1.6631, -0.4658, -0.7688, -0.6562, -1.1137, -1.1701, -0.9928, -0.5745,\n",
      "        -1.0018, -0.9262, -0.9002, -0.9701, -4.5659, -1.1920, -1.0370, -2.7529,\n",
      "        -1.0619, -1.2704, -1.0960, -4.7947, -1.0091, -0.9150, -1.3841, -0.8132,\n",
      "        -0.6012, -1.9677, -0.5698, -1.3811, -1.0377, -1.1995, -1.1617, -1.3362],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv2.weight', tensor([[[[-0.0696, -0.0854, -0.0746],\n",
      "          [-0.0531, -0.0015, -0.0653],\n",
      "          [-0.0543, -0.0882, -0.0768]],\n",
      "\n",
      "         [[-0.0078,  0.0253, -0.0619],\n",
      "          [-0.0829, -0.0671, -0.0401],\n",
      "          [-0.0122, -0.0259,  0.0137]],\n",
      "\n",
      "         [[-0.0132, -0.0205,  0.0093],\n",
      "          [-0.0091, -0.0612, -0.0380],\n",
      "          [ 0.0194,  0.0226, -0.0018]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0021,  0.0162, -0.0104],\n",
      "          [-0.0397, -0.0446,  0.0239],\n",
      "          [ 0.0521,  0.0593,  0.0264]],\n",
      "\n",
      "         [[ 0.0337,  0.0475,  0.0871],\n",
      "          [ 0.0890,  0.0407,  0.0703],\n",
      "          [ 0.0706,  0.0931,  0.0357]],\n",
      "\n",
      "         [[-0.0860, -0.0822, -0.1093],\n",
      "          [-0.0256, -0.0195, -0.0576],\n",
      "          [-0.0909, -0.0788, -0.0502]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0365,  0.0430,  0.0308],\n",
      "          [ 0.0795,  0.0606,  0.0521],\n",
      "          [ 0.0659,  0.0440,  0.0264]],\n",
      "\n",
      "         [[ 0.0402, -0.0455,  0.0389],\n",
      "          [ 0.0079, -0.0177,  0.0660],\n",
      "          [ 0.0506,  0.0204,  0.0301]],\n",
      "\n",
      "         [[ 0.0119,  0.0225, -0.0291],\n",
      "          [ 0.0049, -0.0162,  0.0102],\n",
      "          [ 0.0529,  0.0273,  0.0366]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0712,  0.1390,  0.0936],\n",
      "          [ 0.0832,  0.1134,  0.0935],\n",
      "          [ 0.0277,  0.0319,  0.0071]],\n",
      "\n",
      "         [[ 0.0793,  0.0598,  0.0761],\n",
      "          [-0.0352, -0.0487, -0.0027],\n",
      "          [ 0.0092,  0.0403,  0.0255]],\n",
      "\n",
      "         [[-0.0139, -0.0085,  0.0387],\n",
      "          [-0.0401,  0.0185,  0.0311],\n",
      "          [ 0.0539,  0.0422,  0.0461]]],\n",
      "\n",
      "\n",
      "        [[[-0.0087, -0.0495, -0.0209],\n",
      "          [-0.0274, -0.0347, -0.0013],\n",
      "          [-0.0363, -0.0927, -0.0194]],\n",
      "\n",
      "         [[-0.0659, -0.0621, -0.0624],\n",
      "          [-0.0801, -0.0932, -0.0672],\n",
      "          [-0.0902, -0.0445, -0.0934]],\n",
      "\n",
      "         [[ 0.0007, -0.0443,  0.0141],\n",
      "          [ 0.0313, -0.0154,  0.0534],\n",
      "          [ 0.0513, -0.0184,  0.0562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0481, -0.0947, -0.0630],\n",
      "          [-0.1227, -0.1499, -0.0819],\n",
      "          [-0.0728, -0.0873, -0.1199]],\n",
      "\n",
      "         [[-0.0210, -0.0247, -0.0153],\n",
      "          [-0.0765, -0.0115, -0.0395],\n",
      "          [-0.0507, -0.0461, -0.0611]],\n",
      "\n",
      "         [[-0.0326, -0.0480,  0.0107],\n",
      "          [ 0.0533,  0.0368,  0.0668],\n",
      "          [ 0.0099, -0.0214, -0.0038]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0321,  0.0313, -0.0136],\n",
      "          [ 0.0204,  0.0739,  0.0259],\n",
      "          [-0.0031,  0.0671,  0.0283]],\n",
      "\n",
      "         [[-0.0719, -0.0310, -0.0478],\n",
      "          [-0.0702,  0.0082, -0.0718],\n",
      "          [-0.0460, -0.0681, -0.0741]],\n",
      "\n",
      "         [[-0.0441, -0.1194, -0.0885],\n",
      "          [-0.0556, -0.0634, -0.1278],\n",
      "          [-0.0984, -0.0764, -0.0979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0930,  0.0899,  0.1297],\n",
      "          [ 0.0492,  0.0193, -0.0171],\n",
      "          [ 0.0082, -0.0267,  0.0052]],\n",
      "\n",
      "         [[ 0.0191,  0.0483,  0.0055],\n",
      "          [ 0.0546,  0.1075,  0.0402],\n",
      "          [ 0.0397,  0.1084,  0.0694]],\n",
      "\n",
      "         [[ 0.0649,  0.0709,  0.1145],\n",
      "          [ 0.0357,  0.0052,  0.0369],\n",
      "          [ 0.0445,  0.1006,  0.0229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0031, -0.0107, -0.0073],\n",
      "          [-0.0281,  0.0149, -0.0371],\n",
      "          [-0.0670, -0.0329, -0.0544]],\n",
      "\n",
      "         [[-0.0523, -0.0828, -0.0688],\n",
      "          [-0.0584, -0.0706, -0.0450],\n",
      "          [-0.0704, -0.1069, -0.0614]],\n",
      "\n",
      "         [[ 0.0272,  0.0521,  0.0411],\n",
      "          [ 0.0885,  0.0870,  0.0451],\n",
      "          [ 0.0718,  0.1125,  0.0648]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0407, -0.0668, -0.0376],\n",
      "          [-0.0514, -0.0143, -0.0200],\n",
      "          [-0.0619, -0.0745, -0.0876]],\n",
      "\n",
      "         [[-0.0019,  0.0112, -0.0515],\n",
      "          [-0.0881, -0.1004, -0.0966],\n",
      "          [-0.0451, -0.0961, -0.0396]],\n",
      "\n",
      "         [[-0.0768, -0.0662, -0.0529],\n",
      "          [-0.0341, -0.0727, -0.0671],\n",
      "          [-0.0263, -0.0576, -0.0438]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.0037,  0.0319],\n",
      "          [ 0.0342, -0.0111,  0.0261],\n",
      "          [ 0.0629,  0.0145,  0.0237]],\n",
      "\n",
      "         [[-0.0258,  0.0055, -0.0292],\n",
      "          [-0.0147,  0.0127,  0.0237],\n",
      "          [-0.0267,  0.0260, -0.0120]],\n",
      "\n",
      "         [[-0.0346, -0.0512, -0.0664],\n",
      "          [-0.0325,  0.0230, -0.0701],\n",
      "          [ 0.0073, -0.0350, -0.0088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0423, -0.0605, -0.0374],\n",
      "          [-0.0456, -0.0830, -0.0779],\n",
      "          [-0.0291, -0.0555,  0.0148]],\n",
      "\n",
      "         [[-0.0170,  0.0089, -0.0636],\n",
      "          [ 0.0033, -0.0441, -0.0274],\n",
      "          [ 0.0371,  0.0076, -0.0154]],\n",
      "\n",
      "         [[-0.0664, -0.0937,  0.0064],\n",
      "          [-0.0105, -0.0889, -0.0392],\n",
      "          [-0.0770, -0.0460, -0.1120]]]], device='cuda:0')), ('backbone.model.layer4.1.bn2.weight', tensor([2.1864, 1.9280, 2.7044, 2.3575, 2.7352, 2.6606, 2.0999, 1.0829, 3.3370,\n",
      "        1.3340, 3.2443, 2.8303, 2.7262, 2.8775, 2.4398, 3.5566, 3.1597, 3.4936,\n",
      "        3.1565, 3.6323, 3.2555, 2.9758, 2.5234, 3.2622, 2.7411, 4.2296, 3.7546,\n",
      "        3.7125, 3.0454, 0.9889, 3.7742, 3.5873, 2.5223, 2.7980, 2.7927, 2.5301,\n",
      "        2.7752, 1.0456, 3.7106, 2.1523, 3.5275, 3.1583, 2.3727, 3.1535, 3.1632,\n",
      "        3.1005, 4.2142, 2.7404, 2.8433, 2.9486, 2.4443, 3.6761, 2.6147, 3.5324,\n",
      "        3.0318, 1.2856, 3.4409, 2.5919, 2.1008, 2.3011, 2.8864, 2.5634, 2.6018,\n",
      "        3.2442, 1.8974, 2.1523, 1.7223, 1.8057, 2.2793, 1.7542, 2.4861, 2.0020,\n",
      "        1.9405, 2.0337, 2.9248, 1.5728, 1.9215, 2.0185, 2.7387, 2.3957, 2.6344,\n",
      "        3.3667, 3.2538, 4.0653, 3.2675, 2.9785, 3.2579, 3.8978, 3.6865, 0.8769,\n",
      "        2.8214, 2.9553, 3.3726, 3.6476, 3.4486, 3.4726, 3.2495, 3.6588, 3.1567,\n",
      "        3.1699, 4.1796, 0.1029, 4.2862, 2.5823, 2.2962, 3.1342, 3.6080, 3.4456,\n",
      "        4.4713, 3.0771, 2.9943, 3.7801, 2.6141, 2.8937, 2.5491, 2.2995, 1.9387,\n",
      "        2.0539, 2.5894, 2.2351, 2.7963, 2.4869, 2.0458, 1.1865, 2.1041, 2.6171,\n",
      "        2.8538, 2.5816, 3.0889, 2.4337, 2.7994, 1.9032, 2.3123, 3.0631, 2.2747,\n",
      "        1.4581, 4.2745, 3.5284, 2.8094, 3.7590, 3.4285, 2.4611, 3.5714, 2.7610,\n",
      "        2.1132, 2.5640, 2.4025, 1.8994, 2.1894, 2.4209, 2.2799, 2.6607, 2.0615,\n",
      "        1.8578, 2.0621, 3.0940, 3.6223, 1.8458, 2.3871, 1.9870, 2.6067, 3.5968,\n",
      "        3.0555, 3.8167, 3.3340, 3.0700, 3.6678, 3.1269, 2.9813, 2.9063, 3.3921,\n",
      "        3.5012, 3.2306, 0.9859, 2.6967, 3.9038, 3.5402, 3.4468, 3.5044, 0.1660,\n",
      "        3.0917, 3.9799, 3.4501, 5.0615, 3.4564, 2.7300, 3.2331, 3.5529, 3.3975,\n",
      "        3.6456, 3.0327, 3.4325, 2.2354, 2.6561, 2.4361, 2.4282, 1.8808, 2.0312,\n",
      "        4.3317, 2.2149, 2.3012, 2.0849, 2.6045, 2.1979, 3.3045, 1.9502, 2.1289,\n",
      "        1.2784, 2.1611, 0.9803, 2.0989, 3.4259, 2.7871, 2.0110, 2.0029, 2.8229,\n",
      "        2.3389, 2.0551, 2.8276, 2.5189, 2.0989, 3.1358, 3.3994, 2.6951, 3.5634,\n",
      "        3.8864, 4.0430, 3.9020, 4.5365, 5.2544, 4.4061, 3.4833, 3.7093, 2.7353,\n",
      "        4.6672, 0.0928, 5.2005, 3.5366, 4.0649, 4.3468, 2.8086, 2.7992, 2.7064,\n",
      "        2.4287, 2.2421, 3.5500, 3.7944, 2.6337, 2.5705, 2.6543, 4.5468, 2.4581,\n",
      "        1.6465, 2.5721, 1.1272, 3.5963, 2.2673, 1.8943, 2.1991, 1.0571, 2.8119,\n",
      "        3.4325, 3.0235, 2.3124, 2.1737, 2.6446, 2.3345, 2.0673, 1.9337, 2.2561,\n",
      "        2.0557, 2.5382, 2.3252, 2.8637, 2.2121, 2.7045, 3.3805, 2.0615, 3.0512,\n",
      "        2.3976, 2.0652, 2.0696, 2.3624, 1.2102, 3.1079, 2.6877, 1.9189, 2.1571,\n",
      "        2.8633, 3.9168, 0.8884, 3.1606, 3.0666, 2.5747, 2.6675, 3.4044, 3.0453,\n",
      "        2.6667, 2.2284, 2.6729, 2.2711, 3.3599, 3.1457, 3.6364, 2.8005, 2.8182,\n",
      "        2.6736, 2.8625, 2.9680, 2.9114, 2.7005, 2.9383, 2.4247, 2.7493, 2.2164,\n",
      "        1.1371, 2.8145, 3.2227, 2.6100, 2.6113, 4.1444, 3.7389, 3.8578, 3.7833,\n",
      "        3.7409, 3.4039, 3.2696, 3.0337, 0.0701, 3.7720, 3.5695, 5.9179, 3.5103,\n",
      "        4.1280, 3.8489, 4.6474, 1.8655, 1.7772, 2.0756, 2.1491, 2.1487, 2.6874,\n",
      "        1.8219, 2.3571, 1.9825, 2.4192, 2.4050, 1.4154, 2.8007, 2.1861, 2.1482,\n",
      "        1.6854, 2.1643, 2.2072, 2.4855, 2.1718, 2.6376, 3.8144, 2.3959, 2.8501,\n",
      "        2.3125, 1.0627, 2.3600, 2.6915, 2.4221, 3.3584, 2.8980, 1.9830, 0.1273,\n",
      "        2.9255, 2.5885, 3.7754, 4.3181, 4.3501, 9.3819, 4.3041, 4.0945, 4.0310,\n",
      "        3.2350, 6.8520, 5.3303, 3.8957, 3.6588, 3.4015, 1.6708, 3.2161, 2.2772,\n",
      "        2.2338, 1.9515, 2.9338, 1.9752, 2.3619, 2.4178, 1.4755, 1.4740, 1.8293,\n",
      "        2.0830, 1.9569, 1.6964, 2.0180, 1.8891, 1.9150, 2.6883, 2.7362, 1.9251,\n",
      "        2.2297, 2.1454, 1.2273, 2.1417, 2.6172, 1.7390, 1.9461, 2.1652, 1.9223,\n",
      "        2.2463, 2.5527, 2.6086, 3.2779, 3.7947, 3.3413, 2.3741, 2.8616, 1.7001,\n",
      "        2.9845, 2.6164, 2.9571, 2.7818, 2.7728, 2.6704, 2.5120, 0.1375, 2.8188,\n",
      "        2.2120, 1.8039, 2.7215, 1.6274, 1.7595, 2.2603, 1.9476, 1.9816, 2.1812,\n",
      "        1.6959, 2.0890, 1.9955, 2.0775, 1.6354, 2.6198, 1.8321, 0.1276, 4.1400,\n",
      "        3.8057, 4.0206, 3.6555, 5.3820, 4.3126, 4.2908, 4.3852, 5.5130, 4.0712,\n",
      "        3.8279, 6.2307, 5.4069, 3.9134, 5.2269, 2.4986, 2.5185, 2.7570, 2.6099,\n",
      "        2.9495, 2.3051, 2.5171, 2.1321, 4.4510, 2.8135, 0.9803, 2.5634, 3.4294,\n",
      "        2.2952, 2.4761, 2.1848, 2.4029, 1.6462, 2.2430, 3.0554, 2.1726, 1.8015,\n",
      "        1.5154, 3.3903, 2.1464, 1.9146, 1.4978, 1.8399, 1.9933, 2.3742, 2.8797,\n",
      "        1.5398, 2.6587, 2.4607, 2.8120, 2.7111, 3.5261, 2.6907, 3.2259, 3.3745,\n",
      "        0.9694, 2.8597, 2.2398, 2.2938, 2.5859, 3.2250, 2.3122, 3.5269],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn2.bias', tensor([-0.2910, -0.8224, -1.0211, -0.6264, -1.1507, -0.7867, -0.5075, -3.7610,\n",
      "        -1.0820, -0.9519, -1.4940, -1.2195, -1.1806, -1.1384, -1.6249, -0.7988,\n",
      "        -0.8381, -2.3586, -1.2844, -1.9951, -1.2949, -1.0223, -0.5901, -0.5252,\n",
      "        -1.1890, -1.2951, -1.6207, -1.2028, -1.0717, -4.4066, -1.8066, -1.3652,\n",
      "        -1.1338, -0.6275, -1.6226, -1.0803, -2.0531, -4.1501, -1.8376, -0.4877,\n",
      "        -2.8594, -2.4620, -2.0433, -1.6164, -1.3265, -0.8831, -2.0438, -0.8029,\n",
      "        -1.7008, -1.8931, -1.1687, -1.7163, -1.0187,  0.3485, -1.5921, -5.0666,\n",
      "        -1.6902, -1.0038, -0.7580, -1.9643, -1.3956, -1.0800, -1.2118, -2.2051,\n",
      "        -1.0978, -1.5572, -0.6803, -3.1943, -2.9018, -2.0797, -2.1187, -1.0235,\n",
      "        -1.0924, -0.6781, -1.1260, -0.3369, -1.2918, -0.9742, -2.3949, -1.5789,\n",
      "        -0.8999, -1.8909, -1.7020, -2.7863, -1.1852, -1.4428, -1.3754, -1.3376,\n",
      "        -1.7983, -3.5400, -1.2881, -1.0638, -1.7311, -1.7959, -1.3942, -1.5163,\n",
      "        -1.2445, -1.7027, -1.9454, -1.4876, -2.0470, -1.6293, -1.6064, -0.9507,\n",
      "        -0.2792, -1.5436, -1.3140, -1.8859, -2.5796, -1.1106, -0.9595, -1.9915,\n",
      "        -0.7758, -1.0221, -1.9239, -1.4307, -0.9034, -0.8485, -1.3587, -1.9402,\n",
      "        -1.2504, -1.6061, -0.3462, -3.2746, -1.4377, -1.3694, -1.7812, -1.1532,\n",
      "        -1.1712, -0.8413, -1.2533, -3.2130, -0.3979, -2.5937, -0.3974, -3.9772,\n",
      "        -2.6724, -1.9631, -1.2717, -1.5807, -3.0875, -0.9283, -1.4287, -1.2028,\n",
      "        -1.1975, -2.1310, -2.3647, -1.2834, -2.2627, -1.0375, -1.4854, -3.5771,\n",
      "        -0.7686, -1.7626, -2.3067, -1.9882, -3.2084, -3.3659, -1.4654, -1.8835,\n",
      "        -1.5031, -0.5821, -1.0901, -1.1486, -0.3911, -0.6935, -0.2257, -0.6447,\n",
      "        -0.4271,  0.0617, -0.1320, -0.2951, -0.4146, -3.9091, -1.7401, -0.7849,\n",
      "        -0.5433, -1.2004, -0.8006, -2.4225, -0.8578, -1.2573, -1.6962, -2.2576,\n",
      "        -1.4746, -0.7573, -1.4949, -1.3136, -1.3165, -1.8412, -0.6672, -1.0251,\n",
      "        -0.8973, -1.2995, -0.8221, -0.9063, -0.1545, -0.1907, -1.9759, -0.4264,\n",
      "        -0.5889, -0.5760, -0.5318, -0.4473, -1.3704,  0.0094, -0.6014, -5.1244,\n",
      "        -0.9184, -3.3049, -0.7983, -1.5952, -1.9063, -0.6729, -0.7733, -1.5820,\n",
      "        -1.2192, -0.8635, -1.9160, -1.9302, -0.8180, -2.1327, -1.9280, -1.4532,\n",
      "        -0.4576, -0.7171, -1.6185, -1.5863, -0.3781, -1.4648, -0.7639, -0.4538,\n",
      "        -0.5503, -1.1487, -0.7711, -1.2558, -3.4236, -0.4967, -0.9692, -0.3478,\n",
      "        -1.3975, -1.0503, -1.2146, -0.7758, -0.8133, -1.7851, -1.8847, -1.0909,\n",
      "        -1.4001, -1.0400, -2.3392, -1.6838, -0.8835, -0.8552, -4.3334, -2.1614,\n",
      "        -0.7530, -0.8519, -1.4152, -3.4265, -1.3863, -2.2804, -2.4042, -1.0045,\n",
      "        -0.7006, -1.3411, -1.0611, -0.6288, -1.0700, -1.3517, -0.8298, -1.3088,\n",
      "        -0.6215, -1.5673, -1.1255, -1.6023, -2.0826, -0.9311, -2.0395, -1.5234,\n",
      "        -0.9697, -1.2327, -1.4501, -4.0407, -1.4923, -1.3861, -1.0921, -1.7348,\n",
      "        -1.4449, -1.4998, -3.5353, -1.7041, -1.9372, -0.3703, -0.9032, -1.4790,\n",
      "        -1.5853, -1.0336, -0.8604, -1.1253, -0.7204, -1.1258, -1.3427, -2.9068,\n",
      "        -0.3904, -1.4555, -1.3890, -1.0614, -1.4366, -1.3614, -1.1089, -1.6524,\n",
      "        -1.7253, -1.0669, -0.7565, -4.6977, -1.4787, -1.9068, -0.6371, -1.1122,\n",
      "        -1.2690, -1.7654, -1.8993, -1.5296, -0.5406, -1.8900, -0.8688, -0.9809,\n",
      "        -1.0298, -1.1889, -1.4032, -1.1003, -2.0522, -0.7965, -1.1826, -0.9061,\n",
      "        -1.6783, -1.4615, -1.0581, -0.8910, -2.1724, -2.6491, -3.5281, -1.4505,\n",
      "        -1.1297, -1.1228, -2.2898,  0.0534, -1.1163, -1.9961, -1.4401, -2.1114,\n",
      "        -0.9751, -0.8469, -1.3276, -0.7403, -1.0516, -2.6435, -0.9586, -1.2061,\n",
      "        -0.9734, -3.6167, -1.7422, -0.9549, -0.8377, -2.1566, -2.0534, -0.6502,\n",
      "        -1.7703, -1.8911,  1.4402, -0.6380, -0.6994, -1.4521,  0.7943, -0.3183,\n",
      "        -0.3074, -0.2983, -2.0585, -1.7731, -1.5802, -0.8530, -0.1452, -0.3159,\n",
      "         0.0196, -2.7921, -0.8810, -1.1364, -0.0793, -3.1241, -2.4747, -1.5680,\n",
      "        -1.5379, -1.6591, -1.0815, -2.7584, -1.8884, -1.3951, -0.8150, -1.0815,\n",
      "        -0.4258, -0.4754, -0.8313, -2.2690, -0.8650, -1.0047, -0.2635, -4.1029,\n",
      "        -1.1553, -1.5925, -0.4885, -0.4615, -0.8192, -0.8885, -1.6280, -1.3548,\n",
      "        -0.2157, -1.1673, -1.9785, -1.5412, -1.6100, -1.2417, -0.7270, -2.4960,\n",
      "        -0.8065, -1.2201, -1.1368, -0.8159, -1.3745, -1.3831, -1.5051, -1.0323,\n",
      "        -1.9344, -0.8259, -2.0803, -0.7358, -0.3791, -1.4218, -1.2508, -0.8571,\n",
      "        -1.1922, -0.4919, -0.9371, -2.6991, -2.9999, -0.7295, -1.1847, -3.3248,\n",
      "        -2.1222, -1.6002, -0.6862, -2.5914, -0.6918, -3.2399, -0.9921, -1.0254,\n",
      "        -0.1130, -2.6462, -1.6869, -0.6757, -2.7903, -0.8407, -0.0653, -2.9889,\n",
      "        -0.8454, -1.1314, -1.3414, -1.6134, -1.0161, -0.1290, -0.6918, -0.3209,\n",
      "        -2.4660, -1.2971, -4.1949, -1.0374, -1.3251, -0.6930, -0.8050, -0.4826,\n",
      "        -1.6305, -3.5595, -1.7442, -1.3930, -1.4176, -1.0760, -1.2620, -3.8088,\n",
      "        -1.0659, -0.6625, -0.4634, -0.5871, -0.7928, -1.4905, -2.5206, -0.6154,\n",
      "        -0.7167, -0.6063, -1.0846, -0.8032, -1.4369, -1.0054, -1.3968, -1.4113,\n",
      "        -3.7246, -0.8006, -0.7236, -0.4813, -0.4346, -1.1232, -0.8401, -1.6943],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv3.weight', tensor([[[[-0.0399]],\n",
      "\n",
      "         [[ 0.0857]],\n",
      "\n",
      "         [[ 0.2080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         [[ 0.0296]],\n",
      "\n",
      "         [[ 0.0591]]],\n",
      "\n",
      "\n",
      "        [[[-0.0568]],\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         [[ 0.0447]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1187]],\n",
      "\n",
      "         [[-0.1218]],\n",
      "\n",
      "         [[-0.1214]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0169]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[ 0.0410]],\n",
      "\n",
      "         [[-0.0641]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0502]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         [[ 0.0339]],\n",
      "\n",
      "         [[-0.0546]]],\n",
      "\n",
      "\n",
      "        [[[-0.0075]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.0382]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0825]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.0742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299]],\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         [[ 0.0494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0507]],\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[ 0.0535]]]], device='cuda:0')), ('backbone.model.layer4.1.bn3.weight', tensor([-2.5672, -2.3754, -4.0941,  ...,  4.2259, -2.8889, -2.8292],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn3.bias', tensor([-0.0643, -0.1564, -0.5905,  ..., -0.1106,  0.1808, -0.3960],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.conv1.weight', tensor([[[[-0.0077]],\n",
      "\n",
      "         [[ 0.0734]],\n",
      "\n",
      "         [[-0.0834]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0989]],\n",
      "\n",
      "         [[-0.1062]],\n",
      "\n",
      "         [[-0.1794]]],\n",
      "\n",
      "\n",
      "        [[[-0.1203]],\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         [[-0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         [[ 0.0632]],\n",
      "\n",
      "         [[-0.0094]]],\n",
      "\n",
      "\n",
      "        [[[-0.0585]],\n",
      "\n",
      "         [[ 0.0371]],\n",
      "\n",
      "         [[-0.2583]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0743]],\n",
      "\n",
      "         [[ 0.0256]],\n",
      "\n",
      "         [[-0.0935]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0452]],\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         [[-0.0758]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0649]],\n",
      "\n",
      "         [[-0.0334]],\n",
      "\n",
      "         [[-0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0787]],\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[ 0.0532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[ 0.0796]],\n",
      "\n",
      "         [[-0.1334]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0881]],\n",
      "\n",
      "         [[-0.1099]],\n",
      "\n",
      "         [[-0.0500]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0090]],\n",
      "\n",
      "         [[-0.0352]],\n",
      "\n",
      "         [[-0.0540]]]], device='cuda:0')), ('backbone.model.layer4.2.bn1.weight', tensor([0.3368, 1.2404, 3.7873, 4.2119, 3.3377, 4.9257, 5.1942, 0.5783, 4.2024,\n",
      "        3.0010, 2.5283, 3.1915, 3.6558, 0.9524, 2.6945, 4.7798, 1.1760, 3.4175,\n",
      "        3.4622, 0.1061, 2.9341, 2.7215, 1.2425, 2.7715, 2.8132, 2.7178, 2.3072,\n",
      "        2.1156, 3.7392, 2.8828, 2.1026, 3.0060, 3.6666, 2.9093, 3.5852, 0.1023,\n",
      "        0.8239, 3.2705, 3.9174, 4.1574, 2.7249, 0.9926, 3.1868, 2.1785, 1.1711,\n",
      "        3.8426, 1.9415, 2.2567, 1.6149, 3.3087, 2.3254, 1.5495, 0.0513, 1.0793,\n",
      "        3.4240, 0.6471, 1.4294, 2.4232, 3.9285, 3.0102, 3.1478, 4.4571, 2.4567,\n",
      "        2.9874, 4.2474, 4.9545, 1.0487, 1.7774, 0.0978, 2.7495, 3.5135, 0.5343,\n",
      "        2.5650, 3.0869, 2.6378, 4.3600, 3.8155, 2.7363, 1.4792, 2.5205, 3.3485,\n",
      "        1.2677, 1.6529, 1.0610, 4.0384, 1.9029, 4.3920, 2.5398, 0.1041, 0.5030,\n",
      "        2.4846, 3.9355, 3.0617, 4.2935, 3.2057, 3.2600, 4.2375, 4.3006, 3.2438,\n",
      "        3.2792, 3.9063, 1.7483, 3.5923, 0.5657, 0.1294, 1.6525, 4.4143, 3.7637,\n",
      "        1.2534, 1.0138, 3.5659, 1.9104, 3.3013, 0.8711, 4.2860, 1.7949, 3.8327,\n",
      "        2.2329, 3.8656, 3.8038, 3.0967, 3.3424, 3.8080, 1.0246, 1.4234, 2.6791,\n",
      "        3.1997, 0.4519, 0.0401, 3.6044, 1.0451, 1.5153, 3.0645, 3.7059, 2.1804,\n",
      "        0.8146, 3.6026, 2.0163, 2.6730, 2.9057, 4.3326, 3.2520, 1.9205, 3.3418,\n",
      "        0.7316, 4.5990, 0.1456, 0.7470, 1.1874, 2.9131, 3.7183, 1.2537, 4.1204,\n",
      "        3.7558, 3.7821, 1.7927, 3.0109, 2.2329, 1.8674, 3.4286, 3.5297, 1.2679,\n",
      "        4.1434, 0.6314, 4.0867, 3.1437, 3.5224, 4.0237, 4.3091, 2.5144, 0.0954,\n",
      "        3.4365, 1.8160, 4.0107, 2.3851, 1.3189, 0.7797, 0.7774, 0.1259, 2.2012,\n",
      "        4.3218, 1.0823, 3.3053, 5.3729, 2.8608, 3.6647, 2.9430, 3.8408, 1.1048,\n",
      "        1.6561, 0.7790, 2.7376, 4.4452, 3.1462, 2.3850, 4.1645, 1.3151, 3.4021,\n",
      "        3.1030, 1.5468, 3.8547, 3.5520, 3.2076, 4.6806, 0.6747, 0.1508, 1.9941,\n",
      "        4.0569, 3.5235, 2.6210, 4.0470, 1.3139, 3.3511, 4.2225, 0.6496, 3.5329,\n",
      "        3.0521, 4.3541, 0.3899, 2.9304, 2.3164, 2.8473, 1.6500, 2.9899, 3.7564,\n",
      "        0.6377, 2.7592, 0.9692, 1.0367, 2.2290, 4.4721, 2.7687, 4.4113, 2.7712,\n",
      "        1.2061, 0.1072, 3.3809, 3.7312, 2.4254, 0.6689, 4.1594, 2.9724, 2.2854,\n",
      "        1.9215, 2.8009, 2.9663, 4.2375, 3.1929, 0.4539, 4.3265, 3.4597, 4.7680,\n",
      "        0.8470, 3.3937, 4.0941, 3.5650, 2.2399, 1.8234, 3.8025, 2.9865, 0.1422,\n",
      "        2.9549, 2.6466, 2.6327, 1.2318, 1.2301, 0.9514, 0.9666, 6.5264, 3.7544,\n",
      "        3.0347, 2.2564, 3.8834, 2.6941, 4.0237, 3.0957, 3.4456, 3.1417, 1.2100,\n",
      "        0.0513, 2.1700, 4.1778, 2.4202, 2.2086, 2.6857, 3.1039, 1.5845, 3.5775,\n",
      "        4.0894, 0.6563, 4.3436, 3.4315, 4.3181, 3.3433, 4.3639, 1.5866, 4.0682,\n",
      "        0.3791, 0.1053, 5.7390, 3.5305, 2.2030, 2.4280, 3.7595, 4.3310, 3.7585,\n",
      "        0.0659, 2.4763, 0.5311, 4.1208, 4.4092, 4.5438, 3.6428, 3.9190, 2.6357,\n",
      "        2.0522, 4.0827, 4.0326, 2.4505, 1.9966, 5.9095, 3.5534, 3.5439, 4.3125,\n",
      "        1.6131, 3.4242, 2.2998, 1.3907, 1.9295, 0.7218, 0.3003, 3.7376, 3.4895,\n",
      "        1.4777, 1.1289, 1.7856, 0.5017, 3.5403, 0.7437, 3.1674, 3.5823, 2.1576,\n",
      "        3.5028, 4.0101, 0.6142, 2.1050, 2.8176, 4.0729, 4.1077, 1.1580, 3.2980,\n",
      "        1.7076, 4.3441, 3.4759, 3.1620, 3.3423, 5.1602, 2.0446, 2.3910, 2.6058,\n",
      "        2.9759, 3.3123, 4.3459, 3.0756, 0.1350, 3.3100, 1.2853, 3.9127, 3.2748,\n",
      "        1.9686, 3.6841, 3.0667, 2.1464, 2.5231, 4.2638, 3.3116, 1.6756, 4.1338,\n",
      "        3.4092, 0.4564, 3.6255, 3.1445, 1.6324, 3.5427, 3.0722, 4.4590, 4.6963,\n",
      "        3.3331, 2.1054, 0.7626, 4.6054, 0.0922, 1.8920, 3.2071, 3.3954, 3.5988,\n",
      "        2.2405, 2.0394, 3.9292, 2.9337, 4.2624, 4.5251, 3.8580, 1.4637, 2.0882,\n",
      "        3.2220, 3.3738, 1.5978, 0.0436, 3.8645, 3.4588, 4.2093, 1.4535, 2.6906,\n",
      "        3.3268, 5.4094, 1.3737, 3.4031, 4.0350, 4.1636, 3.6246, 2.6126, 2.4942,\n",
      "        0.8612, 4.0264, 2.9625, 3.5160, 0.0842, 4.2225, 0.8231, 3.7634, 1.2219,\n",
      "        1.0626, 2.7898, 0.5261, 0.8266, 2.9302, 2.7338, 2.5269, 1.9796, 3.8460,\n",
      "        3.4408, 0.4670, 0.6619, 1.4296, 3.2750, 0.8275, 3.8343, 4.0349, 4.2995,\n",
      "        4.1212, 2.4292, 1.1434, 0.4301, 2.1368, 1.5975, 3.0299, 4.2500, 1.9865,\n",
      "        2.5910, 3.7753, 0.6876, 3.4829, 0.6637, 1.7691, 2.2520, 4.6379, 1.8056,\n",
      "        3.5084, 3.4743, 2.3986, 1.5696, 4.3049, 3.7821, 1.6312, 4.7932, 4.4525,\n",
      "        0.0897, 3.5907, 2.8033, 4.7182, 3.2714, 1.1037, 3.1747, 2.7622, 0.6471,\n",
      "        4.7565, 2.0260, 2.5997, 3.2259, 2.9342, 0.1029, 4.2967, 2.7205, 2.9606,\n",
      "        2.3162, 3.1822, 4.5063, 1.1952, 0.6591, 3.9564, 2.6812, 2.6267, 0.1325,\n",
      "        1.6490, 4.8581, 2.1496, 1.4328, 3.9240, 3.6022, 4.5672, 1.5115],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn1.bias', tensor([-1.8994,  0.7720, -5.9501, -1.4184, -1.1144, -1.9177, -1.8897, -0.4536,\n",
      "        -1.4320, -1.0455, -0.7207, -1.0062, -1.2897, -0.2664, -0.8527, -2.0719,\n",
      "        -0.4532, -1.5032, -1.5672, -2.6030, -1.2798, -1.0269, -0.5850, -1.2526,\n",
      "        -1.2137, -1.1437, -1.0900, -0.7820, -1.6093, -1.4275, -0.8029, -1.0270,\n",
      "        -1.9279, -1.2643, -1.6483, -2.3562, -0.3602, -1.5293, -1.9428, -1.9409,\n",
      "        -1.1894, -0.4876, -1.5456, -0.8275, -0.5255, -1.8294, -0.9194, -0.9412,\n",
      "        -0.8530, -1.0997, -0.8178, -0.6053, -1.8308, -0.2316, -1.2278, -0.6458,\n",
      "        -0.4552, -1.0276, -1.5043, -1.1128, -1.1917, -1.3813, -0.8894, -1.1685,\n",
      "        -1.7263, -1.9684, -0.3486, -0.6017, -2.3134, -1.0606, -1.4247, -0.7767,\n",
      "        -0.9282, -1.1066, -1.0291, -1.7700, -1.4677, -1.0035, -0.4635, -0.9777,\n",
      "        -1.1870, -0.5375, -0.5628, -0.2725, -1.6070, -0.6784, -1.6921, -0.8324,\n",
      "        -2.4094, -0.7986, -0.8511, -1.5533, -1.1000, -1.4517, -1.0552, -1.2065,\n",
      "        -1.6857, -1.5502, -1.2280, -1.5400, -1.4357, -0.5643, -1.2620, -0.7629,\n",
      "        -2.9009, -0.5194, -1.6877, -1.5014, -0.3403, -0.2445, -1.4053, -0.7143,\n",
      "        -1.7591, -0.2939, -1.9580, -0.7661, -1.6828, -0.7687, -1.4093, -1.4131,\n",
      "        -0.9789, -1.5381, -1.5744, -0.3821, -0.5160, -1.1550, -1.3618, -3.7983,\n",
      "        -1.8277, -1.5974, -0.3608, -0.8862, -1.3962, -1.4289, -0.9429, -0.2611,\n",
      "        -1.5681, -0.8688, -1.1769, -1.2274, -1.6243, -1.3753, -0.7499, -1.3428,\n",
      "        -0.3502, -1.8249, -3.3467, -0.4348, -0.3807, -1.0724, -1.5238, -0.5142,\n",
      "        -1.5990, -1.5053, -1.5204, -0.6994, -1.1561, -0.8958, -0.6754, -1.3352,\n",
      "        -1.2043, -0.3320, -1.6228,  0.1023, -1.6149, -1.0630, -1.3918, -1.5984,\n",
      "        -1.6219, -0.9883, -2.3674, -1.3435, -0.6336, -1.6462, -0.8598, -0.2858,\n",
      "        -0.2156, -1.2477, -3.2708, -0.6025, -1.4609, -0.3146, -1.2101, -2.9956,\n",
      "        -0.9583, -1.2123, -1.0812, -1.3552, -0.2938, -0.4029,  0.2478, -0.8708,\n",
      "        -1.8935, -1.1316, -0.8302, -1.9269, -0.5420, -1.4787, -1.2810, -0.6858,\n",
      "        -1.5565, -1.6617, -1.5330, -1.8304, -0.5217, -4.3132, -0.8598, -1.8820,\n",
      "        -1.6583, -1.3504, -1.9954, -0.4629, -1.3400, -1.7919, -0.3671, -1.4936,\n",
      "        -1.3277, -2.0570, -2.7753, -1.2635, -1.0497, -1.3813, -0.5808, -1.1431,\n",
      "        -1.3121, -0.1328, -0.9292, -0.3634, -0.3140, -0.8804, -1.8272, -0.9811,\n",
      "        -1.7050, -0.8504, -0.3184, -2.5355, -1.2241, -1.3230, -0.8171, -0.8056,\n",
      "        -1.8978, -1.4006, -2.4151, -0.7427, -1.2534, -1.2667, -1.8051, -1.4110,\n",
      "        -3.3668, -2.0075, -1.6068, -2.2404, -0.4170, -1.4985, -1.9872, -1.4460,\n",
      "        -0.8806, -0.7884, -1.6658, -1.3862, -3.2375, -1.2562, -1.0083, -1.2257,\n",
      "        -0.5423, -0.3740, -0.3766, -0.3428, -6.8788, -1.7598, -1.6371, -0.8694,\n",
      "        -1.7562, -1.1749, -1.7673, -1.4467, -1.5188, -1.2995, -1.1852, -2.4178,\n",
      "        -0.9043, -2.1220, -1.1333, -0.9206, -1.1049, -1.1973, -0.5700, -1.9180,\n",
      "        -1.6574, -0.6347, -1.8164, -1.3138, -1.8115, -1.4622, -1.9331, -0.7184,\n",
      "        -1.7369,  0.3377, -2.5936, -2.4982, -1.5808, -0.9719, -1.0499, -1.5459,\n",
      "        -1.8138, -1.5829, -2.2363, -1.0917, -0.7564, -1.8545, -1.7509, -1.9439,\n",
      "        -1.4280, -1.4344, -0.9172, -0.7669, -1.9096, -1.7714, -0.9585, -0.7160,\n",
      "        -1.8117, -1.5200, -1.3963, -1.7182, -0.6269, -1.2990, -0.8388, -1.7747,\n",
      "        -0.7885, -0.2265, -1.5624, -1.5698, -1.4411, -0.6413, -0.5090, -0.6182,\n",
      "        -3.9845, -1.4848, -0.3383, -1.4440, -1.5613, -0.8435, -1.6744, -1.7386,\n",
      "        -0.1525, -0.8342, -1.3513, -1.9113, -1.7859, -0.4676, -1.4776, -0.8535,\n",
      "        -2.0246, -1.5390, -1.3063, -1.3228, -2.4362, -0.9522, -1.1720, -1.2112,\n",
      "        -1.2100, -1.6532, -1.9887, -1.3514, -3.1340, -1.5824, -0.4540, -1.7239,\n",
      "        -1.4002, -0.8653, -1.5443, -4.8187, -0.8942, -1.0962, -2.1437, -1.4727,\n",
      "        -0.6863, -1.8178, -1.5645, -3.6511, -1.7042, -1.3306, -0.8740, -1.5911,\n",
      "        -1.2044, -1.7314, -1.7229, -1.0244, -0.5369, -1.8464, -1.5208, -2.3820,\n",
      "        -0.6229, -1.1839, -1.1857, -1.3289, -0.7562, -0.6712, -1.3163, -1.0117,\n",
      "        -1.8939, -2.1691, -1.9699, -0.5858, -1.0192, -1.5602, -1.6408, -0.7588,\n",
      "        -1.8540, -1.9014, -1.5113, -2.0679, -0.6437, -1.1365, -1.3699, -2.6495,\n",
      "        -0.3555, -1.2452, -1.6095, -1.6627, -1.6386, -0.9892, -1.0105, -0.5197,\n",
      "        -1.6604, -1.1150, -1.5357, -2.0059, -1.7692, -0.2549, -1.4533, -0.4058,\n",
      "        -0.2126, -0.7079,  0.1366, -0.3044, -0.7003, -0.8522, -0.7005, -0.4644,\n",
      "        -1.1665, -0.8646, -4.2463, -0.5594,  0.2945, -0.8693, -0.1302, -1.0266,\n",
      "        -1.7448, -1.8253, -2.9208, -1.0921, -0.4108, -3.1652, -0.8872, -0.6171,\n",
      "        -1.2806, -1.7905, -0.8213, -1.4450, -1.5555, -0.1661, -1.5423, -0.2772,\n",
      "        -0.6004, -0.9595, -2.0763, -0.8712, -1.4641, -4.7479, -1.0291, -0.8252,\n",
      "        -1.8140, -1.6347, -0.4907, -1.9313, -1.8216, -1.8971, -1.4094, -1.1601,\n",
      "        -2.0896, -1.5242, -0.3638, -1.3011, -1.2781, -0.1884, -2.1587, -1.1786,\n",
      "        -1.1954, -1.3326, -1.3293, -2.4634, -2.0125, -1.1237, -1.2449, -1.0251,\n",
      "        -1.5413, -1.9851, -0.4433, -0.7230, -1.5634, -0.9816, -0.8015, -2.7590,\n",
      "        -0.5604, -1.8482, -0.5638, -0.4523, -1.5278, -1.2643, -1.8095, -0.5594],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.conv2.weight', tensor([[[[ 4.4445e-02,  1.3422e-02,  9.3911e-03],\n",
      "          [ 2.2293e-02,  5.7773e-02,  4.3260e-02],\n",
      "          [-3.7550e-02, -6.4577e-02, -3.9765e-03]],\n",
      "\n",
      "         [[-1.5412e-02, -5.0461e-02,  4.5361e-06],\n",
      "          [-6.3681e-02, -1.8857e-01, -3.8627e-02],\n",
      "          [ 5.1088e-03, -6.3345e-02,  1.6185e-02]],\n",
      "\n",
      "         [[-7.5960e-03,  8.6050e-03, -1.0055e-01],\n",
      "          [ 2.0580e-03, -5.8172e-02, -3.3499e-02],\n",
      "          [ 8.1772e-02,  6.1836e-02,  3.4213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0819e-02, -3.2936e-02, -4.2055e-02],\n",
      "          [-5.6262e-02, -2.3112e-02,  5.9709e-03],\n",
      "          [ 6.9150e-03, -2.4886e-02,  6.1047e-02]],\n",
      "\n",
      "         [[-2.8365e-02, -2.7701e-02, -5.2660e-03],\n",
      "          [-4.8448e-02, -1.6779e-02, -2.0284e-02],\n",
      "          [-6.7586e-02, -6.0849e-02, -6.3583e-02]],\n",
      "\n",
      "         [[-7.7858e-03, -7.1824e-03, -1.0607e-02],\n",
      "          [-2.1770e-02, -2.2448e-02, -4.5806e-02],\n",
      "          [ 1.6925e-02, -2.5112e-02, -2.7162e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7274e-02, -1.5223e-02,  2.4653e-02],\n",
      "          [ 3.1781e-02, -2.2641e-02,  2.1771e-02],\n",
      "          [-3.1642e-03, -6.0680e-02,  1.1053e-03]],\n",
      "\n",
      "         [[-6.3220e-03, -8.3209e-02,  7.7206e-03],\n",
      "          [-8.0090e-02, -2.4723e-01, -5.5579e-02],\n",
      "          [ 4.4880e-04, -6.5044e-02,  1.6376e-03]],\n",
      "\n",
      "         [[ 1.2458e-02, -7.9441e-03, -1.2750e-01],\n",
      "          [-7.2414e-03, -1.3224e-01, -1.0212e-01],\n",
      "          [-1.1707e-01, -5.3126e-02, -5.7510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8043e-02, -2.0064e-02,  3.1362e-02],\n",
      "          [ 2.1829e-02, -8.4072e-02, -6.7592e-03],\n",
      "          [ 2.6564e-02, -3.2516e-02, -2.9661e-02]],\n",
      "\n",
      "         [[-6.8069e-02, -6.3192e-03, -4.1351e-02],\n",
      "          [-6.3132e-02,  1.3104e-02, -4.9112e-02],\n",
      "          [-1.8942e-02,  2.9097e-02, -3.7188e-02]],\n",
      "\n",
      "         [[ 1.1728e-02,  2.8323e-02,  6.9804e-02],\n",
      "          [-2.3887e-02, -5.3595e-02,  2.8201e-02],\n",
      "          [ 6.7474e-02, -8.1927e-03,  3.4837e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8518e-02,  6.9707e-03, -4.3215e-02],\n",
      "          [ 1.1238e-01,  6.3399e-02, -1.5595e-02],\n",
      "          [-7.3859e-03,  2.5356e-02, -8.9387e-02]],\n",
      "\n",
      "         [[ 1.3938e-02, -7.1635e-02,  2.8517e-02],\n",
      "          [-6.2360e-02, -2.3971e-01, -5.5877e-02],\n",
      "          [ 4.6538e-02, -2.6767e-02,  4.2214e-02]],\n",
      "\n",
      "         [[ 1.8449e-02, -1.8504e-04, -7.6615e-02],\n",
      "          [ 1.2333e-02, -4.6756e-02, -8.1990e-02],\n",
      "          [ 5.8645e-02,  4.2199e-02,  1.1797e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7022e-02,  4.8275e-02, -2.7804e-03],\n",
      "          [ 2.2890e-02,  1.6293e-02, -3.7312e-02],\n",
      "          [-6.9951e-02, -4.2068e-02, -5.4504e-02]],\n",
      "\n",
      "         [[-7.2129e-02,  1.1153e-02, -9.4313e-02],\n",
      "          [ 1.1063e-02,  4.5309e-02, -2.1445e-02],\n",
      "          [-6.4118e-04, -4.5718e-02,  6.7333e-02]],\n",
      "\n",
      "         [[-5.8155e-03, -1.2130e-02, -6.9599e-02],\n",
      "          [ 3.4159e-03, -3.4933e-02,  7.4820e-03],\n",
      "          [ 1.7613e-03, -2.4544e-02, -1.1863e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.2769e-02, -1.3134e-02, -6.1205e-03],\n",
      "          [-2.4432e-02, -1.4062e-02, -2.7120e-02],\n",
      "          [-1.9849e-03, -1.9122e-02, -6.0256e-02]],\n",
      "\n",
      "         [[ 1.0971e-02, -2.6049e-02,  1.1364e-02],\n",
      "          [-4.5428e-02, -2.1749e-01, -4.4689e-02],\n",
      "          [ 6.8380e-03, -2.2441e-02, -5.6900e-03]],\n",
      "\n",
      "         [[ 4.3562e-02,  1.0662e-02, -1.1031e-01],\n",
      "          [-1.4995e-02,  7.3961e-02, -6.4130e-02],\n",
      "          [-3.7269e-02, -2.5041e-02, -3.6129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8158e-02, -1.9907e-02, -1.5402e-02],\n",
      "          [-2.8153e-02, -6.0561e-02, -3.2297e-02],\n",
      "          [ 2.5801e-02, -8.5543e-03,  2.0627e-02]],\n",
      "\n",
      "         [[-2.6275e-03,  1.2296e-02, -3.8324e-02],\n",
      "          [-4.5666e-02,  8.4424e-03, -4.2514e-02],\n",
      "          [ 3.7698e-02,  3.7235e-02, -6.0133e-02]],\n",
      "\n",
      "         [[-8.8733e-02, -6.1174e-02, -1.1378e-01],\n",
      "          [-7.4499e-02, -6.4427e-02, -1.2187e-01],\n",
      "          [-1.3871e-01, -8.5227e-02, -1.1415e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3074e-02,  8.9628e-03,  8.9112e-02],\n",
      "          [ 2.3401e-02, -3.0960e-02,  8.0934e-02],\n",
      "          [-3.0589e-02, -1.9576e-02, -1.1138e-02]],\n",
      "\n",
      "         [[-3.2567e-03, -4.8763e-02, -1.4270e-02],\n",
      "          [-7.4743e-02, -2.4604e-01, -8.1260e-02],\n",
      "          [ 1.4348e-02, -7.6858e-02, -8.2090e-04]],\n",
      "\n",
      "         [[-1.8433e-02, -1.1159e-02,  1.1416e-01],\n",
      "          [-1.1832e-02,  8.2227e-02,  1.9770e-02],\n",
      "          [ 1.0528e-01,  1.9558e-02, -6.0563e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5645e-02, -1.6461e-02,  1.3996e-02],\n",
      "          [ 3.5306e-03, -5.9534e-02,  7.9915e-03],\n",
      "          [ 2.5062e-02, -5.7291e-02, -9.4536e-05]],\n",
      "\n",
      "         [[-5.5531e-02, -6.3085e-02, -3.9783e-02],\n",
      "          [-8.8946e-02, -9.8292e-02, -7.1150e-02],\n",
      "          [-9.0445e-02, -9.7021e-02, -6.3446e-02]],\n",
      "\n",
      "         [[ 1.3294e-01,  1.2049e-01,  1.1785e-01],\n",
      "          [ 1.2616e-01,  9.1127e-02,  8.8260e-02],\n",
      "          [ 8.0664e-02,  5.3519e-02,  9.3385e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0183e-02,  6.7105e-02,  2.8440e-02],\n",
      "          [ 3.9406e-02, -1.8608e-03,  5.5343e-02],\n",
      "          [ 3.5125e-02,  3.9414e-02,  3.8451e-02]],\n",
      "\n",
      "         [[ 2.6159e-02, -4.9367e-02,  9.0855e-03],\n",
      "          [-1.0286e-01, -2.7122e-01, -6.8579e-02],\n",
      "          [-7.9581e-03, -5.6271e-02,  1.0487e-02]],\n",
      "\n",
      "         [[ 1.4787e-02,  2.3495e-02,  5.5510e-02],\n",
      "          [ 1.6614e-02, -1.5464e-01,  7.3531e-02],\n",
      "          [ 7.0173e-02,  5.4278e-02,  1.0549e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9425e-02, -7.8736e-02, -6.0611e-02],\n",
      "          [-1.5397e-02, -5.0796e-02, -4.7329e-03],\n",
      "          [-1.7039e-02,  1.1146e-02,  1.8152e-02]],\n",
      "\n",
      "         [[ 2.9659e-02,  7.2558e-02,  4.7204e-02],\n",
      "          [ 6.0047e-02,  1.0421e-01,  8.8786e-02],\n",
      "          [ 4.3739e-02,  9.2682e-02,  3.0070e-02]],\n",
      "\n",
      "         [[-5.5929e-02, -1.7304e-01, -9.4187e-02],\n",
      "          [-7.4153e-02, -1.6428e-01, -8.7572e-02],\n",
      "          [-5.3347e-02, -1.2718e-01, -1.0945e-01]]]], device='cuda:0')), ('backbone.model.layer4.2.bn2.weight', tensor([1.7691, 2.4915, 2.1124, 1.6742, 1.7442, 2.7256, 1.5812, 1.9456, 2.2188,\n",
      "        2.3135, 2.4656, 1.5898, 2.0004, 2.2021, 1.7802, 1.5509, 2.2493, 2.1295,\n",
      "        1.3575, 2.4581, 1.9458, 1.8179, 2.6442, 2.2466, 2.2574, 2.0624, 2.1201,\n",
      "        2.3454, 1.8895, 1.8534, 1.6164, 1.6587, 2.3822, 2.9469, 0.0901, 3.9225,\n",
      "        2.4838, 4.0487, 3.0101, 2.8157, 3.0796, 3.1579, 2.7924, 5.1066, 2.0971,\n",
      "        2.3415, 3.0674, 3.7572, 1.9630, 2.0525, 2.5782, 2.5995, 2.3212, 1.5014,\n",
      "        1.9460, 1.5450, 2.2617, 1.6914, 2.5845, 2.3339, 1.7787, 1.7016, 1.3642,\n",
      "        1.6823, 2.4363, 1.3963, 2.4893, 1.8002, 2.4605, 2.2332, 2.6683, 2.7544,\n",
      "        2.5608, 2.4519, 2.5277, 1.9656, 2.4649, 2.9631, 1.9211, 1.5163, 2.8665,\n",
      "        0.1114, 2.9725, 2.3932, 3.3547, 2.4065, 3.2262, 4.2646, 2.4592, 3.5764,\n",
      "        2.3232, 2.6147, 3.1781, 2.4012, 4.2393, 3.1650, 1.7421, 1.8430, 1.9333,\n",
      "        2.3976, 2.2080, 1.4740, 2.2204, 1.5063, 1.9826, 2.1234, 2.2016, 1.5741,\n",
      "        1.5083, 2.1333, 1.7472, 1.4746, 1.8340, 2.3002, 1.8855, 1.8066, 1.6943,\n",
      "        1.6047, 1.8417, 2.1610, 2.4242, 1.8996, 1.7409, 1.9866, 2.2133, 2.0299,\n",
      "        1.5760, 2.0159, 2.5593, 3.1356, 3.6122, 4.3704, 3.4156, 3.3420, 3.7339,\n",
      "        3.3724, 3.0327, 3.2846, 3.5875, 3.8901, 4.2601, 3.9988, 3.7001, 3.6519,\n",
      "        2.0913, 2.1793, 1.6013, 1.7655, 1.6041, 2.3344, 1.3799, 2.2983, 2.2890,\n",
      "        3.0952, 1.8049, 1.6827, 2.2601, 2.3564, 1.7745, 2.4603, 2.0738, 2.1057,\n",
      "        2.1429, 1.5521, 1.5437, 1.9241, 2.4244, 2.1506, 2.2402, 1.8226, 1.6619,\n",
      "        1.6764, 1.8830, 1.4670, 1.6442, 1.5954, 1.7648, 2.4186, 1.8107, 1.4503,\n",
      "        2.1411, 1.9520, 2.1160, 2.0103, 1.7218, 1.7484, 2.0732, 1.9006, 2.2549,\n",
      "        1.7650, 2.1164, 1.7236, 3.0960, 2.4336, 2.1110, 2.1044, 1.9080, 1.3832,\n",
      "        1.9631, 2.3337, 1.7826, 2.5209, 1.9561, 1.7719, 1.9751, 2.1766, 1.7001,\n",
      "        2.5620, 1.5728, 2.0056, 2.0049, 2.6281, 2.3053, 2.6224, 2.2175, 1.8061,\n",
      "        2.0137, 2.2417, 1.6505, 2.5703, 2.1325, 2.5019, 1.7444, 2.1528, 3.3463,\n",
      "        2.2638, 1.8143, 3.1028, 1.8592, 3.2210, 3.5330, 2.4720, 2.5090, 2.0920,\n",
      "        0.0841, 2.5072, 2.3539, 3.6223, 2.4166, 2.1926, 2.0397, 2.3176, 2.1491,\n",
      "        1.5185, 2.4471, 1.7385, 1.9692, 2.0998, 1.8942, 1.7884, 2.2900, 1.9121,\n",
      "        2.0395, 2.3208, 1.5836, 1.7628, 1.5812, 2.4866, 2.2339, 2.5643, 1.6628,\n",
      "        2.1921, 1.9609, 2.1787, 2.5795, 2.0603, 2.0438, 1.7523, 2.1867, 2.3830,\n",
      "        2.6434, 2.2869, 2.2243, 2.3525, 1.9220, 1.6569, 2.0343, 1.4501, 1.9294,\n",
      "        1.5613, 1.6674, 2.5381, 2.1764, 1.6905, 1.7230, 2.3479, 2.1970, 1.4728,\n",
      "        1.7423, 2.1623, 1.7189, 1.5582, 2.6751, 1.8264, 1.9171, 2.0458, 1.6988,\n",
      "        2.0011, 1.5771, 1.5053, 2.3533, 1.7663, 1.7704, 1.9700, 1.9120, 1.7009,\n",
      "        2.4156, 2.0232, 1.7569, 2.7640, 1.9526, 2.2903, 1.9428, 2.1907, 2.0896,\n",
      "        1.5328, 1.8140, 1.3757, 1.6128, 1.7138, 8.6483, 6.7484, 4.9196, 4.8204,\n",
      "        4.9907, 0.0599, 6.9037, 5.6264, 5.8276, 4.4588, 4.6998, 7.0331, 7.3658,\n",
      "        3.4100, 3.8775, 5.2153, 2.1959, 1.5864, 3.1098, 2.1744, 1.8940, 2.7604,\n",
      "        1.7318, 1.8828, 2.4856, 1.8550, 1.7683, 1.9738, 2.3940, 2.0028, 1.6676,\n",
      "        1.9050, 1.8155, 0.0844, 3.1607, 3.0328, 3.2269, 3.5794, 2.8334, 2.4406,\n",
      "        3.0556, 3.2245, 3.2354, 3.1464, 2.9121, 2.8115, 2.7192, 3.2974, 2.5404,\n",
      "        3.0258, 4.1946, 3.6561, 5.1648, 4.1725, 3.3545, 5.1750, 3.6324, 4.5195,\n",
      "        3.3769, 4.8006, 4.4571, 4.5242, 0.0982, 3.3149, 2.4687, 3.8923, 3.1259,\n",
      "        2.6149, 3.2797, 4.0376, 3.8072, 3.4525, 2.8134, 2.4084, 2.3891, 1.9213,\n",
      "        2.6828, 2.9319, 3.0626, 0.1217, 2.9784, 1.9685, 2.3194, 2.1014, 1.9761,\n",
      "        1.9685, 1.9283, 1.9726, 2.1611, 1.9534, 2.5119, 2.2564, 2.1368, 1.5351,\n",
      "        2.2033, 1.7447, 3.3946, 2.9341, 4.3180, 2.6670, 3.4220, 4.0018, 2.1472,\n",
      "        1.9711, 0.0634, 3.5144, 3.4886, 4.0870, 2.4103, 2.4713, 2.4713, 3.4438,\n",
      "        2.2793, 1.7044, 1.9463, 2.3399, 2.6268, 2.2270, 1.9853, 2.0316, 1.8955,\n",
      "        2.1310, 2.2005, 2.2710, 2.0228, 1.9881, 2.1331, 1.9152, 1.5831, 1.6506,\n",
      "        1.8622, 1.6528, 2.5537, 1.8811, 1.7900, 1.7792, 1.5781, 1.8022, 1.8447,\n",
      "        2.4986, 1.6284, 1.7653, 2.2962, 1.8278, 1.6330, 1.8960, 2.5407, 1.4933,\n",
      "        1.7702, 2.0344, 1.8158, 2.2436, 2.6603, 1.6989, 1.3340, 2.0318, 2.3218,\n",
      "        2.1759, 2.3070, 1.6419, 1.7604, 2.0947, 1.9874, 2.1928, 2.1451, 1.9120,\n",
      "        1.5710, 2.3375, 1.4801, 1.4450, 1.5779, 1.6591, 2.2560, 1.3208, 1.5326,\n",
      "        2.1375, 2.1321, 2.2398, 1.3302, 1.9619, 2.1403, 1.6517, 1.5365, 1.7107,\n",
      "        1.8543, 2.9595, 1.7497, 1.8480, 1.9581, 1.4936, 1.4163, 2.1403],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn2.bias', tensor([-7.9175e-01, -1.3671e+00, -1.0833e+00, -9.5326e-01, -8.6891e-01,\n",
      "        -2.9064e+00, -5.0012e+00, -1.0431e+00, -1.9233e+00, -1.5428e+00,\n",
      "        -1.4881e+00, -9.6335e-01, -9.5385e-01, -1.2095e+00, -8.8031e-01,\n",
      "        -1.0898e+00, -1.6253e+00, -1.5157e+00, -1.5023e+00, -1.8526e+00,\n",
      "        -1.5990e+00, -1.3190e+00, -2.8556e+00, -1.5454e+00, -1.8313e+00,\n",
      "        -1.4028e+00, -9.4503e-01, -1.7483e+00, -1.2738e+00, -8.0035e-01,\n",
      "        -9.8203e-01, -1.4778e+00, -1.0462e+00, -1.0758e+00, -1.5380e+00,\n",
      "        -1.9832e+00, -4.6306e-01, -1.0724e+00, -3.2117e-01, -4.8164e-01,\n",
      "        -5.3183e-01, -1.5870e+00, -1.1266e+00,  1.4448e-01, -1.9372e-01,\n",
      "        -4.9337e-01, -4.9406e+00, -1.9074e+00, -7.4342e-01, -2.4163e+00,\n",
      "        -1.1646e+00, -3.5413e+00, -2.8948e+00, -1.5916e-01, -8.4375e-01,\n",
      "        -2.9051e-01, -1.2633e+00, -1.2875e+00, -2.0068e+00, -1.0100e+00,\n",
      "        -7.4026e-01, -9.6609e-01, -1.1825e+00, -1.7119e+00, -1.5323e+00,\n",
      "        -2.2778e+00, -9.8220e-01, -4.5108e-01, -7.6483e-01, -1.1102e+00,\n",
      "        -1.6434e+00, -1.2615e+00, -1.0934e+00, -4.9810e+00, -8.2915e-01,\n",
      "        -7.9782e-01, -8.9633e-01, -6.0762e+00, -1.7435e+00, -3.1686e-01,\n",
      "        -7.9721e-01, -1.5560e+00, -8.8574e-01, -3.6342e-01, -8.3473e-01,\n",
      "        -2.5135e+00, -5.3633e+00, -1.3145e+00, -1.9424e-01, -1.3477e+00,\n",
      "         2.3027e-01, -2.1779e-01, -1.0471e+00, -5.6146e-01, -1.4007e+00,\n",
      "        -1.5628e+00, -1.5367e+00, -7.4487e-01, -8.8330e-01, -1.1748e+00,\n",
      "        -1.6182e+00, -5.9983e-01, -1.4468e+00, -8.3820e-01, -2.9809e+00,\n",
      "        -9.9050e-01, -9.7084e-01, -6.4968e-01, -6.7692e-01, -1.3211e+00,\n",
      "        -7.0841e-01, -6.8242e-01, -1.0726e+00, -1.4024e+00, -1.2456e+00,\n",
      "        -7.1272e-01, -4.6091e-01, -5.8568e-01, -1.5465e+00, -1.2917e+00,\n",
      "        -1.8838e+00, -1.0101e+00, -4.3373e+00, -1.0903e+00, -1.1026e+00,\n",
      "        -1.0469e+00, -5.8335e-01, -1.0872e+00, -2.2984e+00, -5.7871e-01,\n",
      "        -1.0100e+00, -2.1685e+00, -6.4015e-01, -2.8804e-01, -4.3833e-01,\n",
      "        -4.8950e-01, -4.6549e-01, -6.0660e-01, -4.6269e-01, -1.1300e+00,\n",
      "        -8.3790e-01, -7.2713e-01, -9.1879e-01, -7.2848e-01, -1.9463e-01,\n",
      "        -2.0504e+00, -1.6409e-01, -2.2459e-03, -1.1936e-01, -8.4880e-01,\n",
      "         4.3946e-02, -5.8643e-01, -3.4412e+00, -1.3281e+00, -4.9990e-01,\n",
      "        -3.2195e-02, -1.1456e+00, -2.1465e+00, -5.0146e+00, -9.6719e-01,\n",
      "        -1.0439e+00, -1.3916e+00, -1.0686e+00, -6.1730e-01, -4.5711e-01,\n",
      "        -9.7506e-01, -1.2865e+00, -9.3089e-01, -1.4327e+00, -1.0044e+00,\n",
      "        -5.7277e-01, -3.6178e+00, -7.0791e-01, -1.5891e-01, -6.4402e-01,\n",
      "        -3.1404e-01, -1.0289e+00, -1.3741e+00, -1.9548e+00, -4.9465e-01,\n",
      "        -1.9779e+00, -1.1466e+00, -1.6566e+00, -2.1268e+00, -1.2232e+00,\n",
      "        -1.1179e+00, -7.3483e-01, -4.8202e-01, -1.4259e+00, -9.9801e-01,\n",
      "        -1.0053e+00, -1.1330e+00, -1.7372e+00, -1.1239e+00, -2.8080e+00,\n",
      "        -1.5010e+00, -1.2697e+00, -2.8034e-01, -5.1304e-01, -1.7025e+00,\n",
      "        -5.6512e-01, -1.1206e+00, -5.4896e-01, -5.4398e-01, -5.2421e+00,\n",
      "        -1.6849e+00, -3.6704e-01, -1.2528e+00, -1.0514e+00, -2.2662e+00,\n",
      "        -2.7409e+00, -4.3911e+00, -2.0172e+00, -2.1232e+00, -2.6583e+00,\n",
      "        -1.0070e+00, -1.3564e+00, -1.4416e+00, -1.4148e+00, -1.4803e+00,\n",
      "        -1.9090e+00, -1.8894e+00, -1.0000e+00, -1.6235e+00, -1.8699e+00,\n",
      "        -1.4841e-01, -2.2598e-01, -1.7601e+00, -2.0421e-01, -3.0132e-01,\n",
      "        -1.6171e+00, -5.5636e-01, -1.0843e-01, -2.7597e-01, -1.1739e+00,\n",
      "        -1.9096e-01, -6.5510e-01, -1.3739e+00, -2.4027e-01, -8.5969e-01,\n",
      "        -9.1960e-01, -1.4586e+00, -1.8692e+00, -7.0724e-01, -2.2335e+00,\n",
      "        -3.4057e+00, -1.3217e+00, -1.2034e+00, -7.6804e-01, -9.6053e-01,\n",
      "        -1.6806e+00, -5.0373e-01, -9.6467e-01, -1.7252e+00, -6.3950e-01,\n",
      "        -1.0306e+00, -7.2847e-01, -1.5051e+00, -1.6073e+00, -2.7688e+00,\n",
      "        -5.3272e+00, -2.0296e+00, -1.3353e+00, -2.4173e+00, -2.9626e+00,\n",
      "        -1.2735e+00, -1.0391e+00, -1.2984e+00, -1.6712e+00, -1.7706e+00,\n",
      "        -2.1535e+00, -1.6793e+00, -1.4301e+00, -1.5334e+00, -1.2759e+00,\n",
      "        -4.3288e+00, -1.0225e+00, -5.0339e-01, -6.0827e-01, -5.7712e-01,\n",
      "        -5.5457e-01, -1.5600e+00, -1.0026e+00, -3.3357e-01, -8.3212e-01,\n",
      "        -1.3425e+00, -1.5094e+00, -7.3351e-01, -1.1388e+00, -1.4320e+00,\n",
      "        -1.0261e+00, -1.0457e+00, -2.5424e+00, -1.1926e+00, -9.5573e-01,\n",
      "        -1.2021e+00, -6.6393e-01, -1.2599e+00, -1.0133e+00, -7.5581e-01,\n",
      "        -1.4149e+00, -7.4489e-01, -7.0495e-01, -1.9168e+00, -1.4155e+00,\n",
      "        -9.2405e-01, -1.8773e+00, -1.1913e+00, -9.7051e-01, -2.7586e+00,\n",
      "        -1.7863e+00, -1.0937e+00, -9.2042e-01, -1.7561e+00, -1.5567e+00,\n",
      "        -6.5727e-01, -1.3078e+00, -9.0296e-01, -1.2156e+00, -1.0324e+00,\n",
      "         5.2035e-01,  3.0635e-01,  6.6434e-01, -1.6697e-01,  6.2572e-01,\n",
      "        -1.1665e+00,  6.4430e-01, -2.3990e+00,  3.4293e-01,  6.8541e-01,\n",
      "        -3.5415e-01,  3.3426e-01,  3.2487e-01, -4.6085e+00,  3.6402e-01,\n",
      "         5.0425e-01, -8.2871e-01,  2.7456e-01, -1.4382e+00, -9.5108e-01,\n",
      "        -6.2524e-01, -1.3131e+00, -3.6936e-01, -1.2589e-01, -1.6537e+00,\n",
      "        -1.8542e+00, -4.0071e-01, -6.1698e-01, -1.1179e+00, -3.2610e-01,\n",
      "        -5.6026e-01, -5.9679e+00,  1.4960e-01, -1.4563e+00, -2.9005e-01,\n",
      "        -3.1721e+00,  1.4404e-01, -6.7792e-01,  3.5237e-01, -5.2152e+00,\n",
      "        -3.3669e-01, -4.1064e+00, -4.5190e-01, -5.0002e-01,  1.4562e-01,\n",
      "         1.6377e-01,  1.5138e-01, -5.2270e+00,  2.1103e-01,  3.1448e-01,\n",
      "         1.3221e-01, -5.8688e+00,  7.8000e-01,  4.3278e-01,  1.8302e-01,\n",
      "         1.5159e-01,  9.0752e-02, -2.1142e-01,  3.4001e-01,  4.3513e-01,\n",
      "        -4.7393e-01, -3.0634e+00, -1.5178e+00,  7.7333e-01, -7.6067e-02,\n",
      "        -1.5728e+00, -1.1223e+00, -4.9717e-01, -1.0127e+00, -1.7767e+00,\n",
      "        -1.8344e+00, -1.4330e+00, -5.4198e-01, -4.2219e-01, -5.1697e-01,\n",
      "        -3.5251e-01, -3.4845e-01, -1.1801e+00, -3.2191e-01, -1.9053e+00,\n",
      "        -1.9101e+00, -8.0433e-01, -3.0149e+00, -8.4541e-01, -1.7574e+00,\n",
      "        -1.3087e+00, -1.6132e+00, -1.3879e+00, -2.1133e+00, -7.9603e-01,\n",
      "        -2.5795e+00, -1.5557e+00, -2.4753e+00, -1.1709e+00, -2.0304e+00,\n",
      "        -1.1035e+00, -5.3329e+00, -9.7641e-01, -1.8126e+00,  1.2066e-01,\n",
      "        -1.2295e+00, -9.3812e-01, -3.9651e-01, -6.3787e-01, -1.0871e+00,\n",
      "        -1.5045e+00, -1.0442e+00, -6.9809e-01, -3.8291e-01,  3.5314e-01,\n",
      "        -8.5383e-02, -1.6916e+00, -1.9574e+00, -1.4648e+00, -1.6879e+00,\n",
      "        -2.3478e+00, -2.3765e+00, -2.0627e+00, -1.9957e+00, -1.2946e+00,\n",
      "        -2.6396e+00, -1.4161e+00, -1.5711e+00, -1.2249e+00, -2.0992e+00,\n",
      "        -1.8185e+00, -1.3451e+00, -1.1803e+00, -4.2479e-01, -6.7109e-01,\n",
      "        -1.2568e+00, -1.0642e+00, -4.4785e+00, -1.4591e+00, -1.3104e-01,\n",
      "        -7.8366e-01, -4.2093e-01, -1.9350e-01, -6.9758e-01, -1.9538e+00,\n",
      "        -9.1960e-01, -1.1077e+00, -1.9689e+00, -1.1614e+00, -1.6699e-01,\n",
      "        -7.0157e-01, -1.5871e+00, -2.2050e-01, -7.8789e-01, -9.1360e-01,\n",
      "        -3.4194e+00, -1.4689e+00, -2.7159e+00, -5.3250e-01, -1.6729e+00,\n",
      "        -1.2261e+00, -1.2833e+00, -7.5643e-01, -1.0683e+00, -6.0654e-01,\n",
      "         8.9925e-02, -8.9326e-01, -1.0690e+00, -1.4296e+00, -1.5919e+00,\n",
      "        -8.7958e-01, -4.0961e-01, -2.4319e+00, -2.4067e+00, -4.9095e-01,\n",
      "        -2.0822e-02, -9.9284e-01, -1.5285e+00, -3.2422e-01,  5.1024e-02,\n",
      "        -1.3472e+00, -1.0678e+00, -1.0548e+00, -4.0405e-01, -1.4922e+00,\n",
      "        -6.8784e-01, -1.1882e+00, -8.6106e-01, -6.9834e-01, -9.8198e-01,\n",
      "        -3.7834e+00, -8.2076e-01, -5.2978e-01, -1.9117e+00, -5.8863e-01,\n",
      "        -4.2552e-01, -1.0383e+00], device='cuda:0')), ('backbone.model.layer4.2.conv3.weight', tensor([[[[ 0.0527]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         [[-0.1376]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0154]],\n",
      "\n",
      "         [[-0.0655]],\n",
      "\n",
      "         [[ 0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0077]],\n",
      "\n",
      "         [[-0.0299]],\n",
      "\n",
      "         [[ 0.0368]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0221]],\n",
      "\n",
      "         [[ 0.0645]],\n",
      "\n",
      "         [[-0.0525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0184]],\n",
      "\n",
      "         [[ 0.0439]],\n",
      "\n",
      "         [[ 0.0474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682]],\n",
      "\n",
      "         [[ 0.0694]],\n",
      "\n",
      "         [[-0.0089]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0275]],\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[ 0.0876]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         [[ 0.0808]],\n",
      "\n",
      "         [[-0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.1195]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         [[-0.0200]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0699]],\n",
      "\n",
      "         [[-0.0196]],\n",
      "\n",
      "         [[ 0.0437]]],\n",
      "\n",
      "\n",
      "        [[[-0.0816]],\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[ 0.1342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1433]],\n",
      "\n",
      "         [[ 0.1463]],\n",
      "\n",
      "         [[-0.0070]]]], device='cuda:0')), ('backbone.model.layer4.2.bn3.weight', tensor([ 3.1467,  2.9796,  3.5381,  ..., -4.0625,  3.6846, -3.2800],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn3.bias', tensor([-0.1647, -0.0732,  0.0506,  ..., -0.0855,  0.0549, -0.0458],\n",
      "       device='cuda:0')), ('heads.bodypart.heatmap_head.deconv_layers.0.weight', tensor([[[[ 4.5745e-03,  3.5365e-03, -5.3904e-05],\n",
      "          [ 3.0810e-03,  1.6233e-03, -1.4993e-03],\n",
      "          [-1.1619e-03, -2.7563e-04,  9.9996e-04]],\n",
      "\n",
      "         [[ 2.0500e-03,  2.4230e-03, -1.3525e-03],\n",
      "          [ 1.9543e-04, -1.0506e-03, -4.7239e-04],\n",
      "          [ 1.5107e-05,  2.0520e-03,  1.8542e-03]],\n",
      "\n",
      "         [[ 3.2510e-03,  3.5625e-03, -1.0928e-03],\n",
      "          [ 1.1341e-03,  8.2989e-04, -2.8447e-04],\n",
      "          [ 4.0911e-04,  1.5806e-03,  5.0330e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4474e-04, -2.9750e-04, -3.2006e-04],\n",
      "          [-1.6142e-03,  2.4558e-03,  3.5922e-03],\n",
      "          [-1.7402e-03,  1.5714e-03,  2.3839e-03]],\n",
      "\n",
      "         [[ 4.1788e-03,  4.8816e-03,  1.0130e-03],\n",
      "          [ 6.3152e-03,  6.2879e-03,  1.6920e-03],\n",
      "          [ 3.7218e-03,  3.8382e-03,  5.0317e-04]],\n",
      "\n",
      "         [[-9.0086e-04,  8.1618e-04, -5.1925e-04],\n",
      "          [-1.0373e-03, -1.1069e-03, -1.6622e-04],\n",
      "          [-6.9406e-04, -6.3202e-04,  2.5042e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8078e-05,  4.4300e-04,  3.6194e-05],\n",
      "          [ 2.7126e-05,  4.3309e-04,  2.5194e-04],\n",
      "          [ 7.1844e-04,  7.5536e-04,  2.9778e-04]],\n",
      "\n",
      "         [[-9.1652e-04,  1.6463e-04, -9.0776e-05],\n",
      "          [-2.0597e-04,  6.7657e-04,  3.6497e-04],\n",
      "          [ 8.9868e-04,  1.2566e-03,  7.3998e-04]],\n",
      "\n",
      "         [[-7.2596e-04, -7.0243e-04,  2.8967e-04],\n",
      "          [-4.2324e-04, -5.9376e-05, -3.0912e-04],\n",
      "          [ 9.5739e-04,  4.3546e-04,  3.6120e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4634e-04, -1.6282e-03, -1.0613e-03],\n",
      "          [ 3.1665e-03, -6.3514e-05, -3.0237e-03],\n",
      "          [ 3.3238e-03,  2.3046e-03, -1.6260e-03]],\n",
      "\n",
      "         [[-9.9608e-04, -9.4505e-04, -8.5099e-05],\n",
      "          [-4.7692e-04, -1.1317e-03, -5.1328e-04],\n",
      "          [ 1.0900e-03,  7.0907e-04,  3.9561e-04]],\n",
      "\n",
      "         [[ 8.7180e-04,  1.0762e-03, -1.4787e-04],\n",
      "          [ 1.7836e-04,  5.9557e-04, -4.9842e-04],\n",
      "          [-4.9882e-04, -2.6017e-04, -7.4396e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.6764e-04, -9.1192e-04, -1.4252e-04],\n",
      "          [-1.0868e-03, -1.1576e-03, -1.0681e-04],\n",
      "          [-7.4198e-04, -9.4900e-04, -5.5327e-04]],\n",
      "\n",
      "         [[-1.6179e-04, -5.0009e-04,  3.8579e-04],\n",
      "          [-3.1636e-04,  1.9574e-04,  1.4132e-04],\n",
      "          [-2.2951e-04, -2.6815e-04, -4.0902e-04]],\n",
      "\n",
      "         [[-3.0580e-04, -3.2198e-04,  2.0972e-04],\n",
      "          [-3.3629e-04,  2.0617e-04, -2.7510e-04],\n",
      "          [-2.3841e-04, -5.1038e-06, -7.4311e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6810e-04,  3.0566e-03,  2.3643e-03],\n",
      "          [ 3.4388e-03,  1.1435e-02,  4.1142e-03],\n",
      "          [ 1.1475e-03,  6.0872e-03,  1.8321e-03]],\n",
      "\n",
      "         [[ 1.0783e-04, -9.1005e-04, -1.2958e-04],\n",
      "          [ 1.7342e-03,  8.0927e-04, -1.7751e-03],\n",
      "          [ 1.8443e-03,  1.8236e-03, -1.0988e-03]],\n",
      "\n",
      "         [[-7.6010e-05,  2.0035e-04,  2.0425e-04],\n",
      "          [ 5.5614e-05,  8.9881e-04,  1.4567e-04],\n",
      "          [-9.3111e-05,  1.9903e-04, -1.5402e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2537e-04, -5.2437e-04,  4.9891e-04],\n",
      "          [-4.4556e-04, -1.0086e-03, -1.8878e-04],\n",
      "          [-6.9996e-05, -1.8882e-04, -4.8691e-05]],\n",
      "\n",
      "         [[-3.3142e-04, -2.0195e-04,  8.8394e-04],\n",
      "          [-9.2858e-04, -9.6530e-04, -5.8220e-05],\n",
      "          [-2.4707e-04, -4.2766e-04,  2.6945e-05]],\n",
      "\n",
      "         [[-3.9224e-04, -6.5290e-04,  5.8476e-04],\n",
      "          [-1.4988e-03, -1.3049e-03, -2.5374e-04],\n",
      "          [-3.6813e-04, -4.6487e-04,  1.4892e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6422e-04,  1.8789e-03,  2.4787e-03],\n",
      "          [-7.0904e-04,  1.6238e-03,  3.3612e-03],\n",
      "          [-9.8145e-04, -4.0096e-04,  1.1114e-03]],\n",
      "\n",
      "         [[ 3.9663e-05, -7.8474e-04,  1.7475e-04],\n",
      "          [-8.8299e-04, -1.1854e-03,  6.8807e-05],\n",
      "          [-2.1368e-03, -1.8551e-03, -8.8342e-06]],\n",
      "\n",
      "         [[ 3.8269e-03,  6.1028e-03,  3.0579e-03],\n",
      "          [ 1.2251e-03,  2.9228e-03,  1.4290e-03],\n",
      "          [-3.8335e-04, -4.0619e-04, -1.7761e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.5862e-04, -2.1885e-03,  1.3294e-04],\n",
      "          [ 1.6914e-03, -4.5800e-04,  9.7152e-04],\n",
      "          [ 2.8799e-03,  2.8540e-03,  1.3936e-04]],\n",
      "\n",
      "         [[ 9.2973e-04, -1.7636e-03,  1.1392e-03],\n",
      "          [ 1.4499e-03, -2.0849e-03,  4.7154e-06],\n",
      "          [ 2.4550e-03,  1.8645e-03,  3.3377e-03]],\n",
      "\n",
      "         [[ 1.8515e-03,  2.3904e-04,  1.8204e-04],\n",
      "          [ 3.0422e-03, -1.0386e-03,  9.3707e-04],\n",
      "          [ 2.0466e-03,  8.4616e-05,  3.5363e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2462e-04, -3.1685e-04, -7.6951e-04],\n",
      "          [ 2.6703e-03,  7.6831e-03,  1.2995e-03],\n",
      "          [ 3.6273e-03,  9.2726e-03,  6.2008e-04]],\n",
      "\n",
      "         [[ 1.9627e-03,  3.8813e-03,  2.9801e-03],\n",
      "          [ 1.9915e-03,  6.6258e-03,  6.7060e-03],\n",
      "          [ 3.7089e-03,  1.5811e-03,  2.5167e-03]],\n",
      "\n",
      "         [[ 1.2215e-03,  2.3349e-03, -1.3431e-04],\n",
      "          [ 3.3877e-03,  4.2918e-03,  7.3581e-04],\n",
      "          [ 1.0652e-04,  7.3566e-04, -1.3240e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.8666e-04, -4.9113e-05, -8.8820e-04],\n",
      "          [ 5.6792e-05,  3.3918e-04, -1.0722e-03],\n",
      "          [-4.6137e-04, -1.0754e-03, -7.0967e-04]],\n",
      "\n",
      "         [[-6.2436e-04, -2.8342e-04, -9.0163e-04],\n",
      "          [-1.2065e-04, -4.1152e-04, -8.1204e-04],\n",
      "          [-3.9606e-04,  1.0911e-04, -6.7932e-05]],\n",
      "\n",
      "         [[-1.9169e-04,  1.2076e-03,  3.8723e-04],\n",
      "          [-8.2379e-05,  2.0266e-03,  1.9320e-03],\n",
      "          [ 4.1765e-04,  9.0121e-04,  1.9343e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.3579e-04,  8.0966e-04, -7.6275e-04],\n",
      "          [ 1.6683e-03, -3.5527e-04, -1.5291e-03],\n",
      "          [ 8.7151e-04, -1.7402e-05, -1.2041e-03]],\n",
      "\n",
      "         [[ 7.4610e-04,  9.2694e-04,  3.4977e-04],\n",
      "          [ 6.2762e-04, -2.0838e-04,  1.0298e-03],\n",
      "          [ 1.9952e-06, -5.2228e-04, -3.5076e-04]],\n",
      "\n",
      "         [[-3.4906e-05,  3.3202e-04,  1.9141e-04],\n",
      "          [ 6.0415e-04,  7.7920e-04, -8.3487e-05],\n",
      "          [ 8.1761e-05, -4.3629e-05, -3.8424e-04]]]], device='cuda:0')), ('heads.bodypart.heatmap_head.deconv_layers.0.bias', tensor([ 8.6940e-06, -6.1576e-06,  7.2428e-06,  1.3746e-04,  2.4619e-04,\n",
      "         5.5362e-05, -4.2505e-06,  1.3108e-04,  1.8960e-04,  1.2324e-04,\n",
      "         6.1530e-05], device='cuda:0')), ('heads.bodypart.locref_head.deconv_layers.0.weight', tensor([[[[-3.6984e-07,  3.3287e-03,  1.4184e-03],\n",
      "          [-1.6044e-03,  6.1992e-03, -2.8497e-05],\n",
      "          [-1.7738e-03,  2.4558e-03,  4.2275e-04]],\n",
      "\n",
      "         [[ 1.7079e-04, -3.5593e-03, -9.6510e-04],\n",
      "          [-3.8046e-03,  3.5058e-04, -8.6146e-04],\n",
      "          [-5.5178e-03, -1.6528e-03,  2.4964e-03]],\n",
      "\n",
      "         [[-4.3526e-04,  2.4444e-03, -3.9095e-03],\n",
      "          [-2.4245e-03,  1.8555e-03, -1.7132e-03],\n",
      "          [-3.2249e-03, -3.1784e-03, -2.7299e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0673e-03,  1.3291e-03, -6.4213e-04],\n",
      "          [-2.4680e-03,  2.8578e-03,  1.2131e-03],\n",
      "          [ 6.7255e-04, -1.5590e-03,  2.0590e-03]],\n",
      "\n",
      "         [[ 2.0912e-03, -2.1297e-03, -3.8766e-04],\n",
      "          [-2.5183e-03, -2.0608e-03,  3.7578e-03],\n",
      "          [-7.2185e-04, -1.9036e-03,  8.9262e-05]],\n",
      "\n",
      "         [[ 3.6372e-03,  2.0381e-03,  2.1197e-03],\n",
      "          [-1.3578e-03,  9.1782e-04,  1.6604e-03],\n",
      "          [-1.7659e-03, -1.8609e-03, -1.8538e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.4599e-03, -1.7946e-03, -8.5653e-03],\n",
      "          [-8.2845e-03, -6.6691e-03, -6.9900e-03],\n",
      "          [ 1.4471e-04, -2.5189e-03, -3.3894e-03]],\n",
      "\n",
      "         [[ 7.7437e-03,  3.3055e-03, -4.7894e-04],\n",
      "          [ 1.9096e-03, -1.0936e-03, -3.0007e-03],\n",
      "          [ 7.4213e-04, -1.6448e-03, -2.1883e-03]],\n",
      "\n",
      "         [[-8.2088e-03, -2.0525e-03,  5.8540e-04],\n",
      "          [-3.0490e-03, -3.7569e-03,  4.5553e-03],\n",
      "          [ 4.6774e-04, -2.6674e-03, -7.2901e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1726e-03,  5.9823e-03,  3.6088e-03],\n",
      "          [ 6.8294e-04,  8.3981e-04,  1.0156e-03],\n",
      "          [-1.2101e-03,  1.2209e-03,  9.0694e-04]],\n",
      "\n",
      "         [[ 4.9303e-03,  3.2891e-03,  3.6241e-03],\n",
      "          [-3.5204e-03, -3.6310e-03, -1.6492e-03],\n",
      "          [-3.2776e-03, -5.3240e-03, -4.5901e-03]],\n",
      "\n",
      "         [[ 3.1348e-03,  1.1516e-03,  2.7889e-04],\n",
      "          [ 6.2283e-03,  5.4829e-03,  5.0845e-03],\n",
      "          [-2.0189e-03, -4.9252e-03, -3.8059e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.5934e-03, -5.7348e-03, -2.1527e-03],\n",
      "          [ 3.3991e-03, -2.5534e-03, -2.4544e-03],\n",
      "          [-2.3223e-03, -1.5068e-03, -1.3911e-03]],\n",
      "\n",
      "         [[-4.0027e-04, -5.3774e-04,  4.4089e-03],\n",
      "          [ 1.7022e-03, -1.8635e-03, -1.3564e-04],\n",
      "          [-1.1996e-03, -2.5732e-03,  1.1242e-03]],\n",
      "\n",
      "         [[ 3.6783e-03, -1.1743e-02, -7.5396e-04],\n",
      "          [ 8.2390e-04, -3.8923e-04,  6.9896e-04],\n",
      "          [ 8.7070e-04, -1.6213e-03, -2.8503e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9480e-03,  2.8022e-03,  2.4684e-03],\n",
      "          [ 4.2581e-03,  6.0427e-03,  2.4235e-03],\n",
      "          [ 2.4127e-03,  1.8163e-03,  1.0667e-03]],\n",
      "\n",
      "         [[ 1.3829e-03,  5.4422e-03,  2.6133e-03],\n",
      "          [ 2.5821e-03,  5.0582e-03,  1.1025e-03],\n",
      "          [ 1.2829e-04,  1.0998e-03,  1.2378e-03]],\n",
      "\n",
      "         [[ 6.7148e-04, -5.8779e-03, -2.5386e-03],\n",
      "          [ 6.1650e-04, -9.6282e-03, -5.2430e-03],\n",
      "          [-3.8950e-04, -3.0610e-03, -4.1795e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7133e-03,  8.3795e-04,  1.9417e-03],\n",
      "          [ 6.0039e-03,  4.8288e-03, -3.7002e-03],\n",
      "          [ 2.7542e-03,  2.3610e-03, -2.9751e-03]],\n",
      "\n",
      "         [[ 2.1101e-03,  5.1545e-03, -2.6033e-03],\n",
      "          [ 1.1585e-02,  1.0629e-02,  7.4310e-03],\n",
      "          [ 2.6636e-03,  2.7536e-03, -3.5243e-04]],\n",
      "\n",
      "         [[ 2.4708e-03,  1.6709e-03, -2.0233e-06],\n",
      "          [ 6.3407e-03,  2.8401e-03, -8.8848e-04],\n",
      "          [-9.0681e-04, -2.1404e-03,  7.0673e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7226e-03, -1.5429e-03, -2.8536e-04],\n",
      "          [-7.1945e-03, -7.7846e-03, -2.2399e-03],\n",
      "          [-1.4093e-03,  4.1183e-03,  1.2779e-03]],\n",
      "\n",
      "         [[ 1.5451e-03, -8.3687e-04, -5.8802e-03],\n",
      "          [-1.5400e-04, -3.5396e-03, -3.0190e-03],\n",
      "          [-2.0445e-03, -7.1533e-03, -4.7666e-03]],\n",
      "\n",
      "         [[ 1.8735e-03,  1.4470e-03, -4.4761e-03],\n",
      "          [-4.6384e-03, -5.7516e-03, -2.8011e-03],\n",
      "          [-7.2811e-03, -5.4767e-03,  1.4988e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0153e-03,  3.0578e-04,  5.7293e-04],\n",
      "          [ 1.2593e-03,  2.5290e-03, -1.7675e-03],\n",
      "          [-1.9134e-03, -2.3643e-03,  1.2812e-03]],\n",
      "\n",
      "         [[-1.6784e-03, -3.1248e-03, -1.9490e-04],\n",
      "          [ 1.1425e-03, -2.4076e-03, -3.3669e-04],\n",
      "          [ 1.3132e-03,  2.1017e-03, -2.2617e-03]],\n",
      "\n",
      "         [[ 8.1710e-04,  2.4984e-03,  4.9728e-03],\n",
      "          [ 1.0937e-03,  2.6213e-03, -2.0898e-03],\n",
      "          [ 2.4010e-03,  1.6596e-03, -6.3775e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1296e-03, -3.8729e-03, -4.8127e-03],\n",
      "          [-2.8473e-03, -2.6621e-03, -5.8175e-03],\n",
      "          [-1.1472e-03, -2.7813e-03, -4.0049e-03]],\n",
      "\n",
      "         [[ 1.5745e-03,  2.4493e-03,  9.3286e-04],\n",
      "          [-3.4616e-03, -2.9066e-03, -3.4016e-03],\n",
      "          [-1.1936e-03, -2.3647e-03, -5.7200e-04]],\n",
      "\n",
      "         [[ 4.4516e-03,  4.1522e-03,  1.6393e-03],\n",
      "          [-2.8798e-03,  1.3888e-04, -3.0603e-03],\n",
      "          [-3.3584e-03, -4.0189e-03, -5.6764e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2862e-04,  2.4632e-03, -2.1962e-03],\n",
      "          [ 1.3629e-03,  5.5554e-03, -4.9889e-05],\n",
      "          [ 1.5205e-03,  3.5941e-03,  1.6204e-03]],\n",
      "\n",
      "         [[-3.8872e-05, -1.5342e-03, -2.2161e-05],\n",
      "          [ 4.2136e-03,  2.0037e-03, -5.5311e-04],\n",
      "          [ 7.8968e-03,  3.8460e-03,  2.1397e-03]],\n",
      "\n",
      "         [[ 2.9894e-03,  8.5482e-04, -3.1672e-03],\n",
      "          [ 1.2546e-03,  3.3389e-03, -3.7876e-03],\n",
      "          [ 1.1582e-03, -4.5749e-04, -1.7613e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8027e-03, -4.4796e-04, -3.3573e-03],\n",
      "          [-2.7631e-03, -9.0576e-04, -3.0229e-03],\n",
      "          [-8.6855e-04, -4.0997e-03, -5.1005e-03]],\n",
      "\n",
      "         [[-2.2329e-03, -2.3727e-03,  1.7342e-03],\n",
      "          [-1.4947e-03, -1.4577e-03,  1.8667e-04],\n",
      "          [ 1.3916e-03, -3.5212e-04,  1.4529e-03]],\n",
      "\n",
      "         [[ 8.5156e-05, -8.9214e-03, -4.1107e-03],\n",
      "          [-3.1265e-03,  2.1616e-03, -1.9609e-03],\n",
      "          [ 2.0291e-03,  2.4337e-03, -4.5667e-04]]]], device='cuda:0')), ('heads.bodypart.locref_head.deconv_layers.0.bias', tensor([ 0.0033, -0.0038,  0.0045, -0.0023,  0.0040,  0.0040,  0.0036,  0.0042,\n",
      "         0.0017, -0.0037, -0.0001,  0.0054, -0.0004, -0.0030,  0.0009,  0.0055,\n",
      "         0.0005,  0.0025, -0.0007, -0.0042, -0.0030,  0.0039], device='cuda:0'))])}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m         size_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_bytes\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m size_str\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_model_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/snapshot-263.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mget_model_size\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m---> 19\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m())\n\u001b[1;32m     20\u001b[0m     size_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39melement_size() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Convert to KB, MB, GB, etc.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_model_size(model_path):\n",
    "    \"\"\"\n",
    "    Calculates the size of an ONNX model in bytes.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The path to the ONNX model file.\n",
    "\n",
    "    Returns:\n",
    "        int: The size of the model in bytes.\n",
    "    \"\"\"\n",
    "    if '.onnx' in model_path:\n",
    "        model = onnx.load(model_path)\n",
    "        size_bytes = len(model.SerializeToString())\n",
    "    elif \".pt\" in model_path:\n",
    "        model = torch.load(model_path)\n",
    "        print(model)\n",
    "        params = list(model.parameters())\n",
    "        size_bytes = sum([p.numel() * p.element_size() for p in params])\n",
    "        \n",
    "    # Convert to KB, MB, GB, etc.\n",
    "    if size_bytes < 1024:\n",
    "        size_str = f\"{size_bytes} B\"\n",
    "    elif size_bytes < 1024 * 1024:\n",
    "        size_str = f\"{size_bytes / 1024:.2f} KB\"\n",
    "    elif size_bytes < 1024 * 1024 * 1024:\n",
    "        size_str = f\"{size_bytes / (1024 * 1024):.2f} MB\"\n",
    "    else:\n",
    "        size_str = f\"{size_bytes / (1024 * 1024 * 1024):.2f} GB\"\n",
    "\n",
    "    return size_str\n",
    "\n",
    "\n",
    "get_model_size(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/snapshot-263.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 150.0\n",
      "Number of frames: 1500.0\n",
      "Video length (seconds): 10.0\n",
      "Frame size: (658, 302)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_characteristics(video_path):\n",
    "    \"\"\"\n",
    "    Extracts the FPS, number of frames, length in seconds, and frame size of a video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): The path to the video file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the FPS, number of frames, length in seconds, and frame size.\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate video length in seconds\n",
    "    video_length = frame_count / fps\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return fps, frame_count, video_length, (frame_width, frame_height)\n",
    "\n",
    "# Example usage:\n",
    "video_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/1_20cms_0degUP_first.avi\"\n",
    "fps, frame_count, video_length, frame_size = get_video_characteristics(video_path)\n",
    "\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Number of frames:\", frame_count)\n",
    "print(\"Video length (seconds):\", video_length)\n",
    "print(\"Frame size:\", frame_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
