{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Live PyTorch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot to ONNX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you do not have a .onnx model exported, use this cell to export your DLC3.0 snapshot\n",
    "\n",
    "from deeplabcut.pose_estimation_pytorch.config import read_config_as_dict\n",
    "from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#Dikra\n",
    "# root = Path(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\")\n",
    "# model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "# weights_path = root / \"snapshot-200.pt\"\n",
    "\n",
    "#Anna\n",
    "root = Path(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\")\n",
    "model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "weights_path = root / \"snapshot-263.pt\"\n",
    "\n",
    "model = PoseModel.build(model_cfg[\"model\"])\n",
    "weights = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "dummy_input = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/resnet.onnx\",\n",
    "    verbose=False,\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test frame\n",
    "img = cv2.imread(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/img008.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with ONNX exported DLC 3.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dikra\n",
    "onnx_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# onnx_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# onnx_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "onnx_pose = onnx_dlc_live.init_inference(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot from 2024-08-20 14-29-53.png](./docs/assets/Screenshot%20from%202024-08-20%2014-36-00.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_pose = onnx_dlc_live.get_pose(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with snaptshot of DLC 3.0 model (.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dikra\n",
    "pytorch_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# pytorch_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# pytorch_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "pytorch_pose = pytorch_dlc_live.init_inference(frame=img)\n",
    "pytorch_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PyTorch model inference](./docs/assets/Screenshot%20from%202024-08-20%2014-29-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "root = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\"\n",
    "test_images = glob.glob(os.path.normpath(root + \"/*.png\"))\n",
    "\n",
    "\n",
    "def mean_time_inference(dlc_live, images):\n",
    "    times = []\n",
    "    for i, img_p in enumerate(images):\n",
    "        img = cv2.imread(img_p)\n",
    "\n",
    "        if i == 0:\n",
    "            start = time.time()\n",
    "            dlc_live.init_inference(img)\n",
    "            end = time.time()\n",
    "        else:\n",
    "            start = time.time()\n",
    "            dlc_live.get_pose(img)\n",
    "            end = time.time()\n",
    "        times.append(end - start)\n",
    "    print(times)\n",
    "\n",
    "    return np.mean(times), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"TOTAL Inference of ONNX model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\"\n",
    ")\n",
    "root = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\"\n",
    "test_images = glob.glob(os.path.normpath(root + \"/*.png\"))\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images) \n",
    "print(f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "Currently the benchmark_pytorch.py script serves to provide a function for analyzing a preexisting video to test PyTorch for running video inference in DLC-Live. Code for running video inference on a live video feed is WIP.\n",
    "\n",
    "For true benchmarking purposes, we aim to add feature for recording the time it takes to analyze each frame / how many frames can be analyzed per second. Discuss what measure to use and consult the DLC Live paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import the analyze_video function from the file where it's defined\n",
    "from dlclive.benchmark_pytorch import analyze_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.19529318809509277 sec\n",
      "(False, 0.5, 10)\n",
      "ONNX inference took 0.08277511596679688 sec\n",
      "Frame 0 processing time: 0.7322 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.020071029663085938 sec\n",
      "Frame 1 processing time: 0.0395 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.08681607246398926 sec\n",
      "Frame 2 processing time: 0.1013 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.07651567459106445 sec\n",
      "Frame 3 processing time: 0.0930 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.1179802417755127 sec\n",
      "Frame 4 processing time: 0.1333 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.024595022201538086 sec\n",
      "Frame 5 processing time: 0.0451 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.11923360824584961 sec\n",
      "Frame 6 processing time: 0.1358 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.02418375015258789 sec\n",
      "Frame 7 processing time: 0.0433 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.12104606628417969 sec\n",
      "Frame 8 processing time: 0.1354 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.029593944549560547 sec\n",
      "Frame 9 processing time: 0.0431 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.1113579273223877 sec\n",
      "Frame 10 processing time: 0.1338 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.024258136749267578 sec\n",
      "Frame 11 processing time: 0.0447 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.10893511772155762 sec\n",
      "Frame 12 processing time: 0.1353 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.026179790496826172 sec\n",
      "Frame 13 processing time: 0.0417 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.11181116104125977 sec\n",
      "Frame 14 processing time: 0.1349 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.024836301803588867 sec\n",
      "Frame 15 processing time: 0.0434 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.1345977783203125 sec\n",
      "Frame 16 processing time: 0.1733 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.05120277404785156 sec\n",
      "Frame 17 processing time: 0.0726 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.20719599723815918 sec\n",
      "Frame 18 processing time: 0.2380 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.03429913520812988 sec\n",
      "Frame 19 processing time: 0.0554 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.11024904251098633 sec\n",
      "Frame 20 processing time: 0.1346 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.028177976608276367 sec\n",
      "Frame 21 processing time: 0.0428 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.13470911979675293 sec\n",
      "Frame 22 processing time: 0.1526 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.04783916473388672 sec\n",
      "Frame 23 processing time: 0.0596 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.20224595069885254 sec\n",
      "Frame 24 processing time: 0.2178 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.032681941986083984 sec\n",
      "Frame 25 processing time: 0.0419 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.13912391662597656 sec\n",
      "Frame 26 processing time: 0.1716 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.03926992416381836 sec\n",
      "Frame 27 processing time: 0.0548 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.23497986793518066 sec\n",
      "Frame 28 processing time: 0.2515 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.051239967346191406 sec\n",
      "Frame 29 processing time: 0.0600 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.2749197483062744 sec\n",
      "Frame 30 processing time: 0.3021 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.05209088325500488 sec\n",
      "Frame 31 processing time: 0.0758 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.24599981307983398 sec\n",
      "Frame 32 processing time: 0.2680 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.05596208572387695 sec\n",
      "Frame 33 processing time: 0.0762 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.3406813144683838 sec\n",
      "Frame 34 processing time: 0.3683 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.052742958068847656 sec\n",
      "Frame 35 processing time: 0.0764 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.2324509620666504 sec\n",
      "Frame 36 processing time: 0.2511 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.06775903701782227 sec\n",
      "Frame 37 processing time: 0.0953 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.361220121383667 sec\n",
      "Frame 38 processing time: 0.3825 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.07810020446777344 sec\n",
      "Frame 39 processing time: 0.0920 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.2923851013183594 sec\n",
      "Frame 40 processing time: 0.3189 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.04073905944824219 sec\n",
      "Frame 41 processing time: 0.0589 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.30202198028564453 sec\n",
      "Frame 42 processing time: 0.3184 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.06128191947937012 sec\n",
      "Frame 43 processing time: 0.0762 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.2544431686401367 sec\n",
      "Frame 44 processing time: 0.2850 seconds\n",
      "{'host_name': 'MCKDQTN4YXDV', 'op_sys': 'macOS-14.5-arm64-arm-64bit', 'python': 'deeplabcut3', 'device_type': 'CPU', 'device': ['Apple M2'], 'freeze': ['absl-py==2.1.0', 'alabaster==0.7.16', 'albumentations==1.4.3', 'app-model==0.2.7', 'appdirs==1.4.4', 'appnope==0.1.4', 'asttokens==2.4.1', 'astunparse==1.6.3', 'attrs==23.2.0', 'Babel==2.15.0', 'blosc2==2.0.0', 'build==1.2.1', 'cachetools==5.4.0', 'cachey==0.2.1', 'certifi==2024.7.4', 'charset-normalizer==3.3.2', 'click==8.1.7', 'cloudpickle==3.0.0', 'colorcet==3.1.0', 'coloredlogs==15.0.1', 'comm==0.2.2', 'contourpy==1.2.1', 'cycler==0.12.1', 'Cython==3.0.10', 'dask==2024.7.0', 'dask-expr==1.1.7', 'dask-image==2024.5.3', 'debugpy==1.8.2', 'decorator==5.1.1', 'deeplabcut @ git+https://github.com/DeepLabCut/DeepLabCut.git@83f1acb9c179caf46353cdb211318b29832ff6ec', 'deeplabcut-live==1.0.2', 'deeplabcut-live-gui @ file:///Users/annastuckert/Documents/DeepLabCut-live-GUI', 'dill==0.3.8', 'dlclibrary==0.0.6', 'docker-pycreds==0.4.0', 'docstring_parser==0.16', 'docutils==0.17.1', 'einops==0.8.0', 'exceptiongroup==1.2.2', 'executing==2.0.1', 'filelock==3.15.4', 'filterpy==1.4.5', 'flatbuffers==24.3.25', 'flexcache==0.3', 'flexparser==0.3.1', 'fonttools==4.53.1', 'freetype-py==2.4.0', 'fsspec==2024.6.1', 'gast==0.4.0', 'gitdb==4.0.11', 'GitPython==3.1.43', 'google-auth==2.32.0', 'google-auth-oauthlib==0.4.6', 'google-pasta==0.2.0', 'grpcio==1.65.4', 'h5py==3.11.0', 'HeapDict==1.0.1', 'hsluv==5.0.4', 'huggingface-hub==0.23.5', 'humanfriendly==10.0', 'idna==3.7', 'imageio==2.34.2', 'imageio-ffmpeg==0.5.1', 'imagesize==1.4.1', 'imgaug==0.4.0', 'importlib_metadata==8.0.0', 'imutils==0.5.4', 'in-n-out==0.2.1', 'ipykernel==6.29.5', 'ipython==8.26.0', 'jedi==0.19.1', 'Jinja2==3.1.4', 'joblib==1.4.2', 'jsonschema==4.23.0', 'jsonschema-specifications==2023.12.1', 'jupyter_client==8.6.2', 'jupyter_core==5.7.2', 'keras==2.11.0', 'kiwisolver==1.4.5', 'lazy_loader==0.4', 'libclang==18.1.1', 'llvmlite==0.43.0', 'locket==1.0.0', 'magicgui==0.8.3', 'Markdown==3.6', 'markdown-it-py==3.0.0', 'MarkupSafe==2.1.5', 'matplotlib==3.8.4', 'matplotlib-inline==0.1.7', 'mdurl==0.1.2', 'memory-profiler==0.61.0', 'ml-dtypes==0.4.0', 'mpmath==1.3.0', 'msgpack==1.0.8', 'msgpack-numpy==0.4.8', 'multiprocess==0.70.16', 'namex==0.0.8', 'napari==0.4.18', 'napari-console==0.0.9', 'napari-deeplabcut==0.2.1.7', 'napari-plugin-engine==0.2.0', 'napari-svg==0.2.0', 'natsort==8.4.0', 'nest-asyncio==1.6.0', 'networkx==3.3', 'npe2==0.7.6', 'numba==0.60.0', 'numexpr @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_45yefq0kt6/croot/numexpr_1696515289183/work', 'numpy==1.26.4', 'numpydoc==1.5.0', 'oauthlib==3.2.2', 'onnx==1.16.2', 'onnxruntime==1.18.1', 'onnxruntime-tools==1.7.0', 'onnxscript==0.1.0.dev20240813', 'opencv-python==4.10.0.84', 'opencv-python-headless==4.10.0.84', 'opt-einsum==3.3.0', 'optree==0.12.1', 'packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1718189413536/work', 'pandas==1.5.3', 'parso==0.8.4', 'partd==1.4.2', 'patsy==0.5.6', 'pexpect==4.9.0', 'pillow==10.4.0', 'PIMS==0.7', 'Pint==0.24.3', 'pip==24.0', 'platformdirs==4.2.2', 'pooch==1.8.2', 'prompt_toolkit==3.0.47', 'protobuf==5.27.3', 'psutil==6.0.0', 'psygnal==0.11.1', 'ptyprocess==0.7.0', 'pure-eval==0.2.2', 'py-cpuinfo @ file:///home/conda/feedstock_root/build_artifacts/py-cpuinfo_1666774466606/work', 'py3nvml==0.2.7', 'pyarrow==17.0.0', 'pyasn1==0.6.0', 'pyasn1_modules==0.4.0', 'pycocotools==2.0.8', 'pyconify==0.1.6', 'pydantic==1.10.17', 'pydantic-compat==0.1.2', 'Pygments==2.18.0', 'PyOpenGL==3.1.7', 'pyparsing==3.1.2', 'pyproject_hooks==1.1.0', 'pyserial==3.5', 'PySide6==6.4.2', 'PySide6-Addons==6.4.2', 'PySide6-Essentials==6.4.2', 'python-dateutil==2.9.0.post0', 'pytz==2024.1', 'PyYAML==6.0.1', 'pyzmq==26.0.3', 'QDarkStyle==3.1', 'qtconsole==5.5.2', 'QtPy==2.4.1', 'referencing==0.35.1', 'requests==2.32.3', 'requests-oauthlib==2.0.0', 'rich==13.7.1', 'rpds-py==0.19.0', 'rsa==4.9', 'ruamel.yaml==0.17.40', 'ruamel.yaml.clib==0.2.8', 'safetensors==0.4.3', 'scikit-image==0.24.0', 'scikit-learn==1.5.1', 'scipy==1.10.1', 'sentry-sdk==2.10.0', 'setproctitle==1.3.3', 'setuptools==69.5.1', 'shapely==2.0.5', 'shellingham==1.5.4', 'shiboken6==6.4.2', 'six==1.16.0', 'slicerator==1.1.0', 'smmap==5.0.1', 'snowballstemmer==2.2.0', 'Sphinx==4.5.0', 'sphinxcontrib-applehelp==1.0.8', 'sphinxcontrib-devhelp==1.0.6', 'sphinxcontrib-htmlhelp==2.0.5', 'sphinxcontrib-jsmath==1.0.1', 'sphinxcontrib-qthelp==1.0.7', 'sphinxcontrib-serializinghtml==1.1.10', 'stack-data==0.6.3', 'statsmodels==0.14.2', 'superqt==0.6.7', 'sympy==1.13.0', 'tables @ file:///private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_81qnps6056/croot/pytables_1691621471831/work', 'tabulate==0.9.0', 'tensorboard==2.11.2', 'tensorboard-data-server==0.6.1', 'tensorboard-plugin-wit==1.8.1', 'tensorflow-estimator==2.11.0', 'tensorflow-io-gcs-filesystem==0.37.1', 'tensorflow-macos==2.11.0', 'tensorflow-metal==1.1.0', 'tensorpack==0.11', 'termcolor==2.4.0', 'tf-slim==1.1.0', 'threadpoolctl==3.5.0', 'tifffile==2024.7.2', 'timm==1.0.7', 'tomli==2.0.1', 'tomli_w==1.0.0', 'toolz==0.12.1', 'torch==2.3.1', 'torchvision==0.18.1', 'tornado==6.4.1', 'tqdm==4.66.4', 'traitlets==5.14.3', 'typer==0.12.3', 'typing_extensions==4.12.2', 'tzdata==2024.1', 'urllib3==2.2.2', 'vispy==0.12.2', 'wandb==0.17.4', 'wcwidth==0.2.13', 'Werkzeug==3.0.3', 'wheel==0.43.0', 'wrapt==1.16.0', 'xmltodict==0.13.0', 'zipp==3.19.2'], 'python_version': '3.10.14 (main, May  6 2024, 14:42:37) [Clang 14.0.6 ]', 'git_hash': 'd7010c5387ae43d880273cfef1f8d8430797d6d2', 'dlclive_version': '1.0.4'}\n"
     ]
    }
   ],
   "source": [
    "# New version with DLCLive object included in the code\n",
    "\n",
    "\n",
    "\n",
    "# Define the paths\n",
    "video_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/1_20cms_0degUP_first_03s.avi'\n",
    "model_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train'\n",
    "\n",
    "# import cProfile\n",
    "# import io\n",
    "# import pstats\n",
    "\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "# Call the analyze_video function with the appropriate arguments\n",
    "poses = analyze_video(\n",
    "    video_path=video_path,\n",
    "    model_path=model_path,\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",      \n",
    "    display=True,      \n",
    "    save_poses=True,\n",
    "    resize= 0.5,\n",
    "    #cropping= [50, 250, 100, 450], # manually set the cropping to specific pixels\n",
    "    dynamic=(True, 0.5, 10), #True = we want to apply dynamic cropping, 0.5 = the threshold for accepting a KP as detected, 10 = the margin to expand the calculatted cropping window by so it is not too narrow\n",
    "    save_dir='output_directory',  \n",
    "    get_sys_info=True,\n",
    "    draw_keypoint_names=True      \n",
    ")\n",
    "\n",
    "# #'poses' will contain the list of poses detected\n",
    "\n",
    "# # Create a stream to capture the profiler's output\n",
    "# s = io.StringIO()\n",
    "# sortby = 'cumulative'\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "\n",
    "# # Print the profiling output\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/envs/deeplabcut3/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.19833016395568848 sec\n",
      "(False, 0.5, 10)\n",
      "ONNX inference took 0.6125681400299072 sec\n",
      "Frame 0 processing time: 1.7313 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.7607908248901367 sec\n",
      "Frame 1 processing time: 0.8297 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.5932559967041016 sec\n",
      "Frame 2 processing time: 0.6324 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.5236778259277344 sec\n",
      "Frame 3 processing time: 0.5676 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.5804789066314697 sec\n",
      "Frame 4 processing time: 0.6206 seconds\n",
      "(True, 0.5, 10)\n",
      "ONNX inference took 0.5585100650787354 sec\n",
      "Frame 5 processing time: 0.5962 seconds\n",
      "(True, 0.5, 10)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#hand model and video\n",
    "\n",
    "# Define the paths\n",
    "video_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Hand-AnnaStuckert-2024-08-21/videos/Hand.avi'\n",
    "model_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Hand-AnnaStuckert-2024-08-21/dlc-models-pytorch/iteration-0/HandAug21-trainset95shuffle101/train'\n",
    "\n",
    "\n",
    "# Call the analyze_video function with the appropriate arguments\n",
    "poses = analyze_video(\n",
    "    video_path=video_path,\n",
    "    model_path=model_path,\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",      \n",
    "    display=True,      \n",
    "    save_poses=True,\n",
    "    resize= 0.4,\n",
    "    #cropping= [50, 250, 100, 450], # manually set the cropping to specific pixels\n",
    "    dynamic=(True, 0.5, 10), #True = we want to apply dynamic cropping, 0.5 = the threshold for accepting a KP as detected, 10 = the margin to expand the calculatted cropping window by so it is not too narrow\n",
    "    save_dir='output_directory',  \n",
    "    get_sys_info=True,\n",
    "    draw_keypoint_names=True      \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test download of benchmarking dataset \n",
    "#OBS link it not working, waiting for updated link to benchmarking dataset\n",
    "\n",
    "# from dlclive.benchmark_pytorch import download_benchmarking_data\n",
    "\n",
    "# download_benchmarking_data()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
