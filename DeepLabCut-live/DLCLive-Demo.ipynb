{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Live PyTorch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc4...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikra/miniconda3/envs/dlc-live/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dlclive import DLCLive, Processor\n",
    "from dlclive.display import Display\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snapshot to ONNX model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34268/968774635.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(weights_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# In case you do not have a .onnx model exported, use this cell to export your DLC3.0 snapshot\n",
    "\n",
    "from deeplabcut.pose_estimation_pytorch.config import read_config_as_dict\n",
    "from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "root = Path(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\")\n",
    "model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "weights_path = root / \"snapshot-200.pt\"\n",
    "\n",
    "model = PoseModel.build(model_cfg[\"model\"])\n",
    "weights = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "dummy_input = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/resnet.onnx\",\n",
    "    verbose=False,\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test frame\n",
    "img = cv2.imread(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/img008.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with ONNX exported DLC 3.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.22803378105163574 sec\n",
      "ONNX inference took 1.7877936363220215 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'poses': tensor([[[[3.6219e+02, 4.1237e+02, 5.0484e-01],\n",
       "           [3.6271e+02, 3.9583e+02, 5.8567e-01],\n",
       "           [3.5676e+02, 3.7445e+02, 7.0499e-01],\n",
       "           [3.4043e+02, 3.5935e+02, 7.1168e-01],\n",
       "           [3.3437e+02, 4.0497e+02, 6.5114e-01],\n",
       "           [3.3772e+02, 4.0690e+02, 4.4899e-01],\n",
       "           [2.0013e+02, 4.3546e+02, 5.2085e-01],\n",
       "           [3.4130e+02, 4.3089e+02, 3.4881e-01],\n",
       "           [2.1540e+02, 3.9427e+02, 7.8372e-01],\n",
       "           [1.9975e+02, 3.7728e+02, 5.2776e-01],\n",
       "           [1.8255e+02, 3.6741e+02, 6.4682e-01],\n",
       "           [2.7520e+02, 3.3175e+02, 5.7621e-01],\n",
       "           [3.5014e+02, 4.3089e+02, 4.1483e-01],\n",
       "           [4.3459e+02, 3.1565e+02, 8.1688e-01],\n",
       "           [4.2561e+02, 2.9912e+02, 8.8812e-01],\n",
       "           [2.4359e+02, 5.0566e+02, 5.7648e-01],\n",
       "           [3.5792e+02, 4.8275e+02, 3.0060e-01],\n",
       "           [4.0234e+02, 4.1449e+02, 5.4227e-01],\n",
       "           [1.7143e+02, 4.8667e+02, 4.5833e-01],\n",
       "           [3.2110e+02, 5.1144e+02, 2.5105e-01],\n",
       "           [3.9915e+02, 4.1933e+02, 6.2738e-01],\n",
       "           [2.3576e+02, 4.3456e+02, 6.5920e-01],\n",
       "           [3.1891e+02, 4.2855e+02, 6.0911e-01],\n",
       "           [1.7677e+02, 4.1291e+02, 3.5333e-01],\n",
       "           [3.1286e+02, 4.2730e+02, 6.1892e-01]]]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "onnx_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# onnx_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# onnx_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "onnx_pose = onnx_dlc_live.init_inference(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot from 2024-08-20 14-29-53.png](./docs/assets/Screenshot%20from%202024-08-20%2014-36-00.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.06539440155029297 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'poses': tensor([[[[3.6219e+02, 4.1237e+02, 5.0484e-01],\n",
       "           [3.6271e+02, 3.9583e+02, 5.8567e-01],\n",
       "           [3.5676e+02, 3.7445e+02, 7.0499e-01],\n",
       "           [3.4043e+02, 3.5935e+02, 7.1168e-01],\n",
       "           [3.3437e+02, 4.0497e+02, 6.5114e-01],\n",
       "           [3.3772e+02, 4.0690e+02, 4.4899e-01],\n",
       "           [2.0013e+02, 4.3546e+02, 5.2085e-01],\n",
       "           [3.4130e+02, 4.3089e+02, 3.4881e-01],\n",
       "           [2.1540e+02, 3.9427e+02, 7.8372e-01],\n",
       "           [1.9975e+02, 3.7728e+02, 5.2776e-01],\n",
       "           [1.8255e+02, 3.6741e+02, 6.4682e-01],\n",
       "           [2.7520e+02, 3.3175e+02, 5.7621e-01],\n",
       "           [3.5014e+02, 4.3089e+02, 4.1483e-01],\n",
       "           [4.3459e+02, 3.1565e+02, 8.1688e-01],\n",
       "           [4.2561e+02, 2.9912e+02, 8.8812e-01],\n",
       "           [2.4359e+02, 5.0566e+02, 5.7648e-01],\n",
       "           [3.5792e+02, 4.8275e+02, 3.0060e-01],\n",
       "           [4.0234e+02, 4.1449e+02, 5.4227e-01],\n",
       "           [1.7143e+02, 4.8667e+02, 4.5833e-01],\n",
       "           [3.2110e+02, 5.1144e+02, 2.5105e-01],\n",
       "           [3.9915e+02, 4.1933e+02, 6.2738e-01],\n",
       "           [2.3576e+02, 4.3456e+02, 6.5920e-01],\n",
       "           [3.1891e+02, 4.2855e+02, 6.0911e-01],\n",
       "           [1.7677e+02, 4.1291e+02, 3.5333e-01],\n",
       "           [3.1286e+02, 4.2730e+02, 6.1892e-01]]]])}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pose = onnx_dlc_live.get_pose(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with snaptshot of DLC 3.0 model (.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikra/MyHub/Code/DLC24_Hub/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:260: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_path, map_location=torch.device(self.device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'poses': tensor([[[[4.6099e+02, 3.0565e+02, 2.2497e-01],\n",
       "           [4.6334e+02, 2.9737e+02, 5.2393e-01],\n",
       "           [4.7105e+02, 2.9226e+02, 5.7827e-01],\n",
       "           [4.7816e+02, 2.9004e+02, 6.5970e-01],\n",
       "           [5.7700e+02, 3.4287e+02, 6.7695e-01],\n",
       "           [4.4610e+02, 3.3317e+02, 6.4596e-01],\n",
       "           [5.3632e+02, 4.2195e+02, 5.4373e-01],\n",
       "           [4.5563e+02, 3.5570e+02, 2.5123e-01],\n",
       "           [5.5438e+02, 3.6476e+02, 6.2622e-01],\n",
       "           [5.3584e+02, 3.6377e+02, 6.4735e-01],\n",
       "           [5.1307e+02, 3.6640e+02, 6.0587e-01],\n",
       "           [5.2159e+02, 2.9548e+02, 4.5409e-01],\n",
       "           [4.8214e+02, 3.8471e+02, 2.4118e-01],\n",
       "           [4.8334e+02, 2.1336e+02, 7.4011e-01],\n",
       "           [4.5919e+02, 2.0870e+02, 6.2153e-01],\n",
       "           [6.0561e+02, 4.7224e+02, 5.8598e-01],\n",
       "           [5.9742e+02, 4.2868e+02, 4.8355e-01],\n",
       "           [5.7910e+02, 4.2470e+02, 2.6089e-01],\n",
       "           [4.6775e+02, 4.9880e+02, 8.5475e-01],\n",
       "           [4.4069e+02, 4.2392e+02, 6.7025e-01],\n",
       "           [4.3888e+02, 4.0817e+02, 6.0956e-01],\n",
       "           [5.7074e+02, 4.0371e+02, 5.8136e-01],\n",
       "           [5.8398e+02, 3.5102e+02, 9.8475e-01],\n",
       "           [4.8705e+02, 4.1552e+02, 7.0512e-01],\n",
       "           [4.4030e+02, 3.6436e+02, 7.3079e-01]]]], grad_fn=<CopySlices>)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "pytorch_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# pytorch_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# pytorch_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "pytorch_pose = pytorch_dlc_live.init_inference(frame=img)\n",
    "pytorch_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PyTorch model inference](./docs/assets/Screenshot%20from%202024-08-20%2014-29-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "root = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\"\n",
    "test_images = glob.glob(os.path.normpath(root + \"/*.png\"))\n",
    "\n",
    "\n",
    "def mean_time_inference(dlc_live, images):\n",
    "    times = []\n",
    "    for i, img_p in enumerate(images):\n",
    "        img = cv2.imread(img_p)\n",
    "\n",
    "        if i == 0:\n",
    "            start = time.time()\n",
    "            dlc_live.init_inference(img)\n",
    "            end = time.time()\n",
    "        else:\n",
    "            start = time.time()\n",
    "            dlc_live.get_pose(img)\n",
    "            end = time.time()\n",
    "        times.append(end - start)\n",
    "    print(times)\n",
    "\n",
    "    return np.mean(times), times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.5293464660644531 sec\n",
      "ONNX inference took 2.8643910884857178 sec\n",
      "ONNX inference took 0.06293821334838867 sec\n",
      "ONNX inference took 0.06203794479370117 sec\n",
      "ONNX inference took 0.06301212310791016 sec\n",
      "ONNX inference took 0.06281137466430664 sec\n",
      "ONNX inference took 0.06262016296386719 sec\n",
      "ONNX inference took 0.06253719329833984 sec\n",
      "ONNX inference took 0.06359624862670898 sec\n",
      "ONNX inference took 0.06127595901489258 sec\n",
      "ONNX inference took 0.0638742446899414 sec\n",
      "ONNX inference took 0.06360268592834473 sec\n",
      "ONNX inference took 0.06196093559265137 sec\n",
      "ONNX inference took 0.06411862373352051 sec\n",
      "ONNX inference took 0.062486886978149414 sec\n",
      "ONNX inference took 0.06318998336791992 sec\n",
      "ONNX inference took 0.06252145767211914 sec\n",
      "ONNX inference took 0.06220364570617676 sec\n",
      "ONNX inference took 0.06342172622680664 sec\n",
      "ONNX inference took 0.06285452842712402 sec\n",
      "ONNX inference took 0.061716318130493164 sec\n",
      "ONNX inference took 0.0622098445892334 sec\n",
      "ONNX inference took 0.06132149696350098 sec\n",
      "ONNX inference took 0.060708045959472656 sec\n",
      "ONNX inference took 0.06439352035522461 sec\n",
      "ONNX inference took 0.06228303909301758 sec\n",
      "ONNX inference took 0.061907052993774414 sec\n",
      "ONNX inference took 0.06296086311340332 sec\n",
      "ONNX inference took 0.06260347366333008 sec\n",
      "ONNX inference took 0.06310629844665527 sec\n",
      "ONNX inference took 0.06171703338623047 sec\n",
      "ONNX inference took 0.06274557113647461 sec\n",
      "ONNX inference took 0.06219792366027832 sec\n",
      "ONNX inference took 0.0631253719329834 sec\n",
      "ONNX inference took 0.06525635719299316 sec\n",
      "ONNX inference took 0.062381744384765625 sec\n",
      "ONNX inference took 0.06477046012878418 sec\n",
      "ONNX inference took 0.06212353706359863 sec\n",
      "ONNX inference took 0.062134742736816406 sec\n",
      "[3.6004927158355713, 0.16333270072937012, 0.16322565078735352, 0.15692901611328125, 0.14582180976867676, 0.19791460037231445, 0.16245031356811523, 0.22297453880310059, 0.20104360580444336, 0.17827916145324707, 0.17180466651916504, 0.18144559860229492, 0.18686938285827637, 0.15880894660949707, 0.17464232444763184, 0.1588892936706543, 0.13772320747375488, 0.14135098457336426, 0.15580487251281738, 0.13239407539367676, 0.1489095687866211, 0.18770885467529297, 0.14936494827270508, 0.16499829292297363, 0.18494272232055664, 0.16262269020080566, 0.20069432258605957, 0.18917632102966309, 0.14367079734802246, 0.1674509048461914, 0.20622968673706055, 0.15231919288635254, 0.18451619148254395, 0.17963075637817383, 0.1724414825439453, 0.1865828037261963, 0.16090035438537598, 0.16449904441833496]\n",
      "TOTAL Inference of ONNX model took on average (0.26049622109061793, [3.6004927158355713, 0.16333270072937012, 0.16322565078735352, 0.15692901611328125, 0.14582180976867676, 0.19791460037231445, 0.16245031356811523, 0.22297453880310059, 0.20104360580444336, 0.17827916145324707, 0.17180466651916504, 0.18144559860229492, 0.18686938285827637, 0.15880894660949707, 0.17464232444763184, 0.1588892936706543, 0.13772320747375488, 0.14135098457336426, 0.15580487251281738, 0.13239407539367676, 0.1489095687866211, 0.18770885467529297, 0.14936494827270508, 0.16499829292297363, 0.18494272232055664, 0.16262269020080566, 0.20069432258605957, 0.18917632102966309, 0.14367079734802246, 0.1674509048461914, 0.20622968673706055, 0.15231919288635254, 0.18451619148254395, 0.17963075637817383, 0.1724414825439453, 0.1865828037261963, 0.16090035438537598, 0.16449904441833496]) seconds for 38 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"TOTAL Inference of ONNX model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikra/MyHub/Code/DLC24_Hub/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:257: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.pose_model = PoseModel.build(self.cfg[\"model\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.2649521827697754 sec\n",
      "PyTorch inference took 0.004726886749267578 sec\n",
      "PyTorch inference took 0.013677835464477539 sec\n",
      "PyTorch inference took 0.03649282455444336 sec\n",
      "PyTorch inference took 0.032695770263671875 sec\n",
      "PyTorch inference took 0.008616924285888672 sec\n",
      "PyTorch inference took 0.012260675430297852 sec\n",
      "PyTorch inference took 0.039740800857543945 sec\n",
      "PyTorch inference took 0.016360998153686523 sec\n",
      "PyTorch inference took 0.029901742935180664 sec\n",
      "PyTorch inference took 0.013670206069946289 sec\n",
      "PyTorch inference took 0.006944894790649414 sec\n",
      "PyTorch inference took 0.015252113342285156 sec\n",
      "PyTorch inference took 0.00914621353149414 sec\n",
      "PyTorch inference took 0.028045177459716797 sec\n",
      "PyTorch inference took 0.027249574661254883 sec\n",
      "PyTorch inference took 0.028400182723999023 sec\n",
      "PyTorch inference took 0.02504706382751465 sec\n",
      "PyTorch inference took 0.03605461120605469 sec\n",
      "PyTorch inference took 0.019296646118164062 sec\n",
      "PyTorch inference took 0.016387224197387695 sec\n",
      "PyTorch inference took 0.009374380111694336 sec\n",
      "PyTorch inference took 0.03654932975769043 sec\n",
      "PyTorch inference took 0.012722969055175781 sec\n",
      "PyTorch inference took 0.027462482452392578 sec\n",
      "PyTorch inference took 0.015032291412353516 sec\n",
      "PyTorch inference took 0.04392647743225098 sec\n",
      "PyTorch inference took 0.017442703247070312 sec\n",
      "PyTorch inference took 0.015609502792358398 sec\n",
      "PyTorch inference took 0.046546220779418945 sec\n",
      "PyTorch inference took 0.014932394027709961 sec\n",
      "PyTorch inference took 0.015069961547851562 sec\n",
      "PyTorch inference took 0.0039157867431640625 sec\n",
      "PyTorch inference took 0.011582136154174805 sec\n",
      "PyTorch inference took 0.009721040725708008 sec\n",
      "PyTorch inference took 0.016019105911254883 sec\n",
      "PyTorch inference took 0.010933160781860352 sec\n",
      "PyTorch inference took 0.01641845703125 sec\n",
      "PyTorch inference took 0.010236024856567383 sec\n",
      "[0.3584418296813965, 0.11312270164489746, 0.07643866539001465, 0.09857773780822754, 0.08085846900939941, 0.10492062568664551, 0.0926964282989502, 0.1187436580657959, 0.1404552459716797, 0.08995485305786133, 0.07388854026794434, 0.060804128646850586, 0.06808638572692871, 0.09235692024230957, 0.10183048248291016, 0.09524154663085938, 0.11664533615112305, 0.1053309440612793, 0.08962821960449219, 0.0972282886505127, 0.05475497245788574, 0.1108846664428711, 0.08182597160339355, 0.12437582015991211, 0.0915369987487793, 0.08167767524719238, 0.10096359252929688, 0.08533310890197754, 0.0942385196685791, 0.05704927444458008, 0.05634474754333496, 0.06014871597290039, 0.061289072036743164, 0.054155826568603516, 0.04961681365966797, 0.05791473388671875, 0.049634456634521484, 0.08701348304748535]\n",
      "Inference of PyTorch model took on average (0.0930002488588032, [0.3584418296813965, 0.11312270164489746, 0.07643866539001465, 0.09857773780822754, 0.08085846900939941, 0.10492062568664551, 0.0926964282989502, 0.1187436580657959, 0.1404552459716797, 0.08995485305786133, 0.07388854026794434, 0.060804128646850586, 0.06808638572692871, 0.09235692024230957, 0.10183048248291016, 0.09524154663085938, 0.11664533615112305, 0.1053309440612793, 0.08962821960449219, 0.0972282886505127, 0.05475497245788574, 0.1108846664428711, 0.08182597160339355, 0.12437582015991211, 0.0915369987487793, 0.08167767524719238, 0.10096359252929688, 0.08533310890197754, 0.0942385196685791, 0.05704927444458008, 0.05634474754333496, 0.06014871597290039, 0.061289072036743164, 0.054155826568603516, 0.04961681365966797, 0.05791473388671875, 0.049634456634521484, 0.08701348304748535]) seconds for 38 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error /onnxruntime_src/onnxruntime/python/onnxruntime_pybind_state.cc:490 void onnxruntime::python::RegisterTensorRTPluginsAsCustomOps(PySessionOptions&, const onnxruntime::ProviderOptions&) Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "Loading the model took 0.4814929962158203 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2024-08-21 14:16:18.942517786 [E:onnxruntime:Default, provider_bridge_ort.cc:1978 TryGetProviderInfo_TensorRT] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1637 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_tensorrt.so with error: libnvinfer.so.10: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.6044352054595947 sec\n",
      "ONNX inference took 0.6298971176147461 sec\n",
      "ONNX inference took 0.5582480430603027 sec\n",
      "ONNX inference took 0.5535740852355957 sec\n",
      "ONNX inference took 0.5072672367095947 sec\n",
      "ONNX inference took 0.48339295387268066 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m dlc_live \u001b[38;5;241m=\u001b[39m DLCLive(\n\u001b[1;32m      2\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorrt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     model_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     display\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m mean_time \u001b[38;5;241m=\u001b[39m \u001b[43mmean_time_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdlc_live\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference of PyTorch model took on average \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_images)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m images\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mmean_time_inference\u001b[0;34m(dlc_live, images)\u001b[0m\n\u001b[1;32m      9\u001b[0m times \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(images):\n\u001b[0;32m---> 11\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     14\u001b[0m         start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    device=\"tensorrt\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPUExecutionProvider': {},\n",
       " 'CUDAExecutionProvider': {'sdpa_kernel': '0',\n",
       "  'use_tf32': '1',\n",
       "  'prefer_nhwc': '0',\n",
       "  'tunable_op_max_tuning_duration_ms': '0',\n",
       "  'enable_skip_layer_norm_strict_mode': '0',\n",
       "  'tunable_op_tuning_enable': '0',\n",
       "  'tunable_op_enable': '0',\n",
       "  'use_ep_level_unified_stream': '0',\n",
       "  'device_id': '0',\n",
       "  'has_user_compute_stream': '0',\n",
       "  'gpu_external_empty_cache': '0',\n",
       "  'cudnn_conv_algo_search': 'EXHAUSTIVE',\n",
       "  'cudnn_conv1d_pad_to_nc1d': '0',\n",
       "  'gpu_mem_limit': '18446744073709551615',\n",
       "  'gpu_external_alloc': '0',\n",
       "  'gpu_external_free': '0',\n",
       "  'arena_extend_strategy': 'kNextPowerOfTwo',\n",
       "  'do_copy_in_default_stream': '1',\n",
       "  'enable_cuda_graph': '0',\n",
       "  'user_compute_stream': '0',\n",
       "  'cudnn_conv_use_max_workspace': '1'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlc_live.sess.get_provider_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live.display.destroy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
