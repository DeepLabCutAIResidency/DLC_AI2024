{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLC Live PyTorch Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from onnxruntime import quantization\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [\"fly-kevin\", \"hand-track\", \"superbird\", \"ventral-gait\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4604/1313231765.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(weights_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# In case you do not have a .onnx model exported, use this cell to export your DLC3.0 snapshot\n",
    "\n",
    "from deeplabcut.pose_estimation_pytorch.config import read_config_as_dict\n",
    "from deeplabcut.pose_estimation_pytorch.models import PoseModel\n",
    "import torch\n",
    "import onnxruntime as ort\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "#Dikra\n",
    "root = Path(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3])\n",
    "model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "weights_path = root / \"snapshot-263.pt\"\n",
    "\n",
    "#Anna\n",
    "# root = Path(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\")\n",
    "# model_cfg = read_config_as_dict(root / \"pytorch_config.yaml\")\n",
    "# weights_path = root / \"snapshot-263.pt\"\n",
    "\n",
    "model = PoseModel.build(model_cfg[\"model\"])\n",
    "weights = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(weights[\"model\"])\n",
    "\n",
    "dummy_input = torch.zeros((1, 3, 224, 224))\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\",\n",
    "    verbose=False,\n",
    "    input_names=[\"input\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quant ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP32 to FP16\n",
    "from onnxconverter_common import float16\n",
    "\n",
    "onnx_fp32_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\"\n",
    "onnx_fp16_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet_fp16.onnx\"\n",
    "\n",
    "model_fp32 = onnx.load(onnx_fp32_model_path)\n",
    "model_fp16 = float16.convert_float_to_float16(model_fp32)\n",
    "onnx.save(model_fp16, onnx_fp16_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_fp32_model_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet.onnx\"\n",
    "model_prep_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3] + \"/resnet_quant_prep.onnx\"\n",
    "\n",
    "# prep for quantisation\n",
    "quantization.shape_inference.quant_pre_process(onnx_fp32_model_path, model_prep_path, skip_symbolic_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test frame\n",
    "img = cv2.imread(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\"+ projects[3] +\"/img0006.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with ONNX exported DLC 3.0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.09379959106445312 sec\n",
      "ONNX inference took 1.7872130870819092 sec\n",
      "ONNX postprocessing took 0.002176523208618164 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0182, 162.2244,   0.9150],\n",
       "            [146.8820, 158.9966,   0.9463],\n",
       "            [150.3497, 149.1153,   0.9092],\n",
       "            [196.7127, 137.2184,   0.8843],\n",
       "            [204.8954, 172.0166,   0.6792],\n",
       "            [342.8758,  81.4316,   0.6938],\n",
       "            [325.4095, 151.0748,   0.7803],\n",
       "            [240.2870, 110.5364,   0.6489],\n",
       "            [261.0193, 128.8380,   0.6074],\n",
       "            [254.8812, 154.8065,   0.8237],\n",
       "            [385.2753, 112.8754,   0.8096]]]])},\n",
       " 1.7872130870819092)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "onnx_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3],\n",
    "    model_type=\"onnx\",\n",
    "    device=\"cuda\",\n",
    "    display=True,\n",
    "    precision=\"FP16\"\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# onnx_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# onnx_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "onnx_pose = onnx_dlc_live.init_inference(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot from 2024-08-20 14-29-53.png](./docs/assets/Screenshot%20from%202024-08-20%2014-36-00.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[162.2244, 158.9966, 149.1153, 137.2184, 172.0166,  81.4316, 151.0748,\n",
       "          110.5364, 128.8380, 154.8065, 112.8754]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected = (onnx_pose[0][\"poses\"][0][0][:, 2] > 0.9)\n",
    "print(torch.any(detected))\n",
    "x = onnx_pose[0][\"poses\"][0][0][detected, 0]\n",
    "y = onnx_pose[0][\"poses\"][0][0][detected, 1]\n",
    "onnx_pose[0][\"poses\"][:, :, :, 1][:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.0162506103515625 sec\n",
      "ONNX postprocessing took 0.0006670951843261719 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0218, 162.2289,   0.9150],\n",
       "            [146.8865, 158.9966,   0.9463],\n",
       "            [150.3515, 149.1109,   0.9092],\n",
       "            [196.7047, 137.2219,   0.8848],\n",
       "            [204.8865, 172.0128,   0.6797],\n",
       "            [342.8776,  81.4281,   0.6934],\n",
       "            [325.4157, 151.0748,   0.7803],\n",
       "            [240.2977, 110.5328,   0.6484],\n",
       "            [261.0255, 128.8380,   0.6074],\n",
       "            [254.8812, 154.8029,   0.8237],\n",
       "            [385.2806, 112.8754,   0.8101]]]])},\n",
       " 0.0162506103515625)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pose = onnx_dlc_live.get_pose(frame=img)\n",
    "onnx_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLC Live with snaptshot of DLC 3.0 model (.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dikra/MyHub/Code/DLC24_Hub/DLC_AI2024/DeepLabCut-live/dlclive/dlclive.py:257: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_path, map_location=torch.device(self.device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.4676992893218994 sec\n",
      "PyTorch inference took 0.034587860107421875 sec\n",
      "PyTorch postprocessing took 0.0018115043640136719 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'poses': tensor([[[[154.0203, 162.2280,   0.9152],\n",
       "            [146.8848, 158.9930,   0.9459],\n",
       "            [150.3487, 149.1102,   0.9093],\n",
       "            [196.7133, 137.2184,   0.8843],\n",
       "            [204.8920, 172.0188,   0.6791],\n",
       "            [342.8778,  81.4373,   0.6930],\n",
       "            [325.4101, 151.0759,   0.7803],\n",
       "            [240.2807, 110.5330,   0.6488],\n",
       "            [261.0057, 128.8403,   0.6076],\n",
       "            [254.8730, 154.8122,   0.8238],\n",
       "            [385.2763, 112.8773,   0.8098]]]])},\n",
       " 0.034587860107421875)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dikra\n",
    "pytorch_dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    snapshot=\"snapshot-263.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "# Anna\n",
    "# pytorch_dlc_live = DLCLive(pytorch_cfg=\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train\", processor=dlc_proc, snapshot='/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/train/snapshot-263.pt')\n",
    "# pytorch_dlc_live = DLCLive(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/DLC_dev-single-animal_resnet_50_iteration-1_shuffle-1\", processor=dlc_proc)\n",
    "# img = cv2.imread(\"/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/exported DLC model for dlc-live/img049.png\")\n",
    "\n",
    "pytorch_pose = pytorch_dlc_live.init_inference(frame=img)\n",
    "pytorch_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PyTorch model inference](./docs/assets/Screenshot%20from%202024-08-20%2014-29-53.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which is faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "root = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\"\n",
    "test_images = glob.glob(os.path.normpath(root + \"/*.png\"))\n",
    "\n",
    "\n",
    "def mean_time_inference(dlc_live, images):\n",
    "    times = []\n",
    "    for i, img_p in enumerate(images):\n",
    "        img = cv2.imread(img_p)\n",
    "\n",
    "        if i == 0:\n",
    "            start = time.time()\n",
    "            dlc_live.init_inference(img)\n",
    "            end = time.time()\n",
    "        else:\n",
    "            start = time.time()\n",
    "            dlc_live.get_pose(img)\n",
    "            end = time.time()\n",
    "        times.append(end - start)\n",
    "    print(times)\n",
    "\n",
    "    return np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 0.4884378910064697 sec\n",
      "ONNX inference took 2.5211031436920166 sec\n",
      "ONNX postprocessing took 0.0028717517852783203 sec\n",
      "[3.2065136432647705]\n",
      "TOTAL Inference of ONNX model took on average 3.2065136432647705 seconds for 1 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images)\n",
    "print(\n",
    "    f\"TOTAL Inference of ONNX model took on average {mean_time} seconds for {len(test_images)} images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy\",\n",
    "    snapshot=\"snapshot-200.pt\",\n",
    "    device=\"cuda\",\n",
    "    model_type=\"pytorch\"\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images) \n",
    "print(f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model took 4.69077205657959 sec\n",
      "ONNX inference took 49.87957811355591 sec\n",
      "ONNX postprocessing took 0.0015039443969726562 sec\n",
      "[54.57309126853943]\n",
      "Inference of PyTorch model took on average 54.57309126853943 seconds for 1 images\n"
     ]
    }
   ],
   "source": [
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/\" + projects[3],\n",
    "    device=\"tensorrt\",\n",
    "    model_type=\"onnx\"\n",
    ")\n",
    "\n",
    "mean_time = mean_time_inference(dlc_live, test_images) \n",
    "print(f\"Inference of PyTorch model took on average {mean_time} seconds for {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 0.02220296859741211 sec\n",
      "ONNX postprocessing took 0.0027968883514404297 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dlc_live.get_pose(img)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "Currently the benchmark_pytorch.py script serves to provide a function for analyzing a preexisting video to test PyTorch for running video inference in DLC-Live. Code for running video inference on a live video feed is WIP.\n",
    "\n",
    "For true benchmarking purposes, we aim to add feature for recording the time it takes to analyze each frame / how many frames can be analyzed per second. Discuss what measure to use and consult the DLC Live paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX inference took 33.29072904586792 sec\n",
      "ONNX postprocessing took 0.0012803077697753906 sec\n",
      "ONNX inference took 0.01046609878540039 sec\n",
      "ONNX postprocessing took 0.0005767345428466797 sec\n",
      "ONNX inference took 0.009783506393432617 sec\n",
      "ONNX postprocessing took 0.0007724761962890625 sec\n",
      "ONNX inference took 0.010523080825805664 sec\n",
      "ONNX postprocessing took 0.0010080337524414062 sec\n",
      "ONNX inference took 0.010600566864013672 sec\n",
      "ONNX postprocessing took 0.002904653549194336 sec\n",
      "ONNX inference took 0.009979486465454102 sec\n",
      "ONNX postprocessing took 0.0009732246398925781 sec\n",
      "ONNX inference took 0.010604619979858398 sec\n",
      "ONNX postprocessing took 0.0014319419860839844 sec\n",
      "ONNX inference took 0.010870933532714844 sec\n",
      "ONNX postprocessing took 0.0029296875 sec\n",
      "ONNX inference took 0.010835647583007812 sec\n",
      "ONNX postprocessing took 0.0050792694091796875 sec\n",
      "ONNX inference took 0.011114120483398438 sec\n",
      "ONNX postprocessing took 0.004021406173706055 sec\n",
      "ONNX inference took 0.012862205505371094 sec\n",
      "ONNX postprocessing took 0.005742788314819336 sec\n",
      "ONNX inference took 0.010248184204101562 sec\n",
      "ONNX postprocessing took 0.002701997756958008 sec\n",
      "ONNX inference took 0.01040792465209961 sec\n",
      "ONNX postprocessing took 0.0008444786071777344 sec\n",
      "ONNX inference took 0.010401248931884766 sec\n",
      "ONNX postprocessing took 0.0008690357208251953 sec\n",
      "ONNX inference took 0.010237932205200195 sec\n",
      "ONNX postprocessing took 0.0008280277252197266 sec\n",
      "ONNX inference took 0.009980916976928711 sec\n",
      "ONNX postprocessing took 0.0011036396026611328 sec\n",
      "ONNX inference took 0.01043081283569336 sec\n",
      "ONNX postprocessing took 0.001669168472290039 sec\n",
      "ONNX inference took 0.01036691665649414 sec\n",
      "ONNX postprocessing took 0.0009365081787109375 sec\n",
      "ONNX inference took 0.009914159774780273 sec\n",
      "ONNX postprocessing took 0.0009396076202392578 sec\n",
      "ONNX inference took 0.010756492614746094 sec\n",
      "ONNX postprocessing took 0.001374959945678711 sec\n",
      "ONNX inference took 0.009929180145263672 sec\n",
      "ONNX postprocessing took 0.0016353130340576172 sec\n",
      "ONNX inference took 0.013103723526000977 sec\n",
      "ONNX postprocessing took 0.006339311599731445 sec\n",
      "ONNX inference took 0.012053251266479492 sec\n",
      "ONNX postprocessing took 0.001798868179321289 sec\n",
      "ONNX inference took 0.012451171875 sec\n",
      "ONNX postprocessing took 0.005080223083496094 sec\n",
      "ONNX inference took 0.011208772659301758 sec\n",
      "ONNX postprocessing took 0.0009350776672363281 sec\n",
      "ONNX inference took 0.016178131103515625 sec\n",
      "ONNX postprocessing took 0.006203174591064453 sec\n",
      "ONNX inference took 0.011862754821777344 sec\n",
      "ONNX postprocessing took 0.0024132728576660156 sec\n",
      "ONNX inference took 0.012167215347290039 sec\n",
      "ONNX postprocessing took 0.0026552677154541016 sec\n",
      "ONNX inference took 0.012521982192993164 sec\n",
      "ONNX postprocessing took 0.002900362014770508 sec\n",
      "ONNX inference took 0.01194310188293457 sec\n",
      "ONNX postprocessing took 0.0032749176025390625 sec\n",
      "ONNX inference took 0.01136016845703125 sec\n",
      "ONNX postprocessing took 0.0024721622467041016 sec\n",
      "ONNX inference took 0.013704061508178711 sec\n",
      "ONNX postprocessing took 0.0027484893798828125 sec\n",
      "ONNX inference took 0.01243138313293457 sec\n",
      "ONNX postprocessing took 0.0030574798583984375 sec\n",
      "ONNX inference took 0.013415336608886719 sec\n",
      "ONNX postprocessing took 0.004575252532958984 sec\n",
      "ONNX inference took 0.011224508285522461 sec\n",
      "ONNX postprocessing took 0.0008356571197509766 sec\n",
      "ONNX inference took 0.013030529022216797 sec\n",
      "ONNX postprocessing took 0.0018687248229980469 sec\n",
      "ONNX inference took 0.012268304824829102 sec\n",
      "ONNX postprocessing took 0.0006403923034667969 sec\n",
      "ONNX inference took 0.013558149337768555 sec\n",
      "ONNX postprocessing took 0.0007994174957275391 sec\n",
      "ONNX inference took 0.012758255004882812 sec\n",
      "ONNX postprocessing took 0.0017638206481933594 sec\n",
      "ONNX inference took 0.011854410171508789 sec\n",
      "ONNX postprocessing took 0.0009307861328125 sec\n",
      "ONNX inference took 0.013097524642944336 sec\n",
      "ONNX postprocessing took 0.005361080169677734 sec\n",
      "ONNX inference took 0.013028860092163086 sec\n",
      "ONNX postprocessing took 0.006578922271728516 sec\n",
      "ONNX inference took 0.011163711547851562 sec\n",
      "ONNX postprocessing took 0.002224445343017578 sec\n",
      "ONNX inference took 0.011624574661254883 sec\n",
      "ONNX postprocessing took 0.003233671188354492 sec\n",
      "ONNX inference took 0.012153863906860352 sec\n",
      "ONNX postprocessing took 0.0017855167388916016 sec\n",
      "ONNX inference took 0.012194633483886719 sec\n",
      "ONNX postprocessing took 0.0037326812744140625 sec\n",
      "ONNX inference took 0.01206064224243164 sec\n",
      "ONNX postprocessing took 0.0012247562408447266 sec\n",
      "ONNX inference took 0.012054443359375 sec\n",
      "ONNX postprocessing took 0.001196146011352539 sec\n",
      "ONNX inference took 0.012359857559204102 sec\n",
      "ONNX postprocessing took 0.0007269382476806641 sec\n",
      "ONNX inference took 0.011229515075683594 sec\n",
      "ONNX postprocessing took 0.004611968994140625 sec\n",
      "ONNX inference took 0.012117624282836914 sec\n",
      "ONNX postprocessing took 0.0011615753173828125 sec\n",
      "ONNX inference took 0.013750314712524414 sec\n",
      "ONNX postprocessing took 0.002061605453491211 sec\n",
      "ONNX inference took 0.011861324310302734 sec\n",
      "ONNX postprocessing took 0.0011279582977294922 sec\n",
      "ONNX inference took 0.012197732925415039 sec\n",
      "ONNX postprocessing took 0.0018591880798339844 sec\n",
      "ONNX inference took 0.012130498886108398 sec\n",
      "ONNX postprocessing took 0.0013103485107421875 sec\n",
      "ONNX inference took 0.012322425842285156 sec\n",
      "ONNX postprocessing took 0.002932310104370117 sec\n",
      "ONNX inference took 0.012352705001831055 sec\n",
      "ONNX postprocessing took 0.004042148590087891 sec\n",
      "ONNX inference took 0.011479616165161133 sec\n",
      "ONNX postprocessing took 0.0010485649108886719 sec\n",
      "ONNX inference took 0.011768579483032227 sec\n",
      "ONNX postprocessing took 0.0008223056793212891 sec\n",
      "ONNX inference took 0.013390302658081055 sec\n",
      "ONNX postprocessing took 0.001031637191772461 sec\n",
      "ONNX inference took 0.014771223068237305 sec\n",
      "ONNX postprocessing took 0.003503561019897461 sec\n",
      "ONNX inference took 0.012151956558227539 sec\n",
      "ONNX postprocessing took 0.0009121894836425781 sec\n",
      "ONNX inference took 0.011980056762695312 sec\n",
      "ONNX postprocessing took 0.0006248950958251953 sec\n",
      "ONNX inference took 0.011064529418945312 sec\n",
      "ONNX postprocessing took 0.003041505813598633 sec\n",
      "ONNX inference took 0.011345386505126953 sec\n",
      "ONNX postprocessing took 0.0008199214935302734 sec\n",
      "ONNX inference took 0.011150121688842773 sec\n",
      "ONNX postprocessing took 0.0005896091461181641 sec\n",
      "ONNX inference took 0.01154327392578125 sec\n",
      "ONNX postprocessing took 0.000885009765625 sec\n",
      "ONNX inference took 0.011462688446044922 sec\n",
      "ONNX postprocessing took 0.0007941722869873047 sec\n",
      "ONNX inference took 0.011188030242919922 sec\n",
      "ONNX postprocessing took 0.0005691051483154297 sec\n",
      "ONNX inference took 0.010895729064941406 sec\n",
      "ONNX postprocessing took 0.0005929470062255859 sec\n",
      "ONNX inference took 0.011379003524780273 sec\n",
      "ONNX postprocessing took 0.0006024837493896484 sec\n",
      "ONNX inference took 0.011530160903930664 sec\n",
      "ONNX postprocessing took 0.0006892681121826172 sec\n",
      "ONNX inference took 0.01197195053100586 sec\n",
      "ONNX postprocessing took 0.00091552734375 sec\n",
      "ONNX inference took 0.012518882751464844 sec\n",
      "ONNX postprocessing took 0.0015916824340820312 sec\n",
      "ONNX inference took 0.013980627059936523 sec\n",
      "ONNX postprocessing took 0.0009315013885498047 sec\n",
      "ONNX inference took 0.010869026184082031 sec\n",
      "ONNX postprocessing took 0.0008420944213867188 sec\n",
      "ONNX inference took 0.012464761734008789 sec\n",
      "ONNX postprocessing took 0.0009601116180419922 sec\n",
      "ONNX inference took 0.011919498443603516 sec\n",
      "ONNX postprocessing took 0.0031960010528564453 sec\n",
      "ONNX inference took 0.012688159942626953 sec\n",
      "ONNX postprocessing took 0.0027000904083251953 sec\n",
      "ONNX inference took 0.011077404022216797 sec\n",
      "ONNX postprocessing took 0.0019314289093017578 sec\n",
      "ONNX inference took 0.011598587036132812 sec\n",
      "ONNX postprocessing took 0.0006196498870849609 sec\n",
      "ONNX inference took 0.011854171752929688 sec\n",
      "ONNX postprocessing took 0.0006031990051269531 sec\n",
      "ONNX inference took 0.01151275634765625 sec\n",
      "ONNX postprocessing took 0.0005621910095214844 sec\n",
      "ONNX inference took 0.011141300201416016 sec\n",
      "ONNX postprocessing took 0.0005614757537841797 sec\n",
      "ONNX inference took 0.011354207992553711 sec\n",
      "ONNX postprocessing took 0.0005812644958496094 sec\n",
      "ONNX inference took 0.010879993438720703 sec\n",
      "ONNX postprocessing took 0.0008096694946289062 sec\n",
      "ONNX inference took 0.011395454406738281 sec\n",
      "ONNX postprocessing took 0.0005629062652587891 sec\n",
      "ONNX inference took 0.011143207550048828 sec\n",
      "ONNX postprocessing took 0.0005588531494140625 sec\n",
      "ONNX inference took 0.011144161224365234 sec\n",
      "ONNX postprocessing took 0.0006062984466552734 sec\n",
      "ONNX inference took 0.011347055435180664 sec\n",
      "ONNX postprocessing took 0.0005881786346435547 sec\n",
      "ONNX inference took 0.010855913162231445 sec\n",
      "ONNX postprocessing took 0.00055694580078125 sec\n",
      "ONNX inference took 0.0119476318359375 sec\n",
      "ONNX postprocessing took 0.0009009838104248047 sec\n",
      "ONNX inference took 0.012953519821166992 sec\n",
      "ONNX postprocessing took 0.0009067058563232422 sec\n",
      "ONNX inference took 0.012961149215698242 sec\n",
      "ONNX postprocessing took 0.010387897491455078 sec\n",
      "ONNX inference took 0.011110305786132812 sec\n",
      "ONNX postprocessing took 0.0009005069732666016 sec\n",
      "ONNX inference took 0.012149810791015625 sec\n",
      "ONNX postprocessing took 0.0017819404602050781 sec\n",
      "ONNX inference took 0.012696981430053711 sec\n",
      "ONNX postprocessing took 0.0029480457305908203 sec\n",
      "ONNX inference took 0.011365413665771484 sec\n",
      "ONNX postprocessing took 0.0008323192596435547 sec\n",
      "ONNX inference took 0.013308525085449219 sec\n",
      "ONNX postprocessing took 0.0022125244140625 sec\n",
      "ONNX inference took 0.01363992691040039 sec\n",
      "ONNX postprocessing took 0.003915309906005859 sec\n",
      "ONNX inference took 0.012253522872924805 sec\n",
      "ONNX postprocessing took 0.00124359130859375 sec\n",
      "ONNX inference took 0.012685298919677734 sec\n",
      "ONNX postprocessing took 0.0008845329284667969 sec\n",
      "ONNX inference took 0.011380910873413086 sec\n",
      "ONNX postprocessing took 0.002971649169921875 sec\n",
      "ONNX inference took 0.011152029037475586 sec\n",
      "ONNX postprocessing took 0.0019071102142333984 sec\n",
      "ONNX inference took 0.013725042343139648 sec\n",
      "ONNX postprocessing took 0.006475687026977539 sec\n",
      "ONNX inference took 0.01127481460571289 sec\n",
      "ONNX postprocessing took 0.0008530616760253906 sec\n",
      "ONNX inference took 0.012878894805908203 sec\n",
      "ONNX postprocessing took 0.003204345703125 sec\n",
      "ONNX inference took 0.011715888977050781 sec\n",
      "ONNX postprocessing took 0.0017886161804199219 sec\n",
      "ONNX inference took 0.011684894561767578 sec\n",
      "ONNX postprocessing took 0.0008432865142822266 sec\n",
      "ONNX inference took 0.013089179992675781 sec\n",
      "ONNX postprocessing took 0.0009062290191650391 sec\n",
      "ONNX inference took 0.013319015502929688 sec\n",
      "ONNX postprocessing took 0.0031239986419677734 sec\n",
      "ONNX inference took 0.01188039779663086 sec\n",
      "ONNX postprocessing took 0.0012097358703613281 sec\n",
      "ONNX inference took 0.010936260223388672 sec\n",
      "ONNX postprocessing took 0.0005986690521240234 sec\n",
      "ONNX inference took 0.011919736862182617 sec\n",
      "ONNX postprocessing took 0.0005910396575927734 sec\n",
      "ONNX inference took 0.01182413101196289 sec\n",
      "ONNX postprocessing took 0.0006232261657714844 sec\n",
      "ONNX inference took 0.011345863342285156 sec\n",
      "ONNX postprocessing took 0.0008211135864257812 sec\n",
      "ONNX inference took 0.011221885681152344 sec\n",
      "ONNX postprocessing took 0.0012514591217041016 sec\n",
      "ONNX inference took 0.011550188064575195 sec\n",
      "ONNX postprocessing took 0.0009126663208007812 sec\n",
      "ONNX inference took 0.011075258255004883 sec\n",
      "ONNX postprocessing took 0.0013012886047363281 sec\n",
      "ONNX inference took 0.011987686157226562 sec\n",
      "ONNX postprocessing took 0.0012547969818115234 sec\n",
      "ONNX inference took 0.015080451965332031 sec\n",
      "ONNX postprocessing took 0.002493143081665039 sec\n",
      "ONNX inference took 0.013050079345703125 sec\n",
      "ONNX postprocessing took 0.003253459930419922 sec\n",
      "ONNX inference took 0.011720657348632812 sec\n",
      "ONNX postprocessing took 0.0006403923034667969 sec\n",
      "ONNX inference took 0.01154470443725586 sec\n",
      "ONNX postprocessing took 0.001764059066772461 sec\n",
      "ONNX inference took 0.010996341705322266 sec\n",
      "ONNX postprocessing took 0.001829385757446289 sec\n",
      "ONNX inference took 0.011373758316040039 sec\n",
      "ONNX postprocessing took 0.003999233245849609 sec\n",
      "ONNX inference took 0.012541055679321289 sec\n",
      "ONNX postprocessing took 0.0007550716400146484 sec\n",
      "ONNX inference took 0.011418581008911133 sec\n",
      "ONNX postprocessing took 0.0009722709655761719 sec\n",
      "ONNX inference took 0.01119542121887207 sec\n",
      "ONNX postprocessing took 0.0008764266967773438 sec\n",
      "ONNX inference took 0.01107335090637207 sec\n",
      "ONNX postprocessing took 0.0005826950073242188 sec\n",
      "ONNX inference took 0.010957002639770508 sec\n",
      "ONNX postprocessing took 0.0008740425109863281 sec\n",
      "ONNX inference took 0.011913537979125977 sec\n",
      "ONNX postprocessing took 0.003815889358520508 sec\n",
      "ONNX inference took 0.012758255004882812 sec\n",
      "ONNX postprocessing took 0.003698587417602539 sec\n",
      "ONNX inference took 0.011351585388183594 sec\n",
      "ONNX postprocessing took 0.0008552074432373047 sec\n",
      "ONNX inference took 0.01270294189453125 sec\n",
      "ONNX postprocessing took 0.004255771636962891 sec\n",
      "ONNX inference took 0.011058568954467773 sec\n",
      "ONNX postprocessing took 0.0015988349914550781 sec\n",
      "ONNX inference took 0.013212203979492188 sec\n",
      "ONNX postprocessing took 0.008898258209228516 sec\n",
      "ONNX inference took 0.012415170669555664 sec\n",
      "ONNX postprocessing took 0.0014705657958984375 sec\n",
      "ONNX inference took 0.011503934860229492 sec\n",
      "ONNX postprocessing took 0.0027642250061035156 sec\n",
      "ONNX inference took 0.012627840042114258 sec\n",
      "ONNX postprocessing took 0.002292156219482422 sec\n",
      "ONNX inference took 0.011596441268920898 sec\n",
      "ONNX postprocessing took 0.002710580825805664 sec\n",
      "ONNX inference took 0.012202978134155273 sec\n",
      "ONNX postprocessing took 0.006505489349365234 sec\n",
      "ONNX inference took 0.01238560676574707 sec\n",
      "ONNX postprocessing took 0.0014503002166748047 sec\n",
      "ONNX inference took 0.012896060943603516 sec\n",
      "ONNX postprocessing took 0.006113290786743164 sec\n",
      "ONNX inference took 0.012080192565917969 sec\n",
      "ONNX postprocessing took 0.0013129711151123047 sec\n",
      "ONNX inference took 0.012614727020263672 sec\n",
      "ONNX postprocessing took 0.003757953643798828 sec\n",
      "ONNX inference took 0.011853456497192383 sec\n",
      "ONNX postprocessing took 0.0017628669738769531 sec\n",
      "ONNX inference took 0.011386632919311523 sec\n",
      "ONNX postprocessing took 0.0008087158203125 sec\n",
      "ONNX inference took 0.013495683670043945 sec\n",
      "ONNX postprocessing took 0.0027942657470703125 sec\n",
      "ONNX inference took 0.012019872665405273 sec\n",
      "ONNX postprocessing took 0.0030333995819091797 sec\n",
      "ONNX inference took 0.012700557708740234 sec\n",
      "ONNX postprocessing took 0.0021381378173828125 sec\n",
      "ONNX inference took 0.011457443237304688 sec\n",
      "ONNX postprocessing took 0.0007948875427246094 sec\n",
      "ONNX inference took 0.013049125671386719 sec\n",
      "ONNX postprocessing took 0.0022263526916503906 sec\n",
      "ONNX inference took 0.01241922378540039 sec\n",
      "ONNX postprocessing took 0.0028362274169921875 sec\n",
      "ONNX inference took 0.012925148010253906 sec\n",
      "ONNX postprocessing took 0.0041577816009521484 sec\n",
      "ONNX inference took 0.012855291366577148 sec\n",
      "ONNX postprocessing took 0.003305673599243164 sec\n",
      "ONNX inference took 0.01248621940612793 sec\n",
      "ONNX postprocessing took 0.0010492801666259766 sec\n",
      "ONNX inference took 0.011528491973876953 sec\n",
      "ONNX postprocessing took 0.00077056884765625 sec\n",
      "ONNX inference took 0.011912345886230469 sec\n",
      "ONNX postprocessing took 0.003793478012084961 sec\n",
      "ONNX inference took 0.012522220611572266 sec\n",
      "ONNX postprocessing took 0.0028531551361083984 sec\n",
      "ONNX inference took 0.01194453239440918 sec\n",
      "ONNX postprocessing took 0.00197601318359375 sec\n",
      "ONNX inference took 0.01131129264831543 sec\n",
      "ONNX postprocessing took 0.0005993843078613281 sec\n",
      "ONNX inference took 0.011431217193603516 sec\n",
      "ONNX postprocessing took 0.000995635986328125 sec\n",
      "ONNX inference took 0.01171422004699707 sec\n",
      "ONNX postprocessing took 0.0008492469787597656 sec\n",
      "ONNX inference took 0.012413740158081055 sec\n",
      "ONNX postprocessing took 0.0027523040771484375 sec\n",
      "ONNX inference took 0.011753320693969727 sec\n",
      "ONNX postprocessing took 0.0028562545776367188 sec\n",
      "ONNX inference took 0.011649847030639648 sec\n",
      "ONNX postprocessing took 0.0008256435394287109 sec\n",
      "ONNX inference took 0.012252092361450195 sec\n",
      "ONNX postprocessing took 0.0009758472442626953 sec\n",
      "ONNX inference took 0.011486053466796875 sec\n",
      "ONNX postprocessing took 0.0006072521209716797 sec\n",
      "ONNX inference took 0.014512300491333008 sec\n",
      "ONNX postprocessing took 0.0051839351654052734 sec\n",
      "ONNX inference took 0.011556625366210938 sec\n",
      "ONNX postprocessing took 0.0011670589447021484 sec\n",
      "ONNX inference took 0.013050317764282227 sec\n",
      "ONNX postprocessing took 0.002263307571411133 sec\n",
      "ONNX inference took 0.012156486511230469 sec\n",
      "ONNX postprocessing took 0.0019598007202148438 sec\n",
      "ONNX inference took 0.01229548454284668 sec\n",
      "ONNX postprocessing took 0.003591299057006836 sec\n",
      "ONNX inference took 0.01175069808959961 sec\n",
      "ONNX postprocessing took 0.002151966094970703 sec\n",
      "ONNX inference took 0.014038562774658203 sec\n",
      "ONNX postprocessing took 0.004099607467651367 sec\n",
      "ONNX inference took 0.011761665344238281 sec\n",
      "ONNX postprocessing took 0.0015392303466796875 sec\n",
      "ONNX inference took 0.013656377792358398 sec\n",
      "ONNX postprocessing took 0.0022017955780029297 sec\n",
      "ONNX inference took 0.012256860733032227 sec\n",
      "ONNX postprocessing took 0.001026153564453125 sec\n",
      "ONNX inference took 0.012224674224853516 sec\n",
      "ONNX postprocessing took 0.009798765182495117 sec\n",
      "ONNX inference took 0.012080669403076172 sec\n",
      "ONNX postprocessing took 0.0005803108215332031 sec\n",
      "ONNX inference took 0.011775732040405273 sec\n",
      "ONNX postprocessing took 0.0005793571472167969 sec\n",
      "ONNX inference took 0.011900186538696289 sec\n",
      "ONNX postprocessing took 0.0043370723724365234 sec\n",
      "ONNX inference took 0.01238703727722168 sec\n",
      "ONNX postprocessing took 0.0035872459411621094 sec\n",
      "ONNX inference took 0.011793136596679688 sec\n",
      "ONNX postprocessing took 0.0010683536529541016 sec\n",
      "ONNX inference took 0.012158393859863281 sec\n",
      "ONNX postprocessing took 0.00555419921875 sec\n",
      "ONNX inference took 0.011487483978271484 sec\n",
      "ONNX postprocessing took 0.002749204635620117 sec\n",
      "ONNX inference took 0.012491464614868164 sec\n",
      "ONNX postprocessing took 0.0025627613067626953 sec\n",
      "ONNX inference took 0.012928485870361328 sec\n",
      "ONNX postprocessing took 0.005367755889892578 sec\n",
      "ONNX inference took 0.01226043701171875 sec\n",
      "ONNX postprocessing took 0.0007295608520507812 sec\n",
      "ONNX inference took 0.011215925216674805 sec\n",
      "ONNX postprocessing took 0.00363922119140625 sec\n",
      "ONNX inference took 0.011095762252807617 sec\n",
      "ONNX postprocessing took 0.0007815361022949219 sec\n",
      "ONNX inference took 0.01161050796508789 sec\n",
      "ONNX postprocessing took 0.002950906753540039 sec\n",
      "ONNX inference took 0.011704683303833008 sec\n",
      "ONNX postprocessing took 0.0015401840209960938 sec\n",
      "ONNX inference took 0.014612436294555664 sec\n",
      "ONNX postprocessing took 0.006328582763671875 sec\n",
      "ONNX inference took 0.01206517219543457 sec\n",
      "ONNX postprocessing took 0.0005812644958496094 sec\n",
      "ONNX inference took 0.014815330505371094 sec\n",
      "ONNX postprocessing took 0.008402824401855469 sec\n",
      "ONNX inference took 0.012191057205200195 sec\n",
      "ONNX postprocessing took 0.0011444091796875 sec\n",
      "ONNX inference took 0.011327266693115234 sec\n",
      "ONNX postprocessing took 0.0027761459350585938 sec\n",
      "ONNX inference took 0.012442350387573242 sec\n",
      "ONNX postprocessing took 0.0020914077758789062 sec\n",
      "ONNX inference took 0.012827157974243164 sec\n",
      "ONNX postprocessing took 0.002227783203125 sec\n",
      "ONNX inference took 0.01151275634765625 sec\n",
      "ONNX postprocessing took 0.00086212158203125 sec\n",
      "ONNX inference took 0.01166081428527832 sec\n",
      "ONNX postprocessing took 0.0005733966827392578 sec\n",
      "ONNX inference took 0.011938333511352539 sec\n",
      "ONNX postprocessing took 0.001085519790649414 sec\n",
      "ONNX inference took 0.014451742172241211 sec\n",
      "ONNX postprocessing took 0.0013425350189208984 sec\n",
      "ONNX inference took 0.013331890106201172 sec\n",
      "ONNX postprocessing took 0.002180337905883789 sec\n",
      "ONNX inference took 0.011724233627319336 sec\n",
      "ONNX postprocessing took 0.005197286605834961 sec\n",
      "ONNX inference took 0.012180089950561523 sec\n",
      "ONNX postprocessing took 0.0017595291137695312 sec\n",
      "ONNX inference took 0.01207590103149414 sec\n",
      "ONNX postprocessing took 0.0014405250549316406 sec\n",
      "ONNX inference took 0.012179136276245117 sec\n",
      "ONNX postprocessing took 0.00213623046875 sec\n",
      "ONNX inference took 0.011210918426513672 sec\n",
      "ONNX postprocessing took 0.0010335445404052734 sec\n",
      "ONNX inference took 0.011382341384887695 sec\n",
      "ONNX postprocessing took 0.0008614063262939453 sec\n",
      "ONNX inference took 0.011413097381591797 sec\n",
      "ONNX postprocessing took 0.0005729198455810547 sec\n",
      "ONNX inference took 0.01232004165649414 sec\n",
      "ONNX postprocessing took 0.0026865005493164062 sec\n",
      "ONNX inference took 0.015206336975097656 sec\n",
      "ONNX postprocessing took 0.008037805557250977 sec\n",
      "ONNX inference took 0.011836051940917969 sec\n",
      "ONNX postprocessing took 0.0008478164672851562 sec\n",
      "ONNX inference took 0.013251781463623047 sec\n",
      "ONNX postprocessing took 0.004317045211791992 sec\n",
      "ONNX inference took 0.012913703918457031 sec\n",
      "ONNX postprocessing took 0.0034186840057373047 sec\n",
      "ONNX inference took 0.011943340301513672 sec\n",
      "ONNX postprocessing took 0.0010676383972167969 sec\n",
      "ONNX inference took 0.013564109802246094 sec\n",
      "ONNX postprocessing took 0.007174015045166016 sec\n",
      "ONNX inference took 0.012258291244506836 sec\n",
      "ONNX postprocessing took 0.0006034374237060547 sec\n",
      "ONNX inference took 0.011342048645019531 sec\n",
      "ONNX postprocessing took 0.001218557357788086 sec\n",
      "ONNX inference took 0.01161813735961914 sec\n",
      "ONNX postprocessing took 0.002006053924560547 sec\n",
      "ONNX inference took 0.012108325958251953 sec\n",
      "ONNX postprocessing took 0.005460262298583984 sec\n",
      "ONNX inference took 0.011504411697387695 sec\n",
      "ONNX postprocessing took 0.0008165836334228516 sec\n",
      "ONNX inference took 0.01343989372253418 sec\n",
      "ONNX postprocessing took 0.0014476776123046875 sec\n",
      "ONNX inference took 0.012975454330444336 sec\n",
      "ONNX postprocessing took 0.0020904541015625 sec\n",
      "ONNX inference took 0.011641263961791992 sec\n",
      "ONNX postprocessing took 0.0030736923217773438 sec\n",
      "ONNX inference took 0.012702465057373047 sec\n",
      "ONNX postprocessing took 0.0029904842376708984 sec\n",
      "ONNX inference took 0.011618614196777344 sec\n",
      "ONNX postprocessing took 0.0008840560913085938 sec\n",
      "ONNX inference took 0.011951684951782227 sec\n",
      "ONNX postprocessing took 0.0017528533935546875 sec\n",
      "ONNX inference took 0.011396169662475586 sec\n",
      "ONNX postprocessing took 0.0008285045623779297 sec\n",
      "ONNX inference took 0.012176513671875 sec\n",
      "ONNX postprocessing took 0.004334449768066406 sec\n",
      "ONNX inference took 0.014860153198242188 sec\n",
      "ONNX postprocessing took 0.0030205249786376953 sec\n",
      "ONNX inference took 0.011784553527832031 sec\n",
      "ONNX postprocessing took 0.0028929710388183594 sec\n",
      "ONNX inference took 0.01133871078491211 sec\n",
      "ONNX postprocessing took 0.0028629302978515625 sec\n",
      "ONNX inference took 0.011910438537597656 sec\n",
      "ONNX postprocessing took 0.000997304916381836 sec\n",
      "ONNX inference took 0.014801502227783203 sec\n",
      "ONNX postprocessing took 0.008707761764526367 sec\n",
      "ONNX inference took 0.012589454650878906 sec\n",
      "ONNX postprocessing took 0.004845142364501953 sec\n",
      "ONNX inference took 0.012432098388671875 sec\n",
      "ONNX postprocessing took 0.004312276840209961 sec\n",
      "ONNX inference took 0.0122833251953125 sec\n",
      "ONNX postprocessing took 0.003018617630004883 sec\n",
      "ONNX inference took 0.011226892471313477 sec\n",
      "ONNX postprocessing took 0.0023088455200195312 sec\n",
      "ONNX inference took 0.011285066604614258 sec\n",
      "ONNX postprocessing took 0.0062940120697021484 sec\n",
      "ONNX inference took 0.012308359146118164 sec\n",
      "ONNX postprocessing took 0.0007007122039794922 sec\n",
      "ONNX inference took 0.011483907699584961 sec\n",
      "ONNX postprocessing took 0.0006487369537353516 sec\n",
      "ONNX inference took 0.011729955673217773 sec\n",
      "ONNX postprocessing took 0.001661062240600586 sec\n",
      "ONNX inference took 0.01186227798461914 sec\n",
      "ONNX postprocessing took 0.0029981136322021484 sec\n",
      "ONNX inference took 0.012000083923339844 sec\n",
      "ONNX postprocessing took 0.004693269729614258 sec\n",
      "ONNX inference took 0.012273073196411133 sec\n",
      "ONNX postprocessing took 0.0013051033020019531 sec\n",
      "ONNX inference took 0.01341557502746582 sec\n",
      "ONNX postprocessing took 0.00660395622253418 sec\n",
      "ONNX inference took 0.012363672256469727 sec\n",
      "ONNX postprocessing took 0.0016980171203613281 sec\n",
      "ONNX inference took 0.012608766555786133 sec\n",
      "ONNX postprocessing took 0.0033135414123535156 sec\n",
      "ONNX inference took 0.014768123626708984 sec\n",
      "ONNX postprocessing took 0.003036022186279297 sec\n",
      "ONNX inference took 0.012691736221313477 sec\n",
      "ONNX postprocessing took 0.003177642822265625 sec\n",
      "ONNX inference took 0.012977838516235352 sec\n",
      "ONNX postprocessing took 0.004771232604980469 sec\n",
      "ONNX inference took 0.012197732925415039 sec\n",
      "ONNX postprocessing took 0.0007150173187255859 sec\n",
      "ONNX inference took 0.013088226318359375 sec\n",
      "ONNX postprocessing took 0.0008687973022460938 sec\n",
      "ONNX inference took 0.012211799621582031 sec\n",
      "ONNX postprocessing took 0.0007884502410888672 sec\n",
      "ONNX inference took 0.013074874877929688 sec\n",
      "ONNX postprocessing took 0.002490997314453125 sec\n",
      "ONNX inference took 0.01168513298034668 sec\n",
      "ONNX postprocessing took 0.0013072490692138672 sec\n",
      "ONNX inference took 0.013628959655761719 sec\n",
      "ONNX postprocessing took 0.005638837814331055 sec\n",
      "ONNX inference took 0.011002779006958008 sec\n",
      "ONNX postprocessing took 0.0010251998901367188 sec\n",
      "ONNX inference took 0.011792898178100586 sec\n",
      "ONNX postprocessing took 0.0020651817321777344 sec\n",
      "ONNX inference took 0.011749744415283203 sec\n",
      "ONNX postprocessing took 0.0031290054321289062 sec\n",
      "ONNX inference took 0.0113525390625 sec\n",
      "ONNX postprocessing took 0.0008065700531005859 sec\n",
      "ONNX inference took 0.012697935104370117 sec\n",
      "ONNX postprocessing took 0.004065036773681641 sec\n",
      "ONNX inference took 0.012785673141479492 sec\n",
      "ONNX postprocessing took 0.0012164115905761719 sec\n",
      "ONNX inference took 0.011085748672485352 sec\n",
      "ONNX postprocessing took 0.004713773727416992 sec\n",
      "ONNX inference took 0.012384891510009766 sec\n",
      "ONNX postprocessing took 0.0010976791381835938 sec\n",
      "ONNX inference took 0.012151956558227539 sec\n",
      "ONNX postprocessing took 0.002670764923095703 sec\n",
      "ONNX inference took 0.011951923370361328 sec\n",
      "ONNX postprocessing took 0.0010848045349121094 sec\n",
      "ONNX inference took 0.01185464859008789 sec\n",
      "ONNX postprocessing took 0.002416849136352539 sec\n",
      "ONNX inference took 0.012079477310180664 sec\n",
      "ONNX postprocessing took 0.0009222030639648438 sec\n",
      "ONNX inference took 0.011785030364990234 sec\n",
      "ONNX postprocessing took 0.0008244514465332031 sec\n",
      "ONNX inference took 0.012438297271728516 sec\n",
      "ONNX postprocessing took 0.00600743293762207 sec\n",
      "ONNX inference took 0.012035369873046875 sec\n",
      "ONNX postprocessing took 0.0006794929504394531 sec\n",
      "ONNX inference took 0.011516332626342773 sec\n",
      "ONNX postprocessing took 0.000682830810546875 sec\n",
      "ONNX inference took 0.011590719223022461 sec\n",
      "ONNX postprocessing took 0.0011730194091796875 sec\n",
      "ONNX inference took 0.014159679412841797 sec\n",
      "ONNX postprocessing took 0.002561807632446289 sec\n",
      "ONNX inference took 0.011750936508178711 sec\n",
      "ONNX postprocessing took 0.003178834915161133 sec\n",
      "ONNX inference took 0.011698722839355469 sec\n",
      "ONNX postprocessing took 0.001814126968383789 sec\n",
      "ONNX inference took 0.012563705444335938 sec\n",
      "ONNX postprocessing took 0.003566741943359375 sec\n",
      "ONNX inference took 0.011529207229614258 sec\n",
      "ONNX postprocessing took 0.001323699951171875 sec\n",
      "ONNX inference took 0.013142824172973633 sec\n",
      "ONNX postprocessing took 0.0017278194427490234 sec\n",
      "ONNX inference took 0.012420654296875 sec\n",
      "ONNX postprocessing took 0.004579305648803711 sec\n",
      "ONNX inference took 0.012228727340698242 sec\n",
      "ONNX postprocessing took 0.0045468807220458984 sec\n",
      "ONNX inference took 0.011745929718017578 sec\n",
      "ONNX postprocessing took 0.0008630752563476562 sec\n",
      "ONNX inference took 0.012134552001953125 sec\n",
      "ONNX postprocessing took 0.0034933090209960938 sec\n",
      "ONNX inference took 0.011946916580200195 sec\n",
      "ONNX postprocessing took 0.0012404918670654297 sec\n",
      "ONNX inference took 0.011970043182373047 sec\n",
      "ONNX postprocessing took 0.002024412155151367 sec\n",
      "ONNX inference took 0.012826204299926758 sec\n",
      "ONNX postprocessing took 0.003134489059448242 sec\n",
      "ONNX inference took 0.011441707611083984 sec\n",
      "ONNX postprocessing took 0.004973411560058594 sec\n",
      "ONNX inference took 0.011611223220825195 sec\n",
      "ONNX postprocessing took 0.002332448959350586 sec\n",
      "ONNX inference took 0.012477397918701172 sec\n",
      "ONNX postprocessing took 0.0032219886779785156 sec\n",
      "ONNX inference took 0.011872053146362305 sec\n",
      "ONNX postprocessing took 0.0006165504455566406 sec\n",
      "ONNX inference took 0.011742830276489258 sec\n",
      "ONNX postprocessing took 0.00226593017578125 sec\n",
      "ONNX inference took 0.011488676071166992 sec\n",
      "ONNX postprocessing took 0.0014820098876953125 sec\n",
      "ONNX inference took 0.011750221252441406 sec\n",
      "ONNX postprocessing took 0.0009045600891113281 sec\n",
      "ONNX inference took 0.011874914169311523 sec\n",
      "ONNX postprocessing took 0.0013508796691894531 sec\n",
      "ONNX inference took 0.012016057968139648 sec\n",
      "ONNX postprocessing took 0.001718282699584961 sec\n",
      "ONNX inference took 0.011391639709472656 sec\n",
      "ONNX postprocessing took 0.0017426013946533203 sec\n",
      "ONNX inference took 0.01172018051147461 sec\n",
      "ONNX postprocessing took 0.0011708736419677734 sec\n",
      "ONNX inference took 0.011586189270019531 sec\n",
      "ONNX postprocessing took 0.0006303787231445312 sec\n",
      "ONNX inference took 0.01190805435180664 sec\n",
      "ONNX postprocessing took 0.0011456012725830078 sec\n",
      "ONNX inference took 0.012221097946166992 sec\n",
      "ONNX postprocessing took 0.0008838176727294922 sec\n",
      "ONNX inference took 0.01152944564819336 sec\n",
      "ONNX postprocessing took 0.0012955665588378906 sec\n",
      "ONNX inference took 0.011151790618896484 sec\n",
      "ONNX postprocessing took 0.0005984306335449219 sec\n",
      "ONNX inference took 0.012295007705688477 sec\n",
      "ONNX postprocessing took 0.0036339759826660156 sec\n",
      "ONNX inference took 0.011612176895141602 sec\n",
      "ONNX postprocessing took 0.0012094974517822266 sec\n",
      "ONNX inference took 0.013144493103027344 sec\n",
      "ONNX postprocessing took 0.003838062286376953 sec\n",
      "ONNX inference took 0.011246681213378906 sec\n",
      "ONNX postprocessing took 0.0013828277587890625 sec\n",
      "ONNX inference took 0.01262521743774414 sec\n",
      "ONNX postprocessing took 0.0009334087371826172 sec\n",
      "ONNX inference took 0.012317180633544922 sec\n",
      "ONNX postprocessing took 0.0018758773803710938 sec\n",
      "ONNX inference took 0.01150202751159668 sec\n",
      "ONNX postprocessing took 0.0009660720825195312 sec\n",
      "ONNX inference took 0.012163639068603516 sec\n",
      "ONNX postprocessing took 0.0030975341796875 sec\n",
      "ONNX inference took 0.012179136276245117 sec\n",
      "ONNX postprocessing took 0.0019865036010742188 sec\n",
      "ONNX inference took 0.01737689971923828 sec\n",
      "ONNX postprocessing took 0.003994941711425781 sec\n",
      "ONNX inference took 0.011643409729003906 sec\n",
      "ONNX postprocessing took 0.0009882450103759766 sec\n",
      "ONNX inference took 0.013723373413085938 sec\n",
      "ONNX postprocessing took 0.008656024932861328 sec\n",
      "ONNX inference took 0.01257634162902832 sec\n",
      "ONNX postprocessing took 0.0028841495513916016 sec\n",
      "ONNX inference took 0.011679649353027344 sec\n",
      "ONNX postprocessing took 0.0019085407257080078 sec\n",
      "ONNX inference took 0.011911869049072266 sec\n",
      "ONNX postprocessing took 0.002599000930786133 sec\n",
      "ONNX inference took 0.012604951858520508 sec\n",
      "ONNX postprocessing took 0.002338409423828125 sec\n",
      "ONNX inference took 0.012587785720825195 sec\n",
      "ONNX postprocessing took 0.004711627960205078 sec\n",
      "ONNX inference took 0.011369943618774414 sec\n",
      "ONNX postprocessing took 0.0009963512420654297 sec\n",
      "ONNX inference took 0.01343226432800293 sec\n",
      "ONNX postprocessing took 0.007851123809814453 sec\n",
      "ONNX inference took 0.012746810913085938 sec\n",
      "ONNX postprocessing took 0.0026540756225585938 sec\n",
      "ONNX inference took 0.01276087760925293 sec\n",
      "ONNX postprocessing took 0.004397392272949219 sec\n",
      "ONNX inference took 0.012386560440063477 sec\n",
      "ONNX postprocessing took 0.0028684139251708984 sec\n",
      "ONNX inference took 0.014094114303588867 sec\n",
      "ONNX postprocessing took 0.006255626678466797 sec\n",
      "ONNX inference took 0.01117253303527832 sec\n",
      "ONNX postprocessing took 0.0038776397705078125 sec\n",
      "ONNX inference took 0.013899564743041992 sec\n",
      "ONNX postprocessing took 0.004405021667480469 sec\n",
      "ONNX inference took 0.012572050094604492 sec\n",
      "ONNX postprocessing took 0.001996755599975586 sec\n",
      "ONNX inference took 0.013988971710205078 sec\n",
      "ONNX postprocessing took 0.004292964935302734 sec\n",
      "ONNX inference took 0.011990070343017578 sec\n",
      "ONNX postprocessing took 0.002672433853149414 sec\n",
      "ONNX inference took 0.011738777160644531 sec\n",
      "ONNX postprocessing took 0.003526449203491211 sec\n",
      "ONNX inference took 0.012261390686035156 sec\n",
      "ONNX postprocessing took 0.0013175010681152344 sec\n",
      "ONNX inference took 0.011574506759643555 sec\n",
      "ONNX postprocessing took 0.0017540454864501953 sec\n",
      "ONNX inference took 0.011912107467651367 sec\n",
      "ONNX postprocessing took 0.0016753673553466797 sec\n",
      "ONNX inference took 0.012765645980834961 sec\n",
      "ONNX postprocessing took 0.0014293193817138672 sec\n",
      "ONNX inference took 0.012939214706420898 sec\n",
      "ONNX postprocessing took 0.0022575855255126953 sec\n",
      "ONNX inference took 0.012744426727294922 sec\n",
      "ONNX postprocessing took 0.0007684230804443359 sec\n",
      "ONNX inference took 0.011382579803466797 sec\n",
      "ONNX postprocessing took 0.0008256435394287109 sec\n",
      "ONNX inference took 0.012160778045654297 sec\n",
      "ONNX postprocessing took 0.0008053779602050781 sec\n",
      "ONNX inference took 0.012428760528564453 sec\n",
      "ONNX postprocessing took 0.0029594898223876953 sec\n",
      "ONNX inference took 0.01446986198425293 sec\n",
      "ONNX postprocessing took 0.0035207271575927734 sec\n",
      "ONNX inference took 0.01257467269897461 sec\n",
      "ONNX postprocessing took 0.0031585693359375 sec\n",
      "ONNX inference took 0.014804840087890625 sec\n",
      "ONNX postprocessing took 0.0021407604217529297 sec\n",
      "ONNX inference took 0.017566204071044922 sec\n",
      "ONNX postprocessing took 0.004546403884887695 sec\n",
      "ONNX inference took 0.011055469512939453 sec\n",
      "ONNX postprocessing took 0.0013456344604492188 sec\n",
      "ONNX inference took 0.011506080627441406 sec\n",
      "ONNX postprocessing took 0.0010657310485839844 sec\n",
      "ONNX inference took 0.011375188827514648 sec\n",
      "ONNX postprocessing took 0.0010645389556884766 sec\n",
      "ONNX inference took 0.012514591217041016 sec\n",
      "ONNX postprocessing took 0.0012557506561279297 sec\n",
      "ONNX inference took 0.013184070587158203 sec\n",
      "ONNX postprocessing took 0.0041043758392333984 sec\n",
      "ONNX inference took 0.011934280395507812 sec\n",
      "ONNX postprocessing took 0.0018038749694824219 sec\n",
      "ONNX inference took 0.011320114135742188 sec\n",
      "ONNX postprocessing took 0.000993967056274414 sec\n",
      "ONNX inference took 0.012369394302368164 sec\n",
      "ONNX postprocessing took 0.0010402202606201172 sec\n",
      "ONNX inference took 0.01140284538269043 sec\n",
      "ONNX postprocessing took 0.0012979507446289062 sec\n",
      "ONNX inference took 0.011756420135498047 sec\n",
      "ONNX postprocessing took 0.0008828639984130859 sec\n",
      "ONNX inference took 0.012501716613769531 sec\n",
      "ONNX postprocessing took 0.0016582012176513672 sec\n",
      "ONNX inference took 0.012468814849853516 sec\n",
      "ONNX postprocessing took 0.0024199485778808594 sec\n",
      "ONNX inference took 0.012559652328491211 sec\n",
      "ONNX postprocessing took 0.002655506134033203 sec\n",
      "ONNX inference took 0.0126190185546875 sec\n",
      "ONNX postprocessing took 0.0023980140686035156 sec\n",
      "ONNX inference took 0.011148452758789062 sec\n",
      "ONNX postprocessing took 0.0010790824890136719 sec\n",
      "ONNX inference took 0.011581897735595703 sec\n",
      "ONNX postprocessing took 0.0010764598846435547 sec\n",
      "ONNX inference took 0.012029170989990234 sec\n",
      "ONNX postprocessing took 0.0010526180267333984 sec\n",
      "ONNX inference took 0.011661529541015625 sec\n",
      "ONNX postprocessing took 0.0006346702575683594 sec\n",
      "ONNX inference took 0.011809349060058594 sec\n",
      "ONNX postprocessing took 0.0008823871612548828 sec\n",
      "ONNX inference took 0.011632680892944336 sec\n",
      "ONNX postprocessing took 0.0010013580322265625 sec\n",
      "ONNX inference took 0.011535882949829102 sec\n",
      "ONNX postprocessing took 0.0008747577667236328 sec\n",
      "ONNX inference took 0.011734247207641602 sec\n",
      "ONNX postprocessing took 0.0010297298431396484 sec\n",
      "ONNX inference took 0.011689901351928711 sec\n",
      "ONNX postprocessing took 0.0009708404541015625 sec\n",
      "ONNX inference took 0.013385772705078125 sec\n",
      "ONNX postprocessing took 0.0014531612396240234 sec\n",
      "ONNX inference took 0.012003660202026367 sec\n",
      "ONNX postprocessing took 0.0018799304962158203 sec\n",
      "ONNX inference took 0.01218557357788086 sec\n",
      "ONNX postprocessing took 0.0029363632202148438 sec\n",
      "ONNX inference took 0.010921716690063477 sec\n",
      "ONNX postprocessing took 0.0012013912200927734 sec\n",
      "ONNX inference took 0.012251853942871094 sec\n",
      "ONNX postprocessing took 0.003350973129272461 sec\n",
      "ONNX inference took 0.011687517166137695 sec\n",
      "ONNX postprocessing took 0.0032067298889160156 sec\n",
      "ONNX inference took 0.012137651443481445 sec\n",
      "ONNX postprocessing took 0.0032644271850585938 sec\n",
      "ONNX inference took 0.015007972717285156 sec\n",
      "ONNX postprocessing took 0.004290103912353516 sec\n",
      "ONNX inference took 0.011370182037353516 sec\n",
      "ONNX postprocessing took 0.003316164016723633 sec\n",
      "ONNX inference took 0.012509346008300781 sec\n",
      "ONNX postprocessing took 0.0043981075286865234 sec\n",
      "ONNX inference took 0.012354373931884766 sec\n",
      "ONNX postprocessing took 0.0018856525421142578 sec\n",
      "ONNX inference took 0.011598587036132812 sec\n",
      "ONNX postprocessing took 0.00084686279296875 sec\n",
      "ONNX inference took 0.01251530647277832 sec\n",
      "ONNX postprocessing took 0.002677440643310547 sec\n",
      "ONNX inference took 0.012535810470581055 sec\n",
      "ONNX postprocessing took 0.0013935565948486328 sec\n",
      "ONNX inference took 0.012399911880493164 sec\n",
      "ONNX postprocessing took 0.002928018569946289 sec\n",
      "ONNX inference took 0.011691808700561523 sec\n",
      "ONNX postprocessing took 0.0009493827819824219 sec\n",
      "ONNX inference took 0.011756420135498047 sec\n",
      "ONNX postprocessing took 0.0009746551513671875 sec\n",
      "ONNX inference took 0.011402606964111328 sec\n",
      "ONNX postprocessing took 0.001092672348022461 sec\n",
      "ONNX inference took 0.011576175689697266 sec\n",
      "ONNX postprocessing took 0.004161834716796875 sec\n",
      "ONNX inference took 0.013317584991455078 sec\n",
      "ONNX postprocessing took 0.0031003952026367188 sec\n",
      "ONNX inference took 0.011678695678710938 sec\n",
      "ONNX postprocessing took 0.0009615421295166016 sec\n",
      "ONNX inference took 0.012207269668579102 sec\n",
      "ONNX postprocessing took 0.0006449222564697266 sec\n",
      "ONNX inference took 0.011563301086425781 sec\n",
      "ONNX postprocessing took 0.0029473304748535156 sec\n",
      "ONNX inference took 0.012223005294799805 sec\n",
      "ONNX postprocessing took 0.0009088516235351562 sec\n",
      "ONNX inference took 0.012581348419189453 sec\n",
      "ONNX postprocessing took 0.0013740062713623047 sec\n",
      "ONNX inference took 0.012610435485839844 sec\n",
      "ONNX postprocessing took 0.0034139156341552734 sec\n",
      "ONNX inference took 0.011652469635009766 sec\n",
      "ONNX postprocessing took 0.0022232532501220703 sec\n",
      "ONNX inference took 0.012477874755859375 sec\n",
      "ONNX postprocessing took 0.0011684894561767578 sec\n",
      "ONNX inference took 0.012348413467407227 sec\n",
      "ONNX postprocessing took 0.005192995071411133 sec\n",
      "ONNX inference took 0.011398553848266602 sec\n",
      "ONNX postprocessing took 0.0008294582366943359 sec\n",
      "ONNX inference took 0.0119476318359375 sec\n",
      "ONNX postprocessing took 0.0008776187896728516 sec\n",
      "ONNX inference took 0.012633323669433594 sec\n",
      "ONNX postprocessing took 0.004059314727783203 sec\n",
      "ONNX inference took 0.011869192123413086 sec\n",
      "ONNX postprocessing took 0.0011327266693115234 sec\n",
      "ONNX inference took 0.012315750122070312 sec\n",
      "ONNX postprocessing took 0.003000974655151367 sec\n",
      "ONNX inference took 0.012085914611816406 sec\n",
      "ONNX postprocessing took 0.0022606849670410156 sec\n",
      "ONNX inference took 0.011486291885375977 sec\n",
      "ONNX postprocessing took 0.004419088363647461 sec\n",
      "ONNX inference took 0.011724233627319336 sec\n",
      "ONNX postprocessing took 0.0009539127349853516 sec\n",
      "ONNX inference took 0.011880636215209961 sec\n",
      "ONNX postprocessing took 0.0009667873382568359 sec\n",
      "ONNX inference took 0.013664722442626953 sec\n",
      "ONNX postprocessing took 0.0013670921325683594 sec\n",
      "ONNX inference took 0.012162208557128906 sec\n",
      "ONNX postprocessing took 0.0009527206420898438 sec\n",
      "ONNX inference took 0.012341499328613281 sec\n",
      "ONNX postprocessing took 0.002976655960083008 sec\n",
      "ONNX inference took 0.012087345123291016 sec\n",
      "ONNX postprocessing took 0.002682924270629883 sec\n",
      "ONNX inference took 0.01198267936706543 sec\n",
      "ONNX postprocessing took 0.001068115234375 sec\n",
      "ONNX inference took 0.012018442153930664 sec\n",
      "ONNX postprocessing took 0.0012929439544677734 sec\n",
      "ONNX inference took 0.012160062789916992 sec\n",
      "ONNX postprocessing took 0.0008683204650878906 sec\n",
      "ONNX inference took 0.012371301651000977 sec\n",
      "ONNX postprocessing took 0.0006577968597412109 sec\n",
      "ONNX inference took 0.013355016708374023 sec\n",
      "ONNX postprocessing took 0.0028350353240966797 sec\n",
      "ONNX inference took 0.012209415435791016 sec\n",
      "ONNX postprocessing took 0.004106998443603516 sec\n",
      "ONNX inference took 0.012475252151489258 sec\n",
      "ONNX postprocessing took 0.0029685497283935547 sec\n",
      "ONNX inference took 0.012125968933105469 sec\n",
      "ONNX postprocessing took 0.0034332275390625 sec\n",
      "ONNX inference took 0.01328897476196289 sec\n",
      "ONNX postprocessing took 0.0012133121490478516 sec\n",
      "ONNX inference took 0.011677026748657227 sec\n",
      "ONNX postprocessing took 0.0038356781005859375 sec\n",
      "ONNX inference took 0.011873245239257812 sec\n",
      "ONNX postprocessing took 0.002704620361328125 sec\n",
      "ONNX inference took 0.012022018432617188 sec\n",
      "ONNX postprocessing took 0.004445075988769531 sec\n",
      "ONNX inference took 0.011745214462280273 sec\n",
      "ONNX postprocessing took 0.0033063888549804688 sec\n",
      "ONNX inference took 0.012010812759399414 sec\n",
      "ONNX postprocessing took 0.0016770362854003906 sec\n",
      "ONNX inference took 0.01163339614868164 sec\n",
      "ONNX postprocessing took 0.0031495094299316406 sec\n",
      "ONNX inference took 0.0117034912109375 sec\n",
      "ONNX postprocessing took 0.0011031627655029297 sec\n",
      "ONNX inference took 0.012370824813842773 sec\n",
      "ONNX postprocessing took 0.0017991065979003906 sec\n",
      "ONNX inference took 0.012269020080566406 sec\n",
      "ONNX postprocessing took 0.002179861068725586 sec\n",
      "ONNX inference took 0.011702299118041992 sec\n",
      "ONNX postprocessing took 0.0006058216094970703 sec\n",
      "ONNX inference took 0.01174616813659668 sec\n",
      "ONNX postprocessing took 0.0010840892791748047 sec\n",
      "ONNX inference took 0.012066125869750977 sec\n",
      "ONNX postprocessing took 0.002441883087158203 sec\n",
      "ONNX inference took 0.011539697647094727 sec\n",
      "ONNX postprocessing took 0.0005896091461181641 sec\n",
      "ONNX inference took 0.011693954467773438 sec\n",
      "ONNX postprocessing took 0.0006191730499267578 sec\n",
      "ONNX inference took 0.01231241226196289 sec\n",
      "ONNX postprocessing took 0.0044536590576171875 sec\n",
      "ONNX inference took 0.012966394424438477 sec\n",
      "ONNX postprocessing took 0.002768993377685547 sec\n",
      "ONNX inference took 0.011348962783813477 sec\n",
      "ONNX postprocessing took 0.001531362533569336 sec\n",
      "ONNX inference took 0.012368440628051758 sec\n",
      "ONNX postprocessing took 0.0033500194549560547 sec\n",
      "ONNX inference took 0.011775493621826172 sec\n",
      "ONNX postprocessing took 0.003410816192626953 sec\n",
      "ONNX inference took 0.012759685516357422 sec\n",
      "ONNX postprocessing took 0.003182649612426758 sec\n",
      "ONNX inference took 0.012310981750488281 sec\n",
      "ONNX postprocessing took 0.0011069774627685547 sec\n",
      "ONNX inference took 0.012310504913330078 sec\n",
      "ONNX postprocessing took 0.0024919509887695312 sec\n",
      "ONNX inference took 0.011366844177246094 sec\n",
      "ONNX postprocessing took 0.0005967617034912109 sec\n",
      "ONNX inference took 0.01172637939453125 sec\n",
      "ONNX postprocessing took 0.0008592605590820312 sec\n",
      "ONNX inference took 0.011403083801269531 sec\n",
      "ONNX postprocessing took 0.0006012916564941406 sec\n",
      "ONNX inference took 0.011604785919189453 sec\n",
      "ONNX postprocessing took 0.0010700225830078125 sec\n",
      "ONNX inference took 0.011484622955322266 sec\n",
      "ONNX postprocessing took 0.0006124973297119141 sec\n",
      "ONNX inference took 0.013658285140991211 sec\n",
      "ONNX postprocessing took 0.0010211467742919922 sec\n",
      "ONNX inference took 0.011607885360717773 sec\n",
      "ONNX postprocessing took 0.00274658203125 sec\n",
      "ONNX inference took 0.012187004089355469 sec\n",
      "ONNX postprocessing took 0.0031328201293945312 sec\n",
      "ONNX inference took 0.011858463287353516 sec\n",
      "ONNX postprocessing took 0.0009908676147460938 sec\n",
      "ONNX inference took 0.011569738388061523 sec\n",
      "ONNX postprocessing took 0.0005793571472167969 sec\n",
      "ONNX inference took 0.011260747909545898 sec\n",
      "ONNX postprocessing took 0.001041412353515625 sec\n",
      "ONNX inference took 0.011709451675415039 sec\n",
      "ONNX postprocessing took 0.0008437633514404297 sec\n",
      "ONNX inference took 0.012190103530883789 sec\n",
      "ONNX postprocessing took 0.0018124580383300781 sec\n",
      "ONNX inference took 0.011950254440307617 sec\n",
      "ONNX postprocessing took 0.0008475780487060547 sec\n",
      "ONNX inference took 0.011262893676757812 sec\n",
      "ONNX postprocessing took 0.0008051395416259766 sec\n",
      "ONNX inference took 0.01570439338684082 sec\n",
      "ONNX postprocessing took 0.006381988525390625 sec\n",
      "ONNX inference took 0.01216435432434082 sec\n",
      "ONNX postprocessing took 0.0021529197692871094 sec\n",
      "ONNX inference took 0.01206660270690918 sec\n",
      "ONNX postprocessing took 0.0009057521820068359 sec\n",
      "ONNX inference took 0.011699914932250977 sec\n",
      "ONNX postprocessing took 0.0009069442749023438 sec\n",
      "ONNX inference took 0.011475801467895508 sec\n",
      "ONNX postprocessing took 0.001613616943359375 sec\n",
      "ONNX inference took 0.013366460800170898 sec\n",
      "ONNX postprocessing took 0.002565145492553711 sec\n",
      "ONNX inference took 0.011824369430541992 sec\n",
      "ONNX postprocessing took 0.0012483596801757812 sec\n",
      "ONNX inference took 0.013283014297485352 sec\n",
      "ONNX postprocessing took 0.00087738037109375 sec\n",
      "ONNX inference took 0.013691425323486328 sec\n",
      "ONNX postprocessing took 0.008966922760009766 sec\n",
      "ONNX inference took 0.011956214904785156 sec\n",
      "ONNX postprocessing took 0.0008189678192138672 sec\n",
      "ONNX inference took 0.012151956558227539 sec\n",
      "ONNX postprocessing took 0.001827239990234375 sec\n",
      "ONNX inference took 0.011366844177246094 sec\n",
      "ONNX postprocessing took 0.0067920684814453125 sec\n",
      "ONNX inference took 0.01233363151550293 sec\n",
      "ONNX postprocessing took 0.0018072128295898438 sec\n",
      "ONNX inference took 0.0114593505859375 sec\n",
      "ONNX postprocessing took 0.0009717941284179688 sec\n",
      "ONNX inference took 0.011559486389160156 sec\n",
      "ONNX postprocessing took 0.0008513927459716797 sec\n",
      "ONNX inference took 0.01125645637512207 sec\n",
      "ONNX postprocessing took 0.0006103515625 sec\n",
      "ONNX inference took 0.011592626571655273 sec\n",
      "ONNX postprocessing took 0.0017130374908447266 sec\n",
      "ONNX inference took 0.012620210647583008 sec\n",
      "ONNX postprocessing took 0.003200054168701172 sec\n",
      "ONNX inference took 0.011694908142089844 sec\n",
      "ONNX postprocessing took 0.0008866786956787109 sec\n",
      "ONNX inference took 0.011438608169555664 sec\n",
      "ONNX postprocessing took 0.0008497238159179688 sec\n",
      "ONNX inference took 0.012125253677368164 sec\n",
      "ONNX postprocessing took 0.0008726119995117188 sec\n",
      "ONNX inference took 0.01224064826965332 sec\n",
      "ONNX postprocessing took 0.004750251770019531 sec\n",
      "ONNX inference took 0.012685298919677734 sec\n",
      "ONNX postprocessing took 0.005644798278808594 sec\n",
      "ONNX inference took 0.011830806732177734 sec\n",
      "ONNX postprocessing took 0.0029075145721435547 sec\n",
      "ONNX inference took 0.013676643371582031 sec\n",
      "ONNX postprocessing took 0.005328655242919922 sec\n",
      "ONNX inference took 0.011237144470214844 sec\n",
      "ONNX postprocessing took 0.004296064376831055 sec\n",
      "ONNX inference took 0.012583017349243164 sec\n",
      "ONNX postprocessing took 0.0015454292297363281 sec\n",
      "ONNX inference took 0.01177072525024414 sec\n",
      "ONNX postprocessing took 0.0009942054748535156 sec\n",
      "ONNX inference took 0.011630058288574219 sec\n",
      "ONNX postprocessing took 0.0009033679962158203 sec\n",
      "ONNX inference took 0.011536598205566406 sec\n",
      "ONNX postprocessing took 0.0006320476531982422 sec\n",
      "ONNX inference took 0.011015653610229492 sec\n",
      "ONNX postprocessing took 0.0006031990051269531 sec\n",
      "ONNX inference took 0.011571884155273438 sec\n",
      "ONNX postprocessing took 0.0033457279205322266 sec\n",
      "ONNX inference took 0.01278376579284668 sec\n",
      "ONNX postprocessing took 0.0034215450286865234 sec\n",
      "ONNX inference took 0.011719465255737305 sec\n",
      "ONNX postprocessing took 0.0012497901916503906 sec\n",
      "ONNX inference took 0.011275053024291992 sec\n",
      "ONNX postprocessing took 0.0006000995635986328 sec\n",
      "ONNX inference took 0.012645483016967773 sec\n",
      "ONNX postprocessing took 0.001252889633178711 sec\n",
      "ONNX inference took 0.013048171997070312 sec\n",
      "ONNX postprocessing took 0.0008594989776611328 sec\n",
      "ONNX inference took 0.01230621337890625 sec\n",
      "ONNX postprocessing took 0.0011615753173828125 sec\n",
      "ONNX inference took 0.012330770492553711 sec\n",
      "ONNX postprocessing took 0.0009608268737792969 sec\n",
      "ONNX inference took 0.011670351028442383 sec\n",
      "ONNX postprocessing took 0.0024919509887695312 sec\n",
      "ONNX inference took 0.012623786926269531 sec\n",
      "ONNX postprocessing took 0.0009400844573974609 sec\n",
      "ONNX inference took 0.012758970260620117 sec\n",
      "ONNX postprocessing took 0.0033409595489501953 sec\n",
      "ONNX inference took 0.011562108993530273 sec\n",
      "ONNX postprocessing took 0.0025434494018554688 sec\n",
      "ONNX inference took 0.011461496353149414 sec\n",
      "ONNX postprocessing took 0.0023479461669921875 sec\n",
      "ONNX inference took 0.011355161666870117 sec\n",
      "ONNX postprocessing took 0.0009186267852783203 sec\n",
      "ONNX inference took 0.01825857162475586 sec\n",
      "ONNX postprocessing took 0.004442930221557617 sec\n",
      "ONNX inference took 0.012106180191040039 sec\n",
      "ONNX postprocessing took 0.0015902519226074219 sec\n",
      "ONNX inference took 0.011891365051269531 sec\n",
      "ONNX postprocessing took 0.0010597705841064453 sec\n",
      "ONNX inference took 0.012368917465209961 sec\n",
      "ONNX postprocessing took 0.002015352249145508 sec\n",
      "ONNX inference took 0.013202667236328125 sec\n",
      "ONNX postprocessing took 0.002679109573364258 sec\n",
      "ONNX inference took 0.011446714401245117 sec\n",
      "ONNX postprocessing took 0.003134489059448242 sec\n",
      "ONNX inference took 0.011297225952148438 sec\n",
      "ONNX postprocessing took 0.0011191368103027344 sec\n",
      "ONNX inference took 0.011304616928100586 sec\n",
      "ONNX postprocessing took 0.0005803108215332031 sec\n",
      "ONNX inference took 0.011293888092041016 sec\n",
      "ONNX postprocessing took 0.0005927085876464844 sec\n",
      "ONNX inference took 0.011657476425170898 sec\n",
      "ONNX postprocessing took 0.0005841255187988281 sec\n",
      "ONNX inference took 0.011642217636108398 sec\n",
      "ONNX postprocessing took 0.0005810260772705078 sec\n",
      "ONNX inference took 0.011904478073120117 sec\n",
      "ONNX postprocessing took 0.0007641315460205078 sec\n",
      "ONNX inference took 0.011430978775024414 sec\n",
      "ONNX postprocessing took 0.005124568939208984 sec\n",
      "ONNX inference took 0.011546134948730469 sec\n",
      "ONNX postprocessing took 0.0006122589111328125 sec\n",
      "ONNX inference took 0.01181173324584961 sec\n",
      "ONNX postprocessing took 0.001088857650756836 sec\n",
      "ONNX inference took 0.012239456176757812 sec\n",
      "ONNX postprocessing took 0.005369663238525391 sec\n",
      "ONNX inference took 0.012421846389770508 sec\n",
      "ONNX postprocessing took 0.00348663330078125 sec\n",
      "ONNX inference took 0.01223611831665039 sec\n",
      "ONNX postprocessing took 0.0017001628875732422 sec\n",
      "ONNX inference took 0.012377262115478516 sec\n",
      "ONNX postprocessing took 0.0032341480255126953 sec\n",
      "ONNX inference took 0.012288331985473633 sec\n",
      "ONNX postprocessing took 0.0011124610900878906 sec\n",
      "ONNX inference took 0.011144638061523438 sec\n",
      "ONNX postprocessing took 0.0022683143615722656 sec\n",
      "ONNX inference took 0.01182413101196289 sec\n",
      "ONNX postprocessing took 0.0025675296783447266 sec\n",
      "ONNX inference took 0.011497735977172852 sec\n",
      "ONNX postprocessing took 0.0008695125579833984 sec\n",
      "ONNX inference took 0.011499643325805664 sec\n",
      "ONNX postprocessing took 0.0011436939239501953 sec\n",
      "ONNX inference took 0.011718988418579102 sec\n",
      "ONNX postprocessing took 0.001993417739868164 sec\n",
      "ONNX inference took 0.012394189834594727 sec\n",
      "ONNX postprocessing took 0.0009672641754150391 sec\n",
      "ONNX inference took 0.015514850616455078 sec\n",
      "ONNX postprocessing took 0.005577802658081055 sec\n",
      "ONNX inference took 0.011642694473266602 sec\n",
      "ONNX postprocessing took 0.0013213157653808594 sec\n",
      "ONNX inference took 0.012304544448852539 sec\n",
      "ONNX postprocessing took 0.0031952857971191406 sec\n",
      "ONNX inference took 0.012631893157958984 sec\n",
      "ONNX postprocessing took 0.004762887954711914 sec\n",
      "ONNX inference took 0.012851238250732422 sec\n",
      "ONNX postprocessing took 0.0008089542388916016 sec\n",
      "ONNX inference took 0.012052774429321289 sec\n",
      "ONNX postprocessing took 0.002022981643676758 sec\n",
      "ONNX inference took 0.015247106552124023 sec\n",
      "ONNX postprocessing took 0.00312042236328125 sec\n",
      "ONNX inference took 0.012422323226928711 sec\n",
      "ONNX postprocessing took 0.002534151077270508 sec\n",
      "ONNX inference took 0.01227712631225586 sec\n",
      "ONNX postprocessing took 0.000911712646484375 sec\n",
      "ONNX inference took 0.011310100555419922 sec\n",
      "ONNX postprocessing took 0.0031218528747558594 sec\n",
      "ONNX inference took 0.012149572372436523 sec\n",
      "ONNX postprocessing took 0.0025548934936523438 sec\n",
      "ONNX inference took 0.01165914535522461 sec\n",
      "ONNX postprocessing took 0.0010488033294677734 sec\n",
      "ONNX inference took 0.011422157287597656 sec\n",
      "ONNX postprocessing took 0.0007083415985107422 sec\n",
      "ONNX inference took 0.01289820671081543 sec\n",
      "ONNX postprocessing took 0.0010738372802734375 sec\n",
      "ONNX inference took 0.011409521102905273 sec\n",
      "ONNX postprocessing took 0.0028328895568847656 sec\n",
      "ONNX inference took 0.016071796417236328 sec\n",
      "ONNX postprocessing took 0.004251003265380859 sec\n",
      "ONNX inference took 0.011685609817504883 sec\n",
      "ONNX postprocessing took 0.0034940242767333984 sec\n",
      "ONNX inference took 0.012141704559326172 sec\n",
      "ONNX postprocessing took 0.0007593631744384766 sec\n",
      "ONNX inference took 0.011878013610839844 sec\n",
      "ONNX postprocessing took 0.0014193058013916016 sec\n",
      "ONNX inference took 0.012976646423339844 sec\n",
      "ONNX postprocessing took 0.005735874176025391 sec\n",
      "ONNX inference took 0.011305570602416992 sec\n",
      "ONNX postprocessing took 0.0008649826049804688 sec\n",
      "ONNX inference took 0.011903524398803711 sec\n",
      "ONNX postprocessing took 0.003656148910522461 sec\n",
      "ONNX inference took 0.012177228927612305 sec\n",
      "ONNX postprocessing took 0.0029838085174560547 sec\n",
      "ONNX inference took 0.012302875518798828 sec\n",
      "ONNX postprocessing took 0.0045282840728759766 sec\n",
      "ONNX inference took 0.01244974136352539 sec\n",
      "ONNX postprocessing took 0.005383968353271484 sec\n",
      "ONNX inference took 0.012395143508911133 sec\n",
      "ONNX postprocessing took 0.001041412353515625 sec\n",
      "ONNX inference took 0.011385440826416016 sec\n",
      "ONNX postprocessing took 0.0011243820190429688 sec\n",
      "ONNX inference took 0.013290166854858398 sec\n",
      "ONNX postprocessing took 0.004412412643432617 sec\n",
      "ONNX inference took 0.012822389602661133 sec\n",
      "ONNX postprocessing took 0.0026006698608398438 sec\n",
      "ONNX inference took 0.012948751449584961 sec\n",
      "ONNX postprocessing took 0.0033311843872070312 sec\n",
      "ONNX inference took 0.012934446334838867 sec\n",
      "ONNX postprocessing took 0.0027723312377929688 sec\n",
      "ONNX inference took 0.011578083038330078 sec\n",
      "ONNX postprocessing took 0.000881195068359375 sec\n",
      "ONNX inference took 0.011981964111328125 sec\n",
      "ONNX postprocessing took 0.003570079803466797 sec\n",
      "ONNX inference took 0.01132512092590332 sec\n",
      "ONNX postprocessing took 0.0008001327514648438 sec\n",
      "ONNX inference took 0.012872457504272461 sec\n",
      "ONNX postprocessing took 0.00131988525390625 sec\n",
      "ONNX inference took 0.01251220703125 sec\n",
      "ONNX postprocessing took 0.0010764598846435547 sec\n",
      "ONNX inference took 0.013689041137695312 sec\n",
      "ONNX postprocessing took 0.001565694808959961 sec\n",
      "ONNX inference took 0.013033866882324219 sec\n",
      "ONNX postprocessing took 0.003357410430908203 sec\n",
      "ONNX inference took 0.013727426528930664 sec\n",
      "ONNX postprocessing took 0.005070686340332031 sec\n",
      "ONNX inference took 0.013142824172973633 sec\n",
      "ONNX postprocessing took 0.003310680389404297 sec\n",
      "ONNX inference took 0.01253199577331543 sec\n",
      "ONNX postprocessing took 0.002871274948120117 sec\n",
      "ONNX inference took 0.012826204299926758 sec\n",
      "ONNX postprocessing took 0.0020618438720703125 sec\n",
      "ONNX inference took 0.012746334075927734 sec\n",
      "ONNX postprocessing took 0.0008575916290283203 sec\n",
      "ONNX inference took 0.012090206146240234 sec\n",
      "ONNX postprocessing took 0.0030775070190429688 sec\n",
      "ONNX inference took 0.01233220100402832 sec\n",
      "ONNX postprocessing took 0.0013031959533691406 sec\n",
      "ONNX inference took 0.013007402420043945 sec\n",
      "ONNX postprocessing took 0.0006957054138183594 sec\n",
      "ONNX inference took 0.012023448944091797 sec\n",
      "ONNX postprocessing took 0.0009601116180419922 sec\n",
      "ONNX inference took 0.012222528457641602 sec\n",
      "ONNX postprocessing took 0.0009002685546875 sec\n",
      "ONNX inference took 0.012995719909667969 sec\n",
      "ONNX postprocessing took 0.0016629695892333984 sec\n",
      "ONNX inference took 0.011826276779174805 sec\n",
      "ONNX postprocessing took 0.003888368606567383 sec\n",
      "ONNX inference took 0.011577129364013672 sec\n",
      "ONNX postprocessing took 0.0008730888366699219 sec\n",
      "ONNX inference took 0.011436939239501953 sec\n",
      "ONNX postprocessing took 0.0008766651153564453 sec\n",
      "ONNX inference took 0.011466503143310547 sec\n",
      "ONNX postprocessing took 0.0028581619262695312 sec\n",
      "ONNX inference took 0.011645317077636719 sec\n",
      "ONNX postprocessing took 0.001638174057006836 sec\n",
      "ONNX inference took 0.01189875602722168 sec\n",
      "ONNX postprocessing took 0.002184152603149414 sec\n",
      "ONNX inference took 0.01273202896118164 sec\n",
      "ONNX postprocessing took 0.0019598007202148438 sec\n",
      "ONNX inference took 0.012310504913330078 sec\n",
      "ONNX postprocessing took 0.0063402652740478516 sec\n",
      "ONNX inference took 0.01190805435180664 sec\n",
      "ONNX postprocessing took 0.0008649826049804688 sec\n",
      "ONNX inference took 0.012438058853149414 sec\n",
      "ONNX postprocessing took 0.0006175041198730469 sec\n",
      "ONNX inference took 0.011467695236206055 sec\n",
      "ONNX postprocessing took 0.001542806625366211 sec\n",
      "ONNX inference took 0.012081146240234375 sec\n",
      "ONNX postprocessing took 0.0014204978942871094 sec\n",
      "ONNX inference took 0.012201547622680664 sec\n",
      "ONNX postprocessing took 0.0010371208190917969 sec\n",
      "ONNX inference took 0.012660741806030273 sec\n",
      "ONNX postprocessing took 0.0007863044738769531 sec\n",
      "ONNX inference took 0.011354923248291016 sec\n",
      "ONNX postprocessing took 0.0012919902801513672 sec\n",
      "ONNX inference took 0.011524200439453125 sec\n",
      "ONNX postprocessing took 0.0009696483612060547 sec\n",
      "ONNX inference took 0.01143956184387207 sec\n",
      "ONNX postprocessing took 0.0008947849273681641 sec\n",
      "ONNX inference took 0.011807918548583984 sec\n",
      "ONNX postprocessing took 0.0008883476257324219 sec\n",
      "ONNX inference took 0.012199640274047852 sec\n",
      "ONNX postprocessing took 0.002373933792114258 sec\n",
      "ONNX inference took 0.011552095413208008 sec\n",
      "ONNX postprocessing took 0.0009310245513916016 sec\n",
      "ONNX inference took 0.01160430908203125 sec\n",
      "ONNX postprocessing took 0.0017681121826171875 sec\n",
      "ONNX inference took 0.011822223663330078 sec\n",
      "ONNX postprocessing took 0.0015659332275390625 sec\n",
      "ONNX inference took 0.011504650115966797 sec\n",
      "ONNX postprocessing took 0.0016508102416992188 sec\n",
      "ONNX inference took 0.011325359344482422 sec\n",
      "ONNX postprocessing took 0.0009024143218994141 sec\n",
      "ONNX inference took 0.012006521224975586 sec\n",
      "ONNX postprocessing took 0.0009164810180664062 sec\n",
      "ONNX inference took 0.013438224792480469 sec\n",
      "ONNX postprocessing took 0.00232696533203125 sec\n",
      "ONNX inference took 0.01327657699584961 sec\n",
      "ONNX postprocessing took 0.0009572505950927734 sec\n",
      "ONNX inference took 0.011506795883178711 sec\n",
      "ONNX postprocessing took 0.0009419918060302734 sec\n",
      "ONNX inference took 0.011285543441772461 sec\n",
      "ONNX postprocessing took 0.0005781650543212891 sec\n",
      "ONNX inference took 0.011758089065551758 sec\n",
      "ONNX postprocessing took 0.0009837150573730469 sec\n",
      "ONNX inference took 0.013313770294189453 sec\n",
      "ONNX postprocessing took 0.00270843505859375 sec\n",
      "ONNX inference took 0.012061595916748047 sec\n",
      "ONNX postprocessing took 0.0005972385406494141 sec\n",
      "ONNX inference took 0.011685848236083984 sec\n",
      "ONNX postprocessing took 0.00109100341796875 sec\n",
      "ONNX inference took 0.011416912078857422 sec\n",
      "ONNX postprocessing took 0.0005800724029541016 sec\n",
      "ONNX inference took 0.011766195297241211 sec\n",
      "ONNX postprocessing took 0.001003265380859375 sec\n",
      "ONNX inference took 0.011945486068725586 sec\n",
      "ONNX postprocessing took 0.0016124248504638672 sec\n",
      "ONNX inference took 0.011586904525756836 sec\n",
      "ONNX postprocessing took 0.001066446304321289 sec\n",
      "ONNX inference took 0.011471271514892578 sec\n",
      "ONNX postprocessing took 0.00061798095703125 sec\n",
      "ONNX inference took 0.012485027313232422 sec\n",
      "ONNX postprocessing took 0.0006630420684814453 sec\n",
      "ONNX inference took 0.01331472396850586 sec\n",
      "ONNX postprocessing took 0.003229856491088867 sec\n",
      "ONNX inference took 0.011897087097167969 sec\n",
      "ONNX postprocessing took 0.0008306503295898438 sec\n",
      "ONNX inference took 0.01148533821105957 sec\n",
      "ONNX postprocessing took 0.0008375644683837891 sec\n",
      "ONNX inference took 0.013162612915039062 sec\n",
      "ONNX postprocessing took 0.003626585006713867 sec\n",
      "ONNX inference took 0.01234889030456543 sec\n",
      "ONNX postprocessing took 0.002682924270629883 sec\n",
      "ONNX inference took 0.010972261428833008 sec\n",
      "ONNX postprocessing took 0.0006222724914550781 sec\n",
      "ONNX inference took 0.011812686920166016 sec\n",
      "ONNX postprocessing took 0.0005805492401123047 sec\n",
      "ONNX inference took 0.011066675186157227 sec\n",
      "ONNX postprocessing took 0.0033469200134277344 sec\n",
      "ONNX inference took 0.01215815544128418 sec\n",
      "ONNX postprocessing took 0.002840280532836914 sec\n",
      "ONNX inference took 0.012707710266113281 sec\n",
      "ONNX postprocessing took 0.00455927848815918 sec\n",
      "ONNX inference took 0.012374639511108398 sec\n",
      "ONNX postprocessing took 0.0021762847900390625 sec\n",
      "ONNX inference took 0.011367082595825195 sec\n",
      "ONNX postprocessing took 0.000732421875 sec\n",
      "ONNX inference took 0.011703729629516602 sec\n",
      "ONNX postprocessing took 0.0026950836181640625 sec\n",
      "ONNX inference took 0.013021230697631836 sec\n",
      "ONNX postprocessing took 0.0020971298217773438 sec\n",
      "ONNX inference took 0.012471437454223633 sec\n",
      "ONNX postprocessing took 0.0020377635955810547 sec\n",
      "ONNX inference took 0.013354778289794922 sec\n",
      "ONNX postprocessing took 0.0037050247192382812 sec\n",
      "ONNX inference took 0.013788223266601562 sec\n",
      "ONNX postprocessing took 0.0029532909393310547 sec\n",
      "ONNX inference took 0.012141704559326172 sec\n",
      "ONNX postprocessing took 0.001110076904296875 sec\n",
      "ONNX inference took 0.011370658874511719 sec\n",
      "ONNX postprocessing took 0.0005743503570556641 sec\n",
      "ONNX inference took 0.012383460998535156 sec\n",
      "ONNX postprocessing took 0.0014078617095947266 sec\n",
      "ONNX inference took 0.011531591415405273 sec\n",
      "ONNX postprocessing took 0.0009095668792724609 sec\n",
      "ONNX inference took 0.011266708374023438 sec\n",
      "ONNX postprocessing took 0.005621194839477539 sec\n",
      "ONNX inference took 0.011644363403320312 sec\n",
      "ONNX postprocessing took 0.002472400665283203 sec\n",
      "ONNX inference took 0.013987064361572266 sec\n",
      "ONNX postprocessing took 0.004239797592163086 sec\n",
      "ONNX inference took 0.01275944709777832 sec\n",
      "ONNX postprocessing took 0.0007884502410888672 sec\n",
      "ONNX inference took 0.012701272964477539 sec\n",
      "ONNX postprocessing took 0.0007488727569580078 sec\n",
      "ONNX inference took 0.011925935745239258 sec\n",
      "ONNX postprocessing took 0.00087738037109375 sec\n",
      "ONNX inference took 0.01157999038696289 sec\n",
      "ONNX postprocessing took 0.0022029876708984375 sec\n",
      "ONNX inference took 0.011568307876586914 sec\n",
      "ONNX postprocessing took 0.0009744167327880859 sec\n",
      "ONNX inference took 0.01116323471069336 sec\n",
      "ONNX postprocessing took 0.0009336471557617188 sec\n",
      "ONNX inference took 0.012146711349487305 sec\n",
      "ONNX postprocessing took 0.0029153823852539062 sec\n",
      "ONNX inference took 0.011611223220825195 sec\n",
      "ONNX postprocessing took 0.0009024143218994141 sec\n",
      "ONNX inference took 0.012813091278076172 sec\n",
      "ONNX postprocessing took 0.0008528232574462891 sec\n",
      "ONNX inference took 0.012030363082885742 sec\n",
      "ONNX postprocessing took 0.0014085769653320312 sec\n",
      "ONNX inference took 0.012797117233276367 sec\n",
      "ONNX postprocessing took 0.000949859619140625 sec\n",
      "ONNX inference took 0.011435270309448242 sec\n",
      "ONNX postprocessing took 0.002276897430419922 sec\n",
      "ONNX inference took 0.012498140335083008 sec\n",
      "ONNX postprocessing took 0.0012154579162597656 sec\n",
      "ONNX inference took 0.013125896453857422 sec\n",
      "ONNX postprocessing took 0.0010623931884765625 sec\n",
      "ONNX inference took 0.012244701385498047 sec\n",
      "ONNX postprocessing took 0.0006244182586669922 sec\n",
      "ONNX inference took 0.010860204696655273 sec\n",
      "ONNX postprocessing took 0.0005958080291748047 sec\n",
      "ONNX inference took 0.0114288330078125 sec\n",
      "ONNX postprocessing took 0.0007731914520263672 sec\n",
      "ONNX inference took 0.011480569839477539 sec\n",
      "ONNX postprocessing took 0.0006070137023925781 sec\n",
      "ONNX inference took 0.011300325393676758 sec\n",
      "ONNX postprocessing took 0.0005905628204345703 sec\n",
      "ONNX inference took 0.011268377304077148 sec\n",
      "ONNX postprocessing took 0.0006053447723388672 sec\n",
      "ONNX inference took 0.013279438018798828 sec\n",
      "ONNX postprocessing took 0.0024840831756591797 sec\n",
      "ONNX inference took 0.01244974136352539 sec\n",
      "ONNX postprocessing took 0.0034945011138916016 sec\n",
      "ONNX inference took 0.011696815490722656 sec\n",
      "ONNX postprocessing took 0.0011830329895019531 sec\n",
      "ONNX inference took 0.013096809387207031 sec\n",
      "ONNX postprocessing took 0.002872467041015625 sec\n",
      "ONNX inference took 0.01231074333190918 sec\n",
      "ONNX postprocessing took 0.0009410381317138672 sec\n",
      "ONNX inference took 0.011522531509399414 sec\n",
      "ONNX postprocessing took 0.0008859634399414062 sec\n",
      "ONNX inference took 0.011540889739990234 sec\n",
      "ONNX postprocessing took 0.0006170272827148438 sec\n",
      "ONNX inference took 0.012573719024658203 sec\n",
      "ONNX postprocessing took 0.00072479248046875 sec\n",
      "ONNX inference took 0.011687755584716797 sec\n",
      "ONNX postprocessing took 0.002778768539428711 sec\n",
      "ONNX inference took 0.011610984802246094 sec\n",
      "ONNX postprocessing took 0.0008666515350341797 sec\n",
      "ONNX inference took 0.011003971099853516 sec\n",
      "ONNX postprocessing took 0.0008685588836669922 sec\n",
      "ONNX inference took 0.011468172073364258 sec\n",
      "ONNX postprocessing took 0.0023620128631591797 sec\n",
      "ONNX inference took 0.01277923583984375 sec\n",
      "ONNX postprocessing took 0.0015151500701904297 sec\n",
      "ONNX inference took 0.011916399002075195 sec\n",
      "ONNX postprocessing took 0.0021162033081054688 sec\n",
      "ONNX inference took 0.01220846176147461 sec\n",
      "ONNX postprocessing took 0.0041484832763671875 sec\n",
      "ONNX inference took 0.012238264083862305 sec\n",
      "ONNX postprocessing took 0.0012993812561035156 sec\n",
      "ONNX inference took 0.012449026107788086 sec\n",
      "ONNX postprocessing took 0.0025479793548583984 sec\n",
      "ONNX inference took 0.012577295303344727 sec\n",
      "ONNX postprocessing took 0.001321554183959961 sec\n",
      "ONNX inference took 0.012903451919555664 sec\n",
      "ONNX postprocessing took 0.0021729469299316406 sec\n",
      "ONNX inference took 0.012169837951660156 sec\n",
      "ONNX postprocessing took 0.0009491443634033203 sec\n",
      "ONNX inference took 0.01214909553527832 sec\n",
      "ONNX postprocessing took 0.0020341873168945312 sec\n",
      "ONNX inference took 0.013713836669921875 sec\n",
      "ONNX postprocessing took 0.0034394264221191406 sec\n",
      "ONNX inference took 0.012647151947021484 sec\n",
      "ONNX postprocessing took 0.0008857250213623047 sec\n",
      "ONNX inference took 0.012210607528686523 sec\n",
      "ONNX postprocessing took 0.002942800521850586 sec\n",
      "ONNX inference took 0.011708498001098633 sec\n",
      "ONNX postprocessing took 0.001974821090698242 sec\n",
      "ONNX inference took 0.012900352478027344 sec\n",
      "ONNX postprocessing took 0.0028231143951416016 sec\n",
      "ONNX inference took 0.01157379150390625 sec\n",
      "ONNX postprocessing took 0.0009045600891113281 sec\n",
      "ONNX inference took 0.012304306030273438 sec\n",
      "ONNX postprocessing took 0.0022721290588378906 sec\n",
      "ONNX inference took 0.01163935661315918 sec\n",
      "ONNX postprocessing took 0.0020127296447753906 sec\n",
      "ONNX inference took 0.012262344360351562 sec\n",
      "ONNX postprocessing took 0.003188610076904297 sec\n",
      "ONNX inference took 0.011985301971435547 sec\n",
      "ONNX postprocessing took 0.0025224685668945312 sec\n",
      "ONNX inference took 0.01543569564819336 sec\n",
      "ONNX postprocessing took 0.007685661315917969 sec\n",
      "ONNX inference took 0.01158285140991211 sec\n",
      "ONNX postprocessing took 0.0008549690246582031 sec\n",
      "ONNX inference took 0.01118922233581543 sec\n",
      "ONNX postprocessing took 0.0008299350738525391 sec\n",
      "ONNX inference took 0.011342287063598633 sec\n",
      "ONNX postprocessing took 0.0007805824279785156 sec\n",
      "ONNX inference took 0.011474847793579102 sec\n",
      "ONNX postprocessing took 0.0008614063262939453 sec\n",
      "ONNX inference took 0.011643648147583008 sec\n",
      "ONNX postprocessing took 0.0021867752075195312 sec\n",
      "ONNX inference took 0.01341700553894043 sec\n",
      "ONNX postprocessing took 0.0027365684509277344 sec\n",
      "ONNX inference took 0.012244224548339844 sec\n",
      "ONNX postprocessing took 0.0026493072509765625 sec\n",
      "ONNX inference took 0.011946439743041992 sec\n",
      "ONNX postprocessing took 0.0006842613220214844 sec\n",
      "ONNX inference took 0.013020753860473633 sec\n",
      "ONNX postprocessing took 0.001150369644165039 sec\n",
      "ONNX inference took 0.01407003402709961 sec\n",
      "ONNX postprocessing took 0.003529787063598633 sec\n",
      "ONNX inference took 0.011645793914794922 sec\n",
      "ONNX postprocessing took 0.0009341239929199219 sec\n",
      "ONNX inference took 0.011431455612182617 sec\n",
      "ONNX postprocessing took 0.0008223056793212891 sec\n",
      "ONNX inference took 0.012204408645629883 sec\n",
      "ONNX postprocessing took 0.0005710124969482422 sec\n",
      "ONNX inference took 0.011289358139038086 sec\n",
      "ONNX postprocessing took 0.0010328292846679688 sec\n",
      "ONNX inference took 0.011124134063720703 sec\n",
      "ONNX postprocessing took 0.001855611801147461 sec\n",
      "ONNX inference took 0.012074470520019531 sec\n",
      "ONNX postprocessing took 0.004628896713256836 sec\n",
      "ONNX inference took 0.011973857879638672 sec\n",
      "ONNX postprocessing took 0.0038270950317382812 sec\n",
      "ONNX inference took 0.012076139450073242 sec\n",
      "ONNX postprocessing took 0.0009152889251708984 sec\n",
      "ONNX inference took 0.014131307601928711 sec\n",
      "ONNX postprocessing took 0.0010790824890136719 sec\n",
      "ONNX inference took 0.013499975204467773 sec\n",
      "ONNX postprocessing took 0.010145902633666992 sec\n",
      "ONNX inference took 0.011721134185791016 sec\n",
      "ONNX postprocessing took 0.0020394325256347656 sec\n",
      "ONNX inference took 0.01178741455078125 sec\n",
      "ONNX postprocessing took 0.0034313201904296875 sec\n",
      "ONNX inference took 0.012279272079467773 sec\n",
      "ONNX postprocessing took 0.0016703605651855469 sec\n",
      "ONNX inference took 0.012337207794189453 sec\n",
      "ONNX postprocessing took 0.0009441375732421875 sec\n",
      "ONNX inference took 0.013083457946777344 sec\n",
      "ONNX postprocessing took 0.0006742477416992188 sec\n",
      "ONNX inference took 0.012714862823486328 sec\n",
      "ONNX postprocessing took 0.002687215805053711 sec\n",
      "ONNX inference took 0.011540651321411133 sec\n",
      "ONNX postprocessing took 0.001119852066040039 sec\n",
      "ONNX inference took 0.014739990234375 sec\n",
      "ONNX postprocessing took 0.0034995079040527344 sec\n",
      "ONNX inference took 0.012162208557128906 sec\n",
      "ONNX postprocessing took 0.0017392635345458984 sec\n",
      "ONNX inference took 0.01163482666015625 sec\n",
      "ONNX postprocessing took 0.0017240047454833984 sec\n",
      "ONNX inference took 0.012608528137207031 sec\n",
      "ONNX postprocessing took 0.0010082721710205078 sec\n",
      "ONNX inference took 0.015007972717285156 sec\n",
      "ONNX postprocessing took 0.0033097267150878906 sec\n",
      "ONNX inference took 0.01169729232788086 sec\n",
      "ONNX postprocessing took 0.0008466243743896484 sec\n",
      "ONNX inference took 0.012446880340576172 sec\n",
      "ONNX postprocessing took 0.0009472370147705078 sec\n",
      "ONNX inference took 0.011599540710449219 sec\n",
      "ONNX postprocessing took 0.002347707748413086 sec\n",
      "ONNX inference took 0.011355161666870117 sec\n",
      "ONNX postprocessing took 0.0010089874267578125 sec\n",
      "ONNX inference took 0.012104034423828125 sec\n",
      "ONNX postprocessing took 0.0007846355438232422 sec\n",
      "ONNX inference took 0.01271963119506836 sec\n",
      "ONNX postprocessing took 0.0008525848388671875 sec\n",
      "ONNX inference took 0.013621807098388672 sec\n",
      "ONNX postprocessing took 0.00403594970703125 sec\n",
      "ONNX inference took 0.011559247970581055 sec\n",
      "ONNX postprocessing took 0.0006177425384521484 sec\n",
      "ONNX inference took 0.011630058288574219 sec\n",
      "ONNX postprocessing took 0.0012600421905517578 sec\n",
      "ONNX inference took 0.011684894561767578 sec\n",
      "ONNX postprocessing took 0.0015459060668945312 sec\n",
      "ONNX inference took 0.011657953262329102 sec\n",
      "ONNX postprocessing took 0.0017611980438232422 sec\n",
      "ONNX inference took 0.01163935661315918 sec\n",
      "ONNX postprocessing took 0.0010759830474853516 sec\n",
      "ONNX inference took 0.01262211799621582 sec\n",
      "ONNX postprocessing took 0.0036208629608154297 sec\n",
      "ONNX inference took 0.011776447296142578 sec\n",
      "ONNX postprocessing took 0.002725839614868164 sec\n",
      "ONNX inference took 0.011901378631591797 sec\n",
      "ONNX postprocessing took 0.005429267883300781 sec\n",
      "ONNX inference took 0.012850284576416016 sec\n",
      "ONNX postprocessing took 0.0006275177001953125 sec\n",
      "ONNX inference took 0.012863874435424805 sec\n",
      "ONNX postprocessing took 0.0008060932159423828 sec\n",
      "ONNX inference took 0.012126445770263672 sec\n",
      "ONNX postprocessing took 0.0005869865417480469 sec\n",
      "ONNX inference took 0.011546611785888672 sec\n",
      "ONNX postprocessing took 0.0009169578552246094 sec\n",
      "ONNX inference took 0.012265920639038086 sec\n",
      "ONNX postprocessing took 0.004400014877319336 sec\n",
      "ONNX inference took 0.011474132537841797 sec\n",
      "ONNX postprocessing took 0.0032966136932373047 sec\n",
      "ONNX inference took 0.011787891387939453 sec\n",
      "ONNX postprocessing took 0.0018930435180664062 sec\n",
      "ONNX inference took 0.011434078216552734 sec\n",
      "ONNX postprocessing took 0.0030112266540527344 sec\n",
      "ONNX inference took 0.012261152267456055 sec\n",
      "ONNX postprocessing took 0.0018284320831298828 sec\n",
      "ONNX inference took 0.011648178100585938 sec\n",
      "ONNX postprocessing took 0.0019423961639404297 sec\n",
      "ONNX inference took 0.013708114624023438 sec\n",
      "ONNX postprocessing took 0.0026750564575195312 sec\n",
      "ONNX inference took 0.013141632080078125 sec\n",
      "ONNX postprocessing took 0.0009095668792724609 sec\n",
      "ONNX inference took 0.012232303619384766 sec\n",
      "ONNX postprocessing took 0.003099679946899414 sec\n",
      "ONNX inference took 0.012239694595336914 sec\n",
      "ONNX postprocessing took 0.003880739212036133 sec\n",
      "ONNX inference took 0.012415170669555664 sec\n",
      "ONNX postprocessing took 0.0022444725036621094 sec\n",
      "ONNX inference took 0.012476205825805664 sec\n",
      "ONNX postprocessing took 0.0034592151641845703 sec\n",
      "ONNX inference took 0.011877059936523438 sec\n",
      "ONNX postprocessing took 0.0048177242279052734 sec\n",
      "ONNX inference took 0.01112985610961914 sec\n",
      "ONNX postprocessing took 0.0014576911926269531 sec\n",
      "ONNX inference took 0.011659383773803711 sec\n",
      "ONNX postprocessing took 0.0027108192443847656 sec\n",
      "ONNX inference took 0.012513160705566406 sec\n",
      "ONNX postprocessing took 0.003473997116088867 sec\n",
      "ONNX inference took 0.011621475219726562 sec\n",
      "ONNX postprocessing took 0.0009238719940185547 sec\n",
      "ONNX inference took 0.011414051055908203 sec\n",
      "ONNX postprocessing took 0.003247976303100586 sec\n",
      "ONNX inference took 0.011505126953125 sec\n",
      "ONNX postprocessing took 0.003953218460083008 sec\n",
      "ONNX inference took 0.0128173828125 sec\n",
      "ONNX postprocessing took 0.002612590789794922 sec\n",
      "ONNX inference took 0.011971235275268555 sec\n",
      "ONNX postprocessing took 0.002882242202758789 sec\n",
      "ONNX inference took 0.012932538986206055 sec\n",
      "ONNX postprocessing took 0.0012481212615966797 sec\n",
      "ONNX inference took 0.014713048934936523 sec\n",
      "ONNX postprocessing took 0.001390218734741211 sec\n",
      "ONNX inference took 0.013674497604370117 sec\n",
      "ONNX postprocessing took 0.003885030746459961 sec\n",
      "ONNX inference took 0.011888742446899414 sec\n",
      "ONNX postprocessing took 0.003534078598022461 sec\n",
      "ONNX inference took 0.011614322662353516 sec\n",
      "ONNX postprocessing took 0.0008962154388427734 sec\n",
      "ONNX inference took 0.011620044708251953 sec\n",
      "ONNX postprocessing took 0.00091552734375 sec\n",
      "ONNX inference took 0.011802434921264648 sec\n",
      "ONNX postprocessing took 0.002225637435913086 sec\n",
      "ONNX inference took 0.012017011642456055 sec\n",
      "ONNX postprocessing took 0.0016069412231445312 sec\n",
      "ONNX inference took 0.012510538101196289 sec\n",
      "ONNX postprocessing took 0.0021109580993652344 sec\n",
      "ONNX inference took 0.012191057205200195 sec\n",
      "ONNX postprocessing took 0.0015180110931396484 sec\n",
      "ONNX inference took 0.012084722518920898 sec\n",
      "ONNX postprocessing took 0.0026197433471679688 sec\n",
      "ONNX inference took 0.012351512908935547 sec\n",
      "ONNX postprocessing took 0.004811763763427734 sec\n",
      "ONNX inference took 0.011893749237060547 sec\n",
      "ONNX postprocessing took 0.002038240432739258 sec\n",
      "ONNX inference took 0.013181209564208984 sec\n",
      "ONNX postprocessing took 0.005393028259277344 sec\n",
      "ONNX inference took 0.012342691421508789 sec\n",
      "ONNX postprocessing took 0.0026712417602539062 sec\n",
      "ONNX inference took 0.0128021240234375 sec\n",
      "ONNX postprocessing took 0.0019490718841552734 sec\n",
      "ONNX inference took 0.011902809143066406 sec\n",
      "ONNX postprocessing took 0.0031120777130126953 sec\n",
      "ONNX inference took 0.01200556755065918 sec\n",
      "ONNX postprocessing took 0.0009002685546875 sec\n",
      "ONNX inference took 0.011146306991577148 sec\n",
      "ONNX postprocessing took 0.000835418701171875 sec\n",
      "ONNX inference took 0.011513233184814453 sec\n",
      "ONNX postprocessing took 0.0018830299377441406 sec\n",
      "ONNX inference took 0.011741399765014648 sec\n",
      "ONNX postprocessing took 0.0008418560028076172 sec\n",
      "ONNX inference took 0.011822938919067383 sec\n",
      "ONNX postprocessing took 0.00588226318359375 sec\n",
      "ONNX inference took 0.012334585189819336 sec\n",
      "ONNX postprocessing took 0.0007193088531494141 sec\n",
      "ONNX inference took 0.01173543930053711 sec\n",
      "ONNX postprocessing took 0.002602100372314453 sec\n",
      "ONNX inference took 0.011453866958618164 sec\n",
      "ONNX postprocessing took 0.0034525394439697266 sec\n",
      "ONNX inference took 0.01231837272644043 sec\n",
      "ONNX postprocessing took 0.002203702926635742 sec\n",
      "ONNX inference took 0.011788606643676758 sec\n",
      "ONNX postprocessing took 0.0006201267242431641 sec\n",
      "ONNX inference took 0.011260986328125 sec\n",
      "ONNX postprocessing took 0.0006823539733886719 sec\n",
      "ONNX inference took 0.011423110961914062 sec\n",
      "ONNX postprocessing took 0.0005528926849365234 sec\n",
      "ONNX inference took 0.011541604995727539 sec\n",
      "ONNX postprocessing took 0.0016431808471679688 sec\n",
      "ONNX inference took 0.010935306549072266 sec\n",
      "ONNX postprocessing took 0.0008025169372558594 sec\n",
      "ONNX inference took 0.011523723602294922 sec\n",
      "ONNX postprocessing took 0.002942800521850586 sec\n",
      "ONNX inference took 0.012120723724365234 sec\n",
      "ONNX postprocessing took 0.003054380416870117 sec\n",
      "ONNX inference took 0.012210369110107422 sec\n",
      "ONNX postprocessing took 0.0013234615325927734 sec\n",
      "ONNX inference took 0.01178884506225586 sec\n",
      "ONNX postprocessing took 0.0006382465362548828 sec\n",
      "ONNX inference took 0.011962652206420898 sec\n",
      "ONNX postprocessing took 0.0006234645843505859 sec\n",
      "ONNX inference took 0.011623144149780273 sec\n",
      "ONNX postprocessing took 0.0032587051391601562 sec\n",
      "ONNX inference took 0.011792182922363281 sec\n",
      "ONNX postprocessing took 0.004354953765869141 sec\n",
      "ONNX inference took 0.013478755950927734 sec\n",
      "ONNX postprocessing took 0.0016222000122070312 sec\n",
      "ONNX inference took 0.012147665023803711 sec\n",
      "ONNX postprocessing took 0.00292205810546875 sec\n",
      "ONNX inference took 0.0136260986328125 sec\n",
      "ONNX postprocessing took 0.0045893192291259766 sec\n",
      "ONNX inference took 0.011946916580200195 sec\n",
      "ONNX postprocessing took 0.0008091926574707031 sec\n",
      "ONNX inference took 0.01214742660522461 sec\n",
      "ONNX postprocessing took 0.001127481460571289 sec\n",
      "ONNX inference took 0.01166844367980957 sec\n",
      "ONNX postprocessing took 0.0011212825775146484 sec\n",
      "ONNX inference took 0.01243734359741211 sec\n",
      "ONNX postprocessing took 0.001018524169921875 sec\n",
      "ONNX inference took 0.013391971588134766 sec\n",
      "ONNX postprocessing took 0.0035142898559570312 sec\n",
      "ONNX inference took 0.012390613555908203 sec\n",
      "ONNX postprocessing took 0.0011997222900390625 sec\n",
      "ONNX inference took 0.011658906936645508 sec\n",
      "ONNX postprocessing took 0.0033941268920898438 sec\n",
      "ONNX inference took 0.011560201644897461 sec\n",
      "ONNX postprocessing took 0.0006511211395263672 sec\n",
      "ONNX inference took 0.012063264846801758 sec\n",
      "ONNX postprocessing took 0.0009009838104248047 sec\n",
      "ONNX inference took 0.01219797134399414 sec\n",
      "ONNX postprocessing took 0.0011315345764160156 sec\n",
      "ONNX inference took 0.013260364532470703 sec\n",
      "ONNX postprocessing took 0.0029578208923339844 sec\n",
      "ONNX inference took 0.011676788330078125 sec\n",
      "ONNX postprocessing took 0.0013883113861083984 sec\n",
      "ONNX inference took 0.01189422607421875 sec\n",
      "ONNX postprocessing took 0.0017406940460205078 sec\n",
      "ONNX inference took 0.012119770050048828 sec\n",
      "ONNX postprocessing took 0.0027763843536376953 sec\n",
      "ONNX inference took 0.011236429214477539 sec\n",
      "ONNX postprocessing took 0.0009686946868896484 sec\n",
      "ONNX inference took 0.011651039123535156 sec\n",
      "ONNX postprocessing took 0.0010564327239990234 sec\n",
      "ONNX inference took 0.011632204055786133 sec\n",
      "ONNX postprocessing took 0.0017070770263671875 sec\n",
      "ONNX inference took 0.01175379753112793 sec\n",
      "ONNX postprocessing took 0.0008881092071533203 sec\n",
      "ONNX inference took 0.011941909790039062 sec\n",
      "ONNX postprocessing took 0.0015163421630859375 sec\n",
      "ONNX inference took 0.011108875274658203 sec\n",
      "ONNX postprocessing took 0.0006167888641357422 sec\n",
      "ONNX inference took 0.012689590454101562 sec\n",
      "ONNX postprocessing took 0.004261016845703125 sec\n",
      "ONNX inference took 0.012337923049926758 sec\n",
      "ONNX postprocessing took 0.0006277561187744141 sec\n",
      "ONNX inference took 0.0126800537109375 sec\n",
      "ONNX postprocessing took 0.0008635520935058594 sec\n",
      "ONNX inference took 0.013391256332397461 sec\n",
      "ONNX postprocessing took 0.0019333362579345703 sec\n",
      "ONNX inference took 0.011834144592285156 sec\n",
      "ONNX postprocessing took 0.0055484771728515625 sec\n",
      "ONNX inference took 0.012264728546142578 sec\n",
      "ONNX postprocessing took 0.0009474754333496094 sec\n",
      "ONNX inference took 0.012741327285766602 sec\n",
      "ONNX postprocessing took 0.0030241012573242188 sec\n",
      "ONNX inference took 0.012494325637817383 sec\n",
      "ONNX postprocessing took 0.0010323524475097656 sec\n",
      "ONNX inference took 0.011766433715820312 sec\n",
      "ONNX postprocessing took 0.002655506134033203 sec\n",
      "ONNX inference took 0.011843442916870117 sec\n",
      "ONNX postprocessing took 0.0006289482116699219 sec\n",
      "ONNX inference took 0.013050317764282227 sec\n",
      "ONNX postprocessing took 0.0009508132934570312 sec\n",
      "ONNX inference took 0.017630815505981445 sec\n",
      "ONNX postprocessing took 0.005576610565185547 sec\n",
      "ONNX inference took 0.011888504028320312 sec\n",
      "ONNX postprocessing took 0.002552509307861328 sec\n",
      "ONNX inference took 0.011685848236083984 sec\n",
      "ONNX postprocessing took 0.0008878707885742188 sec\n",
      "ONNX inference took 0.011701345443725586 sec\n",
      "ONNX postprocessing took 0.0031235218048095703 sec\n",
      "ONNX inference took 0.012483358383178711 sec\n",
      "ONNX postprocessing took 0.0015637874603271484 sec\n",
      "ONNX inference took 0.012312650680541992 sec\n",
      "ONNX postprocessing took 0.0021276473999023438 sec\n",
      "ONNX inference took 0.011161088943481445 sec\n",
      "ONNX postprocessing took 0.004971742630004883 sec\n",
      "ONNX inference took 0.011876583099365234 sec\n",
      "ONNX postprocessing took 0.0008530616760253906 sec\n",
      "ONNX inference took 0.015218973159790039 sec\n",
      "ONNX postprocessing took 0.004698753356933594 sec\n",
      "ONNX inference took 0.011397600173950195 sec\n",
      "ONNX postprocessing took 0.0029828548431396484 sec\n",
      "ONNX inference took 0.012152671813964844 sec\n",
      "ONNX postprocessing took 0.0010528564453125 sec\n",
      "ONNX inference took 0.012609720230102539 sec\n",
      "ONNX postprocessing took 0.003117084503173828 sec\n",
      "ONNX inference took 0.01283407211303711 sec\n",
      "ONNX postprocessing took 0.002857208251953125 sec\n",
      "ONNX inference took 0.012552022933959961 sec\n",
      "ONNX postprocessing took 0.0013155937194824219 sec\n",
      "ONNX inference took 0.013272523880004883 sec\n",
      "ONNX postprocessing took 0.007970333099365234 sec\n",
      "ONNX inference took 0.0118865966796875 sec\n",
      "ONNX postprocessing took 0.0014612674713134766 sec\n",
      "ONNX inference took 0.011384963989257812 sec\n",
      "ONNX postprocessing took 0.0012586116790771484 sec\n",
      "ONNX inference took 0.01196908950805664 sec\n",
      "ONNX postprocessing took 0.0028409957885742188 sec\n",
      "ONNX inference took 0.011072397232055664 sec\n",
      "ONNX postprocessing took 0.0006773471832275391 sec\n",
      "ONNX inference took 0.011327505111694336 sec\n",
      "ONNX postprocessing took 0.0008459091186523438 sec\n",
      "ONNX inference took 0.011578559875488281 sec\n",
      "ONNX postprocessing took 0.0017046928405761719 sec\n",
      "ONNX inference took 0.011242389678955078 sec\n",
      "ONNX postprocessing took 0.0020058155059814453 sec\n",
      "ONNX inference took 0.012538671493530273 sec\n",
      "ONNX postprocessing took 0.002953767776489258 sec\n",
      "ONNX inference took 0.012067794799804688 sec\n",
      "ONNX postprocessing took 0.0005841255187988281 sec\n",
      "ONNX inference took 0.011873006820678711 sec\n",
      "ONNX postprocessing took 0.002172708511352539 sec\n",
      "ONNX inference took 0.011600494384765625 sec\n",
      "ONNX postprocessing took 0.0021283626556396484 sec\n",
      "ONNX inference took 0.012458562850952148 sec\n",
      "ONNX postprocessing took 0.0011105537414550781 sec\n",
      "ONNX inference took 0.011708259582519531 sec\n",
      "ONNX postprocessing took 0.0022280216217041016 sec\n",
      "ONNX inference took 0.01109457015991211 sec\n",
      "ONNX postprocessing took 0.002130270004272461 sec\n",
      "ONNX inference took 0.0123443603515625 sec\n",
      "ONNX postprocessing took 0.002526998519897461 sec\n",
      "ONNX inference took 0.013110637664794922 sec\n",
      "ONNX postprocessing took 0.0014319419860839844 sec\n",
      "ONNX inference took 0.012300252914428711 sec\n",
      "ONNX postprocessing took 0.00229644775390625 sec\n",
      "ONNX inference took 0.011890649795532227 sec\n",
      "ONNX postprocessing took 0.002134561538696289 sec\n",
      "ONNX inference took 0.012115001678466797 sec\n",
      "ONNX postprocessing took 0.008578062057495117 sec\n",
      "ONNX inference took 0.011667728424072266 sec\n",
      "ONNX postprocessing took 0.0010161399841308594 sec\n",
      "ONNX inference took 0.011469364166259766 sec\n",
      "ONNX postprocessing took 0.0013968944549560547 sec\n",
      "ONNX inference took 0.01317143440246582 sec\n",
      "ONNX postprocessing took 0.0029611587524414062 sec\n",
      "ONNX inference took 0.012680530548095703 sec\n",
      "ONNX postprocessing took 0.004081249237060547 sec\n",
      "ONNX inference took 0.013845205307006836 sec\n",
      "ONNX postprocessing took 0.00525212287902832 sec\n",
      "ONNX inference took 0.011705160140991211 sec\n",
      "ONNX postprocessing took 0.0032205581665039062 sec\n",
      "ONNX inference took 0.011993646621704102 sec\n",
      "ONNX postprocessing took 0.006065845489501953 sec\n",
      "ONNX inference took 0.012299776077270508 sec\n",
      "ONNX postprocessing took 0.004329681396484375 sec\n",
      "ONNX inference took 0.013402223587036133 sec\n",
      "ONNX postprocessing took 0.00402379035949707 sec\n",
      "ONNX inference took 0.011824846267700195 sec\n",
      "ONNX postprocessing took 0.002498149871826172 sec\n",
      "ONNX inference took 0.012934207916259766 sec\n",
      "ONNX postprocessing took 0.0016858577728271484 sec\n",
      "ONNX inference took 0.011306524276733398 sec\n",
      "ONNX postprocessing took 0.004141807556152344 sec\n",
      "ONNX inference took 0.011566877365112305 sec\n",
      "ONNX postprocessing took 0.0008568763732910156 sec\n",
      "ONNX inference took 0.012064218521118164 sec\n",
      "ONNX postprocessing took 0.002997875213623047 sec\n",
      "ONNX inference took 0.012243509292602539 sec\n",
      "ONNX postprocessing took 0.0008959770202636719 sec\n",
      "ONNX inference took 0.011708498001098633 sec\n",
      "ONNX postprocessing took 0.002189159393310547 sec\n",
      "ONNX inference took 0.014402389526367188 sec\n",
      "ONNX postprocessing took 0.0036165714263916016 sec\n",
      "ONNX inference took 0.012296676635742188 sec\n",
      "ONNX postprocessing took 0.004050016403198242 sec\n",
      "ONNX inference took 0.01223301887512207 sec\n",
      "ONNX postprocessing took 0.0017282962799072266 sec\n",
      "ONNX inference took 0.012440681457519531 sec\n",
      "ONNX postprocessing took 0.0010199546813964844 sec\n",
      "ONNX inference took 0.012085199356079102 sec\n",
      "ONNX postprocessing took 0.0005939006805419922 sec\n",
      "ONNX inference took 0.011547088623046875 sec\n",
      "ONNX postprocessing took 0.0009114742279052734 sec\n",
      "ONNX inference took 0.01202702522277832 sec\n",
      "ONNX postprocessing took 0.0009868144989013672 sec\n",
      "ONNX inference took 0.013546943664550781 sec\n",
      "ONNX postprocessing took 0.0013818740844726562 sec\n",
      "ONNX inference took 0.013634681701660156 sec\n",
      "ONNX postprocessing took 0.005280971527099609 sec\n",
      "ONNX inference took 0.01143646240234375 sec\n",
      "ONNX postprocessing took 0.001317739486694336 sec\n",
      "ONNX inference took 0.012418270111083984 sec\n",
      "ONNX postprocessing took 0.0024421215057373047 sec\n",
      "ONNX inference took 0.012298345565795898 sec\n",
      "ONNX postprocessing took 0.0014619827270507812 sec\n",
      "ONNX inference took 0.011446714401245117 sec\n",
      "ONNX postprocessing took 0.0018842220306396484 sec\n",
      "ONNX inference took 0.012339591979980469 sec\n",
      "ONNX postprocessing took 0.0016379356384277344 sec\n",
      "ONNX inference took 0.011563777923583984 sec\n",
      "ONNX postprocessing took 0.002401590347290039 sec\n",
      "ONNX inference took 0.011810541152954102 sec\n",
      "ONNX postprocessing took 0.0008568763732910156 sec\n",
      "ONNX inference took 0.011404991149902344 sec\n",
      "ONNX postprocessing took 0.0017306804656982422 sec\n",
      "ONNX inference took 0.012018918991088867 sec\n",
      "ONNX postprocessing took 0.0010747909545898438 sec\n",
      "ONNX inference took 0.012002706527709961 sec\n",
      "ONNX postprocessing took 0.0009052753448486328 sec\n",
      "ONNX inference took 0.013223648071289062 sec\n",
      "ONNX postprocessing took 0.002747774124145508 sec\n",
      "ONNX inference took 0.011939048767089844 sec\n",
      "ONNX postprocessing took 0.0020935535430908203 sec\n",
      "ONNX inference took 0.012050390243530273 sec\n",
      "ONNX postprocessing took 0.0006322860717773438 sec\n",
      "ONNX inference took 0.011157512664794922 sec\n",
      "ONNX postprocessing took 0.001026153564453125 sec\n",
      "ONNX inference took 0.0122833251953125 sec\n",
      "ONNX postprocessing took 0.0015954971313476562 sec\n",
      "ONNX inference took 0.012867927551269531 sec\n",
      "ONNX postprocessing took 0.0007476806640625 sec\n",
      "ONNX inference took 0.012644290924072266 sec\n",
      "ONNX postprocessing took 0.0005812644958496094 sec\n",
      "ONNX inference took 0.011168479919433594 sec\n",
      "ONNX postprocessing took 0.0006480216979980469 sec\n",
      "ONNX inference took 0.011533021926879883 sec\n",
      "ONNX postprocessing took 0.0007243156433105469 sec\n",
      "ONNX inference took 0.012154102325439453 sec\n",
      "ONNX postprocessing took 0.0008409023284912109 sec\n",
      "ONNX inference took 0.012261152267456055 sec\n",
      "ONNX postprocessing took 0.0031986236572265625 sec\n",
      "ONNX inference took 0.012141942977905273 sec\n",
      "ONNX postprocessing took 0.0005872249603271484 sec\n",
      "ONNX inference took 0.01143026351928711 sec\n",
      "ONNX postprocessing took 0.0030426979064941406 sec\n",
      "ONNX inference took 0.014273881912231445 sec\n",
      "ONNX postprocessing took 0.006325721740722656 sec\n",
      "ONNX inference took 0.012180089950561523 sec\n",
      "ONNX postprocessing took 0.005280017852783203 sec\n",
      "ONNX inference took 0.011734247207641602 sec\n",
      "ONNX postprocessing took 0.001169443130493164 sec\n",
      "ONNX inference took 0.012746334075927734 sec\n",
      "ONNX postprocessing took 0.001725912094116211 sec\n",
      "ONNX inference took 0.012867450714111328 sec\n",
      "ONNX postprocessing took 0.002743959426879883 sec\n",
      "ONNX inference took 0.01317906379699707 sec\n",
      "ONNX postprocessing took 0.0013802051544189453 sec\n",
      "ONNX inference took 0.011564016342163086 sec\n",
      "ONNX postprocessing took 0.0036382675170898438 sec\n",
      "ONNX inference took 0.012935638427734375 sec\n",
      "ONNX postprocessing took 0.002035856246948242 sec\n",
      "ONNX inference took 0.011300325393676758 sec\n",
      "ONNX postprocessing took 0.0018987655639648438 sec\n",
      "ONNX inference took 0.012302875518798828 sec\n",
      "ONNX postprocessing took 0.0030875205993652344 sec\n",
      "ONNX inference took 0.011689186096191406 sec\n",
      "ONNX postprocessing took 0.0014061927795410156 sec\n",
      "ONNX inference took 0.012087345123291016 sec\n",
      "ONNX postprocessing took 0.0017139911651611328 sec\n",
      "ONNX inference took 0.012466907501220703 sec\n",
      "ONNX postprocessing took 0.003937482833862305 sec\n",
      "ONNX inference took 0.011932134628295898 sec\n",
      "ONNX postprocessing took 0.0007548332214355469 sec\n",
      "ONNX inference took 0.013094663619995117 sec\n",
      "ONNX postprocessing took 0.0011148452758789062 sec\n",
      "ONNX inference took 0.011480569839477539 sec\n",
      "ONNX postprocessing took 0.0008418560028076172 sec\n",
      "ONNX inference took 0.011101245880126953 sec\n",
      "ONNX postprocessing took 0.003315448760986328 sec\n",
      "ONNX inference took 0.011688709259033203 sec\n",
      "ONNX postprocessing took 0.0023040771484375 sec\n",
      "ONNX inference took 0.013518333435058594 sec\n",
      "ONNX postprocessing took 0.01576519012451172 sec\n",
      "ONNX inference took 0.011437416076660156 sec\n",
      "ONNX postprocessing took 0.0011823177337646484 sec\n",
      "ONNX inference took 0.011947870254516602 sec\n",
      "ONNX postprocessing took 0.0010075569152832031 sec\n",
      "ONNX inference took 0.01257777214050293 sec\n",
      "ONNX postprocessing took 0.0033369064331054688 sec\n",
      "ONNX inference took 0.011793136596679688 sec\n",
      "ONNX postprocessing took 0.0016863346099853516 sec\n",
      "ONNX inference took 0.01204991340637207 sec\n",
      "ONNX postprocessing took 0.0010814666748046875 sec\n",
      "ONNX inference took 0.011953353881835938 sec\n",
      "ONNX postprocessing took 0.0024538040161132812 sec\n",
      "ONNX inference took 0.011723041534423828 sec\n",
      "ONNX postprocessing took 0.0009014606475830078 sec\n",
      "ONNX inference took 0.012166976928710938 sec\n",
      "ONNX postprocessing took 0.0009658336639404297 sec\n",
      "ONNX inference took 0.01156473159790039 sec\n",
      "ONNX postprocessing took 0.0009975433349609375 sec\n",
      "ONNX inference took 0.011913061141967773 sec\n",
      "ONNX postprocessing took 0.0018870830535888672 sec\n",
      "ONNX inference took 0.014622688293457031 sec\n",
      "ONNX postprocessing took 0.0029120445251464844 sec\n",
      "ONNX inference took 0.012657403945922852 sec\n",
      "ONNX postprocessing took 0.00485992431640625 sec\n",
      "ONNX inference took 0.012327432632446289 sec\n",
      "ONNX postprocessing took 0.0013453960418701172 sec\n",
      "ONNX inference took 0.012384653091430664 sec\n",
      "ONNX postprocessing took 0.0008234977722167969 sec\n",
      "ONNX inference took 0.01332998275756836 sec\n",
      "ONNX postprocessing took 0.0009064674377441406 sec\n",
      "ONNX inference took 0.01319432258605957 sec\n",
      "ONNX postprocessing took 0.004097461700439453 sec\n",
      "ONNX inference took 0.011538028717041016 sec\n",
      "ONNX postprocessing took 0.0014841556549072266 sec\n",
      "ONNX inference took 0.01327967643737793 sec\n",
      "ONNX postprocessing took 0.0019378662109375 sec\n",
      "ONNX inference took 0.012979269027709961 sec\n",
      "ONNX postprocessing took 0.0015478134155273438 sec\n",
      "ONNX inference took 0.011937379837036133 sec\n",
      "ONNX postprocessing took 0.0006296634674072266 sec\n",
      "ONNX inference took 0.011408329010009766 sec\n",
      "ONNX postprocessing took 0.0008380413055419922 sec\n",
      "ONNX inference took 0.011707782745361328 sec\n",
      "ONNX postprocessing took 0.002572298049926758 sec\n",
      "ONNX inference took 0.011506080627441406 sec\n",
      "ONNX postprocessing took 0.0006506443023681641 sec\n",
      "ONNX inference took 0.011495113372802734 sec\n",
      "ONNX postprocessing took 0.0012221336364746094 sec\n",
      "ONNX inference took 0.012142658233642578 sec\n",
      "ONNX postprocessing took 0.0011761188507080078 sec\n",
      "ONNX inference took 0.012514591217041016 sec\n",
      "ONNX postprocessing took 0.0009267330169677734 sec\n",
      "ONNX inference took 0.012546062469482422 sec\n",
      "ONNX postprocessing took 0.0013434886932373047 sec\n",
      "ONNX inference took 0.012062788009643555 sec\n",
      "ONNX postprocessing took 0.0008120536804199219 sec\n",
      "ONNX inference took 0.011933326721191406 sec\n",
      "ONNX postprocessing took 0.0008044242858886719 sec\n",
      "ONNX inference took 0.011827945709228516 sec\n",
      "ONNX postprocessing took 0.004581928253173828 sec\n",
      "ONNX inference took 0.013083219528198242 sec\n",
      "ONNX postprocessing took 0.0033082962036132812 sec\n",
      "ONNX inference took 0.014694452285766602 sec\n",
      "ONNX postprocessing took 0.003995180130004883 sec\n",
      "ONNX inference took 0.011233091354370117 sec\n",
      "ONNX postprocessing took 0.002379894256591797 sec\n",
      "ONNX inference took 0.012111425399780273 sec\n",
      "ONNX postprocessing took 0.0023953914642333984 sec\n",
      "ONNX inference took 0.01180577278137207 sec\n",
      "ONNX postprocessing took 0.001990795135498047 sec\n",
      "ONNX inference took 0.012017250061035156 sec\n",
      "ONNX postprocessing took 0.0008246898651123047 sec\n",
      "ONNX inference took 0.012486696243286133 sec\n",
      "ONNX postprocessing took 0.003565549850463867 sec\n",
      "ONNX inference took 0.011929750442504883 sec\n",
      "ONNX postprocessing took 0.0009219646453857422 sec\n",
      "ONNX inference took 0.013241291046142578 sec\n",
      "ONNX postprocessing took 0.0036935806274414062 sec\n",
      "ONNX inference took 0.011661767959594727 sec\n",
      "ONNX postprocessing took 0.0006923675537109375 sec\n",
      "ONNX inference took 0.011461973190307617 sec\n",
      "ONNX postprocessing took 0.0010454654693603516 sec\n",
      "ONNX inference took 0.013509035110473633 sec\n",
      "ONNX postprocessing took 0.0007841587066650391 sec\n",
      "ONNX inference took 0.012556076049804688 sec\n",
      "ONNX postprocessing took 0.0025491714477539062 sec\n",
      "ONNX inference took 0.012361764907836914 sec\n",
      "ONNX postprocessing took 0.0012292861938476562 sec\n",
      "ONNX inference took 0.011331319808959961 sec\n",
      "ONNX postprocessing took 0.0007908344268798828 sec\n",
      "ONNX inference took 0.011605262756347656 sec\n",
      "ONNX postprocessing took 0.004877805709838867 sec\n",
      "ONNX inference took 0.011347532272338867 sec\n",
      "ONNX postprocessing took 0.0006866455078125 sec\n",
      "ONNX inference took 0.012565135955810547 sec\n",
      "ONNX postprocessing took 0.0031523704528808594 sec\n",
      "ONNX inference took 0.013957500457763672 sec\n",
      "ONNX postprocessing took 0.004230499267578125 sec\n",
      "ONNX inference took 0.011716365814208984 sec\n",
      "ONNX postprocessing took 0.0007178783416748047 sec\n",
      "ONNX inference took 0.013158798217773438 sec\n",
      "ONNX postprocessing took 0.0010874271392822266 sec\n",
      "ONNX inference took 0.012705802917480469 sec\n",
      "ONNX postprocessing took 0.001127481460571289 sec\n",
      "ONNX inference took 0.012273550033569336 sec\n",
      "ONNX postprocessing took 0.0011954307556152344 sec\n",
      "ONNX inference took 0.013437271118164062 sec\n",
      "ONNX postprocessing took 0.003763437271118164 sec\n",
      "ONNX inference took 0.012116432189941406 sec\n",
      "ONNX postprocessing took 0.0037546157836914062 sec\n",
      "ONNX inference took 0.012525320053100586 sec\n",
      "ONNX postprocessing took 0.0018815994262695312 sec\n",
      "ONNX inference took 0.012734174728393555 sec\n",
      "ONNX postprocessing took 0.0006203651428222656 sec\n",
      "ONNX inference took 0.012195825576782227 sec\n",
      "ONNX postprocessing took 0.0028629302978515625 sec\n",
      "ONNX inference took 0.012263774871826172 sec\n",
      "ONNX postprocessing took 0.0011119842529296875 sec\n",
      "ONNX inference took 0.0122833251953125 sec\n",
      "ONNX postprocessing took 0.0014400482177734375 sec\n",
      "ONNX inference took 0.013565540313720703 sec\n",
      "ONNX postprocessing took 0.0043926239013671875 sec\n",
      "ONNX inference took 0.014098644256591797 sec\n",
      "ONNX postprocessing took 0.007755279541015625 sec\n",
      "ONNX inference took 0.01089787483215332 sec\n",
      "ONNX postprocessing took 0.0005681514739990234 sec\n",
      "ONNX inference took 0.012076854705810547 sec\n",
      "ONNX postprocessing took 0.0006017684936523438 sec\n",
      "ONNX inference took 0.013479471206665039 sec\n",
      "ONNX postprocessing took 0.004814863204956055 sec\n",
      "ONNX inference took 0.014140844345092773 sec\n",
      "ONNX postprocessing took 0.0038063526153564453 sec\n",
      "ONNX inference took 0.011820554733276367 sec\n",
      "ONNX postprocessing took 0.0009391307830810547 sec\n",
      "ONNX inference took 0.014012813568115234 sec\n",
      "ONNX postprocessing took 0.010514020919799805 sec\n",
      "ONNX inference took 0.011226892471313477 sec\n",
      "ONNX postprocessing took 0.0015840530395507812 sec\n",
      "ONNX inference took 0.011954545974731445 sec\n",
      "ONNX postprocessing took 0.0016505718231201172 sec\n",
      "ONNX inference took 0.01143336296081543 sec\n",
      "ONNX postprocessing took 0.0016133785247802734 sec\n",
      "ONNX inference took 0.012434720993041992 sec\n",
      "ONNX postprocessing took 0.0049152374267578125 sec\n",
      "ONNX inference took 0.011771678924560547 sec\n",
      "ONNX postprocessing took 0.003229856491088867 sec\n",
      "ONNX inference took 0.011152267456054688 sec\n",
      "ONNX postprocessing took 0.0025196075439453125 sec\n",
      "ONNX inference took 0.013871192932128906 sec\n",
      "ONNX postprocessing took 0.0043942928314208984 sec\n",
      "ONNX inference took 0.011749267578125 sec\n",
      "ONNX postprocessing took 0.0018131732940673828 sec\n",
      "ONNX inference took 0.011977195739746094 sec\n",
      "ONNX postprocessing took 0.0006878376007080078 sec\n",
      "ONNX inference took 0.013448238372802734 sec\n",
      "ONNX postprocessing took 0.00089263916015625 sec\n",
      "ONNX inference took 0.011942863464355469 sec\n",
      "ONNX postprocessing took 0.0030858516693115234 sec\n",
      "ONNX inference took 0.013040304183959961 sec\n",
      "ONNX postprocessing took 0.001176595687866211 sec\n",
      "ONNX inference took 0.011633157730102539 sec\n",
      "ONNX postprocessing took 0.0031821727752685547 sec\n",
      "ONNX inference took 0.015061616897583008 sec\n",
      "ONNX postprocessing took 0.0028772354125976562 sec\n",
      "ONNX inference took 0.01183319091796875 sec\n",
      "ONNX postprocessing took 0.0034716129302978516 sec\n",
      "ONNX inference took 0.012118339538574219 sec\n",
      "ONNX postprocessing took 0.0028595924377441406 sec\n",
      "ONNX inference took 0.013973474502563477 sec\n",
      "ONNX postprocessing took 0.007372140884399414 sec\n",
      "ONNX inference took 0.011795759201049805 sec\n",
      "ONNX postprocessing took 0.0008940696716308594 sec\n",
      "ONNX inference took 0.012978792190551758 sec\n",
      "ONNX postprocessing took 0.002843618392944336 sec\n",
      "ONNX inference took 0.015685081481933594 sec\n",
      "ONNX postprocessing took 0.0026090145111083984 sec\n",
      "ONNX inference took 0.012750387191772461 sec\n",
      "ONNX postprocessing took 0.0035178661346435547 sec\n",
      "ONNX inference took 0.012068033218383789 sec\n",
      "ONNX postprocessing took 0.0027418136596679688 sec\n",
      "ONNX inference took 0.012972831726074219 sec\n",
      "ONNX postprocessing took 0.0035364627838134766 sec\n",
      "ONNX inference took 0.012128829956054688 sec\n",
      "ONNX postprocessing took 0.0013613700866699219 sec\n",
      "ONNX inference took 0.01177072525024414 sec\n",
      "ONNX postprocessing took 0.0032129287719726562 sec\n",
      "ONNX inference took 0.01174163818359375 sec\n",
      "ONNX postprocessing took 0.000926971435546875 sec\n",
      "ONNX inference took 0.012737751007080078 sec\n",
      "ONNX postprocessing took 0.0028760433197021484 sec\n",
      "ONNX inference took 0.011935949325561523 sec\n",
      "ONNX postprocessing took 0.0010828971862792969 sec\n",
      "ONNX inference took 0.013868570327758789 sec\n",
      "ONNX postprocessing took 0.0021953582763671875 sec\n",
      "ONNX inference took 0.011757612228393555 sec\n",
      "ONNX postprocessing took 0.003247499465942383 sec\n",
      "ONNX inference took 0.011591672897338867 sec\n",
      "ONNX postprocessing took 0.0037283897399902344 sec\n",
      "ONNX inference took 0.012007713317871094 sec\n",
      "ONNX postprocessing took 0.001462697982788086 sec\n",
      "ONNX inference took 0.01324605941772461 sec\n",
      "ONNX postprocessing took 0.003859281539916992 sec\n",
      "ONNX inference took 0.012230634689331055 sec\n",
      "ONNX postprocessing took 0.0025043487548828125 sec\n",
      "ONNX inference took 0.013255119323730469 sec\n",
      "ONNX postprocessing took 0.0009765625 sec\n",
      "ONNX inference took 0.013079643249511719 sec\n",
      "ONNX postprocessing took 0.0006868839263916016 sec\n",
      "ONNX inference took 0.011201620101928711 sec\n",
      "ONNX postprocessing took 0.0031287670135498047 sec\n",
      "ONNX inference took 0.012464284896850586 sec\n",
      "ONNX postprocessing took 0.0028045177459716797 sec\n",
      "ONNX inference took 0.011813879013061523 sec\n",
      "ONNX postprocessing took 0.0017201900482177734 sec\n",
      "ONNX inference took 0.012074470520019531 sec\n",
      "ONNX postprocessing took 0.0016443729400634766 sec\n",
      "ONNX inference took 0.011124134063720703 sec\n",
      "ONNX postprocessing took 0.002497434616088867 sec\n",
      "ONNX inference took 0.011716604232788086 sec\n",
      "ONNX postprocessing took 0.003141641616821289 sec\n",
      "ONNX inference took 0.012169837951660156 sec\n",
      "ONNX postprocessing took 0.0014185905456542969 sec\n",
      "ONNX inference took 0.012626409530639648 sec\n",
      "ONNX postprocessing took 0.002309560775756836 sec\n",
      "ONNX inference took 0.012541532516479492 sec\n",
      "ONNX postprocessing took 0.004075288772583008 sec\n",
      "ONNX inference took 0.011780500411987305 sec\n",
      "ONNX postprocessing took 0.0008039474487304688 sec\n",
      "ONNX inference took 0.012434720993041992 sec\n",
      "ONNX postprocessing took 0.0015912055969238281 sec\n",
      "ONNX inference took 0.016871213912963867 sec\n",
      "ONNX postprocessing took 0.0055773258209228516 sec\n",
      "ONNX inference took 0.01266932487487793 sec\n",
      "ONNX postprocessing took 0.001819610595703125 sec\n",
      "ONNX inference took 0.012315511703491211 sec\n",
      "ONNX postprocessing took 0.0021660327911376953 sec\n",
      "ONNX inference took 0.012149810791015625 sec\n",
      "ONNX postprocessing took 0.001100778579711914 sec\n",
      "ONNX inference took 0.011640787124633789 sec\n",
      "ONNX postprocessing took 0.0008378028869628906 sec\n",
      "ONNX inference took 0.011440277099609375 sec\n",
      "ONNX postprocessing took 0.0008370876312255859 sec\n",
      "ONNX inference took 0.011414766311645508 sec\n",
      "ONNX postprocessing took 0.0033016204833984375 sec\n",
      "ONNX inference took 0.012260675430297852 sec\n",
      "ONNX postprocessing took 0.001529693603515625 sec\n",
      "ONNX inference took 0.014535665512084961 sec\n",
      "ONNX postprocessing took 0.006092071533203125 sec\n",
      "ONNX inference took 0.011888504028320312 sec\n",
      "ONNX postprocessing took 0.0006234645843505859 sec\n",
      "ONNX inference took 0.01183009147644043 sec\n",
      "ONNX postprocessing took 0.0006728172302246094 sec\n",
      "ONNX inference took 0.011429548263549805 sec\n",
      "ONNX postprocessing took 0.0015711784362792969 sec\n",
      "ONNX inference took 0.012672185897827148 sec\n",
      "ONNX postprocessing took 0.0022478103637695312 sec\n",
      "ONNX inference took 0.011679887771606445 sec\n",
      "ONNX postprocessing took 0.00465703010559082 sec\n",
      "ONNX inference took 0.01263570785522461 sec\n",
      "ONNX postprocessing took 0.001028299331665039 sec\n",
      "ONNX inference took 0.012819290161132812 sec\n",
      "ONNX postprocessing took 0.0014662742614746094 sec\n",
      "ONNX inference took 0.011049270629882812 sec\n",
      "ONNX postprocessing took 0.0016393661499023438 sec\n",
      "ONNX inference took 0.013799428939819336 sec\n",
      "ONNX postprocessing took 0.002214670181274414 sec\n",
      "ONNX inference took 0.011097192764282227 sec\n",
      "ONNX postprocessing took 0.0011594295501708984 sec\n",
      "ONNX inference took 0.012992382049560547 sec\n",
      "ONNX postprocessing took 0.004355430603027344 sec\n",
      "ONNX inference took 0.011216163635253906 sec\n",
      "ONNX postprocessing took 0.0029401779174804688 sec\n",
      "ONNX inference took 0.01249384880065918 sec\n",
      "ONNX postprocessing took 0.0025184154510498047 sec\n",
      "ONNX inference took 0.012092113494873047 sec\n",
      "ONNX postprocessing took 0.0006399154663085938 sec\n",
      "ONNX inference took 0.011657238006591797 sec\n",
      "ONNX postprocessing took 0.0014302730560302734 sec\n",
      "ONNX inference took 0.011033296585083008 sec\n",
      "ONNX postprocessing took 0.0005490779876708984 sec\n",
      "ONNX inference took 0.011404991149902344 sec\n",
      "ONNX postprocessing took 0.0007493495941162109 sec\n",
      "ONNX inference took 0.011338472366333008 sec\n",
      "ONNX postprocessing took 0.0005743503570556641 sec\n",
      "ONNX inference took 0.011029720306396484 sec\n",
      "ONNX postprocessing took 0.0009090900421142578 sec\n",
      "ONNX inference took 0.011814594268798828 sec\n",
      "ONNX postprocessing took 0.002560853958129883 sec\n",
      "ONNX inference took 0.012937307357788086 sec\n",
      "ONNX postprocessing took 0.002192258834838867 sec\n",
      "ONNX inference took 0.013072967529296875 sec\n",
      "ONNX postprocessing took 0.0012063980102539062 sec\n",
      "ONNX inference took 0.013114690780639648 sec\n",
      "ONNX postprocessing took 0.003893613815307617 sec\n",
      "ONNX inference took 0.012533187866210938 sec\n",
      "ONNX postprocessing took 0.0014142990112304688 sec\n",
      "ONNX inference took 0.01385498046875 sec\n",
      "ONNX postprocessing took 0.003968238830566406 sec\n",
      "ONNX inference took 0.012994527816772461 sec\n",
      "ONNX postprocessing took 0.0006077289581298828 sec\n",
      "ONNX inference took 0.012079954147338867 sec\n",
      "ONNX postprocessing took 0.0022902488708496094 sec\n",
      "ONNX inference took 0.01199960708618164 sec\n",
      "ONNX postprocessing took 0.00115203857421875 sec\n",
      "ONNX inference took 0.011979818344116211 sec\n",
      "ONNX postprocessing took 0.0005974769592285156 sec\n",
      "ONNX inference took 0.011930465698242188 sec\n",
      "ONNX postprocessing took 0.0005993843078613281 sec\n",
      "ONNX inference took 0.014563322067260742 sec\n",
      "ONNX postprocessing took 0.008594751358032227 sec\n",
      "ONNX inference took 0.011344432830810547 sec\n",
      "ONNX postprocessing took 0.001560211181640625 sec\n",
      "ONNX inference took 0.013511180877685547 sec\n",
      "ONNX postprocessing took 0.003690481185913086 sec\n",
      "ONNX inference took 0.011202812194824219 sec\n",
      "ONNX postprocessing took 0.0006113052368164062 sec\n",
      "ONNX inference took 0.012779474258422852 sec\n",
      "ONNX postprocessing took 0.0008759498596191406 sec\n",
      "ONNX inference took 0.012750625610351562 sec\n",
      "ONNX postprocessing took 0.010848283767700195 sec\n",
      "ONNX inference took 0.01156306266784668 sec\n",
      "ONNX postprocessing took 0.0020351409912109375 sec\n",
      "ONNX inference took 0.012137889862060547 sec\n",
      "ONNX postprocessing took 0.0033540725708007812 sec\n",
      "ONNX inference took 0.011528730392456055 sec\n",
      "ONNX postprocessing took 0.0039768218994140625 sec\n",
      "ONNX inference took 0.01199483871459961 sec\n",
      "ONNX postprocessing took 0.002935647964477539 sec\n",
      "ONNX inference took 0.012128114700317383 sec\n",
      "ONNX postprocessing took 0.0039327144622802734 sec\n",
      "ONNX inference took 0.011655092239379883 sec\n",
      "ONNX postprocessing took 0.004997730255126953 sec\n",
      "ONNX inference took 0.011935949325561523 sec\n",
      "ONNX postprocessing took 0.0016222000122070312 sec\n",
      "ONNX inference took 0.011826753616333008 sec\n",
      "ONNX postprocessing took 0.002917766571044922 sec\n",
      "ONNX inference took 0.012165307998657227 sec\n",
      "ONNX postprocessing took 0.0012409687042236328 sec\n",
      "ONNX inference took 0.011710643768310547 sec\n",
      "ONNX postprocessing took 0.0011322498321533203 sec\n",
      "ONNX inference took 0.012119531631469727 sec\n",
      "ONNX postprocessing took 0.0019309520721435547 sec\n",
      "ONNX inference took 0.011490821838378906 sec\n",
      "ONNX postprocessing took 0.0006144046783447266 sec\n",
      "ONNX inference took 0.013864755630493164 sec\n",
      "ONNX postprocessing took 0.0026738643646240234 sec\n",
      "ONNX inference took 0.013556241989135742 sec\n",
      "ONNX postprocessing took 0.0034329891204833984 sec\n",
      "ONNX inference took 0.011072874069213867 sec\n",
      "ONNX postprocessing took 0.0010073184967041016 sec\n",
      "ONNX inference took 0.011590242385864258 sec\n",
      "ONNX postprocessing took 0.001985311508178711 sec\n",
      "ONNX inference took 0.011337518692016602 sec\n",
      "ONNX postprocessing took 0.0025262832641601562 sec\n",
      "ONNX inference took 0.012122392654418945 sec\n",
      "ONNX postprocessing took 0.0029103755950927734 sec\n",
      "ONNX inference took 0.0133209228515625 sec\n",
      "ONNX postprocessing took 0.004410266876220703 sec\n",
      "ONNX inference took 0.011595726013183594 sec\n",
      "ONNX postprocessing took 0.0042002201080322266 sec\n",
      "ONNX inference took 0.011349678039550781 sec\n",
      "ONNX postprocessing took 0.0011713504791259766 sec\n",
      "ONNX inference took 0.012582063674926758 sec\n",
      "ONNX postprocessing took 0.0025272369384765625 sec\n",
      "ONNX inference took 0.011718034744262695 sec\n",
      "ONNX postprocessing took 0.005987882614135742 sec\n",
      "ONNX inference took 0.012313127517700195 sec\n",
      "ONNX postprocessing took 0.0024576187133789062 sec\n",
      "ONNX inference took 0.012304544448852539 sec\n",
      "ONNX postprocessing took 0.0022399425506591797 sec\n",
      "ONNX inference took 0.012327909469604492 sec\n",
      "ONNX postprocessing took 0.004931449890136719 sec\n",
      "ONNX inference took 0.011911392211914062 sec\n",
      "ONNX postprocessing took 0.0012123584747314453 sec\n",
      "ONNX inference took 0.012178897857666016 sec\n",
      "ONNX postprocessing took 0.0005719661712646484 sec\n",
      "ONNX inference took 0.012942075729370117 sec\n",
      "ONNX postprocessing took 0.0027506351470947266 sec\n",
      "ONNX inference took 0.012557029724121094 sec\n",
      "ONNX postprocessing took 0.0007474422454833984 sec\n",
      "ONNX inference took 0.013607978820800781 sec\n",
      "ONNX postprocessing took 0.004323720932006836 sec\n",
      "ONNX inference took 0.012376070022583008 sec\n",
      "ONNX postprocessing took 0.003668069839477539 sec\n",
      "ONNX inference took 0.012537240982055664 sec\n",
      "ONNX postprocessing took 0.0008952617645263672 sec\n",
      "ONNX inference took 0.01193380355834961 sec\n",
      "ONNX postprocessing took 0.0011067390441894531 sec\n",
      "ONNX inference took 0.011600017547607422 sec\n",
      "ONNX postprocessing took 0.002172231674194336 sec\n",
      "ONNX inference took 0.011888980865478516 sec\n",
      "ONNX postprocessing took 0.004876852035522461 sec\n",
      "ONNX inference took 0.012290239334106445 sec\n",
      "ONNX postprocessing took 0.0057525634765625 sec\n",
      "ONNX inference took 0.011309385299682617 sec\n",
      "ONNX postprocessing took 0.0005877017974853516 sec\n",
      "ONNX inference took 0.011692285537719727 sec\n",
      "ONNX postprocessing took 0.0032701492309570312 sec\n",
      "ONNX inference took 0.011837482452392578 sec\n",
      "ONNX postprocessing took 0.004514932632446289 sec\n",
      "ONNX inference took 0.011152505874633789 sec\n",
      "ONNX postprocessing took 0.002213716506958008 sec\n",
      "ONNX inference took 0.012258052825927734 sec\n",
      "ONNX postprocessing took 0.0036058425903320312 sec\n",
      "ONNX inference took 0.011622905731201172 sec\n",
      "ONNX postprocessing took 0.0006074905395507812 sec\n",
      "ONNX inference took 0.012879371643066406 sec\n",
      "ONNX postprocessing took 0.0008950233459472656 sec\n",
      "ONNX inference took 0.011336088180541992 sec\n",
      "ONNX postprocessing took 0.0017862319946289062 sec\n",
      "ONNX inference took 0.011743783950805664 sec\n",
      "ONNX postprocessing took 0.0008156299591064453 sec\n",
      "ONNX inference took 0.01168060302734375 sec\n",
      "ONNX postprocessing took 0.0008640289306640625 sec\n",
      "ONNX inference took 0.011717557907104492 sec\n",
      "ONNX postprocessing took 0.004274845123291016 sec\n",
      "ONNX inference took 0.011967658996582031 sec\n",
      "ONNX postprocessing took 0.0030434131622314453 sec\n",
      "ONNX inference took 0.01129603385925293 sec\n",
      "ONNX postprocessing took 0.0021102428436279297 sec\n",
      "ONNX inference took 0.011579275131225586 sec\n",
      "ONNX postprocessing took 0.0009069442749023438 sec\n",
      "ONNX inference took 0.011558771133422852 sec\n",
      "ONNX postprocessing took 0.004567861557006836 sec\n",
      "ONNX inference took 0.011238813400268555 sec\n",
      "ONNX postprocessing took 0.0006012916564941406 sec\n",
      "ONNX inference took 0.011588573455810547 sec\n",
      "ONNX postprocessing took 0.0008907318115234375 sec\n",
      "ONNX inference took 0.011451244354248047 sec\n",
      "ONNX postprocessing took 0.0006608963012695312 sec\n",
      "ONNX inference took 0.011540412902832031 sec\n",
      "ONNX postprocessing took 0.0016863346099853516 sec\n",
      "ONNX inference took 0.011847734451293945 sec\n",
      "ONNX postprocessing took 0.0012354850769042969 sec\n",
      "ONNX inference took 0.012621641159057617 sec\n",
      "ONNX postprocessing took 0.0024497509002685547 sec\n",
      "ONNX inference took 0.012164592742919922 sec\n",
      "ONNX postprocessing took 0.004000663757324219 sec\n",
      "ONNX inference took 0.011467218399047852 sec\n",
      "ONNX postprocessing took 0.0005524158477783203 sec\n",
      "ONNX inference took 0.011331796646118164 sec\n",
      "ONNX postprocessing took 0.0005846023559570312 sec\n",
      "ONNX inference took 0.011786460876464844 sec\n",
      "ONNX postprocessing took 0.0025408267974853516 sec\n",
      "ONNX inference took 0.014088153839111328 sec\n",
      "ONNX postprocessing took 0.003562450408935547 sec\n",
      "ONNX inference took 0.010982751846313477 sec\n",
      "ONNX postprocessing took 0.0007925033569335938 sec\n",
      "ONNX inference took 0.012398481369018555 sec\n",
      "ONNX postprocessing took 0.0019042491912841797 sec\n",
      "ONNX inference took 0.012608051300048828 sec\n",
      "ONNX postprocessing took 0.0023772716522216797 sec\n",
      "ONNX inference took 0.012882471084594727 sec\n",
      "ONNX postprocessing took 0.0008563995361328125 sec\n",
      "ONNX inference took 0.012595176696777344 sec\n",
      "ONNX postprocessing took 0.0038220882415771484 sec\n",
      "ONNX inference took 0.011954069137573242 sec\n",
      "ONNX postprocessing took 0.004978179931640625 sec\n",
      "ONNX inference took 0.012750864028930664 sec\n",
      "ONNX postprocessing took 0.0018532276153564453 sec\n",
      "ONNX inference took 0.011858701705932617 sec\n",
      "ONNX postprocessing took 0.0011327266693115234 sec\n",
      "ONNX inference took 0.011716604232788086 sec\n",
      "ONNX postprocessing took 0.0008444786071777344 sec\n",
      "ONNX inference took 0.01169133186340332 sec\n",
      "ONNX postprocessing took 0.0008184909820556641 sec\n",
      "ONNX inference took 0.012158393859863281 sec\n",
      "ONNX postprocessing took 0.002645254135131836 sec\n",
      "ONNX inference took 0.012138605117797852 sec\n",
      "ONNX postprocessing took 0.001163482666015625 sec\n",
      "ONNX inference took 0.012843608856201172 sec\n",
      "ONNX postprocessing took 0.0006158351898193359 sec\n",
      "ONNX inference took 0.011004447937011719 sec\n",
      "ONNX postprocessing took 0.0005936622619628906 sec\n",
      "ONNX inference took 0.011501550674438477 sec\n",
      "ONNX postprocessing took 0.0005896091461181641 sec\n",
      "ONNX inference took 0.011647939682006836 sec\n",
      "ONNX postprocessing took 0.0005593299865722656 sec\n",
      "ONNX inference took 0.01150059700012207 sec\n",
      "ONNX postprocessing took 0.0007164478302001953 sec\n",
      "ONNX inference took 0.01197195053100586 sec\n",
      "ONNX postprocessing took 0.0010790824890136719 sec\n",
      "ONNX inference took 0.011483192443847656 sec\n",
      "ONNX postprocessing took 0.0025484561920166016 sec\n",
      "ONNX inference took 0.012656927108764648 sec\n",
      "ONNX postprocessing took 0.002643108367919922 sec\n",
      "ONNX inference took 0.0117645263671875 sec\n",
      "ONNX postprocessing took 0.0013167858123779297 sec\n",
      "ONNX inference took 0.012085437774658203 sec\n",
      "ONNX postprocessing took 0.0030236244201660156 sec\n",
      "ONNX inference took 0.011223316192626953 sec\n",
      "ONNX postprocessing took 0.0005881786346435547 sec\n",
      "ONNX inference took 0.013443946838378906 sec\n",
      "ONNX postprocessing took 0.0027005672454833984 sec\n",
      "ONNX inference took 0.012006759643554688 sec\n",
      "ONNX postprocessing took 0.0049970149993896484 sec\n",
      "ONNX inference took 0.011532306671142578 sec\n",
      "ONNX postprocessing took 0.0016300678253173828 sec\n",
      "ONNX inference took 0.011202573776245117 sec\n",
      "ONNX postprocessing took 0.000850677490234375 sec\n",
      "ONNX inference took 0.01122903823852539 sec\n",
      "ONNX postprocessing took 0.002624988555908203 sec\n",
      "ONNX inference took 0.013426780700683594 sec\n",
      "ONNX postprocessing took 0.0009918212890625 sec\n",
      "ONNX inference took 0.011645317077636719 sec\n",
      "ONNX postprocessing took 0.0010523796081542969 sec\n",
      "ONNX inference took 0.01184391975402832 sec\n",
      "ONNX postprocessing took 0.0019876956939697266 sec\n",
      "ONNX inference took 0.014008760452270508 sec\n",
      "ONNX postprocessing took 0.004122018814086914 sec\n",
      "ONNX inference took 0.012149572372436523 sec\n",
      "ONNX postprocessing took 0.006617307662963867 sec\n",
      "ONNX inference took 0.01208353042602539 sec\n",
      "ONNX postprocessing took 0.0020356178283691406 sec\n",
      "ONNX inference took 0.012169837951660156 sec\n",
      "ONNX postprocessing took 0.0009148120880126953 sec\n",
      "ONNX inference took 0.01166224479675293 sec\n",
      "ONNX postprocessing took 0.003147602081298828 sec\n",
      "ONNX inference took 0.013236045837402344 sec\n",
      "ONNX postprocessing took 0.004873991012573242 sec\n",
      "ONNX inference took 0.011409521102905273 sec\n",
      "ONNX postprocessing took 0.0005805492401123047 sec\n",
      "ONNX inference took 0.01224064826965332 sec\n",
      "ONNX postprocessing took 0.0020999908447265625 sec\n",
      "ONNX inference took 0.01256704330444336 sec\n",
      "ONNX postprocessing took 0.002524137496948242 sec\n",
      "ONNX inference took 0.013147115707397461 sec\n",
      "ONNX postprocessing took 0.0017039775848388672 sec\n",
      "ONNX inference took 0.013824939727783203 sec\n",
      "ONNX postprocessing took 0.0035219192504882812 sec\n",
      "ONNX inference took 0.01135110855102539 sec\n",
      "ONNX postprocessing took 0.0030052661895751953 sec\n",
      "ONNX inference took 0.012884855270385742 sec\n",
      "ONNX postprocessing took 0.0031206607818603516 sec\n",
      "ONNX inference took 0.012406587600708008 sec\n",
      "ONNX postprocessing took 0.0018362998962402344 sec\n",
      "ONNX inference took 0.011877059936523438 sec\n",
      "ONNX postprocessing took 0.0009086132049560547 sec\n",
      "ONNX inference took 0.012450695037841797 sec\n",
      "ONNX postprocessing took 0.0017347335815429688 sec\n",
      "ONNX inference took 0.013602495193481445 sec\n",
      "ONNX postprocessing took 0.0035293102264404297 sec\n",
      "ONNX inference took 0.012498855590820312 sec\n",
      "ONNX postprocessing took 0.0025377273559570312 sec\n",
      "ONNX inference took 0.012098312377929688 sec\n",
      "ONNX postprocessing took 0.0005774497985839844 sec\n",
      "ONNX inference took 0.012163877487182617 sec\n",
      "ONNX postprocessing took 0.0014259815216064453 sec\n",
      "ONNX inference took 0.011630535125732422 sec\n",
      "ONNX postprocessing took 0.004006385803222656 sec\n",
      "ONNX inference took 0.013114690780639648 sec\n",
      "ONNX postprocessing took 0.0022644996643066406 sec\n",
      "ONNX inference took 0.01296544075012207 sec\n",
      "ONNX postprocessing took 0.004222393035888672 sec\n",
      "ONNX inference took 0.012750387191772461 sec\n",
      "ONNX postprocessing took 0.0026013851165771484 sec\n",
      "ONNX inference took 0.013852834701538086 sec\n",
      "ONNX postprocessing took 0.004288434982299805 sec\n",
      "ONNX inference took 0.011342525482177734 sec\n",
      "ONNX postprocessing took 0.002035379409790039 sec\n",
      "ONNX inference took 0.011837244033813477 sec\n",
      "ONNX postprocessing took 0.0008752346038818359 sec\n",
      "ONNX inference took 0.011593103408813477 sec\n",
      "ONNX postprocessing took 0.0008993148803710938 sec\n",
      "ONNX inference took 0.011811971664428711 sec\n",
      "ONNX postprocessing took 0.0023322105407714844 sec\n",
      "ONNX inference took 0.01169729232788086 sec\n",
      "ONNX postprocessing took 0.0006773471832275391 sec\n",
      "ONNX inference took 0.013277769088745117 sec\n",
      "ONNX postprocessing took 0.003949403762817383 sec\n",
      "ONNX inference took 0.013672113418579102 sec\n",
      "ONNX postprocessing took 0.0006022453308105469 sec\n",
      "ONNX inference took 0.012044191360473633 sec\n",
      "ONNX postprocessing took 0.0007021427154541016 sec\n",
      "ONNX inference took 0.01173257827758789 sec\n",
      "ONNX postprocessing took 0.002763509750366211 sec\n",
      "ONNX inference took 0.012624263763427734 sec\n",
      "ONNX postprocessing took 0.002738475799560547 sec\n",
      "ONNX inference took 0.01187276840209961 sec\n",
      "ONNX postprocessing took 0.0009770393371582031 sec\n",
      "ONNX inference took 0.01165771484375 sec\n",
      "ONNX postprocessing took 0.0008428096771240234 sec\n",
      "ONNX inference took 0.012124300003051758 sec\n",
      "ONNX postprocessing took 0.0006844997406005859 sec\n",
      "ONNX inference took 0.011464834213256836 sec\n",
      "ONNX postprocessing took 0.0009047985076904297 sec\n",
      "ONNX inference took 0.011176109313964844 sec\n",
      "ONNX postprocessing took 0.0016694068908691406 sec\n",
      "ONNX inference took 0.011704683303833008 sec\n",
      "ONNX postprocessing took 0.001413583755493164 sec\n",
      "ONNX inference took 0.011559486389160156 sec\n",
      "ONNX postprocessing took 0.0029096603393554688 sec\n",
      "ONNX inference took 0.011543035507202148 sec\n",
      "ONNX postprocessing took 0.0010385513305664062 sec\n",
      "ONNX inference took 0.012414693832397461 sec\n",
      "ONNX postprocessing took 0.002050161361694336 sec\n",
      "ONNX inference took 0.012938976287841797 sec\n",
      "ONNX postprocessing took 0.004202127456665039 sec\n",
      "ONNX inference took 0.013343334197998047 sec\n",
      "ONNX postprocessing took 0.0012688636779785156 sec\n",
      "ONNX inference took 0.011964559555053711 sec\n",
      "ONNX postprocessing took 0.002832651138305664 sec\n",
      "ONNX inference took 0.012605905532836914 sec\n",
      "ONNX postprocessing took 0.0015683174133300781 sec\n",
      "ONNX inference took 0.012280464172363281 sec\n",
      "ONNX postprocessing took 0.001415252685546875 sec\n",
      "ONNX inference took 0.012172698974609375 sec\n",
      "ONNX postprocessing took 0.004446744918823242 sec\n",
      "ONNX inference took 0.012772798538208008 sec\n",
      "ONNX postprocessing took 0.0016071796417236328 sec\n",
      "ONNX inference took 0.01317906379699707 sec\n",
      "ONNX postprocessing took 0.005276918411254883 sec\n",
      "ONNX inference took 0.011893272399902344 sec\n",
      "ONNX postprocessing took 0.0008187294006347656 sec\n",
      "ONNX inference took 0.011840105056762695 sec\n",
      "ONNX postprocessing took 0.003015279769897461 sec\n",
      "ONNX inference took 0.012672901153564453 sec\n",
      "ONNX postprocessing took 0.004006624221801758 sec\n",
      "ONNX inference took 0.012309551239013672 sec\n",
      "ONNX postprocessing took 0.0011398792266845703 sec\n",
      "ONNX inference took 0.012849092483520508 sec\n",
      "ONNX postprocessing took 0.005539894104003906 sec\n",
      "ONNX inference took 0.011592388153076172 sec\n",
      "ONNX postprocessing took 0.0008704662322998047 sec\n",
      "ONNX inference took 0.011928796768188477 sec\n",
      "ONNX postprocessing took 0.002980947494506836 sec\n",
      "ONNX inference took 0.012493133544921875 sec\n",
      "ONNX postprocessing took 0.0007498264312744141 sec\n",
      "ONNX inference took 0.011643648147583008 sec\n",
      "ONNX postprocessing took 0.0008080005645751953 sec\n",
      "ONNX inference took 0.012500524520874023 sec\n",
      "ONNX postprocessing took 0.0016405582427978516 sec\n",
      "ONNX inference took 0.012404203414916992 sec\n",
      "ONNX postprocessing took 0.0010979175567626953 sec\n",
      "ONNX inference took 0.011494636535644531 sec\n",
      "ONNX postprocessing took 0.0016667842864990234 sec\n",
      "ONNX inference took 0.012295007705688477 sec\n",
      "ONNX postprocessing took 0.002521038055419922 sec\n",
      "ONNX inference took 0.01290130615234375 sec\n",
      "ONNX postprocessing took 0.0027093887329101562 sec\n",
      "ONNX inference took 0.0122528076171875 sec\n",
      "ONNX postprocessing took 0.0010752677917480469 sec\n",
      "ONNX inference took 0.012671232223510742 sec\n",
      "ONNX postprocessing took 0.0023827552795410156 sec\n",
      "ONNX inference took 0.01200103759765625 sec\n",
      "ONNX postprocessing took 0.002159595489501953 sec\n",
      "ONNX inference took 0.011994123458862305 sec\n",
      "ONNX postprocessing took 0.0008263587951660156 sec\n",
      "ONNX inference took 0.011893033981323242 sec\n",
      "ONNX postprocessing took 0.002821683883666992 sec\n",
      "ONNX inference took 0.013168573379516602 sec\n",
      "ONNX postprocessing took 0.003267526626586914 sec\n",
      "ONNX inference took 0.013233184814453125 sec\n",
      "ONNX postprocessing took 0.0021257400512695312 sec\n",
      "ONNX inference took 0.013290882110595703 sec\n",
      "ONNX postprocessing took 0.0024869441986083984 sec\n",
      "ONNX inference took 0.01195669174194336 sec\n",
      "ONNX postprocessing took 0.0016307830810546875 sec\n",
      "ONNX inference took 0.01172494888305664 sec\n",
      "ONNX postprocessing took 0.002117633819580078 sec\n",
      "ONNX inference took 0.011754274368286133 sec\n",
      "ONNX postprocessing took 0.0015518665313720703 sec\n",
      "ONNX inference took 0.015049457550048828 sec\n",
      "ONNX postprocessing took 0.002546548843383789 sec\n",
      "ONNX inference took 0.012518644332885742 sec\n",
      "ONNX postprocessing took 0.004236459732055664 sec\n",
      "ONNX inference took 0.011705636978149414 sec\n",
      "ONNX postprocessing took 0.001562356948852539 sec\n",
      "ONNX inference took 0.012160539627075195 sec\n",
      "ONNX postprocessing took 0.003458738327026367 sec\n",
      "ONNX inference took 0.012778759002685547 sec\n",
      "ONNX postprocessing took 0.004435062408447266 sec\n",
      "ONNX inference took 0.01251363754272461 sec\n",
      "ONNX postprocessing took 0.00589299201965332 sec\n",
      "ONNX inference took 0.011526107788085938 sec\n",
      "ONNX postprocessing took 0.0006520748138427734 sec\n",
      "ONNX inference took 0.011183977127075195 sec\n",
      "ONNX postprocessing took 0.0008275508880615234 sec\n",
      "ONNX inference took 0.011330127716064453 sec\n",
      "ONNX postprocessing took 0.0009968280792236328 sec\n",
      "ONNX inference took 0.012233734130859375 sec\n",
      "ONNX postprocessing took 0.002152681350708008 sec\n",
      "ONNX inference took 0.011919498443603516 sec\n",
      "ONNX postprocessing took 0.003101825714111328 sec\n",
      "ONNX inference took 0.013067960739135742 sec\n",
      "ONNX postprocessing took 0.0027816295623779297 sec\n",
      "ONNX inference took 0.012022972106933594 sec\n",
      "ONNX postprocessing took 0.0029747486114501953 sec\n",
      "ONNX inference took 0.011923074722290039 sec\n",
      "ONNX postprocessing took 0.0014605522155761719 sec\n",
      "ONNX inference took 0.01239466667175293 sec\n",
      "ONNX postprocessing took 0.0012311935424804688 sec\n",
      "ONNX inference took 0.012111425399780273 sec\n",
      "ONNX postprocessing took 0.0052716732025146484 sec\n",
      "ONNX inference took 0.012676477432250977 sec\n",
      "ONNX postprocessing took 0.0009479522705078125 sec\n",
      "ONNX inference took 0.011900186538696289 sec\n",
      "ONNX postprocessing took 0.0006568431854248047 sec\n",
      "ONNX inference took 0.012087345123291016 sec\n",
      "ONNX postprocessing took 0.0005571842193603516 sec\n",
      "ONNX inference took 0.011763811111450195 sec\n",
      "ONNX postprocessing took 0.001018524169921875 sec\n",
      "ONNX inference took 0.012986898422241211 sec\n",
      "ONNX postprocessing took 0.0051403045654296875 sec\n",
      "ONNX inference took 0.012276172637939453 sec\n",
      "ONNX postprocessing took 0.0010967254638671875 sec\n",
      "ONNX inference took 0.012408733367919922 sec\n",
      "ONNX postprocessing took 0.0014996528625488281 sec\n",
      "ONNX inference took 0.012031316757202148 sec\n",
      "ONNX postprocessing took 0.004076719284057617 sec\n",
      "ONNX inference took 0.011568546295166016 sec\n",
      "ONNX postprocessing took 0.0008165836334228516 sec\n",
      "ONNX inference took 0.01287388801574707 sec\n",
      "ONNX postprocessing took 0.0024878978729248047 sec\n",
      "ONNX inference took 0.011675357818603516 sec\n",
      "ONNX postprocessing took 0.0008151531219482422 sec\n",
      "ONNX inference took 0.012498617172241211 sec\n",
      "ONNX postprocessing took 0.0021686553955078125 sec\n",
      "ONNX inference took 0.01190042495727539 sec\n",
      "ONNX postprocessing took 0.00298309326171875 sec\n",
      "ONNX inference took 0.012023687362670898 sec\n",
      "ONNX postprocessing took 0.0006110668182373047 sec\n",
      "ONNX inference took 0.0119781494140625 sec\n",
      "ONNX postprocessing took 0.0010058879852294922 sec\n",
      "ONNX inference took 0.012556076049804688 sec\n",
      "ONNX postprocessing took 0.0038483142852783203 sec\n",
      "ONNX inference took 0.011965513229370117 sec\n",
      "ONNX postprocessing took 0.0012519359588623047 sec\n",
      "ONNX inference took 0.013120174407958984 sec\n",
      "ONNX postprocessing took 0.003976583480834961 sec\n",
      "ONNX inference took 0.012681722640991211 sec\n",
      "ONNX postprocessing took 0.004767894744873047 sec\n",
      "ONNX inference took 0.012356042861938477 sec\n",
      "ONNX postprocessing took 0.0008563995361328125 sec\n",
      "ONNX inference took 0.012261629104614258 sec\n",
      "ONNX postprocessing took 0.004302501678466797 sec\n",
      "ONNX inference took 0.011379003524780273 sec\n",
      "ONNX postprocessing took 0.0020198822021484375 sec\n",
      "ONNX inference took 0.012254953384399414 sec\n",
      "ONNX postprocessing took 0.0010738372802734375 sec\n",
      "ONNX inference took 0.012135505676269531 sec\n",
      "ONNX postprocessing took 0.001039743423461914 sec\n",
      "ONNX inference took 0.011733055114746094 sec\n",
      "ONNX postprocessing took 0.003763914108276367 sec\n",
      "ONNX inference took 0.012715578079223633 sec\n",
      "ONNX postprocessing took 0.002196073532104492 sec\n",
      "ONNX inference took 0.011448383331298828 sec\n",
      "ONNX postprocessing took 0.0006105899810791016 sec\n",
      "ONNX inference took 0.011723995208740234 sec\n",
      "ONNX postprocessing took 0.0019273757934570312 sec\n",
      "ONNX inference took 0.0112457275390625 sec\n",
      "ONNX postprocessing took 0.0006103515625 sec\n",
      "ONNX inference took 0.012402057647705078 sec\n",
      "ONNX postprocessing took 0.003075838088989258 sec\n",
      "ONNX inference took 0.012009620666503906 sec\n",
      "ONNX postprocessing took 0.0022966861724853516 sec\n",
      "ONNX inference took 0.012438535690307617 sec\n",
      "ONNX postprocessing took 0.0033462047576904297 sec\n",
      "ONNX inference took 0.012001514434814453 sec\n",
      "ONNX postprocessing took 0.0018429756164550781 sec\n",
      "ONNX inference took 0.012496471405029297 sec\n",
      "ONNX postprocessing took 0.0006921291351318359 sec\n",
      "ONNX inference took 0.011989831924438477 sec\n",
      "ONNX postprocessing took 0.0008726119995117188 sec\n",
      "ONNX inference took 0.010999202728271484 sec\n",
      "ONNX postprocessing took 0.0008835792541503906 sec\n",
      "ONNX inference took 0.012330770492553711 sec\n",
      "ONNX postprocessing took 0.002315521240234375 sec\n",
      "ONNX inference took 0.011624336242675781 sec\n",
      "ONNX postprocessing took 0.0028684139251708984 sec\n",
      "ONNX inference took 0.011442422866821289 sec\n",
      "ONNX postprocessing took 0.0017230510711669922 sec\n",
      "ONNX inference took 0.011990785598754883 sec\n",
      "ONNX postprocessing took 0.003185749053955078 sec\n",
      "ONNX inference took 0.012224674224853516 sec\n",
      "ONNX postprocessing took 0.0026917457580566406 sec\n",
      "ONNX inference took 0.012537479400634766 sec\n",
      "ONNX postprocessing took 0.004680633544921875 sec\n",
      "ONNX inference took 0.012154340744018555 sec\n",
      "ONNX postprocessing took 0.0013124942779541016 sec\n",
      "ONNX inference took 0.011703968048095703 sec\n",
      "ONNX postprocessing took 0.0005807876586914062 sec\n",
      "ONNX inference took 0.011844873428344727 sec\n",
      "ONNX postprocessing took 0.002801179885864258 sec\n",
      "ONNX inference took 0.012763738632202148 sec\n",
      "ONNX postprocessing took 0.0008816719055175781 sec\n",
      "ONNX inference took 0.011927604675292969 sec\n",
      "ONNX postprocessing took 0.0006248950958251953 sec\n",
      "ONNX inference took 0.012146949768066406 sec\n",
      "ONNX postprocessing took 0.0006372928619384766 sec\n",
      "ONNX inference took 0.011430025100708008 sec\n",
      "ONNX postprocessing took 0.0006015300750732422 sec\n",
      "ONNX inference took 0.012071371078491211 sec\n",
      "ONNX postprocessing took 0.0005624294281005859 sec\n",
      "ONNX inference took 0.011741399765014648 sec\n",
      "ONNX postprocessing took 0.0005564689636230469 sec\n",
      "ONNX inference took 0.011870622634887695 sec\n",
      "ONNX postprocessing took 0.001294851303100586 sec\n",
      "ONNX inference took 0.011774539947509766 sec\n",
      "ONNX postprocessing took 0.003937959671020508 sec\n",
      "ONNX inference took 0.012017011642456055 sec\n",
      "ONNX postprocessing took 0.0005881786346435547 sec\n",
      "ONNX inference took 0.011917829513549805 sec\n",
      "ONNX postprocessing took 0.0008928775787353516 sec\n",
      "ONNX inference took 0.01374053955078125 sec\n",
      "ONNX postprocessing took 0.0025680065155029297 sec\n",
      "ONNX inference took 0.012510538101196289 sec\n",
      "ONNX postprocessing took 0.003766775131225586 sec\n",
      "ONNX inference took 0.012935400009155273 sec\n",
      "ONNX postprocessing took 0.0006399154663085938 sec\n",
      "ONNX inference took 0.011746883392333984 sec\n",
      "ONNX postprocessing took 0.0010671615600585938 sec\n",
      "ONNX inference took 0.012614250183105469 sec\n",
      "ONNX postprocessing took 0.0014014244079589844 sec\n",
      "ONNX inference took 0.012936592102050781 sec\n",
      "ONNX postprocessing took 0.002200603485107422 sec\n",
      "ONNX inference took 0.011963844299316406 sec\n",
      "ONNX postprocessing took 0.0029134750366210938 sec\n",
      "ONNX inference took 0.012310266494750977 sec\n",
      "ONNX postprocessing took 0.002225637435913086 sec\n",
      "ONNX inference took 0.012323856353759766 sec\n",
      "ONNX postprocessing took 0.0013418197631835938 sec\n",
      "ONNX inference took 0.013107538223266602 sec\n",
      "ONNX postprocessing took 0.00558781623840332 sec\n",
      "ONNX inference took 0.011830329895019531 sec\n",
      "ONNX postprocessing took 0.0009672641754150391 sec\n",
      "ONNX inference took 0.01183319091796875 sec\n",
      "ONNX postprocessing took 0.00186920166015625 sec\n",
      "ONNX inference took 0.012115001678466797 sec\n",
      "ONNX postprocessing took 0.002925395965576172 sec\n",
      "ONNX inference took 0.01556396484375 sec\n",
      "ONNX postprocessing took 0.00336456298828125 sec\n",
      "ONNX inference took 0.012296676635742188 sec\n",
      "ONNX postprocessing took 0.0018496513366699219 sec\n",
      "ONNX inference took 0.012788534164428711 sec\n",
      "ONNX postprocessing took 0.0015575885772705078 sec\n",
      "ONNX inference took 0.011731624603271484 sec\n",
      "ONNX postprocessing took 0.0010838508605957031 sec\n",
      "ONNX inference took 0.012699365615844727 sec\n",
      "ONNX postprocessing took 0.004219770431518555 sec\n",
      "ONNX inference took 0.012743473052978516 sec\n",
      "ONNX postprocessing took 0.0011134147644042969 sec\n",
      "ONNX inference took 0.011279582977294922 sec\n",
      "ONNX postprocessing took 0.0008258819580078125 sec\n",
      "ONNX inference took 0.01146554946899414 sec\n",
      "ONNX postprocessing took 0.0005578994750976562 sec\n",
      "ONNX inference took 0.011359453201293945 sec\n",
      "ONNX postprocessing took 0.0009424686431884766 sec\n",
      "ONNX inference took 0.01168060302734375 sec\n",
      "ONNX postprocessing took 0.002187490463256836 sec\n",
      "ONNX inference took 0.012809991836547852 sec\n",
      "ONNX postprocessing took 0.0006501674652099609 sec\n",
      "ONNX inference took 0.011549234390258789 sec\n",
      "ONNX postprocessing took 0.0018951892852783203 sec\n",
      "ONNX inference took 0.01367044448852539 sec\n",
      "ONNX postprocessing took 0.003913164138793945 sec\n",
      "ONNX inference took 0.012884378433227539 sec\n",
      "ONNX postprocessing took 0.0009984970092773438 sec\n",
      "ONNX inference took 0.01206064224243164 sec\n",
      "ONNX postprocessing took 0.0016217231750488281 sec\n",
      "ONNX inference took 0.011060237884521484 sec\n",
      "ONNX postprocessing took 0.0008683204650878906 sec\n",
      "ONNX inference took 0.011132478713989258 sec\n",
      "ONNX postprocessing took 0.0017671585083007812 sec\n",
      "ONNX inference took 0.011685371398925781 sec\n",
      "ONNX postprocessing took 0.003253459930419922 sec\n",
      "ONNX inference took 0.012160062789916992 sec\n",
      "ONNX postprocessing took 0.0008244514465332031 sec\n",
      "ONNX inference took 0.012328624725341797 sec\n",
      "ONNX postprocessing took 0.0008933544158935547 sec\n",
      "ONNX inference took 0.011604070663452148 sec\n",
      "ONNX postprocessing took 0.0010914802551269531 sec\n",
      "ONNX inference took 0.01236724853515625 sec\n",
      "ONNX postprocessing took 0.0008046627044677734 sec\n",
      "ONNX inference took 0.014176368713378906 sec\n",
      "ONNX postprocessing took 0.0023598670959472656 sec\n",
      "ONNX inference took 0.011798858642578125 sec\n",
      "ONNX postprocessing took 0.0008873939514160156 sec\n",
      "ONNX inference took 0.012028217315673828 sec\n",
      "ONNX postprocessing took 0.0013554096221923828 sec\n",
      "ONNX inference took 0.01185297966003418 sec\n",
      "ONNX postprocessing took 0.0015854835510253906 sec\n",
      "ONNX inference took 0.012629270553588867 sec\n",
      "ONNX postprocessing took 0.0020303726196289062 sec\n",
      "ONNX inference took 0.013152122497558594 sec\n",
      "ONNX postprocessing took 0.0029342174530029297 sec\n",
      "ONNX inference took 0.012041568756103516 sec\n",
      "ONNX postprocessing took 0.000982522964477539 sec\n",
      "ONNX inference took 0.01293802261352539 sec\n",
      "ONNX postprocessing took 0.0014424324035644531 sec\n",
      "ONNX inference took 0.011780500411987305 sec\n",
      "ONNX postprocessing took 0.002691030502319336 sec\n",
      "ONNX inference took 0.012627124786376953 sec\n",
      "ONNX postprocessing took 0.0020546913146972656 sec\n",
      "ONNX inference took 0.012275218963623047 sec\n",
      "ONNX postprocessing took 0.004472017288208008 sec\n",
      "ONNX inference took 0.011768579483032227 sec\n",
      "ONNX postprocessing took 0.0014748573303222656 sec\n",
      "ONNX inference took 0.012125730514526367 sec\n",
      "ONNX postprocessing took 0.005638599395751953 sec\n",
      "ONNX inference took 0.011587142944335938 sec\n",
      "ONNX postprocessing took 0.0009307861328125 sec\n",
      "ONNX inference took 0.012050628662109375 sec\n",
      "ONNX postprocessing took 0.0005829334259033203 sec\n",
      "ONNX inference took 0.012046337127685547 sec\n",
      "ONNX postprocessing took 0.0006453990936279297 sec\n",
      "ONNX inference took 0.011534929275512695 sec\n",
      "ONNX postprocessing took 0.0006623268127441406 sec\n",
      "ONNX inference took 0.011520624160766602 sec\n",
      "ONNX postprocessing took 0.0005710124969482422 sec\n",
      "ONNX inference took 0.011326313018798828 sec\n",
      "ONNX postprocessing took 0.0010428428649902344 sec\n",
      "ONNX inference took 0.011530160903930664 sec\n",
      "ONNX postprocessing took 0.0009086132049560547 sec\n",
      "ONNX inference took 0.011888504028320312 sec\n",
      "ONNX postprocessing took 0.002954721450805664 sec\n",
      "ONNX inference took 0.012187004089355469 sec\n",
      "ONNX postprocessing took 0.0013082027435302734 sec\n",
      "ONNX inference took 0.012752771377563477 sec\n",
      "ONNX postprocessing took 0.003662586212158203 sec\n",
      "ONNX inference took 0.01224827766418457 sec\n",
      "ONNX postprocessing took 0.0021071434020996094 sec\n",
      "ONNX inference took 0.01227712631225586 sec\n",
      "ONNX postprocessing took 0.0022635459899902344 sec\n",
      "ONNX inference took 0.01150655746459961 sec\n",
      "ONNX postprocessing took 0.0008208751678466797 sec\n",
      "ONNX inference took 0.01233983039855957 sec\n",
      "ONNX postprocessing took 0.003124237060546875 sec\n",
      "ONNX inference took 0.011589527130126953 sec\n",
      "ONNX postprocessing took 0.0005748271942138672 sec\n",
      "ONNX inference took 0.01271963119506836 sec\n",
      "ONNX postprocessing took 0.0007393360137939453 sec\n",
      "ONNX inference took 0.01204371452331543 sec\n",
      "ONNX postprocessing took 0.0009026527404785156 sec\n",
      "ONNX inference took 0.01372385025024414 sec\n",
      "ONNX postprocessing took 0.0036776065826416016 sec\n",
      "ONNX inference took 0.012025833129882812 sec\n",
      "ONNX postprocessing took 0.001421213150024414 sec\n",
      "ONNX inference took 0.013263225555419922 sec\n",
      "ONNX postprocessing took 0.0016775131225585938 sec\n",
      "ONNX inference took 0.01131892204284668 sec\n",
      "ONNX postprocessing took 0.0031855106353759766 sec\n",
      "ONNX inference took 0.011402606964111328 sec\n",
      "ONNX postprocessing took 0.0032095909118652344 sec\n",
      "ONNX inference took 0.012002229690551758 sec\n",
      "ONNX postprocessing took 0.005706310272216797 sec\n",
      "ONNX inference took 0.012174606323242188 sec\n",
      "ONNX postprocessing took 0.000797271728515625 sec\n",
      "ONNX inference took 0.012322664260864258 sec\n",
      "ONNX postprocessing took 0.0010826587677001953 sec\n",
      "ONNX inference took 0.012959718704223633 sec\n",
      "ONNX postprocessing took 0.0042231082916259766 sec\n",
      "ONNX inference took 0.013488531112670898 sec\n",
      "ONNX postprocessing took 0.0018720626831054688 sec\n",
      "ONNX inference took 0.013017416000366211 sec\n",
      "ONNX postprocessing took 0.002095460891723633 sec\n",
      "ONNX inference took 0.013350725173950195 sec\n",
      "ONNX postprocessing took 0.0009906291961669922 sec\n",
      "ONNX inference took 0.011142492294311523 sec\n",
      "ONNX postprocessing took 0.004366159439086914 sec\n",
      "ONNX inference took 0.012041807174682617 sec\n",
      "ONNX postprocessing took 0.003520488739013672 sec\n",
      "ONNX inference took 0.012653589248657227 sec\n",
      "ONNX postprocessing took 0.0031626224517822266 sec\n",
      "ONNX inference took 0.01271820068359375 sec\n",
      "ONNX postprocessing took 0.0032782554626464844 sec\n",
      "ONNX inference took 0.011357545852661133 sec\n",
      "ONNX postprocessing took 0.0009200572967529297 sec\n",
      "ONNX inference took 0.012178897857666016 sec\n",
      "ONNX postprocessing took 0.0031213760375976562 sec\n",
      "ONNX inference took 0.01260995864868164 sec\n",
      "ONNX postprocessing took 0.002494335174560547 sec\n",
      "ONNX inference took 0.013220548629760742 sec\n",
      "ONNX postprocessing took 0.0025687217712402344 sec\n",
      "ONNX inference took 0.012131214141845703 sec\n",
      "ONNX postprocessing took 0.0012531280517578125 sec\n",
      "ONNX inference took 0.011051654815673828 sec\n",
      "ONNX postprocessing took 0.0008323192596435547 sec\n",
      "ONNX inference took 0.01160883903503418 sec\n",
      "ONNX postprocessing took 0.0008187294006347656 sec\n",
      "ONNX inference took 0.011666297912597656 sec\n",
      "ONNX postprocessing took 0.002027750015258789 sec\n",
      "ONNX inference took 0.011591196060180664 sec\n",
      "ONNX postprocessing took 0.0008361339569091797 sec\n",
      "ONNX inference took 0.011224031448364258 sec\n",
      "ONNX postprocessing took 0.0007863044738769531 sec\n",
      "ONNX inference took 0.011861085891723633 sec\n",
      "ONNX postprocessing took 0.0008099079132080078 sec\n",
      "ONNX inference took 0.011572599411010742 sec\n",
      "ONNX postprocessing took 0.0020678043365478516 sec\n",
      "ONNX inference took 0.012154102325439453 sec\n",
      "ONNX postprocessing took 0.003123760223388672 sec\n",
      "ONNX inference took 0.01180410385131836 sec\n",
      "ONNX postprocessing took 0.0005810260772705078 sec\n",
      "ONNX inference took 0.012425899505615234 sec\n",
      "ONNX postprocessing took 0.0025963783264160156 sec\n",
      "ONNX inference took 0.011622905731201172 sec\n",
      "ONNX postprocessing took 0.0006062984466552734 sec\n",
      "ONNX inference took 0.01227116584777832 sec\n",
      "ONNX postprocessing took 0.005556821823120117 sec\n",
      "ONNX inference took 0.011432170867919922 sec\n",
      "ONNX postprocessing took 0.003463268280029297 sec\n",
      "ONNX inference took 0.012156963348388672 sec\n",
      "ONNX postprocessing took 0.002911806106567383 sec\n",
      "ONNX inference took 0.012289047241210938 sec\n",
      "ONNX postprocessing took 0.0014464855194091797 sec\n",
      "ONNX inference took 0.012114286422729492 sec\n",
      "ONNX postprocessing took 0.002219676971435547 sec\n",
      "ONNX inference took 0.012870311737060547 sec\n",
      "ONNX postprocessing took 0.0027191638946533203 sec\n",
      "ONNX inference took 0.011328458786010742 sec\n",
      "ONNX postprocessing took 0.000820159912109375 sec\n",
      "ONNX inference took 0.012063980102539062 sec\n",
      "ONNX postprocessing took 0.0008938312530517578 sec\n",
      "ONNX inference took 0.013234376907348633 sec\n",
      "ONNX postprocessing took 0.0010700225830078125 sec\n",
      "ONNX inference took 0.012094736099243164 sec\n",
      "ONNX postprocessing took 0.0029401779174804688 sec\n",
      "ONNX inference took 0.012494564056396484 sec\n",
      "ONNX postprocessing took 0.0006279945373535156 sec\n",
      "ONNX inference took 0.011658430099487305 sec\n",
      "ONNX postprocessing took 0.0014312267303466797 sec\n",
      "ONNX inference took 0.011425971984863281 sec\n",
      "ONNX postprocessing took 0.0024976730346679688 sec\n",
      "ONNX inference took 0.015427589416503906 sec\n",
      "ONNX postprocessing took 0.00301361083984375 sec\n",
      "ONNX inference took 0.011666297912597656 sec\n",
      "ONNX postprocessing took 0.0024657249450683594 sec\n",
      "ONNX inference took 0.011487007141113281 sec\n",
      "ONNX postprocessing took 0.00104522705078125 sec\n",
      "ONNX inference took 0.012397289276123047 sec\n",
      "ONNX postprocessing took 0.0016529560089111328 sec\n",
      "ONNX inference took 0.011543512344360352 sec\n",
      "ONNX postprocessing took 0.0036554336547851562 sec\n",
      "ONNX inference took 0.011288642883300781 sec\n",
      "ONNX postprocessing took 0.0033521652221679688 sec\n",
      "ONNX inference took 0.011822223663330078 sec\n",
      "ONNX postprocessing took 0.0008509159088134766 sec\n",
      "ONNX inference took 0.011986970901489258 sec\n",
      "ONNX postprocessing took 0.0006580352783203125 sec\n",
      "ONNX inference took 0.012015819549560547 sec\n",
      "ONNX postprocessing took 0.001077413558959961 sec\n",
      "ONNX inference took 0.01183772087097168 sec\n",
      "ONNX postprocessing took 0.0007128715515136719 sec\n",
      "ONNX inference took 0.011652708053588867 sec\n",
      "ONNX postprocessing took 0.0005838871002197266 sec\n",
      "ONNX inference took 0.011316537857055664 sec\n",
      "ONNX postprocessing took 0.0009691715240478516 sec\n",
      "ONNX inference took 0.011615276336669922 sec\n",
      "ONNX postprocessing took 0.0008633136749267578 sec\n",
      "ONNX inference took 0.011933565139770508 sec\n",
      "ONNX postprocessing took 0.0008485317230224609 sec\n",
      "ONNX inference took 0.012223482131958008 sec\n",
      "ONNX postprocessing took 0.0008871555328369141 sec\n",
      "ONNX inference took 0.014020442962646484 sec\n",
      "ONNX postprocessing took 0.002588510513305664 sec\n",
      "ONNX inference took 0.013065576553344727 sec\n",
      "ONNX postprocessing took 0.0006263256072998047 sec\n",
      "ONNX inference took 0.012250661849975586 sec\n",
      "ONNX postprocessing took 0.003283977508544922 sec\n",
      "ONNX inference took 0.011456966400146484 sec\n",
      "ONNX postprocessing took 0.002560853958129883 sec\n",
      "ONNX inference took 0.012484073638916016 sec\n",
      "ONNX postprocessing took 0.0035631656646728516 sec\n",
      "ONNX inference took 0.012575149536132812 sec\n",
      "ONNX postprocessing took 0.0028977394104003906 sec\n",
      "ONNX inference took 0.011831998825073242 sec\n",
      "ONNX postprocessing took 0.0006902217864990234 sec\n",
      "ONNX inference took 0.013536930084228516 sec\n",
      "ONNX postprocessing took 0.003701925277709961 sec\n",
      "ONNX inference took 0.011614799499511719 sec\n",
      "ONNX postprocessing took 0.0005676746368408203 sec\n",
      "ONNX inference took 0.01187276840209961 sec\n",
      "ONNX postprocessing took 0.0006105899810791016 sec\n",
      "ONNX inference took 0.013695478439331055 sec\n",
      "ONNX postprocessing took 0.006793498992919922 sec\n",
      "ONNX inference took 0.012996673583984375 sec\n",
      "ONNX postprocessing took 0.0029616355895996094 sec\n",
      "ONNX inference took 0.013396024703979492 sec\n",
      "ONNX postprocessing took 0.0008215904235839844 sec\n",
      "ONNX inference took 0.011768817901611328 sec\n",
      "ONNX postprocessing took 0.0006256103515625 sec\n",
      "ONNX inference took 0.012475728988647461 sec\n",
      "ONNX postprocessing took 0.000980377197265625 sec\n",
      "ONNX inference took 0.011406660079956055 sec\n",
      "ONNX postprocessing took 0.0020515918731689453 sec\n",
      "ONNX inference took 0.011757373809814453 sec\n",
      "ONNX postprocessing took 0.00531458854675293 sec\n",
      "ONNX inference took 0.012091636657714844 sec\n",
      "ONNX postprocessing took 0.00473475456237793 sec\n",
      "ONNX inference took 0.012581110000610352 sec\n",
      "ONNX postprocessing took 0.002351522445678711 sec\n",
      "ONNX inference took 0.012995481491088867 sec\n",
      "ONNX postprocessing took 0.003088235855102539 sec\n",
      "ONNX inference took 0.01254129409790039 sec\n",
      "ONNX postprocessing took 0.0019145011901855469 sec\n",
      "ONNX inference took 0.011812686920166016 sec\n",
      "ONNX postprocessing took 0.0009007453918457031 sec\n",
      "ONNX inference took 0.011280059814453125 sec\n",
      "ONNX postprocessing took 0.0020308494567871094 sec\n",
      "ONNX inference took 0.012459278106689453 sec\n",
      "ONNX postprocessing took 0.0016589164733886719 sec\n",
      "ONNX inference took 0.012323856353759766 sec\n",
      "ONNX postprocessing took 0.0009849071502685547 sec\n",
      "ONNX inference took 0.012102842330932617 sec\n",
      "ONNX postprocessing took 0.0006198883056640625 sec\n",
      "ONNX inference took 0.012034177780151367 sec\n",
      "ONNX postprocessing took 0.0032792091369628906 sec\n",
      "ONNX inference took 0.011483430862426758 sec\n",
      "ONNX postprocessing took 0.0006744861602783203 sec\n",
      "ONNX inference took 0.011992931365966797 sec\n",
      "ONNX postprocessing took 0.0009853839874267578 sec\n",
      "ONNX inference took 0.013634204864501953 sec\n",
      "ONNX postprocessing took 0.0007064342498779297 sec\n",
      "ONNX inference took 0.013096332550048828 sec\n",
      "ONNX postprocessing took 0.003766298294067383 sec\n",
      "ONNX inference took 0.011477470397949219 sec\n",
      "ONNX postprocessing took 0.0037653446197509766 sec\n",
      "ONNX inference took 0.012312889099121094 sec\n",
      "ONNX postprocessing took 0.001026153564453125 sec\n"
     ]
    }
   ],
   "source": [
    "from dlclive.benchmark_pytorch import analyze_video\n",
    "from dlclive import DLCLive\n",
    "\n",
    "dlc_live = DLCLive(\n",
    "    path=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait\",\n",
    "    device=\"tensorrt\",\n",
    "    # snapshot=\"snapshot-263.pt\",\n",
    "    model_type=\"onnx\",\n",
    "    display=True,\n",
    "    precision=\"FP16\"\n",
    ")\n",
    "#short video\n",
    "# video_path = '/Users/annastuckert/Documents/DLC_AI_Residency/DLC_AI2024/DeepLabCut-live/Ventral_gait_model/1_20cms_0degUP_first_1s.avi'\n",
    "video_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/1_20cms_0degUP_first.avi\"\n",
    "\n",
    "poses, times = analyze_video(video_path=video_path, dlc_live=dlc_live, save_poses=False, save_dir=\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/out\", draw_keypoint_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlc_live.display.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean inference time excluding 1st inference  12.19 ms  0.87\n",
      "Mean inference time including 1st inference  34.37 ms  858.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean inference time excluding 1st inference \", np.round(np.mean(times[1:])*1000, 2), \"ms \", np.round(np.std(times[1:])*1000, 2))\n",
    "print(\"Mean inference time including 1st inference \", np.round(np.mean(times)*1000, 2), \"ms \", np.round(np.std(times)*1000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7d039b363850>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(times[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1433417797088623,\n",
       " 0.019846677780151367,\n",
       " 0.01972174644470215,\n",
       " 0.019562959671020508,\n",
       " 0.02054119110107422,\n",
       " 0.019287586212158203,\n",
       " 0.01930975914001465,\n",
       " 0.019775390625,\n",
       " 0.021361589431762695,\n",
       " 0.020486831665039062,\n",
       " 0.023508310317993164,\n",
       " 0.019176483154296875,\n",
       " 0.022179841995239258,\n",
       " 0.023015975952148438,\n",
       " 0.019678354263305664,\n",
       " 0.020087718963623047,\n",
       " 0.020717859268188477,\n",
       " 0.02086043357849121,\n",
       " 0.023644685745239258,\n",
       " 0.0215909481048584,\n",
       " 0.02092742919921875,\n",
       " 0.020411014556884766,\n",
       " 0.023017406463623047,\n",
       " 0.021517038345336914,\n",
       " 0.021661043167114258,\n",
       " 0.02132582664489746,\n",
       " 0.02152848243713379,\n",
       " 0.019128799438476562,\n",
       " 0.02377772331237793,\n",
       " 0.020733118057250977,\n",
       " 0.021207809448242188,\n",
       " 0.020865917205810547,\n",
       " 0.01990199089050293,\n",
       " 0.019349336624145508,\n",
       " 0.02163100242614746,\n",
       " 0.020320653915405273,\n",
       " 0.020637989044189453,\n",
       " 0.020346879959106445,\n",
       " 0.01885223388671875,\n",
       " 0.01897597312927246,\n",
       " 0.02143716812133789,\n",
       " 0.01978278160095215,\n",
       " 0.022147655487060547,\n",
       " 0.021617650985717773,\n",
       " 0.02158665657043457,\n",
       " 0.02079319953918457,\n",
       " 0.020571470260620117,\n",
       " 0.02292799949645996,\n",
       " 0.021432876586914062,\n",
       " 0.020339012145996094,\n",
       " 0.0234525203704834,\n",
       " 0.019826889038085938,\n",
       " 0.023105382919311523,\n",
       " 0.020264148712158203,\n",
       " 0.019860506057739258,\n",
       " 0.0210268497467041,\n",
       " 0.021668672561645508,\n",
       " 0.021470308303833008,\n",
       " 0.02157735824584961,\n",
       " 0.020766019821166992,\n",
       " 0.021030664443969727,\n",
       " 0.019581079483032227,\n",
       " 0.02145528793334961,\n",
       " 0.01901102066040039,\n",
       " 0.02037334442138672,\n",
       " 0.022805213928222656,\n",
       " 0.021566390991210938,\n",
       " 0.01990199089050293,\n",
       " 0.019785642623901367,\n",
       " 0.021184206008911133,\n",
       " 0.02290511131286621,\n",
       " 0.01918792724609375,\n",
       " 0.021863222122192383,\n",
       " 0.021605491638183594,\n",
       " 0.021327495574951172,\n",
       " 0.01914381980895996,\n",
       " 0.021691322326660156,\n",
       " 0.023492097854614258,\n",
       " 0.01901388168334961,\n",
       " 0.018824100494384766,\n",
       " 0.018850088119506836,\n",
       " 0.018492698669433594,\n",
       " 0.018490314483642578,\n",
       " 0.02127528190612793,\n",
       " 0.02015399932861328,\n",
       " 0.020959854125976562,\n",
       " 0.021033287048339844,\n",
       " 0.020975351333618164,\n",
       " 0.02018117904663086,\n",
       " 0.01982712745666504,\n",
       " 0.020690441131591797,\n",
       " 0.021567583084106445,\n",
       " 0.01869034767150879,\n",
       " 0.019594430923461914,\n",
       " 0.019416332244873047,\n",
       " 0.0204622745513916,\n",
       " 0.019609928131103516,\n",
       " 0.020978689193725586,\n",
       " 0.022556304931640625,\n",
       " 0.019018888473510742,\n",
       " 0.0206301212310791,\n",
       " 0.021826744079589844,\n",
       " 0.02221989631652832,\n",
       " 0.020612001419067383,\n",
       " 0.020490169525146484,\n",
       " 0.021326780319213867,\n",
       " 0.021045684814453125,\n",
       " 0.022190332412719727,\n",
       " 0.020543336868286133,\n",
       " 0.02051520347595215,\n",
       " 0.023082256317138672,\n",
       " 0.020668506622314453,\n",
       " 0.021710872650146484,\n",
       " 0.023267745971679688,\n",
       " 0.01900029182434082,\n",
       " 0.01932048797607422,\n",
       " 0.019585609436035156,\n",
       " 0.023548603057861328,\n",
       " 0.020711183547973633,\n",
       " 0.01883387565612793,\n",
       " 0.019150733947753906,\n",
       " 0.02052593231201172,\n",
       " 0.02247762680053711,\n",
       " 0.021792173385620117,\n",
       " 0.02005624771118164,\n",
       " 0.022275686264038086,\n",
       " 0.021800518035888672,\n",
       " 0.0192110538482666,\n",
       " 0.021728992462158203,\n",
       " 0.021669864654541016,\n",
       " 0.022919416427612305,\n",
       " 0.021080493927001953,\n",
       " 0.021253347396850586,\n",
       " 0.02098870277404785,\n",
       " 0.01954507827758789,\n",
       " 0.021284818649291992,\n",
       " 0.021457910537719727,\n",
       " 0.020999670028686523,\n",
       " 0.021504878997802734,\n",
       " 0.02066779136657715,\n",
       " 0.020615339279174805,\n",
       " 0.02178359031677246,\n",
       " 0.021471023559570312,\n",
       " 0.02303481101989746,\n",
       " 0.020760536193847656,\n",
       " 0.021463632583618164,\n",
       " 0.021490812301635742,\n",
       " 0.0189664363861084,\n",
       " 0.020646333694458008,\n",
       " 0.02136373519897461,\n",
       " 0.022898435592651367,\n",
       " 0.021735668182373047,\n",
       " 0.01891469955444336,\n",
       " 0.019806385040283203,\n",
       " 0.021589279174804688,\n",
       " 0.0201263427734375,\n",
       " 0.019777774810791016,\n",
       " 0.0215609073638916,\n",
       " 0.021979093551635742,\n",
       " 0.022510051727294922,\n",
       " 0.0216522216796875,\n",
       " 0.021480560302734375,\n",
       " 0.02240610122680664,\n",
       " 0.0229642391204834,\n",
       " 0.020876169204711914,\n",
       " 0.02047896385192871,\n",
       " 0.019179582595825195,\n",
       " 0.022357463836669922,\n",
       " 0.021764516830444336,\n",
       " 0.020379304885864258,\n",
       " 0.022864818572998047,\n",
       " 0.020392894744873047,\n",
       " 0.023672103881835938,\n",
       " 0.02073836326599121,\n",
       " 0.023549318313598633,\n",
       " 0.0201718807220459,\n",
       " 0.021453142166137695,\n",
       " 0.018977642059326172,\n",
       " 0.020327091217041016,\n",
       " 0.02261638641357422,\n",
       " 0.023296356201171875,\n",
       " 0.021243572235107422,\n",
       " 0.023144960403442383,\n",
       " 0.022350072860717773,\n",
       " 0.019817113876342773,\n",
       " 0.021335840225219727,\n",
       " 0.020956039428710938,\n",
       " 0.0214846134185791,\n",
       " 0.02112722396850586,\n",
       " 0.022377729415893555,\n",
       " 0.021980762481689453,\n",
       " 0.019533634185791016,\n",
       " 0.021290302276611328,\n",
       " 0.021725177764892578,\n",
       " 0.019849300384521484,\n",
       " 0.0188140869140625,\n",
       " 0.020543575286865234,\n",
       " 0.020437240600585938,\n",
       " 0.019727468490600586,\n",
       " 0.0231168270111084,\n",
       " 0.019585847854614258,\n",
       " 0.020447969436645508,\n",
       " 0.021222829818725586,\n",
       " 0.02071094512939453,\n",
       " 0.022215604782104492,\n",
       " 0.021056413650512695,\n",
       " 0.020544767379760742,\n",
       " 0.02139735221862793,\n",
       " 0.021174192428588867,\n",
       " 0.022590160369873047,\n",
       " 0.023981094360351562,\n",
       " 0.02119135856628418,\n",
       " 0.023427963256835938,\n",
       " 0.02287578582763672,\n",
       " 0.021654605865478516,\n",
       " 0.01881122589111328,\n",
       " 0.019184112548828125,\n",
       " 0.018716096878051758,\n",
       " 0.019258737564086914,\n",
       " 0.021151304244995117,\n",
       " 0.019977569580078125,\n",
       " 0.02356696128845215,\n",
       " 0.0191497802734375,\n",
       " 0.019366025924682617,\n",
       " 0.02071070671081543,\n",
       " 0.018938302993774414,\n",
       " 0.0199434757232666,\n",
       " 0.020465850830078125,\n",
       " 0.020534515380859375,\n",
       " 0.02076244354248047,\n",
       " 0.020325422286987305,\n",
       " 0.019070148468017578,\n",
       " 0.019611358642578125,\n",
       " 0.0212554931640625,\n",
       " 0.019748210906982422,\n",
       " 0.021887779235839844,\n",
       " 0.020158767700195312,\n",
       " 0.022963523864746094,\n",
       " 0.021490097045898438,\n",
       " 0.02075028419494629,\n",
       " 0.01914811134338379,\n",
       " 0.02001476287841797,\n",
       " 0.02231907844543457,\n",
       " 0.0201570987701416,\n",
       " 0.01927924156188965,\n",
       " 0.02317523956298828,\n",
       " 0.021471261978149414,\n",
       " 0.019356727600097656,\n",
       " 0.019365310668945312,\n",
       " 0.019030094146728516,\n",
       " 0.021591901779174805,\n",
       " 0.0214083194732666,\n",
       " 0.021239042282104492,\n",
       " 0.02324676513671875,\n",
       " 0.02028489112854004,\n",
       " 0.021533966064453125,\n",
       " 0.02163076400756836,\n",
       " 0.022033214569091797,\n",
       " 0.019226551055908203,\n",
       " 0.01962590217590332,\n",
       " 0.019731998443603516,\n",
       " 0.018948793411254883,\n",
       " 0.02144145965576172,\n",
       " 0.02259659767150879,\n",
       " 0.02127528190612793,\n",
       " 0.02019357681274414,\n",
       " 0.02144336700439453,\n",
       " 0.023064136505126953,\n",
       " 0.021163225173950195,\n",
       " 0.022347450256347656,\n",
       " 0.02139592170715332,\n",
       " 0.0219573974609375,\n",
       " 0.01961207389831543,\n",
       " 0.021399736404418945,\n",
       " 0.020772933959960938,\n",
       " 0.020611047744750977,\n",
       " 0.021117210388183594,\n",
       " 0.020592212677001953,\n",
       " 0.022211790084838867,\n",
       " 0.019445419311523438,\n",
       " 0.023725509643554688,\n",
       " 0.022340059280395508,\n",
       " 0.020792484283447266,\n",
       " 0.022728681564331055,\n",
       " 0.021834611892700195,\n",
       " 0.01922893524169922,\n",
       " 0.020541906356811523,\n",
       " 0.023157835006713867,\n",
       " 0.019390583038330078,\n",
       " 0.022724628448486328,\n",
       " 0.02336907386779785,\n",
       " 0.021821260452270508,\n",
       " 0.02252483367919922,\n",
       " 0.019482135772705078,\n",
       " 0.019504547119140625,\n",
       " 0.022874832153320312,\n",
       " 0.022007465362548828,\n",
       " 0.019504785537719727,\n",
       " 0.020985841751098633,\n",
       " 0.021214962005615234,\n",
       " 0.023395061492919922,\n",
       " 0.02215123176574707,\n",
       " 0.020570039749145508,\n",
       " 0.02281641960144043,\n",
       " 0.0216677188873291,\n",
       " 0.018963336944580078,\n",
       " 0.020251750946044922,\n",
       " 0.020329952239990234,\n",
       " 0.019306182861328125,\n",
       " 0.018744707107543945,\n",
       " 0.01927042007446289,\n",
       " 0.02062082290649414,\n",
       " 0.021219968795776367,\n",
       " 0.01917409896850586,\n",
       " 0.018975257873535156,\n",
       " 0.02040386199951172,\n",
       " 0.022745847702026367,\n",
       " 0.020372867584228516,\n",
       " 0.020900964736938477,\n",
       " 0.0213162899017334,\n",
       " 0.019373178482055664,\n",
       " 0.01879119873046875,\n",
       " 0.019815921783447266,\n",
       " 0.021353960037231445,\n",
       " 0.021918296813964844,\n",
       " 0.020805835723876953,\n",
       " 0.022568225860595703,\n",
       " 0.022883892059326172,\n",
       " 0.020214319229125977,\n",
       " 0.020057201385498047,\n",
       " 0.02313065528869629,\n",
       " 0.024197101593017578,\n",
       " 0.019160032272338867,\n",
       " 0.022401094436645508,\n",
       " 0.021190881729125977,\n",
       " 0.020275115966796875,\n",
       " 0.020227670669555664,\n",
       " 0.020914316177368164,\n",
       " 0.022298574447631836,\n",
       " 0.019853591918945312,\n",
       " 0.01993250846862793,\n",
       " 0.02148723602294922,\n",
       " 0.02044820785522461,\n",
       " 0.0231931209564209,\n",
       " 0.020050764083862305,\n",
       " 0.019093751907348633,\n",
       " 0.021465301513671875,\n",
       " 0.020475149154663086,\n",
       " 0.020761489868164062,\n",
       " 0.01976299285888672,\n",
       " 0.023182392120361328,\n",
       " 0.01948094367980957,\n",
       " 0.02219557762145996,\n",
       " 0.019052743911743164,\n",
       " 0.019462108612060547,\n",
       " 0.020996809005737305,\n",
       " 0.022154569625854492,\n",
       " 0.021414995193481445,\n",
       " 0.023303985595703125,\n",
       " 0.019675016403198242,\n",
       " 0.019347190856933594,\n",
       " 0.022141456604003906,\n",
       " 0.019775867462158203,\n",
       " 0.0233156681060791,\n",
       " 0.02221202850341797,\n",
       " 0.019667387008666992,\n",
       " 0.021332263946533203,\n",
       " 0.021159887313842773,\n",
       " 0.019467830657958984,\n",
       " 0.019678354263305664,\n",
       " 0.02104783058166504,\n",
       " 0.022812604904174805,\n",
       " 0.019654273986816406,\n",
       " 0.02124929428100586,\n",
       " 0.022352218627929688,\n",
       " 0.01900506019592285,\n",
       " 0.020848751068115234,\n",
       " 0.019831418991088867,\n",
       " 0.01944255828857422,\n",
       " 0.020556926727294922,\n",
       " 0.020089387893676758,\n",
       " 0.021853208541870117,\n",
       " 0.020035982131958008,\n",
       " 0.02141594886779785,\n",
       " 0.020389556884765625,\n",
       " 0.021864891052246094,\n",
       " 0.01996612548828125,\n",
       " 0.0213165283203125,\n",
       " 0.021393775939941406,\n",
       " 0.021619558334350586,\n",
       " 0.02182745933532715,\n",
       " 0.021280765533447266,\n",
       " 0.02112436294555664,\n",
       " 0.021905183792114258,\n",
       " 0.020742177963256836,\n",
       " 0.01990032196044922,\n",
       " 0.01932358741760254,\n",
       " 0.019353389739990234,\n",
       " 0.021116018295288086,\n",
       " 0.021703720092773438,\n",
       " 0.019452333450317383,\n",
       " 0.021199464797973633,\n",
       " 0.02089095115661621,\n",
       " 0.021373987197875977,\n",
       " 0.019360780715942383,\n",
       " 0.022324085235595703,\n",
       " 0.020512104034423828,\n",
       " 0.019188880920410156,\n",
       " 0.0218198299407959,\n",
       " 0.02252054214477539,\n",
       " 0.01931619644165039,\n",
       " 0.021396875381469727,\n",
       " 0.019718170166015625,\n",
       " 0.022223472595214844,\n",
       " 0.019672632217407227,\n",
       " 0.02143383026123047,\n",
       " 0.020296335220336914,\n",
       " 0.020130634307861328,\n",
       " 0.019928693771362305,\n",
       " 0.02162480354309082,\n",
       " 0.02151942253112793,\n",
       " 0.022199630737304688,\n",
       " 0.021123170852661133,\n",
       " 0.021641254425048828,\n",
       " 0.02078390121459961,\n",
       " 0.02175140380859375,\n",
       " 0.020323753356933594,\n",
       " 0.0205996036529541,\n",
       " 0.021796226501464844,\n",
       " 0.02034282684326172,\n",
       " 0.02151179313659668,\n",
       " 0.020467281341552734,\n",
       " 0.021656274795532227,\n",
       " 0.020392656326293945,\n",
       " 0.02076578140258789,\n",
       " 0.021172523498535156,\n",
       " 0.021016359329223633,\n",
       " 0.019033193588256836,\n",
       " 0.02115917205810547,\n",
       " 0.020637989044189453,\n",
       " 0.020137786865234375,\n",
       " 0.020624637603759766,\n",
       " 0.02250075340270996,\n",
       " 0.020775318145751953,\n",
       " 0.019281864166259766,\n",
       " 0.020422697067260742,\n",
       " 0.021333932876586914,\n",
       " 0.02180957794189453,\n",
       " 0.019075393676757812,\n",
       " 0.0200192928314209,\n",
       " 0.02266979217529297,\n",
       " 0.021575212478637695,\n",
       " 0.02150750160217285,\n",
       " 0.02186751365661621,\n",
       " 0.020879507064819336,\n",
       " 0.021743297576904297,\n",
       " 0.020695924758911133,\n",
       " 0.021056175231933594,\n",
       " 0.02182292938232422,\n",
       " 0.01949334144592285,\n",
       " 0.019104480743408203,\n",
       " 0.019034624099731445,\n",
       " 0.022725582122802734,\n",
       " 0.020946502685546875,\n",
       " 0.02206254005432129,\n",
       " 0.019518136978149414,\n",
       " 0.020691871643066406,\n",
       " 0.01913905143737793,\n",
       " 0.019932270050048828,\n",
       " 0.022286176681518555,\n",
       " 0.021854877471923828,\n",
       " 0.021033287048339844,\n",
       " 0.022826671600341797,\n",
       " 0.02169942855834961,\n",
       " 0.019209623336791992,\n",
       " 0.021962404251098633,\n",
       " 0.02057480812072754,\n",
       " 0.021172046661376953,\n",
       " 0.021410226821899414,\n",
       " 0.021144866943359375,\n",
       " 0.01922607421875,\n",
       " 0.02200627326965332,\n",
       " 0.02003335952758789,\n",
       " 0.0205230712890625,\n",
       " 0.021235227584838867,\n",
       " 0.020823240280151367,\n",
       " 0.020825862884521484,\n",
       " 0.018769502639770508,\n",
       " 0.018922090530395508,\n",
       " 0.018922805786132812,\n",
       " 0.019093036651611328,\n",
       " 0.019538402557373047,\n",
       " 0.02052164077758789,\n",
       " 0.019904375076293945,\n",
       " 0.021085023880004883,\n",
       " 0.02022695541381836,\n",
       " 0.020022153854370117,\n",
       " 0.02133941650390625,\n",
       " 0.02165699005126953,\n",
       " 0.021571874618530273,\n",
       " 0.02069568634033203,\n",
       " 0.021895647048950195,\n",
       " 0.019156217575073242,\n",
       " 0.019731760025024414,\n",
       " 0.02179408073425293,\n",
       " 0.019191265106201172,\n",
       " 0.020704269409179688,\n",
       " 0.020735979080200195,\n",
       " 0.02232503890991211,\n",
       " 0.022122621536254883,\n",
       " 0.02066826820373535,\n",
       " 0.02283501625061035,\n",
       " 0.021404504776000977,\n",
       " 0.023372173309326172,\n",
       " 0.02223944664001465,\n",
       " 0.023698091506958008,\n",
       " 0.01947188377380371,\n",
       " 0.02103877067565918,\n",
       " 0.020482540130615234,\n",
       " 0.021442890167236328,\n",
       " 0.019976377487182617,\n",
       " 0.02075028419494629,\n",
       " 0.023246288299560547,\n",
       " 0.019224166870117188,\n",
       " 0.020118236541748047,\n",
       " 0.021548748016357422,\n",
       " 0.02142643928527832,\n",
       " 0.0201876163482666,\n",
       " 0.021120309829711914,\n",
       " 0.020542621612548828,\n",
       " 0.02120375633239746,\n",
       " 0.02219557762145996,\n",
       " 0.023209810256958008,\n",
       " 0.020686864852905273,\n",
       " 0.020998716354370117,\n",
       " 0.019214391708374023,\n",
       " 0.021522998809814453,\n",
       " 0.02111673355102539,\n",
       " 0.01937389373779297,\n",
       " 0.01936817169189453,\n",
       " 0.02038741111755371,\n",
       " 0.01918172836303711,\n",
       " 0.020258426666259766,\n",
       " 0.02080059051513672,\n",
       " 0.01936483383178711,\n",
       " 0.023479461669921875,\n",
       " 0.023150920867919922,\n",
       " 0.02186274528503418,\n",
       " 0.02017664909362793,\n",
       " 0.02156376838684082,\n",
       " 0.019669055938720703,\n",
       " 0.019812822341918945,\n",
       " 0.02030181884765625,\n",
       " 0.021402597427368164,\n",
       " 0.021210432052612305,\n",
       " 0.02046799659729004,\n",
       " 0.01973438262939453,\n",
       " 0.02095341682434082,\n",
       " 0.019820690155029297,\n",
       " 0.01966094970703125,\n",
       " 0.01980113983154297,\n",
       " 0.021009445190429688,\n",
       " 0.021938323974609375,\n",
       " 0.020122051239013672,\n",
       " 0.020894765853881836,\n",
       " 0.01973867416381836,\n",
       " 0.02068042755126953,\n",
       " 0.019885778427124023,\n",
       " 0.02152872085571289,\n",
       " 0.020755290985107422,\n",
       " 0.021454811096191406,\n",
       " 0.021465301513671875,\n",
       " 0.02169966697692871,\n",
       " 0.018919944763183594,\n",
       " 0.019083261489868164,\n",
       " 0.019208431243896484,\n",
       " 0.020143747329711914,\n",
       " 0.021584749221801758,\n",
       " 0.02459120750427246,\n",
       " 0.020534515380859375,\n",
       " 0.02045440673828125,\n",
       " 0.019381284713745117,\n",
       " 0.020267486572265625,\n",
       " 0.02004241943359375,\n",
       " 0.023289203643798828,\n",
       " 0.019057273864746094,\n",
       " 0.019367456436157227,\n",
       " 0.022497177124023438,\n",
       " 0.020339488983154297,\n",
       " 0.020130157470703125,\n",
       " 0.019950151443481445,\n",
       " 0.02308201789855957,\n",
       " 0.02069711685180664,\n",
       " 0.021235227584838867,\n",
       " 0.019842863082885742,\n",
       " 0.022076129913330078,\n",
       " 0.02106928825378418,\n",
       " 0.021924972534179688,\n",
       " 0.021890640258789062,\n",
       " 0.02023172378540039,\n",
       " 0.020537376403808594,\n",
       " 0.019469738006591797,\n",
       " 0.020878314971923828,\n",
       " 0.02084517478942871,\n",
       " 0.020531654357910156,\n",
       " 0.020079374313354492,\n",
       " 0.022400379180908203,\n",
       " 0.020773887634277344,\n",
       " 0.022637605667114258,\n",
       " 0.020659685134887695,\n",
       " 0.021433115005493164,\n",
       " 0.022002458572387695,\n",
       " 0.019501209259033203,\n",
       " 0.020611047744750977,\n",
       " 0.019896745681762695,\n",
       " 0.0219118595123291,\n",
       " 0.021678924560546875,\n",
       " 0.020172119140625,\n",
       " 0.019956111907958984,\n",
       " 0.01976752281188965,\n",
       " 0.022521257400512695,\n",
       " 0.020521163940429688,\n",
       " 0.022774219512939453,\n",
       " 0.023104190826416016,\n",
       " 0.020500659942626953,\n",
       " 0.021576404571533203,\n",
       " 0.02184581756591797,\n",
       " 0.022345781326293945,\n",
       " 0.020259380340576172,\n",
       " 0.021808624267578125,\n",
       " 0.019295692443847656,\n",
       " 0.021555662155151367,\n",
       " 0.019964933395385742,\n",
       " 0.02168130874633789,\n",
       " 0.021801233291625977,\n",
       " 0.021100759506225586,\n",
       " 0.02034139633178711,\n",
       " 0.021992206573486328,\n",
       " 0.022800683975219727,\n",
       " 0.020519733428955078,\n",
       " 0.021572589874267578,\n",
       " 0.021030664443969727,\n",
       " 0.02075672149658203,\n",
       " 0.020155668258666992,\n",
       " 0.020505666732788086,\n",
       " 0.021456480026245117,\n",
       " 0.0214691162109375,\n",
       " 0.021619558334350586,\n",
       " 0.019048452377319336,\n",
       " 0.019922256469726562,\n",
       " 0.0220029354095459,\n",
       " 0.021686553955078125,\n",
       " 0.02097606658935547,\n",
       " 0.019508838653564453,\n",
       " 0.019238710403442383,\n",
       " 0.02182316780090332,\n",
       " 0.02199077606201172,\n",
       " 0.020606040954589844,\n",
       " 0.02162027359008789,\n",
       " 0.019501686096191406,\n",
       " 0.02111649513244629,\n",
       " 0.021685123443603516,\n",
       " 0.021825790405273438,\n",
       " 0.020798683166503906,\n",
       " 0.023335695266723633,\n",
       " 0.020179033279418945,\n",
       " 0.01924443244934082,\n",
       " 0.020511865615844727,\n",
       " 0.0215303897857666,\n",
       " 0.019413232803344727,\n",
       " 0.019126415252685547,\n",
       " 0.019602060317993164,\n",
       " 0.020859718322753906,\n",
       " 0.022675752639770508,\n",
       " 0.022012710571289062,\n",
       " 0.021770477294921875,\n",
       " 0.023041248321533203,\n",
       " 0.01881694793701172,\n",
       " 0.019374608993530273,\n",
       " 0.02109527587890625,\n",
       " 0.021749019622802734,\n",
       " 0.02170872688293457,\n",
       " 0.023248910903930664,\n",
       " 0.019671916961669922,\n",
       " 0.02213287353515625,\n",
       " 0.020386934280395508,\n",
       " 0.020007848739624023,\n",
       " 0.020121097564697266,\n",
       " 0.0224611759185791,\n",
       " 0.019208431243896484,\n",
       " 0.020816802978515625,\n",
       " 0.020760297775268555,\n",
       " 0.020529747009277344,\n",
       " 0.019614696502685547,\n",
       " 0.01894521713256836,\n",
       " 0.02249884605407715,\n",
       " 0.01999068260192871,\n",
       " 0.02103567123413086,\n",
       " 0.020267009735107422,\n",
       " 0.019395828247070312,\n",
       " 0.019658565521240234,\n",
       " 0.01890850067138672,\n",
       " 0.018746376037597656,\n",
       " 0.01923990249633789,\n",
       " 0.021462440490722656,\n",
       " 0.020809173583984375,\n",
       " 0.01955890655517578,\n",
       " 0.020660877227783203,\n",
       " 0.019696712493896484,\n",
       " 0.019939899444580078,\n",
       " 0.020812034606933594,\n",
       " 0.020662307739257812,\n",
       " 0.021481752395629883,\n",
       " 0.021342992782592773,\n",
       " 0.0229489803314209,\n",
       " 0.021024227142333984,\n",
       " 0.02162957191467285,\n",
       " 0.021410703659057617,\n",
       " 0.021108150482177734,\n",
       " 0.021450281143188477,\n",
       " 0.022300004959106445,\n",
       " 0.0239717960357666,\n",
       " 0.02125382423400879,\n",
       " 0.019754886627197266,\n",
       " 0.022174835205078125,\n",
       " 0.021899938583374023,\n",
       " 0.020943403244018555,\n",
       " 0.020981311798095703,\n",
       " 0.020465850830078125,\n",
       " 0.02123403549194336,\n",
       " 0.02237105369567871,\n",
       " 0.020821332931518555,\n",
       " 0.019113779067993164,\n",
       " 0.018764019012451172,\n",
       " 0.01903247833251953,\n",
       " 0.01902937889099121,\n",
       " 0.019013166427612305,\n",
       " 0.01934027671813965,\n",
       " 0.0207669734954834,\n",
       " 0.018289804458618164,\n",
       " 0.01969456672668457,\n",
       " 0.018901348114013672,\n",
       " 0.019330739974975586,\n",
       " 0.0182950496673584,\n",
       " 0.018188953399658203,\n",
       " 0.018061399459838867,\n",
       " 0.01802825927734375,\n",
       " 0.017986774444580078,\n",
       " 0.01794147491455078,\n",
       " 0.018372297286987305,\n",
       " 0.0213320255279541,\n",
       " 0.02158641815185547,\n",
       " 0.019097328186035156,\n",
       " 0.01919412612915039,\n",
       " 0.01938652992248535,\n",
       " 0.021669626235961914,\n",
       " 0.01749110221862793,\n",
       " 0.01838994026184082,\n",
       " 0.01837754249572754,\n",
       " 0.01808643341064453,\n",
       " 0.019619226455688477,\n",
       " 0.019949913024902344,\n",
       " 0.019475936889648438,\n",
       " 0.02063155174255371,\n",
       " 0.021054506301879883,\n",
       " 0.01969289779663086,\n",
       " 0.020270586013793945,\n",
       " 0.019014835357666016,\n",
       " 0.01919412612915039,\n",
       " 0.019833087921142578,\n",
       " 0.01999807357788086,\n",
       " 0.018787384033203125,\n",
       " 0.021123409271240234,\n",
       " 0.022559165954589844,\n",
       " 0.021819114685058594,\n",
       " 0.019222021102905273,\n",
       " 0.020880937576293945,\n",
       " 0.020743370056152344,\n",
       " 0.0209805965423584,\n",
       " 0.019596099853515625,\n",
       " 0.02117633819580078,\n",
       " 0.019777536392211914,\n",
       " 0.020173072814941406,\n",
       " 0.022317886352539062,\n",
       " 0.023370742797851562,\n",
       " 0.020522356033325195,\n",
       " 0.019234180450439453,\n",
       " 0.020738840103149414,\n",
       " 0.021095752716064453,\n",
       " 0.023238182067871094,\n",
       " 0.020005226135253906,\n",
       " 0.021481990814208984,\n",
       " 0.020909547805786133,\n",
       " 0.022296428680419922,\n",
       " 0.022029638290405273,\n",
       " 0.021059036254882812,\n",
       " 0.019210338592529297,\n",
       " 0.022877216339111328,\n",
       " 0.023378610610961914,\n",
       " 0.020192623138427734,\n",
       " 0.022034168243408203,\n",
       " 0.022911787033081055,\n",
       " 0.02126908302307129,\n",
       " 0.021114826202392578,\n",
       " 0.01887965202331543,\n",
       " 0.018720149993896484,\n",
       " 0.018765926361083984,\n",
       " 0.01884317398071289,\n",
       " 0.01929616928100586,\n",
       " 0.0189816951751709,\n",
       " 0.021136760711669922,\n",
       " 0.021339893341064453,\n",
       " 0.021683216094970703,\n",
       " 0.019710540771484375,\n",
       " 0.02085709571838379,\n",
       " 0.02273392677307129,\n",
       " 0.023301124572753906,\n",
       " 0.020603418350219727,\n",
       " 0.021625280380249023,\n",
       " 0.019589662551879883,\n",
       " 0.0223696231842041,\n",
       " 0.019509077072143555,\n",
       " 0.021165132522583008,\n",
       " 0.02015972137451172,\n",
       " 0.021162748336791992,\n",
       " 0.02093791961669922,\n",
       " 0.022282838821411133,\n",
       " 0.020431041717529297,\n",
       " 0.020267248153686523,\n",
       " 0.022841215133666992,\n",
       " 0.020600318908691406,\n",
       " 0.02081298828125,\n",
       " 0.021532773971557617,\n",
       " 0.022948741912841797,\n",
       " 0.02350449562072754,\n",
       " 0.019273042678833008,\n",
       " 0.019165515899658203,\n",
       " 0.023587703704833984,\n",
       " 0.019948720932006836,\n",
       " 0.021440505981445312,\n",
       " 0.021198034286499023,\n",
       " 0.019675016403198242,\n",
       " 0.02026081085205078,\n",
       " 0.020540952682495117,\n",
       " 0.0198667049407959,\n",
       " 0.01921534538269043,\n",
       " 0.020057201385498047,\n",
       " 0.022623062133789062,\n",
       " 0.020596981048583984,\n",
       " 0.02051997184753418,\n",
       " 0.02133917808532715,\n",
       " 0.01981806755065918,\n",
       " 0.0215911865234375,\n",
       " 0.02112436294555664,\n",
       " 0.02084827423095703,\n",
       " 0.021676301956176758,\n",
       " 0.018947124481201172,\n",
       " 0.020818471908569336,\n",
       " 0.0205080509185791,\n",
       " 0.020051956176757812,\n",
       " 0.023363113403320312,\n",
       " 0.020110130310058594,\n",
       " 0.02160191535949707,\n",
       " 0.0213010311126709,\n",
       " 0.021530628204345703,\n",
       " 0.022612333297729492,\n",
       " 0.022186756134033203,\n",
       " 0.01953601837158203,\n",
       " 0.019748449325561523,\n",
       " 0.019608497619628906,\n",
       " 0.021326303482055664,\n",
       " 0.021682262420654297,\n",
       " 0.019667625427246094,\n",
       " 0.02212238311767578,\n",
       " 0.021617412567138672,\n",
       " 0.02081155776977539,\n",
       " 0.019154787063598633,\n",
       " 0.021234512329101562,\n",
       " 0.02116847038269043,\n",
       " 0.021973371505737305,\n",
       " 0.019080400466918945,\n",
       " 0.020239591598510742,\n",
       " 0.01936936378479004,\n",
       " 0.021477699279785156,\n",
       " 0.02303910255432129,\n",
       " 0.02159738540649414,\n",
       " 0.020961999893188477,\n",
       " 0.02225518226623535,\n",
       " 0.02091693878173828,\n",
       " 0.02078390121459961,\n",
       " 0.021319150924682617,\n",
       " 0.02091193199157715,\n",
       " 0.019489526748657227,\n",
       " 0.020314931869506836,\n",
       " 0.020856857299804688,\n",
       " 0.020949602127075195,\n",
       " 0.01958465576171875,\n",
       " 0.022083520889282227,\n",
       " 0.0206911563873291,\n",
       " 0.01993083953857422,\n",
       " 0.01963520050048828,\n",
       " 0.021007061004638672,\n",
       " 0.020088672637939453,\n",
       " 0.02110123634338379,\n",
       " 0.021489858627319336,\n",
       " 0.02045750617980957,\n",
       " 0.023632049560546875,\n",
       " 0.02042388916015625,\n",
       " 0.021248579025268555,\n",
       " 0.019644498825073242,\n",
       " 0.01912713050842285,\n",
       " 0.019719600677490234,\n",
       " 0.01917576789855957,\n",
       " 0.020475149154663086,\n",
       " 0.019188642501831055,\n",
       " 0.019168853759765625,\n",
       " 0.020058631896972656,\n",
       " 0.019062519073486328,\n",
       " 0.01936173439025879,\n",
       " 0.01936507225036621,\n",
       " 0.019608497619628906,\n",
       " 0.01739048957824707,\n",
       " 0.018625974655151367,\n",
       " 0.019321441650390625,\n",
       " 0.01823711395263672,\n",
       " 0.018396854400634766,\n",
       " 0.020140647888183594,\n",
       " 0.018059968948364258,\n",
       " 0.019476890563964844,\n",
       " 0.016481399536132812,\n",
       " 0.02048969268798828,\n",
       " 0.019481420516967773,\n",
       " 0.019747495651245117,\n",
       " 0.017023086547851562,\n",
       " 0.01972222328186035,\n",
       " 0.01937723159790039,\n",
       " 0.019919633865356445,\n",
       " 0.018189668655395508,\n",
       " 0.019678831100463867,\n",
       " 0.019313335418701172,\n",
       " 0.01818370819091797,\n",
       " 0.020837783813476562,\n",
       " 0.020170927047729492,\n",
       " 0.02206134796142578,\n",
       " 0.021350860595703125,\n",
       " 0.021316051483154297,\n",
       " 0.020891189575195312,\n",
       " 0.02089667320251465,\n",
       " 0.021488428115844727,\n",
       " 0.02121424674987793,\n",
       " 0.021326303482055664,\n",
       " 0.020886659622192383,\n",
       " 0.020555496215820312,\n",
       " 0.020099401473999023,\n",
       " 0.020883798599243164,\n",
       " 0.023235082626342773,\n",
       " 0.019799470901489258,\n",
       " 0.02107524871826172,\n",
       " 0.019367456436157227,\n",
       " 0.024115324020385742,\n",
       " 0.019803762435913086,\n",
       " 0.022844791412353516,\n",
       " 0.020523786544799805,\n",
       " 0.021437406539916992,\n",
       " 0.02208542823791504,\n",
       " 0.020971298217773438,\n",
       " 0.019729137420654297,\n",
       " 0.01998114585876465,\n",
       " 0.02094721794128418,\n",
       " 0.02063441276550293,\n",
       " 0.02019214630126953,\n",
       " 0.021288394927978516,\n",
       " 0.02063775062561035,\n",
       " 0.021292448043823242,\n",
       " 0.023349761962890625,\n",
       " 0.021724462509155273,\n",
       " 0.02040386199951172,\n",
       " 0.020169734954833984,\n",
       " 0.020675182342529297,\n",
       " 0.0209500789642334,\n",
       " 0.020704030990600586,\n",
       " 0.019257545471191406,\n",
       " 0.021803617477416992,\n",
       " 0.022823333740234375,\n",
       " 0.022238492965698242,\n",
       " 0.021407365798950195,\n",
       " 0.019550085067749023,\n",
       " 0.02027297019958496,\n",
       " 0.020955324172973633,\n",
       " 0.02204728126525879,\n",
       " 0.02077007293701172,\n",
       " 0.02082538604736328,\n",
       " 0.021271944046020508,\n",
       " 0.02178645133972168,\n",
       " 0.021040678024291992,\n",
       " 0.01982426643371582,\n",
       " 0.021657228469848633,\n",
       " 0.02051234245300293,\n",
       " 0.021570444107055664,\n",
       " 0.022859811782836914,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average FPS: 82.38782556661648\n",
      "Standard Deviation of FPS: 5.821554012597687\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_fps_stats(inference_times):\n",
    "    \"\"\"\n",
    "    Calculates the average FPS rate and its standard deviation from a list of inference times.\n",
    "\n",
    "    Args:\n",
    "        inference_times (list): A list of inference times in seconds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the average FPS rate and its standard deviation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate FPS for each frame\n",
    "    fps_values = [1 / time for time in inference_times]\n",
    "\n",
    "    # Calculate average FPS\n",
    "    average_fps = np.mean(fps_values)\n",
    "\n",
    "    # Calculate standard deviation of FPS\n",
    "    std_dev_fps = np.std(fps_values)\n",
    "\n",
    "    return average_fps, std_dev_fps\n",
    "\n",
    "average_fps, std_dev_fps = calculate_fps_stats(times)\n",
    "\n",
    "print(\"Average FPS:\", average_fps)\n",
    "print(\"Standard Deviation of FPS:\", std_dev_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21133/1837472020.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'epoch': 263, 'metrics': {'metrics/test.rmse': 3.967074360811349, 'metrics/test.rmse_pcutoff': 3.967074360811349, 'metrics/test.mAP': 100.0, 'metrics/test.mAR': 100.0, 'metrics/test.rmse_detections': 3.967074394226074, 'metrics/test.rmse_detections_pcutoff': 3.967074394226074}, 'losses': {'train.bodypart_heatmap': 0.00014600872236769646, 'train.bodypart_locref': 0.012144822627305984, 'train.bodypart_total_loss': 0.00037662492832168937, 'train.total_loss': 0.00037662492832168937, 'eval.bodypart_heatmap': 0.00018658707267604768, 'eval.bodypart_locref': 0.06498149037361145, 'eval.bodypart_total_loss': 0.0017178307753056288, 'eval.total_loss': 0.0017178307753056288}}, 'model': OrderedDict([('backbone.model.conv1.weight', tensor([[[[-1.1734e-03,  1.8400e-03,  2.8247e-03,  ..., -1.4431e-03,\n",
      "           -5.1662e-03, -1.7045e-03],\n",
      "          [ 3.8750e-04,  4.1279e-03, -1.0452e-03,  ..., -6.8253e-03,\n",
      "           -1.9387e-03,  4.8172e-04],\n",
      "          [ 5.0824e-03,  5.2458e-03,  3.1377e-04,  ..., -1.1233e-02,\n",
      "            4.4244e-03,  7.0866e-03],\n",
      "          ...,\n",
      "          [ 4.0868e-03, -1.4321e-03, -1.9171e-02,  ...,  4.9850e-03,\n",
      "            1.8025e-02,  1.7260e-02],\n",
      "          [-4.0767e-03, -4.9845e-03, -1.2389e-02,  ...,  1.0657e-03,\n",
      "            1.0856e-02,  1.0824e-02],\n",
      "          [-4.6780e-03, -6.9025e-03, -6.7356e-03,  ...,  4.7213e-03,\n",
      "            1.4865e-02,  1.3107e-02]],\n",
      "\n",
      "         [[ 8.3831e-03, -1.7392e-03,  3.6174e-03,  ..., -4.8476e-03,\n",
      "           -6.7051e-03, -4.9014e-03],\n",
      "          [ 5.4753e-03, -3.4296e-03,  3.2082e-03,  ..., -6.6423e-03,\n",
      "           -3.4110e-03, -7.3761e-04],\n",
      "          [-3.4774e-03, -7.2002e-03,  2.5210e-03,  ..., -6.9075e-03,\n",
      "            3.1652e-03, -5.6042e-03],\n",
      "          ...,\n",
      "          [-7.3336e-03, -2.3147e-03,  1.8195e-02,  ...,  2.9443e-02,\n",
      "           -1.2168e-02, -4.4035e-02],\n",
      "          [ 2.2664e-04, -1.0024e-03,  2.1615e-02,  ...,  6.2442e-03,\n",
      "           -5.0507e-02, -5.1025e-02],\n",
      "          [ 1.1362e-02, -1.1863e-02,  3.0826e-03,  ..., -5.0288e-03,\n",
      "           -2.0446e-02, -1.1344e-02]],\n",
      "\n",
      "         [[ 2.7087e-02, -1.7082e-02, -1.7682e-02,  ..., -3.5516e-03,\n",
      "            8.3558e-03,  1.4876e-02],\n",
      "          [ 1.5679e-02, -2.3936e-02, -1.6617e-02,  ..., -2.3666e-03,\n",
      "            4.0337e-03,  2.7436e-03],\n",
      "          [-3.1633e-02, -5.6053e-02,  6.6715e-03,  ...,  3.4435e-02,\n",
      "            6.2796e-03, -2.9654e-02],\n",
      "          ...,\n",
      "          [-2.3345e-02,  4.1167e-03,  1.6032e-01,  ...,  9.2925e-02,\n",
      "           -1.1691e-01, -2.2152e-01],\n",
      "          [ 2.7918e-02,  2.9201e-02,  1.3721e-01,  ..., -1.5408e-02,\n",
      "           -1.9746e-01, -2.2431e-01],\n",
      "          [ 2.5736e-02, -2.6586e-02,  2.4837e-02,  ..., -5.9989e-02,\n",
      "           -1.2857e-01, -1.0280e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1818e-02, -1.0843e-02, -5.8094e-03,  ...,  1.2087e-02,\n",
      "            8.2365e-03, -2.8099e-03],\n",
      "          [ 1.0123e-02,  9.5172e-04, -2.6223e-02,  ..., -3.8325e-03,\n",
      "            2.4876e-02,  1.9908e-02],\n",
      "          [-2.9192e-03, -2.6467e-03, -2.6819e-02,  ..., -1.6718e-01,\n",
      "           -1.3293e-01, -5.4490e-02],\n",
      "          ...,\n",
      "          [-1.3169e-03, -1.4465e-02, -2.9032e-02,  ...,  1.2946e-01,\n",
      "            1.2574e-01,  5.3471e-02],\n",
      "          [-9.3325e-03, -1.2132e-02, -4.5727e-02,  ..., -1.1224e-01,\n",
      "           -3.3631e-02,  2.3534e-02],\n",
      "          [ 1.6114e-03,  9.5180e-03,  1.0226e-02,  ..., -1.9930e-02,\n",
      "           -3.3555e-02, -1.2756e-02]],\n",
      "\n",
      "         [[-5.1736e-03, -1.1401e-02, -6.5958e-03,  ...,  1.4054e-02,\n",
      "            2.7076e-03, -3.3586e-03],\n",
      "          [ 7.8285e-03, -1.9157e-03, -3.3156e-02,  ..., -1.6973e-02,\n",
      "            1.8998e-02,  1.9492e-02],\n",
      "          [-1.1713e-02, -6.1706e-03, -3.5156e-02,  ..., -1.9842e-01,\n",
      "           -1.5839e-01, -6.4948e-02],\n",
      "          ...,\n",
      "          [ 9.3135e-03, -2.8707e-03, -1.2573e-02,  ...,  1.5766e-01,\n",
      "            1.5104e-01,  6.1314e-02],\n",
      "          [-1.1371e-02, -2.3910e-02, -5.4820e-02,  ..., -1.2788e-01,\n",
      "           -4.0836e-02,  1.6960e-02],\n",
      "          [ 3.2404e-04,  5.2594e-03,  1.2613e-02,  ..., -1.6970e-02,\n",
      "           -3.0513e-02, -7.6800e-03]],\n",
      "\n",
      "         [[-6.6267e-03, -7.8357e-03,  1.8724e-04,  ...,  1.8809e-03,\n",
      "            4.3579e-04, -7.8104e-03],\n",
      "          [ 4.6346e-03,  1.9360e-03, -6.0629e-03,  ...,  1.2522e-02,\n",
      "            2.7775e-02,  1.1316e-02],\n",
      "          [-1.0782e-02, -1.3018e-02, -2.2786e-02,  ..., -1.0079e-01,\n",
      "           -6.6272e-02, -2.1969e-02],\n",
      "          ...,\n",
      "          [ 1.2819e-02,  1.7279e-03, -2.1472e-02,  ...,  6.9384e-02,\n",
      "            7.5381e-02,  2.3742e-02],\n",
      "          [-1.1094e-02, -6.3011e-03, -1.7823e-02,  ..., -8.5730e-02,\n",
      "           -2.8064e-02, -5.8966e-03],\n",
      "          [-2.9412e-03, -1.6695e-03,  7.6203e-03,  ...,  2.0614e-03,\n",
      "           -7.1656e-03, -9.7257e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1976e-02,  1.5481e-02, -4.7873e-03,  ..., -1.3708e-02,\n",
      "            1.2245e-02, -6.2732e-03],\n",
      "          [ 1.8061e-02, -1.9526e-02, -7.6021e-02,  ..., -2.4476e-02,\n",
      "            1.7691e-02, -3.5460e-03],\n",
      "          [-1.2319e-02, -7.8276e-02, -1.1796e-01,  ...,  2.3060e-02,\n",
      "            4.5632e-02, -7.4658e-03],\n",
      "          ...,\n",
      "          [ 4.4151e-03, -7.8947e-03,  7.5886e-03,  ...,  1.4975e-01,\n",
      "            7.2877e-02, -3.7090e-02],\n",
      "          [-9.4557e-04, -7.0420e-03,  1.9053e-02,  ...,  6.2839e-02,\n",
      "           -1.3489e-02, -8.9893e-02],\n",
      "          [-1.0487e-02, -3.8763e-03,  2.4688e-02,  ..., -1.5948e-02,\n",
      "           -7.0601e-02, -7.3037e-02]],\n",
      "\n",
      "         [[ 3.9833e-02,  3.1349e-02, -1.2981e-02,  ..., -3.8367e-02,\n",
      "            3.0345e-03,  4.1519e-03],\n",
      "          [ 3.4142e-02, -2.9508e-02, -1.1053e-01,  ..., -4.7748e-02,\n",
      "            1.9952e-02,  5.2469e-03],\n",
      "          [-1.9107e-02, -1.2392e-01, -1.7244e-01,  ...,  2.0014e-02,\n",
      "            6.4755e-02,  1.8792e-02],\n",
      "          ...,\n",
      "          [-1.1935e-02, -4.0300e-02, -6.1368e-03,  ...,  2.1194e-01,\n",
      "            9.4453e-02, -3.3537e-02],\n",
      "          [-8.1600e-03, -1.6124e-02,  3.2044e-02,  ...,  1.1687e-01,\n",
      "           -9.6095e-03, -1.0105e-01],\n",
      "          [-5.0163e-03, -3.0744e-03,  3.8515e-02,  ..., -8.4907e-03,\n",
      "           -9.2889e-02, -8.4977e-02]],\n",
      "\n",
      "         [[ 6.0766e-03,  1.5240e-02, -3.1039e-03,  ..., -1.0645e-02,\n",
      "            5.7277e-03, -1.9996e-03],\n",
      "          [ 1.1453e-02, -1.2975e-03, -3.5687e-02,  ..., -1.6138e-02,\n",
      "            8.1178e-03, -6.9524e-03],\n",
      "          [-2.1227e-03, -3.6406e-02, -5.8435e-02,  ...,  7.6464e-04,\n",
      "            1.4493e-02, -8.4283e-03],\n",
      "          ...,\n",
      "          [ 3.2918e-03, -2.4590e-03, -1.4063e-02,  ...,  6.0360e-02,\n",
      "            3.0190e-02, -1.3018e-02],\n",
      "          [-2.3095e-03, -7.2629e-03, -1.2918e-03,  ...,  3.2904e-02,\n",
      "            5.4445e-03, -3.7139e-02],\n",
      "          [-4.4753e-03, -1.9673e-03,  4.5245e-03,  ..., -1.0479e-02,\n",
      "           -3.6606e-02, -3.6356e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.4142e-03, -2.1432e-04, -1.8190e-04,  ...,  2.6516e-03,\n",
      "            5.4140e-03, -7.2974e-04],\n",
      "          [-1.8129e-03,  3.0768e-03,  1.0407e-02,  ..., -4.2028e-03,\n",
      "           -7.9191e-03,  1.1834e-03],\n",
      "          [ 1.4165e-03, -1.2866e-02, -1.7157e-02,  ...,  5.4749e-02,\n",
      "            4.3692e-02, -7.1272e-04],\n",
      "          ...,\n",
      "          [-9.4689e-04, -4.6894e-04,  4.3952e-02,  ...,  2.1418e-01,\n",
      "            1.1873e-01,  1.4828e-02],\n",
      "          [-4.0989e-03, -1.0839e-02, -5.4748e-02,  ..., -1.6354e-01,\n",
      "           -7.4860e-02, -1.0541e-02],\n",
      "          [ 5.1115e-03,  4.5068e-03,  2.6699e-02,  ...,  6.1202e-02,\n",
      "            2.6270e-02,  5.0513e-04]],\n",
      "\n",
      "         [[-2.2595e-03,  3.9380e-03, -1.4466e-03,  ..., -4.0784e-03,\n",
      "            5.7480e-03,  5.7266e-03],\n",
      "          [-3.6478e-03, -2.7574e-04,  9.3746e-03,  ..., -3.5213e-03,\n",
      "           -9.1199e-03,  2.2742e-03],\n",
      "          [ 2.4360e-03, -1.1823e-02, -1.1356e-02,  ...,  6.1367e-02,\n",
      "            5.7086e-02,  2.9751e-03],\n",
      "          ...,\n",
      "          [ 3.9277e-03,  3.6251e-03,  5.6189e-02,  ...,  2.5977e-01,\n",
      "            1.4588e-01,  2.4001e-02],\n",
      "          [-5.6276e-03, -6.8854e-03, -6.2705e-02,  ..., -1.8795e-01,\n",
      "           -7.7243e-02, -6.5728e-03],\n",
      "          [ 1.9124e-03,  5.7188e-04,  2.5445e-02,  ...,  5.4264e-02,\n",
      "            1.9193e-02, -2.5402e-03]],\n",
      "\n",
      "         [[ 1.5133e-03,  2.7781e-03, -1.8148e-03,  ...,  1.7788e-03,\n",
      "            3.2028e-03,  4.5173e-03],\n",
      "          [-5.2059e-03,  1.3756e-03,  3.9126e-03,  ..., -1.4084e-02,\n",
      "           -1.2764e-02, -4.8353e-03],\n",
      "          [-3.2220e-04, -7.9308e-03, -3.5106e-03,  ...,  6.7435e-02,\n",
      "            5.2109e-02,  1.2207e-02],\n",
      "          ...,\n",
      "          [-1.5104e-03, -2.7269e-03,  3.1493e-02,  ...,  1.6962e-01,\n",
      "            8.3051e-02,  7.8761e-03],\n",
      "          [-4.3938e-03,  4.4892e-04, -3.3072e-02,  ..., -1.2170e-01,\n",
      "           -4.8742e-02,  6.2114e-03],\n",
      "          [ 7.5466e-04, -2.1109e-03,  1.2918e-02,  ...,  4.0808e-02,\n",
      "            1.3805e-02, -1.3926e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.4165e-03, -1.0459e-02, -5.1144e-03,  ..., -7.8246e-04,\n",
      "            2.1691e-03, -6.3636e-03],\n",
      "          [-8.2769e-03, -3.8802e-03, -8.2512e-03,  ...,  7.9225e-04,\n",
      "           -4.8156e-03, -4.5225e-03],\n",
      "          [-8.2705e-03, -1.0596e-02, -7.9995e-03,  ...,  1.1382e-02,\n",
      "            2.0498e-03, -7.5115e-03],\n",
      "          ...,\n",
      "          [ 3.7907e-03, -1.9415e-03, -7.1563e-03,  ..., -1.3794e-02,\n",
      "            6.1897e-03, -1.6245e-03],\n",
      "          [-3.4707e-03,  2.2449e-03,  8.3403e-03,  ...,  5.4192e-04,\n",
      "            6.0456e-03, -7.3917e-03],\n",
      "          [-8.2687e-03,  2.0058e-05,  7.2335e-03,  ...,  5.1520e-03,\n",
      "           -3.7709e-03, -3.7343e-03]],\n",
      "\n",
      "         [[-4.9588e-03,  2.1342e-03,  6.4050e-03,  ..., -2.1136e-04,\n",
      "            3.3780e-03,  2.6293e-03],\n",
      "          [-3.4285e-03,  8.4135e-03,  7.2568e-03,  ..., -4.6264e-04,\n",
      "            8.9345e-03,  1.4532e-02],\n",
      "          [ 3.3017e-04,  2.3171e-03, -2.2348e-03,  ...,  1.6736e-02,\n",
      "            9.7672e-03,  3.0537e-03],\n",
      "          ...,\n",
      "          [-4.9892e-03, -1.0085e-02, -3.4475e-02,  ..., -5.1165e-02,\n",
      "            6.1298e-05,  1.2666e-02],\n",
      "          [-3.9403e-03, -4.0298e-03,  3.7119e-03,  ..., -1.5130e-02,\n",
      "            2.9743e-03,  7.0110e-03],\n",
      "          [-9.7449e-04, -1.6909e-03,  5.9618e-03,  ...,  2.9765e-03,\n",
      "            2.3161e-03,  9.1377e-03]],\n",
      "\n",
      "         [[ 1.1210e-02,  6.7449e-03,  1.0299e-02,  ...,  1.2628e-02,\n",
      "            4.8978e-03,  9.5059e-03],\n",
      "          [ 5.7753e-03,  4.5290e-03,  3.6447e-03,  ..., -5.5139e-04,\n",
      "           -7.1058e-03,  3.2542e-03],\n",
      "          [ 1.8031e-03,  4.4530e-03,  7.9554e-03,  ...,  5.5132e-03,\n",
      "           -2.6098e-03,  8.7617e-04],\n",
      "          ...,\n",
      "          [-3.5586e-03, -5.4914e-03, -2.2756e-02,  ..., -8.4720e-02,\n",
      "           -4.9989e-03, -7.5529e-03],\n",
      "          [-2.1845e-04,  4.7580e-03, -2.9432e-03,  ..., -3.3162e-02,\n",
      "            1.9806e-03, -8.7562e-03],\n",
      "          [ 3.9492e-03,  4.9294e-04,  2.5223e-03,  ...,  3.2952e-03,\n",
      "            1.0249e-03,  6.6666e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.6252e-02, -2.0741e-02, -2.6643e-02,  ...,  3.4344e-02,\n",
      "           -1.3835e-02, -6.8427e-03],\n",
      "          [-4.3702e-03, -2.7835e-02, -7.4385e-02,  ...,  8.7817e-02,\n",
      "           -2.8869e-02, -3.2836e-02],\n",
      "          [ 6.0272e-03,  8.1997e-03, -1.4659e-01,  ...,  1.7337e-01,\n",
      "            1.9621e-02, -4.1644e-02],\n",
      "          ...,\n",
      "          [ 1.0217e-03,  8.8249e-02,  8.1954e-02,  ..., -1.0497e-01,\n",
      "            1.7078e-01,  3.0661e-02],\n",
      "          [-1.6981e-02,  2.9942e-02,  1.5218e-01,  ..., -2.2044e-01,\n",
      "            2.9432e-02,  6.1500e-02],\n",
      "          [-1.0169e-02, -1.5923e-02,  7.3051e-02,  ..., -9.1184e-02,\n",
      "           -8.0410e-02,  2.3245e-02]],\n",
      "\n",
      "         [[-5.1445e-04, -9.7249e-03, -2.5018e-02,  ...,  2.8500e-02,\n",
      "           -2.3144e-02, -8.7827e-03],\n",
      "          [ 2.7765e-03,  3.2481e-03, -5.4628e-02,  ...,  8.3189e-02,\n",
      "           -3.7555e-02, -2.8323e-02],\n",
      "          [ 3.4694e-03,  1.9220e-02, -1.2043e-01,  ...,  1.6152e-01,\n",
      "            1.4668e-03, -5.0136e-02],\n",
      "          ...,\n",
      "          [-5.2511e-03,  6.9149e-02,  8.0405e-02,  ..., -7.9098e-02,\n",
      "            1.6944e-01,  2.0187e-03],\n",
      "          [-9.9016e-03,  1.1483e-03,  1.3750e-01,  ..., -1.9587e-01,\n",
      "            4.0160e-02,  4.6761e-02],\n",
      "          [-8.5569e-03, -2.7737e-02,  5.0273e-02,  ..., -6.8416e-02,\n",
      "           -5.0162e-02,  2.0372e-02]],\n",
      "\n",
      "         [[ 6.7215e-03, -7.4823e-03, -2.3550e-02,  ...,  1.3188e-02,\n",
      "           -1.2457e-02, -2.5783e-03],\n",
      "          [ 9.1104e-03,  1.4601e-02, -1.9801e-02,  ...,  1.7950e-02,\n",
      "           -3.1331e-02,  1.7585e-03],\n",
      "          [-9.0108e-03,  1.5389e-02, -4.6844e-02,  ...,  4.6736e-02,\n",
      "           -3.0001e-02, -2.2392e-02],\n",
      "          ...,\n",
      "          [-6.0634e-03,  8.2634e-03,  7.3234e-02,  ..., -1.1329e-02,\n",
      "            7.9805e-02, -3.2138e-02],\n",
      "          [-9.6151e-03, -2.7836e-02,  6.1372e-02,  ..., -7.8082e-02,\n",
      "            3.3029e-02, -2.9617e-03],\n",
      "          [ 9.9649e-03, -2.8591e-02, -9.3271e-04,  ..., -1.1290e-02,\n",
      "            9.5008e-04,  1.1145e-02]]]], device='cuda:0')), ('backbone.model.bn1.weight', tensor([1.7876, 2.5254, 1.6390, 2.9114, 1.2332, 1.8373, 1.4545, 2.5826, 2.6530,\n",
      "        1.4469, 3.3580, 1.3236, 1.3181, 3.5734, 2.6170, 4.3175, 1.4212, 3.6755,\n",
      "        2.1573, 2.1476, 1.3405, 2.1181, 3.9769, 1.6498, 3.2134, 1.9369, 2.0425,\n",
      "        3.2870, 2.6476, 1.5937, 2.1775, 2.5328, 2.0269, 1.9120, 3.4547, 1.1965,\n",
      "        1.5909, 3.1216, 4.5299, 0.8388, 2.0152, 2.7532, 2.4780, 8.6496, 3.4165,\n",
      "        1.6702, 1.4704, 1.9562, 1.3331, 2.2066, 4.0105, 0.9839, 1.4432, 2.9148,\n",
      "        1.8772, 1.5722, 5.3290, 0.8459, 2.6959, 1.7604, 1.3635, 2.4899, 3.6431,\n",
      "        1.7896], device='cuda:0')), ('backbone.model.bn1.bias', tensor([ 0.1870,  0.1582,  0.3879,  0.5360,  0.1836,  0.2910,  0.1354,  0.3151,\n",
      "         0.0989,  0.2400, -1.2663,  0.8283,  0.9292,  1.7492,  0.6620,  0.1066,\n",
      "         0.3386,  0.3458,  0.4554,  1.5663,  0.2046,  0.0425,  0.0411,  0.4502,\n",
      "         0.1171,  0.3353,  0.2995,  0.1214,  0.1926,  0.3422,  0.9238,  2.0051,\n",
      "         0.1793,  0.1056,  1.3729,  1.0369,  0.9453,  1.2361,  3.0312,  0.9495,\n",
      "         0.3352,  0.1524,  0.5253,  0.1007,  0.2322,  0.3498,  0.3236,  0.2153,\n",
      "         0.1422,  0.1549,  2.5448,  0.8512,  0.2327,  0.0063,  0.2356,  0.1698,\n",
      "         1.0967,  0.7192,  0.5527,  0.4744,  0.2992,  0.0085, -2.2687,  1.2773],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.conv1.weight', tensor([[[[ 0.0087]],\n",
      "\n",
      "         [[ 0.0946]],\n",
      "\n",
      "         [[-0.0479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[ 0.0272]],\n",
      "\n",
      "         [[ 0.0426]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0287]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[ 0.0322]],\n",
      "\n",
      "         [[-0.0192]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0645]],\n",
      "\n",
      "         [[-0.0273]],\n",
      "\n",
      "         [[-0.1008]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[-0.0006]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0241]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.0207]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1038]],\n",
      "\n",
      "         [[ 0.0245]],\n",
      "\n",
      "         [[ 0.0904]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[-0.0304]],\n",
      "\n",
      "         [[-0.1172]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0925]],\n",
      "\n",
      "         [[ 0.0123]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         [[ 0.0239]]]], device='cuda:0')), ('backbone.model.layer1.0.bn1.weight', tensor([1.7428, 1.5640, 1.3053, 1.7825, 4.1857, 2.1554, 1.4645, 1.6804, 2.3791,\n",
      "        1.2556, 2.7384, 6.0693, 1.5955, 2.7801, 1.2149, 3.0980, 3.6712, 1.7295,\n",
      "        3.3715, 1.2341, 1.5174, 2.1061, 1.5205, 1.7611, 3.3311, 3.1296, 2.4081,\n",
      "        8.9941, 5.3295, 4.2380, 1.5728, 1.2217, 2.8876, 2.0055, 1.5555, 1.8953,\n",
      "        1.4974, 1.2801, 1.1860, 2.3449, 1.5353, 4.2369, 2.2893, 1.2913, 1.9702,\n",
      "        1.4982, 1.2804, 1.7228, 2.4568, 1.1380, 2.2174, 2.5969, 1.4088, 9.6609,\n",
      "        1.3526, 1.0051, 9.5551, 1.9973, 1.5984, 2.3720, 1.2752, 2.1899, 0.9772,\n",
      "        1.3504], device='cuda:0')), ('backbone.model.layer1.0.bn1.bias', tensor([ 6.1224e-01,  9.3451e-01, -7.9850e-03, -1.6505e-01,  9.9099e-01,\n",
      "         1.1976e+00,  3.7401e-02, -3.8077e-01, -5.1089e-01,  4.0862e-01,\n",
      "         4.6635e-01,  1.6425e+00, -2.3324e-01,  1.0812e+00, -1.0186e-01,\n",
      "         1.7760e+00,  3.0722e+00, -1.3958e+00,  3.9264e-01,  3.8957e-01,\n",
      "        -1.2142e-01,  9.3095e-01,  9.2406e-01, -2.1482e-01, -5.0555e-01,\n",
      "         5.4879e-01,  1.5769e-01,  1.5228e+00, -4.7571e-01, -1.8751e+00,\n",
      "         4.5959e-01,  2.4259e-01, -1.0087e+00,  9.8247e-01,  6.9772e-01,\n",
      "        -8.3210e-01,  1.0253e+00,  6.0734e-01,  3.6186e-01,  2.5036e-02,\n",
      "         9.1700e+00, -2.0061e+00,  3.0220e-02,  7.3245e-01,  3.1733e-01,\n",
      "         4.6182e-01,  3.4267e-01, -3.1618e-01,  9.8911e-01, -3.4359e-03,\n",
      "        -6.1637e-01,  4.8761e-01,  2.2192e-01,  1.8227e+00,  9.3184e-01,\n",
      "        -3.4683e-01,  1.5472e+00,  1.6594e-01,  1.0993e+00, -6.4279e-01,\n",
      "        -4.8168e-02, -1.5863e-02,  4.3915e-02,  7.5184e-02], device='cuda:0')), ('backbone.model.layer1.0.conv2.weight', tensor([[[[ 2.4695e-02,  1.0086e-02, -2.3858e-02],\n",
      "          [ 1.9179e-02,  6.0027e-03,  6.0981e-02],\n",
      "          [-4.0315e-03,  1.9103e-02,  4.8191e-02]],\n",
      "\n",
      "         [[ 1.0775e-01,  7.3541e-02,  4.2278e-02],\n",
      "          [ 1.5126e-01, -3.1031e-01, -1.2756e-01],\n",
      "          [ 1.0151e-01, -1.1620e-01, -1.0673e-01]],\n",
      "\n",
      "         [[-3.9536e-02, -6.3275e-02, -3.9595e-02],\n",
      "          [-3.6045e-03,  3.5791e-02,  6.4414e-02],\n",
      "          [-1.4039e-02,  1.0507e-01,  4.4776e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9047e-02,  7.1056e-03, -1.0831e-02],\n",
      "          [ 7.2402e-03,  2.5787e-02,  3.2578e-02],\n",
      "          [-2.8757e-02,  1.3951e-02,  2.1063e-03]],\n",
      "\n",
      "         [[ 9.4783e-03, -1.0199e-01,  5.0988e-02],\n",
      "          [-2.0060e-01,  1.0124e-01, -9.4664e-03],\n",
      "          [-6.7429e-02, -6.0749e-02, -1.5019e-01]],\n",
      "\n",
      "         [[-5.9941e-02,  9.1738e-03, -2.9570e-02],\n",
      "          [ 3.1002e-02, -1.6512e-01,  9.7076e-02],\n",
      "          [ 1.1224e-01, -1.1444e-01, -4.5157e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2259e-02,  2.4440e-02, -4.7731e-02],\n",
      "          [-9.2976e-02, -6.2424e-02,  1.4603e-02],\n",
      "          [-5.1080e-02,  6.1620e-02, -5.5175e-02]],\n",
      "\n",
      "         [[-3.6038e-03, -3.0751e-02,  9.4263e-03],\n",
      "          [-6.1979e-02,  8.6602e-03,  7.3297e-02],\n",
      "          [-1.8606e-02,  1.1381e-02,  2.7863e-02]],\n",
      "\n",
      "         [[ 3.1933e-02, -1.1556e-02, -1.2463e-02],\n",
      "          [ 1.1482e-02, -1.2715e-02, -2.9173e-03],\n",
      "          [ 3.5213e-02, -6.5394e-03,  3.0486e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0441e-02, -3.4228e-02,  1.0113e-01],\n",
      "          [ 2.3258e-02, -6.2896e-02,  8.2580e-02],\n",
      "          [ 6.7176e-02, -3.0926e-02,  4.2220e-02]],\n",
      "\n",
      "         [[-2.0710e-02,  2.7758e-02,  1.0272e-02],\n",
      "          [-1.2627e-01, -2.1827e-02, -2.8443e-02],\n",
      "          [-4.4869e-02, -1.8450e-02,  1.4296e-02]],\n",
      "\n",
      "         [[-1.0840e-02,  3.4252e-02,  6.8873e-02],\n",
      "          [-9.4221e-02,  1.2409e-01,  4.5053e-02],\n",
      "          [-1.6312e-02,  5.6827e-02,  4.1549e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8605e-02,  1.1836e-01, -3.1557e-02],\n",
      "          [ 1.6018e-01, -2.0068e-01, -4.3765e-02],\n",
      "          [ 6.9260e-02,  1.3684e-01, -3.2580e-02]],\n",
      "\n",
      "         [[ 2.7935e-02, -1.1802e-02,  5.9540e-03],\n",
      "          [-5.3205e-02,  7.5071e-02,  1.6758e-02],\n",
      "          [-1.9096e-02,  1.8013e-02,  1.0237e-02]],\n",
      "\n",
      "         [[-3.4140e-03, -3.2729e-02, -2.7878e-02],\n",
      "          [ 2.3979e-02,  1.3011e-02, -5.8251e-02],\n",
      "          [ 2.2897e-03,  1.0760e-02, -5.2589e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8977e-03,  1.9190e-02, -4.0983e-02],\n",
      "          [ 1.5535e-02,  1.8962e-02, -2.7518e-02],\n",
      "          [ 7.4788e-03,  2.8785e-02, -1.8197e-02]],\n",
      "\n",
      "         [[-3.0588e-03, -1.9175e-03,  6.1002e-03],\n",
      "          [-1.9269e-02, -4.2068e-02,  1.9014e-02],\n",
      "          [ 2.3260e-04, -4.8872e-02,  3.5621e-02]],\n",
      "\n",
      "         [[ 5.9145e-02, -5.3843e-03, -9.0316e-03],\n",
      "          [ 4.0422e-02, -1.9398e-02,  3.7339e-02],\n",
      "          [ 1.1750e-02, -2.2100e-02, -1.1058e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4277e-02, -3.6728e-02,  4.7166e-03],\n",
      "          [-7.5175e-02,  2.2898e-02, -1.1619e-02],\n",
      "          [ 1.1038e-02, -2.4845e-03,  1.5966e-02]],\n",
      "\n",
      "         [[-3.4809e-02, -8.5511e-02, -3.9355e-02],\n",
      "          [ 2.5847e-02,  4.3613e-02,  6.3030e-02],\n",
      "          [ 2.7137e-02,  8.3270e-02, -4.6762e-03]],\n",
      "\n",
      "         [[-1.8493e-01, -9.2023e-02,  6.9007e-02],\n",
      "          [-9.2960e-02,  7.8971e-02,  2.2204e-01],\n",
      "          [ 8.3000e-02,  2.3836e-01,  2.2416e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.5713e-02, -1.4519e-02, -4.5565e-02],\n",
      "          [ 4.0620e-02,  7.0114e-02,  4.2747e-02],\n",
      "          [-3.5114e-03,  3.8729e-02,  8.3594e-02]],\n",
      "\n",
      "         [[-1.3570e-01,  4.0938e-02, -1.3230e-02],\n",
      "          [ 1.3934e-01,  1.2637e-01,  1.2041e-01],\n",
      "          [ 1.0908e-03,  5.9505e-02, -5.2806e-02]],\n",
      "\n",
      "         [[ 4.6313e-02, -5.2850e-02, -6.7227e-02],\n",
      "          [ 6.8413e-02,  6.5659e-02,  7.4004e-02],\n",
      "          [-8.3317e-02, -7.1110e-02, -4.1374e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7298e-02, -3.1057e-02,  2.2961e-02],\n",
      "          [-1.0007e-02, -4.8924e-02, -7.3099e-02],\n",
      "          [ 1.3376e-02, -4.7736e-02,  2.4357e-02]],\n",
      "\n",
      "         [[-7.8698e-03,  9.4809e-02,  1.1155e-01],\n",
      "          [ 1.6513e-02,  2.0548e-02,  6.1094e-02],\n",
      "          [-5.0944e-02, -1.2808e-02,  1.9099e-02]],\n",
      "\n",
      "         [[-6.7879e-03, -6.3103e-02, -6.5972e-02],\n",
      "          [ 1.2818e-03,  6.8528e-05, -1.7127e-02],\n",
      "          [-6.9763e-02,  3.1822e-02, -1.3510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9746e-02,  3.3414e-02,  2.0539e-03],\n",
      "          [ 2.2262e-02, -2.1942e-02,  9.3135e-03],\n",
      "          [-9.0557e-03,  4.4289e-02, -1.7880e-02]],\n",
      "\n",
      "         [[ 1.0962e-01, -2.2386e-03, -1.0721e-01],\n",
      "          [-7.6908e-02,  7.2222e-02,  6.6477e-02],\n",
      "          [-1.2113e-03, -2.3103e-02,  4.1097e-02]],\n",
      "\n",
      "         [[ 5.4525e-03, -1.0068e-01,  7.3182e-03],\n",
      "          [-5.8898e-02,  1.2019e-01, -5.8150e-02],\n",
      "          [ 3.7028e-02,  2.0137e-03,  7.4818e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7099e-02, -4.0706e-02,  2.0972e-02],\n",
      "          [ 1.1825e-01, -1.1538e-01,  1.0786e-01],\n",
      "          [ 4.6835e-02, -1.2157e-01,  2.8924e-02]],\n",
      "\n",
      "         [[ 1.2303e-01, -6.7888e-03, -4.3418e-02],\n",
      "          [ 7.7517e-02,  2.9168e-02,  9.3061e-03],\n",
      "          [-5.9690e-02, -4.7820e-02,  1.4894e-01]],\n",
      "\n",
      "         [[-4.2981e-02,  4.1343e-02, -8.8989e-03],\n",
      "          [ 5.0757e-02,  5.9587e-02, -2.7312e-02],\n",
      "          [-1.2416e-02, -2.0976e-02, -1.7179e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0532e-02,  2.7845e-02, -2.6771e-02],\n",
      "          [-3.9314e-02,  2.0444e-02, -3.6263e-02],\n",
      "          [-2.6364e-02,  2.3681e-02, -2.1631e-02]],\n",
      "\n",
      "         [[-8.4341e-02, -4.2637e-02,  6.0411e-02],\n",
      "          [-5.9907e-02,  2.4596e-02,  5.7906e-02],\n",
      "          [ 2.0350e-02, -7.8071e-04, -3.0761e-02]],\n",
      "\n",
      "         [[-1.0927e-02,  3.3617e-02,  2.8152e-02],\n",
      "          [-3.6588e-02,  2.9720e-02, -3.8277e-02],\n",
      "          [-3.9068e-02,  1.3212e-02, -3.9667e-02]]]], device='cuda:0')), ('backbone.model.layer1.0.bn2.weight', tensor([2.3098, 6.2165, 2.3180, 2.3186, 1.7283, 2.2958, 1.8183, 1.8273, 1.7565,\n",
      "        1.6705, 2.2368, 7.1225, 1.8691, 1.6268, 1.4413, 1.5248, 1.8891, 1.3580,\n",
      "        1.4509, 1.5953, 2.3563, 2.3276, 1.6597, 1.3249, 1.6593, 2.4352, 1.9265,\n",
      "        1.5715, 5.7173, 2.8938, 1.7565, 2.0056, 1.5090, 2.2284, 2.1027, 1.4202,\n",
      "        2.0672, 1.7560, 2.5711, 1.4537, 1.6233, 1.5005, 3.2902, 8.1475, 1.4744,\n",
      "        1.7990, 1.6299, 1.5976, 1.9617, 1.3232, 1.8432, 1.6721, 0.5588, 1.1917,\n",
      "        1.4744, 2.3719, 1.5472, 2.0343, 0.8025, 1.4810, 2.1802, 1.0507, 1.3812,\n",
      "        1.8187], device='cuda:0')), ('backbone.model.layer1.0.bn2.bias', tensor([-2.1738,  1.9930, -1.3362,  2.4051, -1.2322,  2.2132, -1.5980,  1.6567,\n",
      "        -1.4899,  1.6784, -1.8888,  2.5312, -1.6420,  1.3859,  1.1871, -1.3834,\n",
      "        -1.7274,  1.5120,  1.3241, -1.4442,  1.0726, -1.8409, -0.9557,  1.5892,\n",
      "        -1.3159,  2.0348, -1.3388,  1.5511,  0.6281, -2.9204,  1.6924, -1.7380,\n",
      "         1.6418, -1.9118, -1.5958,  1.4056,  1.9835, -1.4126, -2.3350,  1.4418,\n",
      "        -1.3811,  1.2999, -2.1558,  1.7961, -0.8399,  1.6280, -1.0014,  1.5985,\n",
      "        -1.5810,  1.4080, -1.5983,  1.6440, -0.7707,  0.3458,  1.6200, -1.6320,\n",
      "         1.4304, -1.6285,  0.8211, -1.4379, -1.2181,  0.8637,  1.4042, -1.1860],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.conv3.weight', tensor([[[[ 0.0471]],\n",
      "\n",
      "         [[-0.0243]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1113]],\n",
      "\n",
      "         [[ 0.0606]],\n",
      "\n",
      "         [[ 0.0177]]],\n",
      "\n",
      "\n",
      "        [[[-0.0099]],\n",
      "\n",
      "         [[ 0.0063]],\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0115]],\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[-0.0154]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0244]],\n",
      "\n",
      "         [[ 0.0236]],\n",
      "\n",
      "         [[-0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[-0.0357]],\n",
      "\n",
      "         [[-0.0455]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1043]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         [[-0.0537]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0782]],\n",
      "\n",
      "         [[ 0.0146]],\n",
      "\n",
      "         [[ 0.0520]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0484]],\n",
      "\n",
      "         [[ 0.0423]],\n",
      "\n",
      "         [[-0.0275]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0490]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[-0.0132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1716]],\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         [[ 0.0414]]]], device='cuda:0')), ('backbone.model.layer1.0.bn3.weight', tensor([-1.7403e+00,  4.2860e+00, -8.3712e-01, -3.2366e-01,  8.6464e-01,\n",
      "        -7.2928e-02,  3.2385e-01,  5.9597e-01,  3.5978e+00,  1.9886e+00,\n",
      "         5.5826e-02, -2.0875e-02,  2.9070e-02,  1.4638e+00, -1.7539e+00,\n",
      "        -7.7749e-01,  1.6916e+00,  9.6337e-01,  1.3972e+00, -3.3203e+00,\n",
      "         6.8063e-01,  1.0032e+00,  3.2995e-01, -9.5716e-01, -3.6745e+00,\n",
      "        -2.2638e+00,  1.1687e+00,  2.2973e+00,  3.5441e+00, -1.6387e+00,\n",
      "         3.6984e-01,  3.7155e+00, -5.5645e-01, -1.4268e+00,  3.9574e+00,\n",
      "        -3.9116e-02,  1.6752e-01, -3.3708e+00, -7.6030e-02, -4.0946e+00,\n",
      "         2.5805e-01, -2.5423e+00,  1.1727e+00, -1.3917e+00,  2.7416e+00,\n",
      "        -2.4714e+00,  4.4907e+00,  2.2306e-01,  1.7217e-02,  5.6961e-01,\n",
      "        -2.7793e-01,  1.5344e+00, -6.1234e-01,  1.2075e+00,  3.0612e+00,\n",
      "        -4.5734e-01, -1.1394e+00,  3.2970e+00,  1.4025e-01,  2.6926e+00,\n",
      "        -1.2162e+00, -6.0115e-01, -1.2616e+00, -7.2392e-02, -2.4452e+00,\n",
      "         1.1570e+00,  1.1009e+00, -1.5510e+00, -8.1254e-01,  1.3607e+00,\n",
      "         1.8647e+00,  1.8940e+00,  3.4161e+00,  2.6060e+00,  1.8309e+00,\n",
      "        -1.0592e+00,  5.1433e-01, -9.6745e-01, -9.2458e-01, -2.7540e+00,\n",
      "         1.6803e+00, -7.6127e+00, -2.8176e-01, -1.3732e+00,  5.0447e-01,\n",
      "        -4.0315e-01, -1.6604e+00, -2.4661e+00, -1.0735e+00,  4.1993e+00,\n",
      "        -1.4183e+00,  1.7483e+00,  1.2293e+00,  1.5896e+00, -2.4396e+00,\n",
      "         6.5198e-01, -2.6625e-02,  1.0285e+00, -2.2452e+00,  3.6153e+00,\n",
      "         3.6720e+00, -2.0815e+00,  3.3318e+00, -5.8989e-01,  8.7778e-01,\n",
      "        -2.4334e+00,  1.1643e+00, -3.4707e-01, -1.2429e+00, -8.5423e-01,\n",
      "        -1.7891e+00, -4.3558e-01,  1.5574e+00,  1.5729e+00,  9.5818e-01,\n",
      "        -1.8076e+00, -1.0501e+00, -1.3097e+00,  1.2108e+00, -3.2071e+00,\n",
      "        -1.8087e+00,  2.5271e+00,  2.6632e+00, -1.0835e+00,  2.5458e-01,\n",
      "        -1.5114e+00, -2.0092e+00,  9.2493e-01,  9.0242e-02, -1.3594e+00,\n",
      "         3.3692e+00,  2.4189e+00, -3.5297e-01, -1.2694e+00, -2.5830e+00,\n",
      "        -4.3125e+00,  3.1018e-02, -2.7532e+00,  1.5526e+00, -2.7741e+00,\n",
      "        -6.5347e-01, -7.7601e-02,  1.2397e+00, -2.8213e-01,  3.9739e+00,\n",
      "        -6.4317e+00,  1.0187e+00, -1.9177e+00, -8.0499e-01,  1.3661e+00,\n",
      "         3.4885e+00, -2.1841e+00,  7.8059e-01, -3.4142e+00,  1.4708e+00,\n",
      "         3.5233e+00, -3.0034e+00,  1.3043e+00, -3.1105e+00, -2.2040e+00,\n",
      "         2.3435e+00,  9.2082e-01,  9.5136e-01, -9.8944e-01, -2.2832e+00,\n",
      "        -1.7902e+00, -3.2788e-01,  1.0309e+00, -2.2042e+00, -1.4048e+00,\n",
      "         4.3582e-01, -1.2033e+00,  1.5434e+00, -1.6029e+00,  3.5200e+00,\n",
      "        -1.1659e+00, -7.1398e-01,  2.0785e+00,  9.6421e-01,  2.7582e+00,\n",
      "        -6.4305e-01,  2.6200e-01,  1.5402e+00,  1.4139e+00, -7.2825e-01,\n",
      "         1.6158e+00, -9.9987e-01,  3.4511e+00, -3.9850e+00, -3.3185e+00,\n",
      "         2.8787e+00,  1.9258e+00,  2.4323e+00, -3.1119e+00,  7.1674e-03,\n",
      "         4.5102e-03, -2.4143e+00, -1.0166e+00, -9.8332e-01, -1.6923e+00,\n",
      "        -1.6108e+00, -4.6831e-01, -3.7118e+00,  6.1253e-01, -1.0822e+00,\n",
      "         1.0624e+00, -1.4932e+00, -3.2999e+00, -1.0472e+00,  5.2967e-01,\n",
      "         3.5636e+00, -2.3075e+00, -8.0879e-01,  1.0790e+00,  2.9511e+00,\n",
      "        -3.0733e+00,  1.2901e+00,  2.2774e+00, -7.8632e-02,  2.4615e-01,\n",
      "         2.0602e+00, -1.9893e+00, -5.1354e-02,  9.1857e-01,  1.2644e+00,\n",
      "        -2.2370e+00,  3.8721e+00,  4.3976e+00, -8.5761e-01, -1.6976e+00,\n",
      "         2.4123e+00,  3.2546e+00,  1.8159e+00, -2.3795e+00, -1.4408e+00,\n",
      "        -1.1080e+00, -5.7956e-01,  6.9499e-01, -2.9183e+00, -1.1377e+00,\n",
      "        -6.3232e-01, -5.1891e-01, -4.3647e+00, -2.3753e+00,  3.1310e+00,\n",
      "        -1.3071e+00, -1.0362e+00,  1.2238e+00, -1.8426e+00, -3.0312e+00,\n",
      "         3.4583e-01, -2.5622e+00,  1.1681e+00,  2.0634e+00, -9.4285e-01,\n",
      "        -3.1877e+00], device='cuda:0')), ('backbone.model.layer1.0.bn3.bias', tensor([-0.1433,  3.9631, -0.1378,  0.1617,  0.7109, -0.4263,  0.6784, -0.1833,\n",
      "        -0.7120, -0.3659,  1.6142, -0.6518, -1.1245,  0.8053,  0.0739,  1.2166,\n",
      "         0.7268,  2.5406,  0.6380,  0.3794,  0.0605, -0.6514,  1.4830,  1.1963,\n",
      "         0.7331, -0.0684,  0.6388,  1.2360,  0.5716,  0.4660,  1.1423,  0.1811,\n",
      "         1.8862, -0.5286, -0.0224,  1.0179,  2.4492, -0.8219, -0.8479,  0.5242,\n",
      "         1.1452,  0.5192, -0.0271, -0.7797,  1.1569, -0.2032,  0.8612,  0.9125,\n",
      "         0.1113,  0.5695,  1.3195, -0.3934,  0.8467,  0.3010,  0.6758,  1.3206,\n",
      "         0.5636,  2.1382,  1.1673, -0.0929,  1.8233,  2.2080,  0.6498, -0.9419,\n",
      "         1.0441,  0.6534, -0.9413,  0.1661,  0.1427,  0.3577,  0.2685,  0.2962,\n",
      "        -0.9357, -0.5535, -0.3839, -1.0112,  0.5904, -0.5306,  3.9385,  1.2509,\n",
      "         1.1002, -1.1521, -1.5484, -0.4702, -1.3772, -1.1734, -0.2598, -0.4548,\n",
      "         0.4284,  2.8061, -0.4675,  1.0529,  0.5843,  1.6632,  0.1648, -0.4284,\n",
      "         0.7092,  0.4353, -0.1392,  2.6687,  0.4746, -0.6557, -0.5393, -1.4898,\n",
      "        -0.3449,  0.6643,  0.0542,  0.8787, -0.2430,  0.1787,  0.6465,  0.6821,\n",
      "         0.9181,  0.0195,  1.4305,  0.4897,  0.9140,  1.5378,  1.4559,  0.6479,\n",
      "         0.2489,  0.9929,  1.4122, -0.5784,  1.0513, -0.0438,  0.2901,  1.8751,\n",
      "         0.5864, -0.1949,  0.1255, -0.5268,  0.7490, -3.5267,  1.0624,  1.3725,\n",
      "         0.2298, -0.4299, -0.7566, -1.1788, -0.3230,  0.0944, -0.5743,  0.1269,\n",
      "         2.5217,  1.0308,  0.3594,  0.1391, -0.2210,  0.2807,  1.2584,  0.0174,\n",
      "         0.8410,  1.5288, -0.2195,  1.5748,  0.9527,  0.6225,  0.5053,  1.0288,\n",
      "        -0.1252, -1.7318, -0.4203, -0.4502,  1.3477,  0.3574,  0.2577,  1.4554,\n",
      "         0.6274,  0.6352,  0.1985, -0.2091,  2.2724,  0.1426,  1.6804,  1.4529,\n",
      "         0.3488,  0.7443,  1.9732,  1.7856, -1.3888,  1.3265,  1.2564, -0.9147,\n",
      "        -0.0946, -0.2956, -1.6635,  0.9774,  0.5130,  1.0257,  0.8095,  0.1206,\n",
      "         0.4062,  1.8264,  0.2485,  1.1693,  0.7225,  1.9733,  1.9992,  0.1578,\n",
      "        -0.2831, -0.6160,  1.7560, -0.0688, -0.2304,  0.6082, -0.9949,  0.6995,\n",
      "        -1.1430,  1.9911, -2.5203,  1.1075,  0.2107,  0.5232,  0.5860,  1.0788,\n",
      "         0.1240,  0.9159,  0.8836,  0.5451,  1.3733,  0.4772,  1.3352,  1.8314,\n",
      "         1.0254,  0.2568,  1.2999,  1.3164,  0.8044,  0.3004,  0.6941,  1.3724,\n",
      "         0.5819,  1.4052,  0.2064,  0.4824, -1.0385,  0.8320, -1.1576, -1.0856,\n",
      "         0.1684,  0.1326,  2.2150, -0.6418,  1.1336, -0.9601,  0.3483,  0.2783,\n",
      "         0.0451, -0.5781,  0.7067,  0.4985, -0.3594,  0.1605,  0.6702,  0.2843],\n",
      "       device='cuda:0')), ('backbone.model.layer1.0.downsample.0.weight', tensor([[[[-0.2944]],\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.0913]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0147]],\n",
      "\n",
      "         [[ 0.0047]],\n",
      "\n",
      "         [[ 0.0790]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0490]],\n",
      "\n",
      "         [[ 0.0027]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0443]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         [[ 0.0257]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0021]],\n",
      "\n",
      "         [[-0.0406]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4269]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0216]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0879]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[ 0.0161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0603]],\n",
      "\n",
      "         [[-0.0417]],\n",
      "\n",
      "         [[-0.1333]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0412]],\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         [[ 0.1797]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0091]],\n",
      "\n",
      "         [[ 0.0106]],\n",
      "\n",
      "         [[-0.0428]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0809]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         [[ 0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0506]],\n",
      "\n",
      "         [[-0.0504]],\n",
      "\n",
      "         [[-0.1250]]]], device='cuda:0')), ('backbone.model.layer1.0.downsample.1.weight', tensor([ 4.6168e+00,  9.0811e-02,  3.8383e+00,  3.4998e+00,  8.2211e-01,\n",
      "         2.8237e+00,  3.7180e+00,  3.6437e+00,  1.7832e-01,  9.2665e-01,\n",
      "         2.2882e+00, -1.7838e-02,  1.2234e-01,  5.8606e+00,  3.0153e+00,\n",
      "         7.7844e+00,  1.2699e+00,  1.1338e+01,  1.4665e+00, -1.1839e-01,\n",
      "         8.2558e+00,  2.0027e+00,  4.2189e+00,  6.3844e+00, -1.5771e-01,\n",
      "         1.5288e+00,  4.2838e+00,  2.2791e+00,  7.1129e-01,  1.2603e-01,\n",
      "         6.4966e+00, -1.5250e-01,  6.5030e+00,  4.2867e+00,  1.4876e+00,\n",
      "         3.1079e+00,  8.6501e+00,  7.3492e+00,  2.2140e+00,  6.2599e-02,\n",
      "         4.9958e+00,  6.0356e+00,  7.8408e+00,  3.9363e+00,  1.6423e+00,\n",
      "         6.8914e+00,  1.6127e+01,  3.6284e+00,  2.1602e+00,  3.6352e+00,\n",
      "         4.3504e+00,  3.6973e+00,  5.9768e+00,  4.1040e+00,  9.1433e-01,\n",
      "         6.0594e+00,  3.0934e-01,  1.9837e-01,  6.6341e+00, -1.2135e+00,\n",
      "         6.9365e+00,  3.7688e+00,  6.3567e+00, -3.7646e-01,  1.5034e+00,\n",
      "         5.3865e-01,  5.1163e+00,  1.4538e+00,  4.3246e+00,  4.3025e+00,\n",
      "         1.8893e+00,  2.4682e+00,  3.1797e+00,  7.7570e-02,  2.0715e+00,\n",
      "         6.1458e+00,  3.9921e+00,  2.8650e+00,  3.6551e+00,  8.0108e-01,\n",
      "         1.5153e-01, -2.2397e-02,  3.1178e+00,  3.1718e+00,  4.2960e+00,\n",
      "         2.7340e+00,  4.0469e-02,  4.3525e-02,  8.2130e+00,  5.6835e-01,\n",
      "         7.0817e+00,  9.9201e-01,  5.3003e+00,  1.1090e+01, -8.9163e-01,\n",
      "         1.4087e+00,  2.5569e+00,  3.3622e+00, -4.6343e-02, -1.5681e-01,\n",
      "        -1.2970e-01,  2.8168e+00,  2.0399e-01,  2.5814e+00,  2.1722e+00,\n",
      "         1.1502e+00,  2.1639e+00,  4.1719e+00,  6.8564e+00,  3.0892e+00,\n",
      "         5.9682e-01,  3.1400e+00,  1.7392e+00,  2.2962e+00,  7.0112e+00,\n",
      "        -1.6817e+00, -7.6361e+00,  7.7995e+00,  9.6018e+00,  1.8040e+00,\n",
      "         7.3324e+00,  2.3921e+00,  2.4426e-01,  9.6035e+00,  6.0872e+00,\n",
      "         6.0326e-01, -7.5858e-02,  1.2131e+01,  1.7621e+00,  4.5230e+00,\n",
      "        -2.5236e-01,  1.1092e-02,  3.2007e+00,  5.1207e+00,  4.0117e-01,\n",
      "         4.8909e-01,  4.4720e+00, -1.4093e-01,  7.7665e+00,  1.0399e+00,\n",
      "         2.6660e+00,  2.7851e+00,  8.1129e+00,  5.3389e+00,  3.5917e-02,\n",
      "         4.9288e+00,  5.6382e+00,  5.6954e+00,  2.2192e+00,  2.4945e+00,\n",
      "         2.9095e-01,  2.3266e+00,  7.3684e+00,  1.1326e+01,  6.6655e+00,\n",
      "         2.7591e+00, -1.7037e+00,  5.9351e+00,  9.7622e-01,  1.9305e+00,\n",
      "         7.3704e+00,  1.9901e+00,  5.8236e+00, -1.8698e-01,  3.2140e+00,\n",
      "        -5.3678e-01,  7.7871e+00,  6.5627e+00,  1.0431e+00,  6.7705e+00,\n",
      "         2.6470e+00,  1.1712e+01,  1.8630e+01,  1.4658e+00, -4.5124e-02,\n",
      "         3.5059e+00,  2.4166e+00,  4.4398e+00,  7.0977e+00,  8.0849e-01,\n",
      "         4.2997e+00,  5.5763e+00,  5.6901e+00,  2.1268e-01,  6.6532e+00,\n",
      "         4.2950e+00,  3.5215e+00,  1.7133e-03,  1.9832e+00, -2.8516e-01,\n",
      "         3.0703e+00,  7.9427e-01,  1.3160e+00,  4.2156e-01,  3.3715e+00,\n",
      "         4.4382e+00,  2.3092e+00,  1.3385e+01,  4.4329e+00,  1.2965e+00,\n",
      "         3.9108e+00,  3.2581e+00,  2.2844e-01,  3.4274e+00,  1.8617e+00,\n",
      "         4.8370e+00,  3.9517e+00, -1.3155e-02,  3.4881e+00,  3.1088e+00,\n",
      "        -1.5496e-02,  7.7424e-01,  3.2517e+00,  2.2998e+00,  1.1824e+00,\n",
      "         7.1583e-02,  5.5075e+00,  1.2884e+00,  5.5139e+00,  2.2465e+00,\n",
      "         7.8806e-01,  2.2008e+00,  3.4639e+00,  9.7677e+00,  7.2683e+00,\n",
      "         3.9271e+00,  1.9381e+00, -9.5387e-02,  5.0818e+00,  1.7287e+00,\n",
      "         1.1571e+00,  4.4610e+00,  6.9910e-01,  1.8616e-01,  4.7131e-02,\n",
      "         5.0136e+00,  2.9368e+00,  2.0153e+00, -1.8285e-01,  4.9191e+00,\n",
      "         3.7464e+00,  3.5974e+00,  6.4137e-01,  3.6432e+00, -1.6521e-01,\n",
      "         3.2736e+00,  2.9486e+00,  1.1040e+00, -1.4318e-01,  2.6675e-01,\n",
      "         6.8733e+00,  1.5978e+00,  2.8780e+00,  6.2252e-02,  6.5668e+00,\n",
      "        -7.3047e-02], device='cuda:0')), ('backbone.model.layer1.0.downsample.1.bias', tensor([-0.1433,  3.9631, -0.1378,  0.1617,  0.7109, -0.4263,  0.6784, -0.1833,\n",
      "        -0.7120, -0.3659,  1.6142, -0.6518, -1.1245,  0.8053,  0.0739,  1.2166,\n",
      "         0.7268,  2.5406,  0.6380,  0.3794,  0.0605, -0.6514,  1.4830,  1.1963,\n",
      "         0.7331, -0.0684,  0.6388,  1.2360,  0.5716,  0.4660,  1.1423,  0.1811,\n",
      "         1.8862, -0.5286, -0.0224,  1.0179,  2.4492, -0.8219, -0.8479,  0.5242,\n",
      "         1.1452,  0.5192, -0.0271, -0.7797,  1.1569, -0.2032,  0.8612,  0.9125,\n",
      "         0.1113,  0.5695,  1.3195, -0.3934,  0.8467,  0.3010,  0.6758,  1.3206,\n",
      "         0.5636,  2.1382,  1.1673, -0.0929,  1.8233,  2.2080,  0.6498, -0.9419,\n",
      "         1.0441,  0.6534, -0.9413,  0.1661,  0.1427,  0.3577,  0.2685,  0.2962,\n",
      "        -0.9357, -0.5535, -0.3839, -1.0112,  0.5904, -0.5306,  3.9385,  1.2509,\n",
      "         1.1002, -1.1521, -1.5484, -0.4702, -1.3772, -1.1734, -0.2598, -0.4548,\n",
      "         0.4284,  2.8061, -0.4675,  1.0529,  0.5843,  1.6632,  0.1648, -0.4284,\n",
      "         0.7092,  0.4353, -0.1392,  2.6687,  0.4746, -0.6557, -0.5393, -1.4898,\n",
      "        -0.3449,  0.6643,  0.0542,  0.8787, -0.2430,  0.1787,  0.6465,  0.6821,\n",
      "         0.9181,  0.0195,  1.4305,  0.4897,  0.9140,  1.5378,  1.4559,  0.6479,\n",
      "         0.2489,  0.9929,  1.4122, -0.5784,  1.0513, -0.0438,  0.2901,  1.8751,\n",
      "         0.5864, -0.1949,  0.1255, -0.5268,  0.7490, -3.5267,  1.0624,  1.3725,\n",
      "         0.2298, -0.4299, -0.7566, -1.1788, -0.3230,  0.0944, -0.5743,  0.1269,\n",
      "         2.5217,  1.0308,  0.3594,  0.1391, -0.2210,  0.2807,  1.2584,  0.0174,\n",
      "         0.8410,  1.5288, -0.2195,  1.5748,  0.9527,  0.6225,  0.5053,  1.0288,\n",
      "        -0.1252, -1.7318, -0.4203, -0.4502,  1.3477,  0.3574,  0.2577,  1.4554,\n",
      "         0.6274,  0.6352,  0.1985, -0.2091,  2.2724,  0.1426,  1.6804,  1.4529,\n",
      "         0.3488,  0.7443,  1.9732,  1.7856, -1.3888,  1.3265,  1.2564, -0.9147,\n",
      "        -0.0946, -0.2956, -1.6635,  0.9774,  0.5130,  1.0257,  0.8095,  0.1206,\n",
      "         0.4062,  1.8264,  0.2485,  1.1693,  0.7225,  1.9733,  1.9992,  0.1578,\n",
      "        -0.2831, -0.6160,  1.7560, -0.0688, -0.2304,  0.6082, -0.9949,  0.6995,\n",
      "        -1.1430,  1.9911, -2.5203,  1.1075,  0.2107,  0.5232,  0.5860,  1.0788,\n",
      "         0.1240,  0.9159,  0.8836,  0.5451,  1.3733,  0.4772,  1.3352,  1.8314,\n",
      "         1.0254,  0.2568,  1.2999,  1.3164,  0.8044,  0.3004,  0.6941,  1.3724,\n",
      "         0.5819,  1.4052,  0.2064,  0.4824, -1.0385,  0.8320, -1.1576, -1.0856,\n",
      "         0.1684,  0.1326,  2.2150, -0.6418,  1.1336, -0.9601,  0.3483,  0.2783,\n",
      "         0.0451, -0.5781,  0.7067,  0.4985, -0.3594,  0.1605,  0.6702,  0.2843],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv1.weight', tensor([[[[ 0.0972]],\n",
      "\n",
      "         [[ 0.1206]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1477]],\n",
      "\n",
      "         [[-0.0330]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[-0.0662]],\n",
      "\n",
      "         [[-0.0042]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0525]],\n",
      "\n",
      "         [[-0.1164]],\n",
      "\n",
      "         [[-0.0699]]],\n",
      "\n",
      "\n",
      "        [[[-0.0666]],\n",
      "\n",
      "         [[-0.0521]],\n",
      "\n",
      "         [[ 0.0765]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0701]],\n",
      "\n",
      "         [[ 0.0433]],\n",
      "\n",
      "         [[ 0.0307]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0822]],\n",
      "\n",
      "         [[-0.1120]],\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[-0.0346]],\n",
      "\n",
      "         [[-0.0557]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0236]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[-0.1418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.0306]]],\n",
      "\n",
      "\n",
      "        [[[-0.0662]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[-0.0079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0654]],\n",
      "\n",
      "         [[ 0.0391]],\n",
      "\n",
      "         [[-0.0745]]]], device='cuda:0')), ('backbone.model.layer1.1.bn1.weight', tensor([3.2255, 5.4521, 1.8643, 2.3486, 3.3921, 4.2949, 4.7178, 4.6659, 2.1008,\n",
      "        2.0660, 1.9307, 1.7551, 1.9384, 2.6163, 1.7885, 2.0918, 1.7041, 1.8221,\n",
      "        2.0933, 1.2485, 5.0473, 1.2190, 3.9392, 3.3216, 2.5884, 2.2565, 1.9883,\n",
      "        1.8902, 1.6453, 0.7023, 1.8713, 1.3534, 1.0201, 1.3402, 1.5942, 1.8855,\n",
      "        1.1353, 0.7357, 3.1083, 3.4441, 2.4149, 1.9106, 2.1535, 2.0625, 2.9858,\n",
      "        3.3844, 2.0838, 1.3120, 3.4414, 3.0686, 2.1811, 1.6444, 1.8262, 1.2412,\n",
      "        2.8610, 2.6065, 1.7665, 1.9179, 1.6724, 2.1824, 2.3933, 1.7754, 2.1745,\n",
      "        1.4584], device='cuda:0')), ('backbone.model.layer1.1.bn1.bias', tensor([-0.9892,  2.3441,  1.5775, -0.9554, -2.0282,  2.6131,  1.7644, -3.5670,\n",
      "         1.2615, -0.5792, -1.1472,  1.7501, -2.1657, -1.1552,  1.0290,  0.1253,\n",
      "         0.1221,  0.0761, -0.2707,  1.3161, -3.9474,  0.2531,  1.5280, -1.2663,\n",
      "         0.7259, -0.8019,  0.4911, -0.1449, -0.4298,  1.4907, -0.7737,  1.1900,\n",
      "         1.3900, -1.1093,  0.6939,  0.1100, -0.3645,  2.3542, -1.3582,  2.5795,\n",
      "        -1.5417,  1.3857, -0.4581,  1.1488, -1.9365,  2.0469, -1.4159, -0.2044,\n",
      "        -2.0042,  1.3710,  1.1431,  0.1513,  0.5315,  0.8019, -1.8874,  1.9965,\n",
      "         1.5067, -0.2626,  1.6003, -0.1984, -1.5308,  1.2346,  0.3949, -0.7947],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv2.weight', tensor([[[[-0.0307, -0.0454, -0.0236],\n",
      "          [-0.1666,  0.2277, -0.1815],\n",
      "          [ 0.0076, -0.0075, -0.0212]],\n",
      "\n",
      "         [[-0.0104,  0.0567,  0.0136],\n",
      "          [ 0.1201,  0.1226,  0.1139],\n",
      "          [ 0.0178,  0.0074,  0.0251]],\n",
      "\n",
      "         [[-0.0117,  0.0952, -0.0049],\n",
      "          [ 0.0532, -0.0496, -0.0322],\n",
      "          [-0.0638, -0.0777, -0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0342, -0.1099,  0.0177],\n",
      "          [ 0.0198, -0.0825, -0.0045],\n",
      "          [ 0.0203, -0.1228, -0.0019]],\n",
      "\n",
      "         [[ 0.0075,  0.1376,  0.0935],\n",
      "          [-0.0726,  0.0408, -0.1849],\n",
      "          [-0.0338, -0.0986, -0.0075]],\n",
      "\n",
      "         [[-0.0025, -0.0165,  0.0545],\n",
      "          [ 0.0434, -0.0655,  0.0283],\n",
      "          [ 0.0719, -0.0033, -0.0463]]],\n",
      "\n",
      "\n",
      "        [[[-0.0152, -0.0586,  0.1095],\n",
      "          [ 0.0535,  0.1314,  0.0337],\n",
      "          [ 0.1157, -0.0185, -0.0366]],\n",
      "\n",
      "         [[-0.0781,  0.0898, -0.0336],\n",
      "          [-0.0223, -0.0482, -0.0445],\n",
      "          [-0.0088,  0.0847, -0.0588]],\n",
      "\n",
      "         [[-0.1195, -0.1933,  0.1147],\n",
      "          [ 0.0639,  0.0513,  0.0270],\n",
      "          [ 0.0338,  0.1760,  0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0300,  0.0198, -0.0537],\n",
      "          [-0.0200,  0.0218, -0.0419],\n",
      "          [-0.0245,  0.0371,  0.0655]],\n",
      "\n",
      "         [[-0.0789, -0.0600,  0.0470],\n",
      "          [ 0.0924,  0.0466, -0.1102],\n",
      "          [ 0.0636, -0.0636,  0.1206]],\n",
      "\n",
      "         [[-0.0392,  0.0040, -0.0074],\n",
      "          [ 0.0227,  0.1463,  0.0613],\n",
      "          [-0.0412, -0.0104,  0.0028]]],\n",
      "\n",
      "\n",
      "        [[[-0.0182, -0.0897, -0.1059],\n",
      "          [-0.1214, -0.0740, -0.0630],\n",
      "          [-0.1446, -0.0573, -0.0217]],\n",
      "\n",
      "         [[-0.1810, -0.0178, -0.0259],\n",
      "          [-0.0678,  0.0305, -0.0553],\n",
      "          [-0.0364, -0.0368, -0.1115]],\n",
      "\n",
      "         [[ 0.0373, -0.1294,  0.0250],\n",
      "          [-0.0833,  0.1324,  0.0535],\n",
      "          [ 0.0174,  0.0840, -0.0322]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0515,  0.0887, -0.1290],\n",
      "          [ 0.0968,  0.1119,  0.0557],\n",
      "          [-0.0879,  0.0399,  0.0066]],\n",
      "\n",
      "         [[-0.1089, -0.0996, -0.0060],\n",
      "          [ 0.0265,  0.0210, -0.0202],\n",
      "          [-0.0159,  0.0065,  0.1067]],\n",
      "\n",
      "         [[-0.0815, -0.1664, -0.0909],\n",
      "          [ 0.0277, -0.1125, -0.1371],\n",
      "          [-0.0477, -0.2464, -0.1471]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0550, -0.0442,  0.1318],\n",
      "          [-0.1927, -0.1812,  0.3060],\n",
      "          [-0.0231, -0.1031,  0.1275]],\n",
      "\n",
      "         [[-0.0759,  0.0322,  0.0543],\n",
      "          [-0.0502,  0.0246,  0.1015],\n",
      "          [ 0.0574, -0.1096, -0.0062]],\n",
      "\n",
      "         [[ 0.0632, -0.0156,  0.0142],\n",
      "          [ 0.0618, -0.1287, -0.0492],\n",
      "          [ 0.0892, -0.0161, -0.0522]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0298, -0.0352,  0.0823],\n",
      "          [ 0.0122, -0.0440, -0.0050],\n",
      "          [-0.0438, -0.0271,  0.0447]],\n",
      "\n",
      "         [[-0.0739, -0.0312,  0.0097],\n",
      "          [-0.1093, -0.0343,  0.1904],\n",
      "          [ 0.0299,  0.0430, -0.0501]],\n",
      "\n",
      "         [[-0.0151, -0.0531, -0.0203],\n",
      "          [-0.0231,  0.0557, -0.0080],\n",
      "          [-0.1036, -0.0055,  0.0521]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0563,  0.0988,  0.0358],\n",
      "          [ 0.0619,  0.1410,  0.0892],\n",
      "          [ 0.0320,  0.1057,  0.0888]],\n",
      "\n",
      "         [[ 0.3608,  0.1591,  0.1133],\n",
      "          [ 0.2177,  0.0803,  0.1360],\n",
      "          [ 0.1555,  0.1571,  0.3434]],\n",
      "\n",
      "         [[ 0.0282,  0.1189,  0.0525],\n",
      "          [ 0.0635, -0.0299, -0.0619],\n",
      "          [-0.0772, -0.0098, -0.0581]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1126, -0.0635, -0.0597],\n",
      "          [-0.0198,  0.1301,  0.0853],\n",
      "          [-0.0943, -0.0244, -0.0241]],\n",
      "\n",
      "         [[ 0.0793, -0.0008, -0.0488],\n",
      "          [ 0.0237, -0.0324, -0.1217],\n",
      "          [ 0.0678, -0.0381, -0.2170]],\n",
      "\n",
      "         [[-0.0546, -0.0256, -0.0186],\n",
      "          [ 0.0168,  0.0489,  0.1175],\n",
      "          [-0.0068,  0.0203, -0.0108]]],\n",
      "\n",
      "\n",
      "        [[[-0.0044, -0.0401,  0.0156],\n",
      "          [-0.0654, -0.0535,  0.0411],\n",
      "          [-0.0627, -0.0266, -0.0078]],\n",
      "\n",
      "         [[-0.0696, -0.1335,  0.0206],\n",
      "          [-0.0915,  0.0475, -0.0661],\n",
      "          [-0.0349, -0.0849, -0.0633]],\n",
      "\n",
      "         [[ 0.0116, -0.0640, -0.0100],\n",
      "          [-0.0597,  0.0025, -0.0316],\n",
      "          [ 0.0289, -0.0186, -0.0467]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0019,  0.0817,  0.0203],\n",
      "          [ 0.0468, -0.1131, -0.0153],\n",
      "          [ 0.0146, -0.0231,  0.0133]],\n",
      "\n",
      "         [[-0.0064, -0.0146,  0.0049],\n",
      "          [ 0.0284,  0.0248,  0.0319],\n",
      "          [-0.0065, -0.0086,  0.0426]],\n",
      "\n",
      "         [[-0.0427, -0.0620, -0.0596],\n",
      "          [-0.0466,  0.0637, -0.1281],\n",
      "          [-0.0951, -0.0789, -0.1318]]]], device='cuda:0')), ('backbone.model.layer1.1.bn2.weight', tensor([1.7916, 2.3705, 0.8039, 0.8268, 2.1546, 1.5692, 2.0239, 2.6892, 2.3259,\n",
      "        2.3044, 1.9858, 3.0782, 1.5930, 2.4379, 2.8254, 2.4894, 1.3925, 0.3935,\n",
      "        1.4443, 0.6879, 2.7114, 2.2801, 2.6586, 2.4428, 2.0601, 2.4208, 1.8261,\n",
      "        2.4762, 0.4714, 1.5236, 2.2131, 2.1186, 2.3576, 1.7589, 1.4384, 0.3525,\n",
      "        1.2938, 0.7569, 1.3889, 0.5004, 2.3640, 2.6192, 0.8096, 0.8750, 1.0451,\n",
      "        0.9976, 1.4397, 0.2424, 5.3001, 2.4137, 2.5881, 2.1713, 0.8982, 0.6000,\n",
      "        2.4643, 2.7684, 2.4165, 2.6517, 2.2931, 2.4100, 2.6692, 2.0572, 0.3188,\n",
      "        1.5088], device='cuda:0')), ('backbone.model.layer1.1.bn2.bias', tensor([ 2.0851, -1.9334,  0.3521,  0.4959, -0.5685,  1.9035,  1.5894, -1.4805,\n",
      "        -1.9591,  1.9045,  1.4118, -2.8879,  2.4605, -2.3474,  2.4598, -1.3701,\n",
      "        -0.9201,  0.2878,  0.5829, -0.4869, -2.6593,  1.7933, -2.3334,  2.0671,\n",
      "         1.4543, -1.9681,  1.4802, -1.4739,  0.5769, -0.9581,  2.5111, -1.1463,\n",
      "        -1.5300,  1.2756, -0.9329,  0.4548,  0.5285, -0.7760, -0.9820,  0.4021,\n",
      "         1.8991, -2.5145,  0.3861,  0.5878, -0.1995,  0.7160, -1.0315,  0.5508,\n",
      "         2.5575, -1.6291, -2.4942,  1.7395,  0.5580, -0.6141,  2.0318, -2.7923,\n",
      "         2.0439, -1.9598, -1.2297,  1.9252, -1.5978,  1.7111,  0.4090, -1.3005],\n",
      "       device='cuda:0')), ('backbone.model.layer1.1.conv3.weight', tensor([[[[-3.6021e-02]],\n",
      "\n",
      "         [[ 6.2003e-02]],\n",
      "\n",
      "         [[-1.2458e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.0048e-02]],\n",
      "\n",
      "         [[-4.5005e-03]],\n",
      "\n",
      "         [[ 2.6009e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9201e-02]],\n",
      "\n",
      "         [[ 1.0059e-01]],\n",
      "\n",
      "         [[ 1.2573e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7288e-02]],\n",
      "\n",
      "         [[ 3.9465e-02]],\n",
      "\n",
      "         [[-6.1164e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9902e-03]],\n",
      "\n",
      "         [[ 5.0363e-02]],\n",
      "\n",
      "         [[-7.3282e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2831e-02]],\n",
      "\n",
      "         [[-1.3061e-02]],\n",
      "\n",
      "         [[ 1.1690e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.6192e-02]],\n",
      "\n",
      "         [[ 6.6034e-02]],\n",
      "\n",
      "         [[-8.4391e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2520e-02]],\n",
      "\n",
      "         [[-1.1344e-01]],\n",
      "\n",
      "         [[ 1.8090e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9720e-04]],\n",
      "\n",
      "         [[ 9.8898e-03]],\n",
      "\n",
      "         [[ 6.4677e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9629e-03]],\n",
      "\n",
      "         [[ 4.4057e-02]],\n",
      "\n",
      "         [[ 9.9189e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0304e-04]],\n",
      "\n",
      "         [[ 1.0274e-02]],\n",
      "\n",
      "         [[-1.8767e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8253e-02]],\n",
      "\n",
      "         [[-6.0436e-02]],\n",
      "\n",
      "         [[ 2.2992e-02]]]], device='cuda:0')), ('backbone.model.layer1.1.bn3.weight', tensor([-1.3718e+00, -1.5629e-01, -1.7885e+00,  4.3125e+00, -5.2521e+00,\n",
      "         1.6550e+00,  2.9763e+00,  1.9564e+00,  4.9294e-02, -1.1191e+00,\n",
      "         1.2271e-02,  1.1663e+00,  3.4912e+00, -1.1569e+00, -6.4164e-02,\n",
      "        -2.6590e+00,  1.2818e+00,  2.9815e+00, -8.9366e-01,  1.8358e+00,\n",
      "        -1.6243e+00, -7.3487e-01, -1.6049e+00,  1.0759e+00,  1.5582e-01,\n",
      "         2.4674e+00, -2.9049e+00,  5.0579e-01, -4.4905e-01, -5.8917e-01,\n",
      "        -6.7124e-02,  1.8120e+00, -5.5699e-01, -7.9589e-02, -1.1056e+00,\n",
      "        -2.2237e+00,  4.5209e+00, -2.1549e-02,  3.2776e+00,  1.1459e+00,\n",
      "        -1.4793e-02,  5.9748e-02, -7.6958e-01, -2.7664e-03, -4.2576e+00,\n",
      "        -1.6319e+00,  3.9485e+00, -2.0116e+00, -2.8267e+00,  7.7287e-02,\n",
      "        -1.9909e-03, -1.6031e-01, -2.4393e+00,  1.3966e-01,  1.3615e+00,\n",
      "         1.9549e+00, -1.2502e+00, -1.7600e-01,  4.1406e-02, -2.0533e+00,\n",
      "         7.0072e-01,  8.1767e-01, -7.2633e-02,  4.6389e+00, -1.3829e+00,\n",
      "         4.4929e+00, -7.2733e-01, -4.8120e-01, -1.6960e+00,  1.1766e+00,\n",
      "        -9.5817e-01,  6.6568e-02, -5.3395e-01,  9.1556e-01,  2.2194e-01,\n",
      "         1.0097e+00, -4.1979e+00,  1.1756e-01, -2.9639e-01,  1.9378e+00,\n",
      "        -3.6505e+00,  2.8678e+00, -1.9568e-01,  3.1495e+00, -4.8759e-01,\n",
      "         2.1878e+00, -4.0283e+00,  3.7039e+00, -1.6949e+00, -1.4119e+00,\n",
      "         5.0786e-01,  2.4893e+00, -1.4133e+00, -1.3703e-02,  2.3330e+00,\n",
      "         4.1335e-02, -1.8186e-01, -2.6210e-01, -1.3471e+00,  1.4883e+00,\n",
      "         3.0830e+00,  3.9693e-01,  5.5900e+00,  2.7651e-01, -8.7502e-02,\n",
      "        -2.3098e-02,  2.6546e+00, -2.1945e-02, -1.4464e-01, -3.3030e+00,\n",
      "         1.4041e-01,  9.9063e-03, -3.4930e+00, -2.1568e-01, -2.3417e+00,\n",
      "        -1.8471e-01, -3.0683e+00, -9.7043e-01,  1.9116e+00,  1.7202e+00,\n",
      "        -2.3323e+00, -2.2638e+00, -2.7788e+00,  1.8448e+00,  3.2498e-02,\n",
      "        -3.4572e+00,  4.4342e+00,  9.1994e-01, -3.1940e+00,  1.0413e-01,\n",
      "         3.8191e-01, -5.9380e-01, -4.9700e-01,  2.4838e-02, -5.9358e-01,\n",
      "        -8.6057e-03, -3.1196e+00,  1.2905e-01,  1.3768e+00,  2.4299e-02,\n",
      "        -1.9124e+00, -1.3833e+00, -1.3880e+00, -1.8592e+00,  1.7895e+00,\n",
      "         8.4022e+00, -1.6266e+00, -1.5762e+00, -6.1993e-01,  4.0809e+00,\n",
      "         3.8344e-01,  1.0418e-02, -7.0420e-01, -3.8726e+00,  2.0000e-01,\n",
      "         9.8096e-01, -2.3489e+00, -2.3683e+00,  4.2413e+00,  3.3379e+00,\n",
      "         4.1782e-02,  1.6009e+00,  3.5091e-01, -2.2444e+00, -1.4606e+00,\n",
      "        -1.8882e+00,  6.1494e-01,  9.9934e-01, -1.1893e+00,  1.8872e-01,\n",
      "        -5.4430e+00, -4.9340e-01,  8.3177e+00, -1.5204e+00, -2.6614e+00,\n",
      "         2.0412e+00,  5.3135e-01, -6.8495e-02,  2.1500e+00, -1.4842e+00,\n",
      "        -2.4895e-01, -2.6075e+00, -1.5452e+00, -2.4416e+00,  2.6322e+00,\n",
      "         1.6100e-01, -4.7241e-01,  3.4952e+00, -5.8432e+00,  2.6590e+00,\n",
      "         2.3544e+00, -1.5496e+00,  7.1720e-03, -5.0443e-01, -8.8980e-02,\n",
      "        -8.2613e-02,  2.6623e+00, -1.4793e+00, -1.7124e+00,  5.4300e-01,\n",
      "        -2.8193e+00, -1.5716e+00, -2.1806e+00, -1.0025e+00,  4.0776e-02,\n",
      "         1.8247e+00,  5.5751e+00,  5.8324e-01,  1.6477e+00, -6.7194e-02,\n",
      "         2.2132e+00,  8.7835e-01, -3.4949e+00,  1.5287e+00,  1.0953e+00,\n",
      "         2.2767e+00,  3.2006e-02,  1.5873e+00,  2.8752e-02, -1.9822e-02,\n",
      "         2.4777e+00, -4.0568e-01, -3.1995e+00, -8.3949e-01,  1.3805e+00,\n",
      "         3.2108e+00,  8.8609e-01,  5.0376e-02,  1.7131e+00, -6.9646e-01,\n",
      "         1.2979e+00,  2.2090e+00, -1.7786e+00,  2.5952e+00, -3.7048e+00,\n",
      "        -9.9263e-01,  9.4720e-02,  3.3081e-01, -2.6328e+00,  7.3138e-03,\n",
      "        -1.3884e+00,  4.4083e+00, -3.0255e-01, -6.2446e-01, -4.0893e-01,\n",
      "         1.6342e+00,  4.7158e-01,  4.5415e-01,  4.2409e+00, -2.1465e+00,\n",
      "         1.0448e-01,  1.7200e+00, -9.0491e-02,  1.2827e+00, -3.3899e+00,\n",
      "         2.3752e+00], device='cuda:0')), ('backbone.model.layer1.1.bn3.bias', tensor([-1.0659e+00,  7.3578e-02, -1.3410e+00, -9.7044e+00, -5.8285e-01,\n",
      "        -1.3477e-01, -1.4976e+00, -1.6769e-01, -1.0751e-03,  1.1756e+00,\n",
      "        -8.6749e-03,  4.1557e-01, -1.4532e+00, -1.4950e-01, -1.4227e-01,\n",
      "        -8.1816e-01,  5.2645e-01, -1.3673e+01,  7.8612e-01,  1.2400e-01,\n",
      "         5.5543e-01, -1.4506e-01, -1.8301e+00, -5.1386e-01, -4.6945e-02,\n",
      "        -5.3657e-01, -7.0064e-01, -2.7944e-01,  4.6476e-02,  3.7571e-02,\n",
      "        -9.6441e-02, -8.8108e+00, -2.4006e-01,  3.4489e-02, -9.8919e-01,\n",
      "        -1.6638e+00, -1.6786e+00,  7.6370e-03, -8.6502e-01, -4.6501e-01,\n",
      "         1.8142e-02, -4.6586e-02, -1.0322e+00,  1.0136e-02,  1.0148e+00,\n",
      "        -1.9418e+00,  5.2685e-01, -2.0508e+00,  9.0191e-01, -1.1437e-02,\n",
      "        -1.3081e-02,  1.2103e-01,  4.9080e-03,  4.2775e-02, -6.0589e-01,\n",
      "        -1.9776e+00,  1.1937e+00, -1.0981e-01, -2.7252e-02,  1.4278e+00,\n",
      "        -6.3525e-01, -8.4281e-02, -2.1708e-01,  9.8987e-01, -1.3458e+00,\n",
      "         9.9841e-01,  6.2638e-01, -2.5989e-01, -2.0737e+00, -5.7969e-01,\n",
      "        -2.3349e-02,  1.4997e-01,  7.6116e-02, -3.2744e-01, -1.0577e-01,\n",
      "        -1.8849e-01,  1.2065e+00, -9.3550e-01, -6.3089e-03, -1.7561e+00,\n",
      "        -8.9921e-01,  4.4346e-01,  1.0597e-01, -6.5665e-01,  3.8206e-01,\n",
      "        -6.5796e+00, -1.2348e+00, -1.9264e+00, -4.6335e+00, -1.1874e+00,\n",
      "        -6.8364e-01,  1.5367e+00, -8.5879e-03,  4.2273e-02, -1.0617e+00,\n",
      "        -2.1896e-02, -4.6566e-02, -1.1906e-01,  6.6566e-01, -1.5815e+00,\n",
      "        -6.1226e+00, -3.7708e-01,  1.4240e+00, -2.5136e-01,  5.4008e-01,\n",
      "        -8.0141e-03,  2.5559e+00, -2.7268e-02, -1.4107e+01,  8.2130e-01,\n",
      "        -2.1169e-01, -1.9044e-02, -4.5486e-01, -3.0095e-02, -1.3104e+00,\n",
      "        -3.0996e-01, -5.7243e+00, -1.4345e+00,  2.9600e-01, -2.4080e-02,\n",
      "        -8.3646e-01, -1.2732e+00, -7.8319e-01,  1.2346e+00,  3.1633e-02,\n",
      "         2.2527e-01, -1.5340e+00, -2.3234e+00,  3.3604e+00, -5.3010e-02,\n",
      "        -1.1525e+01, -1.1771e-01, -4.9443e-01, -6.9532e-03, -5.8437e-01,\n",
      "         8.8566e-04, -3.2854e+00,  1.9976e-01, -6.3236e-01, -1.9681e-02,\n",
      "         2.1037e+00, -2.1882e+00, -8.6270e-01, -1.2867e+00, -1.1349e+00,\n",
      "         1.1900e-01, -1.0546e+00, -1.5660e+00, -9.4311e-02,  1.1449e-01,\n",
      "        -2.8203e-01, -7.8110e-03, -1.5658e+00, -2.1855e+00, -4.5746e-01,\n",
      "        -1.6787e+00, -8.0073e-01, -2.7147e+00, -1.9688e+00, -7.5646e-01,\n",
      "         1.1561e-02, -2.2359e+00, -1.5436e-01, -2.6642e+00, -2.4789e-01,\n",
      "        -2.2064e+00, -1.6537e-01, -3.9095e-01,  6.1433e-01,  2.1334e-01,\n",
      "         1.0826e-01,  1.2696e+00,  2.1613e+00,  1.5447e-01, -4.5540e-01,\n",
      "        -5.8533e-01, -4.3917e-01,  5.3421e-02, -1.5927e+00, -4.9882e-01,\n",
      "        -4.5755e-01, -4.9006e-01, -1.3597e+00,  6.1186e-01,  1.2327e-01,\n",
      "        -1.0914e-01,  1.7239e-01, -1.1250e+00,  1.2620e-01,  1.1167e-01,\n",
      "         3.8893e-01,  4.8570e-01,  3.0877e-02, -6.5013e-01, -3.0564e-02,\n",
      "        -9.9272e-02, -1.7486e+00, -1.6610e+00,  1.4357e+00,  4.6435e-02,\n",
      "         2.8437e-01,  4.0119e-01, -1.2864e+00, -3.6789e-01, -5.3446e-02,\n",
      "        -2.5409e-01, -3.7203e+00, -1.2381e-01, -3.4731e-01,  7.7287e-02,\n",
      "        -3.7499e+00, -8.1784e-01, -3.5199e-01, -7.3583e-01,  6.6564e-01,\n",
      "        -1.5282e-01, -2.8763e-02,  8.7599e-01,  2.1085e-02, -1.4366e-02,\n",
      "        -1.8364e+00, -2.7832e-01, -1.6921e-01, -3.0430e-01, -5.0632e-01,\n",
      "        -1.7431e+00, -7.4542e-01,  2.4223e-02, -7.5281e-01,  2.1087e-01,\n",
      "         4.1128e-01, -3.9105e-01, -7.5432e-02, -9.3951e-01,  1.8348e+00,\n",
      "        -1.4166e+00,  3.3107e-02,  6.8407e-01, -5.8977e+00,  7.3073e-02,\n",
      "        -1.2291e+00,  2.3532e+00, -9.2946e-02, -2.6228e-01, -6.4299e-02,\n",
      "        -1.5889e-01, -4.4539e-01,  1.5774e-01,  1.1385e+00, -9.5846e-01,\n",
      "        -6.2207e-03, -1.3339e+00,  3.3296e-02, -5.5947e-01, -3.3512e+00,\n",
      "         1.1137e+00], device='cuda:0')), ('backbone.model.layer1.2.conv1.weight', tensor([[[[-0.0756]],\n",
      "\n",
      "         [[-0.0043]],\n",
      "\n",
      "         [[ 0.0673]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         [[ 0.0011]],\n",
      "\n",
      "         [[ 0.0223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0151]],\n",
      "\n",
      "         [[ 0.1022]],\n",
      "\n",
      "         [[-0.0719]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0893]],\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0076]]],\n",
      "\n",
      "\n",
      "        [[[-0.0426]],\n",
      "\n",
      "         [[ 0.0543]],\n",
      "\n",
      "         [[-0.0268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0575]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[ 0.0122]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[ 0.0181]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[-0.0158]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[-0.1441]],\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0923]],\n",
      "\n",
      "         [[-0.0480]],\n",
      "\n",
      "         [[ 0.0036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0393]],\n",
      "\n",
      "         [[ 0.0333]],\n",
      "\n",
      "         [[ 0.0183]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[ 0.0069]],\n",
      "\n",
      "         [[-0.0509]]]], device='cuda:0')), ('backbone.model.layer1.2.bn1.weight', tensor([ 1.0689,  1.0164,  1.2347,  1.2707,  1.7736,  2.1487,  1.3309,  1.6811,\n",
      "         0.5816,  3.4309,  4.0312,  0.5981,  1.3814,  0.6964,  1.2170,  1.0419,\n",
      "         1.6521,  1.8728,  1.7762,  7.0059,  2.0077,  2.7583,  0.9091,  1.4622,\n",
      "         1.9236,  1.2980,  1.1425,  1.7365,  1.4654,  0.6978,  1.9783,  1.1531,\n",
      "         1.7426,  2.0882,  1.9292,  4.5488,  2.2597,  1.1393,  2.5044,  3.0667,\n",
      "         7.8127,  2.0439,  0.6699,  1.4794,  1.3223,  3.7102,  3.0846, 16.4887,\n",
      "         1.2642,  1.4663,  0.6096,  1.2024,  1.3916,  1.8093,  1.0377,  1.0729,\n",
      "         1.4399,  0.8784,  5.2488,  1.6971,  1.3041,  1.1778,  1.2912,  2.0394],\n",
      "       device='cuda:0')), ('backbone.model.layer1.2.bn1.bias', tensor([-1.7389e-01,  6.7523e-01,  2.4712e-02, -1.1986e+00,  7.0450e-01,\n",
      "        -2.2952e+00, -2.2399e+00, -5.4686e-01,  1.0028e+00, -2.6672e+00,\n",
      "        -6.9744e+00, -1.7512e-01, -1.0512e+00,  4.8479e-02,  4.3647e-03,\n",
      "        -1.1449e+00,  8.2519e-01, -1.2187e+00, -1.1053e+00,  2.6411e+00,\n",
      "        -1.2023e+00,  1.5203e+00,  1.6279e+00, -1.8545e+00, -1.1055e+00,\n",
      "         9.0297e-01,  9.3653e-01,  8.6528e-01, -6.9341e-01,  1.0762e-01,\n",
      "         9.1858e-01,  9.9787e-01, -9.5692e-01,  4.2607e+00, -1.5246e+00,\n",
      "        -3.5437e+00,  1.2051e-01, -5.8902e-01,  1.8777e+00, -3.9694e+00,\n",
      "        -3.3624e+00, -1.1731e+00, -3.6937e-01, -4.0179e-01, -1.2458e+00,\n",
      "         7.3625e-01, -3.7109e+00,  1.6324e+00,  3.9806e-02, -4.4950e-01,\n",
      "         9.8170e-01, -4.9737e-01, -4.3586e-01,  1.7394e+00, -7.7517e-01,\n",
      "        -7.7874e-01,  9.0792e-01, -8.2563e-01,  3.6669e+00, -1.2069e+00,\n",
      "         1.4605e+00, -3.3041e-01, -1.2780e+00, -2.1861e+00], device='cuda:0')), ('backbone.model.layer1.2.conv2.weight', tensor([[[[-4.8122e-02, -1.0132e-01, -9.3823e-02],\n",
      "          [-9.1978e-02, -1.8462e-01, -1.4014e-01],\n",
      "          [-4.7879e-02, -1.1343e-01, -8.0527e-02]],\n",
      "\n",
      "         [[ 9.1166e-03, -8.3523e-03,  5.3376e-02],\n",
      "          [-1.5246e-02, -6.7996e-02, -2.6669e-02],\n",
      "          [ 8.4100e-03, -4.6519e-02,  1.8728e-02]],\n",
      "\n",
      "         [[ 4.5904e-02,  5.9449e-02,  5.8353e-02],\n",
      "          [ 1.5882e-02, -6.7311e-02,  1.4752e-02],\n",
      "          [ 6.1281e-02, -2.9421e-02,  1.8829e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6936e-02, -1.1283e-01, -7.6695e-02],\n",
      "          [-1.1467e-01, -1.6072e-01, -1.1420e-01],\n",
      "          [-1.0202e-01, -1.2626e-01, -1.2441e-01]],\n",
      "\n",
      "         [[-7.3167e-02, -6.5631e-02, -3.4983e-02],\n",
      "          [-3.5105e-02, -5.4534e-02, -5.7749e-02],\n",
      "          [ 6.0104e-03, -4.8863e-02,  5.7119e-04]],\n",
      "\n",
      "         [[ 1.3251e-01,  5.9228e-02,  2.3473e-02],\n",
      "          [ 6.0324e-02,  2.8280e-02,  3.0904e-02],\n",
      "          [ 1.1269e-01,  7.1003e-02,  4.5424e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.9975e-03,  9.4904e-03, -2.1614e-02],\n",
      "          [ 1.2504e-02,  3.4806e-02,  5.6039e-02],\n",
      "          [ 7.6676e-04, -1.1987e-01, -2.3389e-03]],\n",
      "\n",
      "         [[ 2.4556e-02,  4.2508e-02,  1.0048e-02],\n",
      "          [ 2.7147e-02,  6.3949e-02,  5.1510e-02],\n",
      "          [ 1.8143e-02, -6.1029e-02, -1.2093e-02]],\n",
      "\n",
      "         [[ 4.4525e-03,  1.2200e-01,  6.7180e-02],\n",
      "          [-5.4831e-02, -9.6267e-02,  2.6864e-02],\n",
      "          [-5.6007e-02, -1.5597e-02, -1.7325e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4093e-02,  5.7092e-02,  1.5262e-02],\n",
      "          [ 2.5740e-04,  1.8209e-02,  3.1720e-02],\n",
      "          [-2.0319e-02, -1.1244e-01, -1.5712e-02]],\n",
      "\n",
      "         [[ 9.5893e-02,  9.0334e-02,  1.0298e-01],\n",
      "          [ 8.6738e-02, -2.7019e-02,  6.4777e-02],\n",
      "          [ 6.1227e-02, -1.3069e-01, -7.7858e-02]],\n",
      "\n",
      "         [[ 1.5445e-02,  5.7287e-02, -9.6420e-03],\n",
      "          [ 1.1468e-01, -1.1010e-02,  1.0764e-01],\n",
      "          [-8.7792e-02, -1.3682e-02, -9.7569e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8531e-03,  2.2393e-03, -1.7149e-02],\n",
      "          [-3.2006e-02,  2.2191e-02, -2.8764e-02],\n",
      "          [-6.9467e-02, -4.9575e-02, -5.5290e-02]],\n",
      "\n",
      "         [[ 6.4690e-03,  7.9290e-03, -1.0111e-02],\n",
      "          [-6.8302e-03,  1.8760e-02, -8.5660e-03],\n",
      "          [-1.6849e-02, -1.7428e-02, -2.4494e-02]],\n",
      "\n",
      "         [[-3.3992e-02, -4.2348e-02, -1.5997e-02],\n",
      "          [-5.9134e-02, -1.6294e-02, -2.6574e-02],\n",
      "          [-3.8138e-02, -3.8333e-02, -2.1457e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7638e-02, -2.2734e-03, -2.8200e-02],\n",
      "          [-7.0825e-04,  4.8091e-02, -1.3987e-03],\n",
      "          [-6.0842e-02, -8.0619e-03, -2.2645e-02]],\n",
      "\n",
      "         [[-2.1905e-02, -7.6262e-02, -2.2758e-02],\n",
      "          [-3.8179e-02, -1.0467e-02, -1.1177e-02],\n",
      "          [-3.2759e-02, -3.0336e-02,  6.8328e-03]],\n",
      "\n",
      "         [[ 1.3684e-02, -1.3186e-02, -6.4235e-02],\n",
      "          [-1.2262e-02,  7.8548e-02,  3.3811e-02],\n",
      "          [-6.6433e-02, -2.0960e-02, -6.6813e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.5399e-02,  7.3217e-02,  5.8530e-02],\n",
      "          [ 7.4246e-02,  3.9589e-02,  8.1363e-02],\n",
      "          [ 4.8728e-02,  7.0342e-02,  7.2811e-02]],\n",
      "\n",
      "         [[-5.1006e-02, -3.3880e-02, -2.5717e-02],\n",
      "          [ 1.9710e-03,  2.2495e-02, -7.4535e-03],\n",
      "          [-3.6500e-02, -5.1222e-02, -4.2913e-02]],\n",
      "\n",
      "         [[-1.3571e-01, -8.4004e-02, -9.5602e-02],\n",
      "          [-7.8577e-02,  5.8174e-02, -9.3491e-02],\n",
      "          [-1.0850e-01, -5.9570e-02, -1.1923e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1136e-02, -8.6830e-02, -7.9670e-02],\n",
      "          [-9.7199e-02,  5.6532e-02, -8.3969e-02],\n",
      "          [-6.6071e-02, -8.5671e-02, -3.6140e-02]],\n",
      "\n",
      "         [[ 4.3222e-02,  4.8644e-02,  3.6801e-02],\n",
      "          [ 7.9945e-03,  4.2287e-02,  4.8047e-02],\n",
      "          [ 3.4945e-02,  2.7280e-02,  5.9850e-02]],\n",
      "\n",
      "         [[-1.5612e-02,  2.1743e-02,  2.3458e-02],\n",
      "          [ 2.0452e-02, -4.2482e-02,  3.1494e-02],\n",
      "          [ 1.0028e-02,  5.1147e-02,  9.6791e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4977e-03,  1.1180e-02, -3.7494e-05],\n",
      "          [-7.9217e-03, -1.0933e-01, -2.4074e-03],\n",
      "          [-1.0700e-02, -1.8005e-02,  1.9496e-02]],\n",
      "\n",
      "         [[-3.2756e-02,  1.7784e-03, -5.0789e-02],\n",
      "          [-4.7867e-02, -4.0979e-02, -7.7592e-02],\n",
      "          [-4.1489e-02, -3.7460e-02, -4.0829e-02]],\n",
      "\n",
      "         [[-2.5788e-02, -1.0696e-02, -4.4420e-02],\n",
      "          [-6.8317e-02, -1.1076e-01, -3.4488e-02],\n",
      "          [-3.7103e-02, -3.4811e-02,  1.6445e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2741e-03,  1.0230e-03,  1.0516e-02],\n",
      "          [ 8.8004e-03, -1.1078e-02, -1.6755e-02],\n",
      "          [ 1.8512e-02, -1.3732e-02,  1.5743e-02]],\n",
      "\n",
      "         [[ 1.6678e-02,  3.0599e-02,  4.8885e-02],\n",
      "          [ 2.2277e-02,  3.2640e-02,  1.2811e-02],\n",
      "          [-2.0627e-02,  1.1388e-02,  4.4097e-02]],\n",
      "\n",
      "         [[ 6.5682e-02,  1.9415e-03, -6.1987e-05],\n",
      "          [ 1.5179e-03,  4.2742e-03, -4.0234e-03],\n",
      "          [ 3.1951e-02,  7.5162e-03,  2.3232e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.1540e-02, -3.4272e-03, -2.7785e-02],\n",
      "          [ 4.5571e-03,  7.4736e-02,  1.8253e-02],\n",
      "          [-2.2846e-02,  3.7936e-02, -2.5545e-02]],\n",
      "\n",
      "         [[ 1.3196e-02,  3.5864e-02,  3.5892e-02],\n",
      "          [ 9.6321e-03,  6.0397e-02,  2.4265e-03],\n",
      "          [-1.9790e-02,  2.6241e-02, -7.3928e-03]],\n",
      "\n",
      "         [[ 3.0531e-02, -3.7883e-02,  4.2675e-02],\n",
      "          [-5.8772e-02, -2.8188e-01, -2.8662e-02],\n",
      "          [ 9.2655e-03, -5.5368e-02,  3.4514e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.9852e-03,  1.5687e-02, -2.4653e-02],\n",
      "          [ 1.0909e-02,  1.4453e-01,  1.4804e-02],\n",
      "          [-1.5972e-02,  1.4813e-02, -2.4333e-02]],\n",
      "\n",
      "         [[-5.8693e-02, -2.5502e-02, -5.2877e-02],\n",
      "          [-3.8955e-02,  5.5559e-02, -3.8759e-02],\n",
      "          [-7.0014e-02, -5.0153e-02, -4.3276e-02]],\n",
      "\n",
      "         [[-2.9908e-02, -8.2116e-02, -2.0663e-02],\n",
      "          [-6.6902e-02,  7.5750e-05, -3.8520e-02],\n",
      "          [ 4.4474e-02, -2.6194e-02, -1.1506e-02]]]], device='cuda:0')), ('backbone.model.layer1.2.bn2.weight', tensor([0.9482, 2.3034, 1.3806, 4.0139, 1.0733, 1.0792, 1.7602, 0.5322, 4.8022,\n",
      "        1.0656, 0.5182, 3.9784, 1.0638, 0.7418, 2.2884, 3.9452, 1.1351, 1.2449,\n",
      "        0.9449, 1.5260, 2.2845, 1.4770, 1.0316, 1.1228, 0.5794, 2.2513, 1.3013,\n",
      "        2.1585, 0.5050, 2.0214, 1.5028, 3.3650, 2.7578, 1.5451, 1.9328, 2.5817,\n",
      "        1.9818, 4.2110, 1.0484, 0.5993, 1.5565, 1.1121, 1.2220, 4.4673, 0.9500,\n",
      "        1.7138, 2.2572, 1.1380, 2.9053, 2.8678, 1.0932, 1.1622, 2.0669, 2.9580,\n",
      "        2.9383, 2.8746, 1.6019, 1.0802, 2.3955, 1.4384, 0.9525, 0.9469, 0.3546,\n",
      "        3.0954], device='cuda:0')), ('backbone.model.layer1.2.bn2.bias', tensor([-1.9545, -0.3402, -2.1961,  3.0568,  1.6428, -0.1372, -1.3491,  0.6801,\n",
      "        -3.8032,  0.0452, -1.0631, -0.6980, -1.9535,  0.5242, -2.5956,  3.1456,\n",
      "        -1.6027, -2.7511, -2.0206, -0.1499,  0.7168, -0.6906,  0.4780, -1.6314,\n",
      "         0.6835, -1.1875, -2.3489,  0.1526,  0.8689, -2.8294,  1.1358, -2.9692,\n",
      "        -1.9256,  1.8794,  0.9236, -1.4042, -2.2856,  3.4050,  0.6711,  0.4547,\n",
      "         0.3008, -1.8221, -2.0154,  1.3544, -1.9320, -0.5660, -2.3981,  0.9868,\n",
      "        -2.0111,  0.9541,  0.4100, -2.0227, -0.6938,  0.7460, -2.0029,  0.9095,\n",
      "         0.3788, -1.4257,  0.1743,  0.1566, -1.8016,  0.8358,  0.9502, -1.8690],\n",
      "       device='cuda:0')), ('backbone.model.layer1.2.conv3.weight', tensor([[[[-0.0203]],\n",
      "\n",
      "         [[-0.0447]],\n",
      "\n",
      "         [[ 0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0398]],\n",
      "\n",
      "         [[-0.0496]],\n",
      "\n",
      "         [[ 0.0172]]],\n",
      "\n",
      "\n",
      "        [[[-0.0489]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         [[-0.0342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         [[ 0.0027]]],\n",
      "\n",
      "\n",
      "        [[[-0.0974]],\n",
      "\n",
      "         [[-0.0686]],\n",
      "\n",
      "         [[-0.1053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0490]],\n",
      "\n",
      "         [[-0.0428]],\n",
      "\n",
      "         [[-0.0202]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0442]],\n",
      "\n",
      "         [[-0.0656]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0042]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[-0.0304]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0012]],\n",
      "\n",
      "         [[-0.0716]],\n",
      "\n",
      "         [[ 0.0547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0489]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[-0.0920]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0120]],\n",
      "\n",
      "         [[-0.3650]],\n",
      "\n",
      "         [[-0.0855]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119]],\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[-0.2741]]]], device='cuda:0')), ('backbone.model.layer1.2.bn3.weight', tensor([-1.6893e-01,  2.3438e-03, -2.2475e-01,  2.2689e+00,  1.1898e-02,\n",
      "         2.4365e-02, -6.7704e-03,  4.9100e-02, -1.0372e+00, -1.0019e+00,\n",
      "         1.9733e+00,  3.5919e+00, -1.4251e-01, -7.0980e-01,  8.2549e-01,\n",
      "         1.4259e-01,  1.0080e+00,  2.3459e+00, -1.6457e+00, -3.4412e-03,\n",
      "         7.9055e-01, -1.7139e-01, -1.4101e-01,  4.3858e-02, -8.3955e-01,\n",
      "         5.7871e-01, -1.9841e-01,  3.2696e-01, -6.0181e-01,  3.3059e+00,\n",
      "        -4.7063e-01, -2.5671e+00, -2.0308e-01, -8.6411e-01,  8.7793e-01,\n",
      "        -1.4161e-01, -7.2770e-01,  3.5380e-01, -3.6666e-01, -5.8752e-01,\n",
      "         1.9508e+00,  8.0162e-01,  3.1814e-03, -1.8675e+00, -4.6898e-01,\n",
      "        -1.4491e-02,  3.4023e+00, -6.2913e-02,  6.8113e-03,  1.7744e+00,\n",
      "        -1.3931e+00, -9.7934e-01, -6.3612e-02,  3.2709e+00,  1.7257e-01,\n",
      "         4.4070e-02, -3.8677e+00, -1.8664e-03,  9.2622e-01,  1.1150e+00,\n",
      "         2.0983e-02, -5.1232e-01, -4.6829e-01,  2.7968e-02, -6.2150e-02,\n",
      "         8.6303e-01, -5.7074e-01,  2.5184e+00, -8.3564e-02, -6.5525e-01,\n",
      "        -2.8706e-01,  3.3167e+00,  1.2546e+00, -4.3212e+00,  9.3258e-01,\n",
      "        -7.5164e-02, -2.0427e-02,  2.6221e+00,  7.8182e-01, -5.8719e-02,\n",
      "         3.6236e-03, -2.4193e+00, -1.2827e-02, -5.8537e-02,  9.2796e-02,\n",
      "         2.7725e+00, -5.0689e-03,  3.4129e-02, -4.0158e+00, -4.5715e-02,\n",
      "        -2.0342e-02,  2.1061e-02,  1.3946e-02, -2.1418e-01,  3.2650e-03,\n",
      "        -2.9260e+00, -1.0569e+00, -2.8533e+00,  1.0491e+00, -6.1190e-01,\n",
      "        -4.4249e+00,  3.1320e+00, -6.0674e+00, -3.6061e-02, -3.2188e-01,\n",
      "         3.8721e+00, -3.4129e-03,  1.2144e+00, -2.9069e+00,  3.5473e-02,\n",
      "        -2.3017e+00, -5.8061e-01, -1.4373e-02,  2.9116e+00, -2.6411e-01,\n",
      "         4.5295e+00,  2.7895e+00, -2.4582e-01, -1.0869e-02, -2.1069e-02,\n",
      "        -2.8531e-01, -2.5919e-01,  1.5782e-01,  6.5228e-01,  8.9436e-01,\n",
      "        -5.7008e-03,  2.9479e-01, -1.1165e+00, -3.4198e-02,  2.3117e+00,\n",
      "        -3.7621e+00,  1.9659e-01,  5.8532e-03,  3.7534e+00, -5.5466e-02,\n",
      "        -1.3612e-03,  1.1993e+00, -1.0980e+00, -1.0720e+00, -4.0539e-01,\n",
      "        -1.6550e-01,  4.9776e-01,  1.0330e+00, -1.0581e-01,  6.3355e-01,\n",
      "        -1.5872e+00,  2.3834e-04, -3.4993e-01,  5.1834e-02, -1.4502e-01,\n",
      "         1.3401e-01, -3.1192e+00, -7.8008e-01, -6.9549e+00,  5.9951e-01,\n",
      "        -1.2491e+00, -8.6250e-03, -3.0882e-01, -1.6033e-01, -2.2360e-01,\n",
      "         2.8125e-01,  1.0361e+00,  6.1035e-01, -3.1887e-01, -5.3781e-02,\n",
      "        -1.7666e+00,  2.8282e-01,  8.1783e-02, -8.2726e-01,  5.2269e-01,\n",
      "        -1.2798e-01,  2.9564e+00, -1.2986e+01, -4.3144e+00, -9.2361e-01,\n",
      "         1.6953e-01,  8.3817e-02, -5.6974e-01,  1.1000e-01,  1.9333e-01,\n",
      "         5.3703e+00, -1.0293e-01, -1.6509e-01, -7.8845e-01,  1.5218e-02,\n",
      "         2.5536e+00, -1.3668e-02, -5.8109e-03, -1.5719e-02,  1.4386e-02,\n",
      "         1.1214e-02,  2.4703e+00, -1.1674e+00, -1.5825e+00,  4.1565e-01,\n",
      "        -5.6528e-01, -1.9463e-01,  4.1332e-01, -2.6326e-01,  2.1294e+00,\n",
      "         4.8563e-04,  8.8410e-03,  5.4875e-01,  7.2804e-03, -2.1302e+00,\n",
      "         6.8441e-02,  4.8835e+00,  5.9744e-02,  4.2403e-02,  6.8642e-01,\n",
      "         1.4166e+00,  2.5638e+00,  1.1629e-02, -7.0913e-02, -4.2492e+00,\n",
      "         1.9636e-02, -9.5844e-01, -2.9615e-01,  4.6357e-01,  2.0015e+00,\n",
      "        -1.5986e-02,  5.9663e-02,  4.9172e-02, -4.8119e-03,  2.9460e-02,\n",
      "         5.6085e-01,  2.9422e+00, -5.8603e-01, -3.4652e-01, -2.1250e+00,\n",
      "        -1.2382e+00,  3.1112e-02, -1.2960e-02,  3.0692e-02,  5.9907e-02,\n",
      "         3.5066e-01, -5.7933e-01, -8.1707e-02,  2.2408e+00,  6.6258e-01,\n",
      "         3.6540e+00, -1.0201e-02, -9.9185e-01,  3.1827e+00,  8.2112e-01,\n",
      "         3.7121e-01,  3.4296e-01, -1.9822e+00,  4.2961e-01, -2.2777e+00,\n",
      "         7.1792e-01,  8.1534e-01,  7.5583e-01, -2.2403e+00,  4.9884e+00,\n",
      "        -1.4112e-02], device='cuda:0')), ('backbone.model.layer1.2.bn3.bias', tensor([-6.2182e-01, -5.1251e-03, -4.4183e-01, -4.9594e+00, -5.4110e-02,\n",
      "        -2.4261e-02, -6.7758e-01, -2.6178e-02, -7.4748e-02, -4.7346e-01,\n",
      "        -2.0024e+00,  8.7358e-01, -1.1521e-01, -5.0739e-01, -8.9005e-01,\n",
      "        -1.0869e-01, -1.0369e+00, -1.3014e+00, -4.9282e-01, -1.9100e-02,\n",
      "        -1.6705e-01, -4.7091e-02, -5.2662e-01, -1.0772e-01, -9.9916e-01,\n",
      "        -4.2235e-02, -2.0368e-01, -3.7831e-01, -6.1449e-01,  2.0740e-01,\n",
      "        -5.3096e-01,  6.5767e-01, -5.2770e-01,  6.8899e-02, -7.2423e-02,\n",
      "        -3.4882e-01, -1.3869e+00, -4.3175e-01, -9.6060e-01, -5.3126e-01,\n",
      "         1.6858e-01, -9.1852e-01, -1.3996e-01, -1.0024e+00, -3.8854e-01,\n",
      "        -7.2055e-03,  2.1136e+00, -1.4500e-01, -2.9396e-02, -1.6042e+00,\n",
      "        -1.3319e+00, -1.6568e-02, -1.7886e-01,  1.7975e+00, -5.1742e-01,\n",
      "        -7.7759e-02,  2.4884e+00, -1.5381e-02, -7.1118e-01, -4.8072e-01,\n",
      "        -1.5608e-01, -2.2869e+00, -7.2505e-01, -3.2532e-02, -5.4869e-02,\n",
      "        -6.1976e-01, -3.3434e-01,  1.6459e+00,  2.2739e-02, -4.2295e-01,\n",
      "        -3.2644e-02,  1.7397e+00, -2.4107e+00, -2.0637e+00, -1.1542e+00,\n",
      "        -2.1329e-01, -6.2341e-02, -5.0923e+00, -3.2384e+00, -1.2025e-01,\n",
      "        -1.4795e-02, -3.6619e+00, -5.1211e-01, -1.3321e-01, -2.7423e-01,\n",
      "        -2.1299e+00, -8.3796e-02, -1.0718e-01, -3.1672e+00, -1.7050e-01,\n",
      "         1.4431e-02, -1.9623e-02, -5.8041e-02, -2.8380e-01, -1.9576e-02,\n",
      "        -3.8575e+00, -2.0067e+00,  3.8070e-01, -3.6033e-01, -7.0353e-01,\n",
      "        -1.9311e+00, -4.2529e-01, -5.6924e-01,  4.4346e-02, -5.5475e-01,\n",
      "         8.2277e-01, -8.1958e-03, -1.6722e+00,  6.7490e-01, -4.0649e-02,\n",
      "        -2.2026e+00, -7.6566e-01, -6.2866e-04, -3.2966e-01, -2.0327e-01,\n",
      "        -1.8435e+00,  2.1093e+00, -6.5162e-01, -1.2919e-02, -1.2208e-02,\n",
      "        -3.1675e-01, -5.8464e-01, -8.1924e-02,  3.8448e-01, -8.5799e-01,\n",
      "        -3.3208e-03, -4.7991e-01, -5.0128e-01, -2.5077e-01, -3.3566e+00,\n",
      "        -9.9572e-01, -4.5599e-01, -9.0983e-02, -1.7168e+00, -8.8729e-02,\n",
      "        -1.5234e-01, -1.1841e+00, -1.1848e+00,  5.8087e-01,  2.6546e-02,\n",
      "        -1.1534e-01, -2.2011e-01,  6.9596e-01, -1.4995e-01, -4.2586e-01,\n",
      "        -1.3524e+00, -2.0015e-02, -3.7933e-01, -2.0054e-02, -2.0238e-01,\n",
      "         3.7156e-02,  2.9409e+00, -1.4565e+00,  4.6184e-01,  7.3529e-02,\n",
      "        -1.1285e+00, -1.8296e-02, -4.2388e-01, -1.5580e-01, -3.3772e-01,\n",
      "        -4.0414e-01, -1.1775e+00, -6.2718e-01, -5.1288e-01, -1.1222e-01,\n",
      "        -3.2824e-01, -5.2021e-01, -2.6281e-01, -4.4966e-01, -4.3764e-01,\n",
      "        -4.3540e-01, -1.5905e+01, -5.3825e+00,  1.9818e+00, -3.6064e-01,\n",
      "        -4.3781e-01, -4.7273e-01, -2.0383e-01, -1.8503e-01, -2.7530e-01,\n",
      "         4.3541e+00, -3.6899e-01, -2.9243e-01, -2.0246e+00, -3.5107e-02,\n",
      "        -3.2385e+00, -1.3671e+00, -2.0610e-02, -3.7839e-01, -1.0797e-01,\n",
      "        -5.7379e-02, -2.0035e+00, -1.4409e+00,  2.3281e-01,  2.2608e-02,\n",
      "        -1.3312e+00, -8.1087e-02, -7.1981e-01, -4.9288e-01,  9.3075e-01,\n",
      "        -3.4035e-02, -2.6018e-02, -4.0551e-01, -5.2301e-02,  1.3941e+00,\n",
      "        -2.3245e-01,  9.8474e-01, -3.6513e-01, -2.8211e-02, -6.2744e-01,\n",
      "        -3.6198e+00, -2.0910e+00, -6.1581e-02, -2.0419e-01,  1.6552e+00,\n",
      "        -3.3650e-02, -9.4743e-01, -1.9566e-01, -9.2473e-01, -2.3454e+00,\n",
      "        -1.3910e-01, -2.1243e-02, -7.1130e-02, -2.2571e-02, -2.2625e-02,\n",
      "        -4.7552e-01, -2.4222e+00, -9.2975e-01, -4.0212e-01,  1.4490e+00,\n",
      "        -7.9385e-02, -1.9376e-02, -4.9993e-02, -1.5699e-01, -1.5152e-01,\n",
      "        -4.0417e-01, -2.1398e+00, -1.0610e+00, -2.3191e+00, -2.8534e-01,\n",
      "         2.1033e-01, -9.6547e-03, -2.2864e-01, -1.5663e+00, -8.6793e-01,\n",
      "        -2.6290e-01, -7.2525e-02,  1.0833e+00, -3.1355e-01, -7.7009e-02,\n",
      "        -3.6561e-01, -9.5230e-01, -2.8178e+00, -1.2827e+00, -5.5705e-01,\n",
      "         1.9011e-03], device='cuda:0')), ('backbone.model.layer2.0.conv1.weight', tensor([[[[-0.0008]],\n",
      "\n",
      "         [[ 0.0068]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[ 0.0523]],\n",
      "\n",
      "         [[-0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.1473]],\n",
      "\n",
      "         [[-0.0128]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0361]],\n",
      "\n",
      "         [[ 0.0543]],\n",
      "\n",
      "         [[-0.0115]]],\n",
      "\n",
      "\n",
      "        [[[-0.0290]],\n",
      "\n",
      "         [[ 0.0762]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[-0.0359]],\n",
      "\n",
      "         [[ 0.0328]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0290]],\n",
      "\n",
      "         [[-0.0470]],\n",
      "\n",
      "         [[-0.0903]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[-0.0680]],\n",
      "\n",
      "         [[ 0.2232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1078]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[-0.1680]],\n",
      "\n",
      "         [[-0.2778]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0465]],\n",
      "\n",
      "         [[-0.0164]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0120]],\n",
      "\n",
      "         [[-0.0822]],\n",
      "\n",
      "         [[-0.0582]]]], device='cuda:0')), ('backbone.model.layer2.0.bn1.weight', tensor([1.7200, 1.7910, 2.8168, 1.7769, 1.3017, 1.5168, 1.7186, 1.2908, 1.4699,\n",
      "        1.5808, 2.3528, 2.4938, 2.4354, 2.1842, 1.6175, 1.6828, 1.5720, 1.7993,\n",
      "        1.2527, 2.4548, 1.8867, 1.6522, 1.2285, 4.2687, 2.4800, 1.9238, 1.7430,\n",
      "        2.6477, 1.9470, 1.6809, 1.9565, 1.8284, 1.8359, 2.6516, 2.7160, 2.5202,\n",
      "        2.3426, 1.7868, 1.4043, 2.3384, 1.6758, 1.8494, 2.4024, 2.9968, 2.2216,\n",
      "        1.2511, 1.7831, 1.8303, 1.7193, 1.9683, 2.5074, 1.4396, 1.8071, 2.2534,\n",
      "        2.4391, 1.5382, 1.5580, 2.3520, 1.7262, 1.7546, 1.3115, 1.5737, 2.0587,\n",
      "        1.7568, 1.3876, 2.3528, 1.7477, 1.3958, 2.0124, 1.5167, 1.6085, 1.5003,\n",
      "        1.8604, 2.1887, 2.2142, 2.1446, 1.9337, 1.9744, 2.3459, 2.8008, 2.2901,\n",
      "        1.9119, 1.8692, 2.0388, 2.3063, 2.1042, 1.9774, 2.2474, 2.3641, 1.8910,\n",
      "        1.5332, 1.8889, 1.8608, 2.2540, 1.6357, 1.9403, 2.0203, 1.7419, 1.5528,\n",
      "        1.6992, 1.6134, 1.6185, 2.7046, 2.9681, 0.0223, 1.7569, 2.2122, 1.9053,\n",
      "        1.9546, 1.7980, 1.6158, 1.6760, 5.6614, 1.3410, 1.3093, 1.9028, 1.7363,\n",
      "        2.4976, 1.7595, 2.1071, 1.1863, 1.7761, 3.5553, 1.6335, 1.5860, 2.0833,\n",
      "        2.1315, 1.7636], device='cuda:0')), ('backbone.model.layer2.0.bn1.bias', tensor([ 2.5203e-01, -1.7694e+00, -1.9549e+00,  4.0734e-01,  1.3745e-01,\n",
      "        -1.1680e+00,  2.1586e-01,  2.3915e-01, -2.8158e-01, -1.8760e+00,\n",
      "        -5.7210e-01,  8.1107e-01, -1.2683e+00, -1.4051e+00, -3.1633e-01,\n",
      "         1.8124e-01, -8.5778e-01, -5.7469e-01,  1.7476e-01, -1.6232e+00,\n",
      "        -2.2939e+00, -1.7305e+00,  2.7361e-01, -3.9341e+00, -1.7490e-01,\n",
      "        -2.3985e+00,  6.8346e-01, -2.3965e-01, -1.5441e+00,  8.3298e-01,\n",
      "        -9.9960e-01, -1.5552e+00, -1.5384e+00, -1.0079e-01, -7.2183e-01,\n",
      "        -1.4711e+00, -3.8321e+00,  3.4702e-01, -1.1203e-01, -5.3681e-01,\n",
      "        -4.9213e-02, -1.2703e+00, -3.3272e+00, -2.7052e+00, -2.9785e+00,\n",
      "         7.7919e-01, -3.5925e-01, -9.4544e-01, -2.7993e-01, -2.1850e+00,\n",
      "        -1.0934e+00,  2.1735e-01, -1.2682e+00, -6.6840e-01, -1.1209e+00,\n",
      "         1.5250e-01,  4.4555e-01,  1.3638e-02, -3.6119e-01, -1.3921e+00,\n",
      "        -1.2031e+00, -3.3534e-01, -8.5482e-01,  1.4585e+00, -1.0342e+00,\n",
      "        -2.4861e+00, -3.3283e-01,  3.2925e-01, -7.1548e-01, -7.5958e-01,\n",
      "        -1.1776e+00,  1.1991e-01, -1.7016e+00, -4.4397e-01, -2.6121e+00,\n",
      "         3.1961e-01,  5.8005e-01, -1.0343e+00, -3.6709e+00, -1.6214e+00,\n",
      "        -1.2802e+00, -1.2229e+00,  2.8823e-01, -1.1603e+00, -1.5697e+00,\n",
      "         1.5112e+00, -7.4576e-01, -1.4323e+00, -3.8277e+00, -1.5910e-03,\n",
      "         4.6383e-01, -2.5488e-01, -2.0494e+00, -1.8231e+00,  1.1505e-01,\n",
      "        -1.3597e+00,  5.7820e-01,  8.6723e-01, -1.9780e-01, -2.2126e+00,\n",
      "        -3.8193e-01, -5.9497e-01, -3.5292e+00, -1.2764e+00, -1.1766e+00,\n",
      "        -1.7774e+00, -2.1859e+00, -1.6802e+00, -6.5175e-01, -2.5347e+00,\n",
      "        -2.1184e-01,  1.3379e-01, -3.3003e+00, -2.1921e-01, -1.9358e-01,\n",
      "        -2.1569e+00, -1.2554e+00,  2.4008e-01,  3.4888e-01, -8.4352e-01,\n",
      "        -9.5211e-01, -1.2642e+00, -1.7587e+00,  1.1958e+00, -6.5021e-01,\n",
      "        -1.0155e-01, -1.1736e+00,  1.7199e-01], device='cuda:0')), ('backbone.model.layer2.0.conv2.weight', tensor([[[[ 3.4793e-02, -1.1682e-01,  7.9975e-03],\n",
      "          [ 3.6265e-02, -8.4149e-02,  3.1866e-05],\n",
      "          [ 3.3237e-02, -7.9489e-02, -2.1221e-02]],\n",
      "\n",
      "         [[-1.6449e-02, -3.1321e-03, -6.0932e-03],\n",
      "          [-3.5074e-02,  6.8292e-02, -2.2003e-02],\n",
      "          [ 1.2712e-04,  2.4425e-02, -1.7457e-02]],\n",
      "\n",
      "         [[-1.5098e-02, -1.7915e-01,  3.5029e-02],\n",
      "          [ 3.1657e-02, -2.0141e-01,  3.7456e-02],\n",
      "          [ 9.9395e-03, -1.6614e-01,  4.5924e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6361e-02, -1.8623e-01, -1.5721e-02],\n",
      "          [ 5.0187e-02, -2.1321e-01,  3.0617e-02],\n",
      "          [ 6.3309e-03, -1.9540e-01,  9.5941e-02]],\n",
      "\n",
      "         [[-1.8462e-02,  4.1735e-02, -2.9739e-02],\n",
      "          [-8.5979e-02,  7.4946e-02, -5.4673e-02],\n",
      "          [-7.2101e-02,  7.1068e-02, -3.3285e-02]],\n",
      "\n",
      "         [[ 3.0355e-02, -4.8602e-02,  4.8654e-02],\n",
      "          [ 1.0009e-01, -2.1391e-01,  8.3665e-02],\n",
      "          [ 1.0443e-01, -8.9226e-02,  6.3843e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0717e-02,  8.8560e-02,  1.5312e-02],\n",
      "          [ 9.5987e-02,  2.5044e-02,  7.5916e-02],\n",
      "          [ 3.1635e-02,  6.7121e-02,  1.0902e-01]],\n",
      "\n",
      "         [[ 3.8169e-02,  1.1915e-02, -4.5517e-02],\n",
      "          [ 5.5564e-03, -3.6381e-02, -2.0597e-02],\n",
      "          [-2.2175e-02,  1.3087e-02,  3.8514e-02]],\n",
      "\n",
      "         [[ 1.0842e-03,  2.0012e-02,  3.2671e-02],\n",
      "          [-3.3287e-03, -1.5462e-02,  1.2168e-02],\n",
      "          [ 4.5672e-03,  4.1116e-03, -8.9293e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8186e-02, -3.9131e-02, -1.9208e-02],\n",
      "          [-1.2509e-02,  7.2525e-02, -3.8008e-02],\n",
      "          [ 5.9124e-03, -1.1461e-03, -4.4033e-02]],\n",
      "\n",
      "         [[-5.5622e-03, -4.6899e-02, -1.7369e-02],\n",
      "          [-1.0476e-01, -1.2266e-01, -8.3017e-02],\n",
      "          [-2.8090e-02, -6.9911e-02, -9.2828e-03]],\n",
      "\n",
      "         [[ 2.2148e-02,  3.1794e-02,  1.6556e-02],\n",
      "          [ 4.3087e-02,  6.5166e-02,  5.5968e-02],\n",
      "          [ 2.6117e-02, -2.8142e-03,  3.7297e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3389e-02,  1.2580e-02, -3.2256e-03],\n",
      "          [-2.8139e-02,  1.5548e-02, -3.7683e-02],\n",
      "          [-5.7841e-02, -1.1160e-03, -2.5895e-02]],\n",
      "\n",
      "         [[ 6.1011e-02,  4.2485e-02,  4.5739e-02],\n",
      "          [ 6.4914e-02,  3.3202e-03,  5.0211e-02],\n",
      "          [ 7.9553e-02,  2.7417e-02,  8.5696e-02]],\n",
      "\n",
      "         [[ 2.3781e-02, -4.7165e-02,  2.6500e-02],\n",
      "          [ 1.6487e-02, -6.9890e-02, -2.8006e-02],\n",
      "          [ 4.3073e-02,  4.9628e-02,  7.6914e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1481e-02, -8.5560e-02, -3.5451e-02],\n",
      "          [-4.8362e-02, -1.7137e-02, -4.8365e-02],\n",
      "          [-2.3754e-02, -4.2934e-02, -3.9122e-02]],\n",
      "\n",
      "         [[ 5.5163e-02,  9.0460e-02,  7.5096e-02],\n",
      "          [ 2.1405e-02,  2.1703e-02,  5.3094e-02],\n",
      "          [ 6.3871e-02,  2.7814e-02,  3.5310e-02]],\n",
      "\n",
      "         [[-1.1514e-01, -1.2496e-01, -5.7494e-02],\n",
      "          [-8.3335e-02, -7.8632e-02, -7.9857e-02],\n",
      "          [-8.4878e-02, -1.6406e-01, -9.4488e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.7121e-03, -3.8258e-03, -1.7786e-02],\n",
      "          [-1.5919e-03, -2.3567e-03, -3.7332e-03],\n",
      "          [ 2.1897e-02, -1.5567e-02,  1.3344e-02]],\n",
      "\n",
      "         [[-1.0496e-02,  2.2333e-02,  2.4710e-02],\n",
      "          [ 3.2914e-02,  2.6641e-02,  4.7012e-02],\n",
      "          [ 2.3165e-02,  3.7380e-02,  3.0998e-02]],\n",
      "\n",
      "         [[ 1.0803e-02,  6.7733e-02,  2.8677e-02],\n",
      "          [ 5.4363e-02,  9.1529e-02,  8.0334e-02],\n",
      "          [ 4.6982e-03,  5.3777e-02,  3.6550e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.1069e-02, -1.4965e-02, -7.7316e-03],\n",
      "          [-1.1739e-02, -8.7771e-04, -2.6936e-03],\n",
      "          [ 1.5415e-03, -1.3079e-03, -1.8854e-02]],\n",
      "\n",
      "         [[-1.7985e-02,  1.5560e-02,  5.9914e-04],\n",
      "          [-1.4221e-02, -1.1626e-04,  1.2551e-02],\n",
      "          [-9.6819e-03,  2.6931e-02,  1.5291e-02]],\n",
      "\n",
      "         [[-2.1776e-02, -5.6972e-03,  1.7158e-02],\n",
      "          [-2.7755e-02, -1.6391e-04,  6.4016e-03],\n",
      "          [-2.5462e-03, -1.7810e-02, -1.0519e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8030e-02,  1.5306e-01,  1.4961e-01],\n",
      "          [-5.4016e-02, -2.1118e-01, -1.5071e-01],\n",
      "          [-1.2107e-01, -2.2928e-01, -9.5552e-02]],\n",
      "\n",
      "         [[-4.5868e-02, -1.1102e-01, -6.1063e-02],\n",
      "          [-1.3498e-02,  1.1320e-02,  2.0450e-02],\n",
      "          [ 8.6506e-03,  1.3844e-02,  5.8495e-02]],\n",
      "\n",
      "         [[-1.8895e-01, -1.9961e-01, -1.4920e-01],\n",
      "          [ 9.2649e-02,  7.7119e-02,  4.2686e-02],\n",
      "          [ 1.9221e-02,  1.4480e-02,  3.9186e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.8553e-03,  5.0080e-02, -2.6891e-03],\n",
      "          [-6.6931e-02, -4.7818e-03, -1.5932e-02],\n",
      "          [ 1.4268e-02, -1.6167e-03, -5.5981e-02]],\n",
      "\n",
      "         [[ 2.7811e-02, -2.7819e-02, -8.1705e-02],\n",
      "          [ 6.3321e-02,  5.8205e-02,  1.6575e-02],\n",
      "          [-2.9270e-02, -2.0783e-02, -1.0608e-02]],\n",
      "\n",
      "         [[ 6.3254e-02,  8.9726e-02,  3.4126e-02],\n",
      "          [-1.3295e-01, -1.7655e-01, -7.5084e-02],\n",
      "          [-1.4634e-02, -1.5757e-02, -6.9421e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4449e-02, -9.0436e-03, -8.0371e-02],\n",
      "          [ 3.9856e-03,  3.2357e-02, -1.1730e-01],\n",
      "          [-1.3414e-02,  7.0745e-02, -1.4081e-01]],\n",
      "\n",
      "         [[ 6.4235e-04, -7.7577e-02,  5.8418e-02],\n",
      "          [ 1.3166e-02,  5.1159e-03, -8.9465e-02],\n",
      "          [-1.3332e-02,  6.9241e-02, -2.8077e-02]],\n",
      "\n",
      "         [[-1.1870e-01,  3.2826e-02,  5.0934e-02],\n",
      "          [-1.1332e-01, -1.2006e-01,  8.7351e-02],\n",
      "          [-3.5860e-02, -2.1867e-01, -4.3203e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4702e-03,  6.6772e-02,  6.7054e-02],\n",
      "          [ 4.0635e-02, -7.4904e-02,  1.6568e-01],\n",
      "          [ 8.0484e-02, -1.2304e-01,  9.8054e-02]],\n",
      "\n",
      "         [[-2.2328e-02, -1.1020e-01, -3.8126e-02],\n",
      "          [ 3.9621e-02,  1.3892e-02, -1.1270e-01],\n",
      "          [ 8.0779e-03,  4.3435e-02, -4.2784e-02]],\n",
      "\n",
      "         [[-3.6806e-02,  3.9987e-02,  5.7901e-03],\n",
      "          [ 2.4158e-02, -4.9721e-03,  8.5342e-02],\n",
      "          [ 1.3733e-02, -7.8582e-02,  5.5813e-02]]]], device='cuda:0')), ('backbone.model.layer2.0.bn2.weight', tensor([1.5396, 1.7487, 1.5244, 2.2709, 1.6043, 2.9140, 2.3637, 3.3936, 1.5976,\n",
      "        2.1094, 2.5723, 2.2036, 1.9948, 1.7272, 1.8990, 1.6931, 1.8969, 1.7667,\n",
      "        2.1943, 2.5137, 2.6814, 2.0705, 2.4113, 2.3775, 2.1889, 1.9288, 2.1096,\n",
      "        2.3274, 2.8937, 3.0406, 2.1887, 1.8924, 2.3420, 1.1390, 2.2360, 1.8885,\n",
      "        1.5119, 2.6943, 1.9991, 2.2817, 2.6540, 1.7577, 2.0949, 2.5280, 2.0978,\n",
      "        2.6760, 1.5226, 2.6191, 1.4060, 1.6575, 1.9176, 1.9208, 1.8862, 1.9670,\n",
      "        1.3952, 1.9864, 1.6470, 2.2589, 2.0927, 2.4957, 2.4354, 2.2141, 1.7324,\n",
      "        2.6287, 1.7494, 2.4731, 1.7460, 1.6201, 1.5811, 2.8106, 2.0982, 2.3973,\n",
      "        1.6840, 1.9846, 1.3073, 1.9746, 2.5634, 2.7953, 2.3761, 2.9608, 1.8885,\n",
      "        2.2747, 1.3107, 2.3031, 1.4288, 1.6276, 2.2292, 1.3817, 2.6280, 2.0873,\n",
      "        2.1411, 2.2650, 2.3484, 2.2388, 2.1461, 2.3892, 1.4726, 2.6524, 1.9562,\n",
      "        3.3624, 1.8172, 1.9277, 1.1689, 1.5448, 2.8680, 2.5305, 1.6352, 2.2088,\n",
      "        1.2356, 1.6509, 1.8306, 1.6498, 2.4140, 2.4396, 2.6504, 2.4194, 2.1466,\n",
      "        2.1344, 2.3565, 2.0278, 1.9375, 2.1518, 2.3959, 2.0978, 2.8609, 2.5530,\n",
      "        1.5804, 2.0956], device='cuda:0')), ('backbone.model.layer2.0.bn2.bias', tensor([-0.1060,  0.4981, -0.1713, -2.1112,  1.2210, -1.4544, -2.2008, -1.9524,\n",
      "         0.4851,  0.4810, -0.8985, -2.1933, -0.9503, -0.0978,  0.4150,  1.0153,\n",
      "         0.5932,  1.1903, -2.1553, -0.6217, -0.7014, -2.3193,  1.1291,  1.1171,\n",
      "        -0.3783,  1.1508, -2.7400, -0.7261, -0.4597,  0.3572,  2.1427, -0.6501,\n",
      "        -2.2405,  1.1948, -1.9746, -0.2420, -0.8165, -0.3327,  1.5096,  0.2912,\n",
      "        -1.6568,  1.3481,  0.1182, -0.9103,  0.1763, -0.1231,  0.7203, -2.9678,\n",
      "         0.3594,  0.9260, -1.5405, -0.1007,  1.4728, -2.2833,  0.7149, -0.7919,\n",
      "         1.2537, -1.5266,  0.4084, -2.8622, -0.2895, -2.6662,  0.1211,  0.7379,\n",
      "        -1.5147, -0.4109, -0.2351,  1.2479,  0.2712, -0.5599, -1.3616,  0.6584,\n",
      "        -0.9675,  0.7922, -0.0436,  1.1043,  1.2275,  0.6925, -2.2711,  0.4712,\n",
      "         1.8181, -1.2171,  0.5601,  0.0516, -0.2354, -1.1749,  0.6937,  0.9874,\n",
      "        -0.7914, -1.9218,  0.9727, -0.6406,  0.5182,  0.6682, -2.3735,  0.5317,\n",
      "         0.7836,  0.3020, -0.8829, -0.5448,  0.4725, -1.4502,  0.5379,  1.0796,\n",
      "        -0.8340, -0.2364,  1.5069, -1.8058,  0.8392,  0.3895, -2.0067, -0.3909,\n",
      "        -2.0467, -1.1439, -0.0545,  0.9429,  0.4562, -1.5992,  0.6398, -1.5939,\n",
      "         0.9451,  0.6725, -1.1609, -0.7248, -1.1637, -1.4278,  1.5307, -0.0457],\n",
      "       device='cuda:0')), ('backbone.model.layer2.0.conv3.weight', tensor([[[[ 0.0702]],\n",
      "\n",
      "         [[ 0.0807]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         [[-0.0276]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0255]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[ 0.0652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0161]],\n",
      "\n",
      "         [[ 0.0272]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[ 0.0684]],\n",
      "\n",
      "         [[-0.0123]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0101]],\n",
      "\n",
      "         [[ 0.0249]],\n",
      "\n",
      "         [[ 0.1023]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0993]],\n",
      "\n",
      "         [[ 0.0094]],\n",
      "\n",
      "         [[ 0.0376]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[-0.0892]],\n",
      "\n",
      "         [[ 0.1414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0688]],\n",
      "\n",
      "         [[-0.0054]],\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         [[-0.1044]]],\n",
      "\n",
      "\n",
      "        [[[-0.0777]],\n",
      "\n",
      "         [[-0.0018]],\n",
      "\n",
      "         [[-0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0900]],\n",
      "\n",
      "         [[ 0.0705]],\n",
      "\n",
      "         [[-0.0166]]]], device='cuda:0')), ('backbone.model.layer2.0.bn3.weight', tensor([-1.6556e+00,  1.5706e+00,  3.4830e+00,  8.5048e-01,  2.2449e+00,\n",
      "         1.4239e+00,  4.5225e+00, -2.3605e+00,  1.9086e+00,  3.8398e+00,\n",
      "         1.7715e-01,  2.9523e+00,  2.5779e+00, -4.1174e-02, -1.5245e+00,\n",
      "        -9.4215e-01, -2.2798e+00, -2.6109e+00,  7.3573e+00,  1.7421e+00,\n",
      "        -2.0971e+00,  3.6011e+00,  5.7548e-01, -2.7574e+00,  1.7019e+00,\n",
      "        -5.3316e+00, -4.6843e+00,  3.3718e-01,  4.5615e+00, -5.4868e+00,\n",
      "         3.5918e+00, -1.8976e+00,  3.0264e+00, -3.0531e+00, -2.9804e+00,\n",
      "        -2.2443e+00, -3.2490e+00, -8.5165e-01, -9.8656e-01,  2.9249e+00,\n",
      "        -5.9875e+00, -6.9451e-01,  4.9652e+00,  2.0827e+00,  1.9112e-01,\n",
      "        -2.0778e+00, -3.5348e+00,  3.0269e+00,  2.3363e+00,  3.8539e-01,\n",
      "         2.8935e+00, -9.4115e-01,  2.5082e+00, -1.8699e+00, -4.0410e-02,\n",
      "         9.6370e-01, -2.2902e+00,  9.1172e-01,  5.4896e+00, -2.1335e+00,\n",
      "         1.6886e-01, -2.2502e+00,  2.0937e+00, -1.0900e+00,  9.1429e+00,\n",
      "         5.6616e-02,  4.1995e-01,  3.0101e+00,  6.4685e-01,  5.3908e+00,\n",
      "        -1.8930e+00,  4.8568e+00, -3.0628e+00, -3.0999e+00, -2.0173e+00,\n",
      "         3.1863e+00, -1.6412e+00,  1.4792e+00, -4.6104e-01, -3.8794e+00,\n",
      "         1.4088e+00, -1.0470e+00,  1.6867e+00,  7.0119e-01,  1.8141e+00,\n",
      "        -3.4695e+00,  5.3434e-02,  4.0493e-02, -2.7622e+00,  2.8614e-01,\n",
      "        -2.4681e+00, -1.1191e+00,  3.5890e+00, -6.9788e-01,  4.0930e+00,\n",
      "        -1.9223e-02,  5.0753e+00,  3.7742e+00, -3.9272e+00,  9.3425e-01,\n",
      "         2.2115e+00, -3.3366e+00,  2.3308e+00, -1.4048e+00, -1.3467e+00,\n",
      "         2.8842e+00,  2.4981e+00,  3.2339e+00,  1.4046e+00,  1.5876e+00,\n",
      "         1.8380e+00, -6.0802e-01, -4.5105e-01, -3.6730e+00, -3.3922e+00,\n",
      "         1.1011e+00,  6.2028e-01, -2.0296e+00,  1.7272e+00,  4.2991e-01,\n",
      "         1.2035e-01,  1.6233e+00, -1.4265e+00,  2.0323e+00,  2.2197e+00,\n",
      "         2.5747e+00,  8.2620e+00,  5.2853e+00, -3.9875e+00,  8.6908e+00,\n",
      "        -4.3619e+00, -5.2644e-01,  2.6022e+00, -3.2419e-02, -1.5706e+00,\n",
      "         5.5844e+00,  5.2333e+00, -3.9078e+00,  1.2754e+00,  5.3893e-01,\n",
      "         1.4298e+00, -2.5441e+00, -2.1125e+00, -2.3715e+00,  2.3791e+00,\n",
      "        -4.4252e+00, -2.7266e+00, -1.1709e+00, -1.1319e+00, -2.4992e+00,\n",
      "         3.3039e+00,  4.2149e+00, -2.9111e+00,  2.7151e+00,  7.4854e-02,\n",
      "         4.0460e+00, -6.2695e+00, -4.2719e+00,  2.5390e+00,  5.6523e+00,\n",
      "         9.7281e-01, -4.7372e+00, -3.6494e+00,  1.1418e+00, -5.0538e+00,\n",
      "        -3.2419e+00, -5.7068e+00, -1.0871e+00, -1.5219e+00, -1.9945e+00,\n",
      "        -8.3360e-01, -1.9525e+00,  2.6987e+00, -1.9415e+00,  2.5342e-01,\n",
      "         3.2099e-01, -1.4963e+00,  1.9564e+00, -2.2042e+00, -1.2758e+00,\n",
      "         2.5125e+00,  4.0204e+00, -3.1110e-02, -1.5251e+00, -7.1271e-01,\n",
      "         5.5473e+00,  7.1926e-01,  2.1802e+00, -6.6692e-02,  2.6144e-01,\n",
      "        -7.2102e-01,  2.1780e+00, -1.2828e+00,  2.5703e+00,  1.8617e+00,\n",
      "        -2.3655e+00,  2.2599e+00, -2.8405e+00, -2.7720e+00, -3.3575e+00,\n",
      "        -1.0883e+00,  8.8690e-01, -3.3839e+00, -2.2281e+00, -2.3588e+00,\n",
      "        -2.4487e+00,  5.1001e+00,  3.0509e+00, -2.7428e+00, -2.0674e+00,\n",
      "        -2.7519e+00,  7.6169e-01, -8.7895e-01, -2.2912e+00, -3.6597e+00,\n",
      "        -4.6736e-01, -1.2831e-01, -3.0757e-01,  1.4126e-01,  1.3752e-01,\n",
      "        -4.0152e-01,  5.2100e-01,  2.9635e-02,  1.4603e+00, -2.2618e+00,\n",
      "        -9.9112e-01, -1.7104e+00, -1.1173e+00,  4.5283e+00,  3.9164e-01,\n",
      "        -1.3526e+00,  1.3578e+00, -1.8625e+00,  3.2918e+00, -3.8094e+00,\n",
      "        -3.8615e+00,  5.9070e+00,  2.4525e+00, -4.0657e-01, -1.4448e+00,\n",
      "        -2.8574e+00, -2.1856e+00, -2.4886e+00,  5.8764e+00,  2.0804e+00,\n",
      "         1.3294e+00, -2.0853e+00,  5.0300e+00,  4.1468e+00, -2.0194e-01,\n",
      "        -3.9687e-01, -1.2437e+00,  1.6219e-01,  8.3982e-01, -2.2857e+00,\n",
      "         3.0953e+00, -2.2263e+00, -7.1852e-01, -4.2750e-01,  1.8391e+00,\n",
      "         1.6158e+00, -2.0073e+00, -2.4105e+00,  2.7810e+00, -4.5878e-01,\n",
      "         3.0226e+00, -2.1373e+00, -2.7780e+00, -1.0371e-01,  1.4582e+00,\n",
      "         2.4641e+00,  1.9074e+00,  3.6553e+00,  1.2920e+00, -2.6908e-01,\n",
      "        -3.1635e+00,  8.6238e-01,  1.5176e+00,  3.3028e+00,  2.2195e+00,\n",
      "         3.1347e+00,  5.9811e+00, -2.9014e+00, -4.4943e-01, -2.0109e+00,\n",
      "         1.3542e+00,  5.4269e-01, -1.0978e+00, -8.5789e-01, -2.1300e+00,\n",
      "         2.3402e+00,  2.9425e+00, -2.1301e+01, -4.1791e+00, -2.4439e+00,\n",
      "        -7.4980e-01,  1.2913e-01, -2.4199e+00,  3.2872e+00, -4.1624e+00,\n",
      "        -1.8670e+00, -2.7605e-01, -1.9030e+00,  2.6381e+00,  9.9894e-01,\n",
      "        -2.6813e-01, -2.4844e+00,  3.8016e-01,  1.8016e+00,  1.7268e+00,\n",
      "         1.2766e-02,  3.2021e+00,  2.2113e-01,  2.7191e+00,  2.0918e-01,\n",
      "        -4.1682e+00, -8.7149e+00, -2.2096e+00,  1.7048e-01, -9.1263e-01,\n",
      "         2.2062e-01, -3.0058e+00, -2.2218e+00, -1.4364e+00, -4.5583e+00,\n",
      "        -3.5960e+00, -1.8727e+00,  3.6523e+00,  1.3371e+00, -1.4674e+00,\n",
      "        -3.0292e+00, -3.1025e+00, -3.7402e+00,  4.4824e-01, -2.5711e+00,\n",
      "         2.1376e+00, -2.2475e-02, -3.9135e+00,  8.4667e-01, -2.3741e+00,\n",
      "         1.6245e+00, -4.6987e+00,  1.4623e+00,  5.8604e+00, -6.4857e+00,\n",
      "        -6.4153e+00, -4.2399e+00, -9.0295e+00, -1.1936e+00,  3.0071e+00,\n",
      "        -4.2090e+00,  3.3413e+00, -5.5099e-01,  3.8520e+00,  1.8541e+00,\n",
      "        -6.2384e-01, -2.1659e+00, -4.0937e-01,  2.0029e-01, -1.1269e+00,\n",
      "        -1.0327e+00, -4.6992e-01,  3.0539e+00, -3.1375e+00,  2.2151e+00,\n",
      "         2.4929e+00,  4.2443e+00,  2.1873e+00, -5.6994e+00,  1.8099e+00,\n",
      "        -3.2079e+00, -6.1161e+00, -3.5759e+00, -3.1289e+00, -4.5946e+00,\n",
      "         2.5644e+00,  2.3731e+00,  5.1706e-01, -4.1498e-01, -2.8066e-01,\n",
      "         2.7298e+00,  2.6400e+00,  1.3180e+00, -3.2167e+00,  2.6236e+00,\n",
      "         1.4550e+00,  2.5902e+00, -6.4994e-01,  3.1431e+00, -1.7911e+00,\n",
      "         3.0101e+00, -3.6023e+00,  4.4388e+00,  1.2637e+00, -5.9028e-01,\n",
      "         1.5255e-01, -3.5319e+00, -2.8115e+00, -1.1524e-01,  5.9453e-01,\n",
      "         2.0244e+00, -3.5436e+00,  2.1214e+00, -8.5589e-01, -3.3964e+00,\n",
      "         2.4739e-01,  2.7361e+00, -7.2926e+00,  1.5871e+00,  1.5032e-01,\n",
      "         6.8394e+00, -9.0340e-02,  2.5093e+00,  1.6413e-01, -2.9811e+00,\n",
      "         2.0843e+00, -1.5680e+00,  1.1571e+00, -5.2224e-02, -2.1344e+00,\n",
      "         3.0311e+00, -3.3276e+00, -2.6017e+00,  7.0774e+00,  1.9221e+00,\n",
      "        -3.8881e+00, -3.1979e+00, -2.4384e+00,  3.5434e+00,  3.8833e+00,\n",
      "        -4.6050e+00,  5.4052e+00, -1.6691e+00, -1.3464e+00,  1.1651e-01,\n",
      "         2.2926e+00, -2.8087e+00,  3.2252e-02, -3.3391e+00, -1.5055e+00,\n",
      "        -2.9890e+00, -2.7055e+00, -4.4549e-02,  2.7659e-01,  2.7741e-01,\n",
      "         2.2608e+00,  3.7036e-01,  3.5756e+00, -7.9952e-01,  3.4437e+00,\n",
      "        -2.9656e+00,  4.0761e+00, -1.0099e-01, -1.6016e+00,  6.5346e+00,\n",
      "        -3.4053e+00,  4.0007e+00, -5.6588e-02,  1.7674e+01,  3.4714e+00,\n",
      "        -3.6798e+00,  1.1879e+00, -3.6336e+00, -2.7620e+00, -1.2607e+00,\n",
      "         1.5166e+00, -7.5199e-01, -3.5592e+00, -1.0351e-01, -5.3591e-01,\n",
      "        -3.3562e+00,  3.5655e+00,  1.1689e+00,  2.1429e+00, -4.2641e+00,\n",
      "        -2.4159e+00,  2.4236e+00, -4.6470e-01,  1.7686e+00,  1.7377e+00,\n",
      "         2.7358e+00,  2.3016e+00, -3.2416e-01, -8.4135e-01, -6.0099e+00,\n",
      "        -1.6929e+00, -1.5887e+00,  4.0629e-01, -1.0824e+00, -3.3010e+00,\n",
      "         3.3529e+00, -5.7570e+00,  2.0762e+00,  3.0505e+00,  2.9866e+00,\n",
      "         1.5118e+00,  1.9483e+00,  4.2226e+00, -2.8503e+00, -1.4626e+00,\n",
      "        -8.2683e-02, -3.2135e+00,  1.3742e+00,  3.5726e+00, -2.4089e-01,\n",
      "         9.7168e-01, -3.3821e+00,  2.5847e+00, -1.8111e+00, -1.3313e-01,\n",
      "         3.6218e+00, -1.3718e+00], device='cuda:0')), ('backbone.model.layer2.0.bn3.bias', tensor([ 1.3259e+00, -7.5733e-01,  4.0805e-01,  4.3565e-01, -3.8836e-01,\n",
      "        -2.0849e-01, -6.2283e-01,  4.2687e-01,  1.1959e-02,  1.3721e+00,\n",
      "         1.4077e+00, -1.1619e-01, -1.2285e+00,  5.0034e-01,  6.2312e-01,\n",
      "         7.7072e-01,  2.7209e-01, -7.3536e-01, -1.8072e-01,  6.2382e-01,\n",
      "        -6.8288e-01, -7.4585e-01,  1.2144e-01, -1.1576e+00,  1.5285e+00,\n",
      "         6.7132e-01,  1.5218e+00,  7.1457e-01,  2.3261e-02,  1.3856e+00,\n",
      "         6.8039e-01, -7.3066e-01, -3.2294e-02,  2.2259e-01,  1.1887e-01,\n",
      "         5.2493e-01,  1.4911e+00,  5.9990e-01,  5.1763e-01,  1.1939e+00,\n",
      "        -1.5443e-02,  4.2133e-01,  1.6987e+00,  4.8882e-01,  9.2548e-01,\n",
      "         1.6501e+00,  7.3845e-01, -3.8020e-01, -1.1500e+00,  1.1286e+00,\n",
      "        -6.7276e-01,  3.4824e-01, -5.7094e-01,  3.8178e-01,  5.2530e-01,\n",
      "         9.0484e-02,  6.3141e-01,  6.5880e-01, -1.4372e+00, -1.0363e+00,\n",
      "         6.4411e-01,  6.8102e-01,  1.5154e+00,  4.8440e-01,  2.7080e+00,\n",
      "         4.8506e-01,  6.1554e-01,  2.1119e+00,  9.9094e-01, -8.5103e-01,\n",
      "         9.3717e-01, -3.9733e-01,  1.4906e+00, -6.9684e-01,  1.0679e+00,\n",
      "         7.6735e-01,  1.6900e+00, -5.1453e-01,  6.7782e-01,  4.2215e-01,\n",
      "         9.5978e-02,  5.2110e-01,  3.8332e-01,  8.4292e-02,  1.4692e+00,\n",
      "        -3.7481e-01,  6.7083e-01, -2.8544e-01,  9.7836e-01,  5.9161e-01,\n",
      "         1.8272e+00,  1.5034e-01,  1.3440e-01,  3.9081e-01, -8.3972e-02,\n",
      "         5.1954e-01, -5.6998e-01, -1.7470e+00,  5.0381e-04, -3.8573e-01,\n",
      "        -5.6792e-01, -8.2629e-02,  6.5522e-01, -2.6939e-01,  6.7608e-01,\n",
      "         4.1502e-01,  2.4055e-02, -1.2951e+00,  1.8093e-01, -1.1844e-01,\n",
      "        -2.8582e-01, -2.8360e-01,  1.3103e-01,  1.1886e+00,  1.4932e+00,\n",
      "         1.0252e+00,  1.1500e+00,  2.8379e-01,  8.4459e-02,  4.9573e-01,\n",
      "        -5.6961e-01, -2.1908e-01,  5.3426e-01, -6.8506e-01,  2.4325e-01,\n",
      "         4.1154e-01, -1.2440e-01,  8.0925e-01,  3.7342e-01, -2.1421e+00,\n",
      "        -1.4805e-01,  1.7452e-01, -2.7922e-02,  3.9563e-01,  9.3072e-01,\n",
      "         1.0015e+00, -8.4893e-01,  1.6629e+00,  8.9033e-02,  9.6589e-01,\n",
      "         2.6677e-01,  1.6562e+00,  7.5039e-01,  1.0687e+00, -2.9098e-01,\n",
      "         2.6382e-01,  1.3561e+00,  4.6413e-01,  8.1927e-01,  1.0470e+00,\n",
      "         5.6048e-01,  4.6244e-01,  1.0337e+00, -9.6742e-01,  5.2499e-01,\n",
      "         6.0002e-01,  1.3704e+00, -2.7584e-01,  2.1904e-01, -5.5844e-01,\n",
      "        -2.2808e-01,  7.0411e-01, -5.4327e-01,  1.7693e+00, -5.1279e-01,\n",
      "         3.9203e-01, -2.7378e+00,  5.9938e-02, -1.4206e+00,  2.4582e-01,\n",
      "         3.5133e-01,  6.4118e-01, -2.1733e-02, -9.6526e-01,  1.2899e+00,\n",
      "         7.5730e-01,  6.1472e-01, -2.4806e-01,  5.2993e-01,  6.5677e-01,\n",
      "        -1.5022e+00, -9.2437e-01,  6.5556e-01, -1.4291e-01,  6.5132e-01,\n",
      "         6.3932e-01,  3.4854e-01,  1.3806e+00,  1.2223e+00,  4.4034e-01,\n",
      "        -5.1553e-01,  9.4942e-01,  8.4736e-01,  8.1633e-01,  5.9665e-01,\n",
      "         8.2488e-01,  1.3921e+00,  2.9431e+00, -9.8798e-02, -8.0159e-01,\n",
      "         4.2788e-01,  5.3526e-01, -1.8260e+00,  1.8556e-01,  2.7349e-01,\n",
      "        -3.2828e-01,  1.7253e+00,  1.7826e-01,  5.6908e-01,  3.3475e-01,\n",
      "         9.2984e-01,  8.9889e-01, -8.3238e-02,  5.9121e-01,  1.6459e+00,\n",
      "        -8.9186e-02,  5.0787e-01,  2.8630e-01,  5.4546e-01,  8.2273e-01,\n",
      "         3.0200e-01,  5.6421e-01,  1.2392e+00,  7.7243e-01,  2.6967e-01,\n",
      "         1.0567e+00,  8.4453e-01,  3.8322e-01,  2.2429e-01,  3.4130e-01,\n",
      "         1.0197e+00,  2.0507e-01,  1.0709e+00,  1.0346e+00,  3.2020e-03,\n",
      "        -3.3274e-01,  1.4493e+00,  4.5719e-01,  5.3370e-01,  7.1288e-01,\n",
      "         5.2927e-01,  1.0626e+00,  7.8677e-01,  1.6569e+00, -5.4349e-02,\n",
      "        -4.8392e-01,  1.2415e+00,  1.0458e+00,  1.1596e+00,  2.6356e-01,\n",
      "         9.5648e-02,  4.4679e-01,  2.7622e-01,  1.5052e-01, -9.9185e-01,\n",
      "         1.3952e+00, -5.3404e-02,  1.1850e+00,  1.0367e+00, -8.0200e-01,\n",
      "         8.0713e-01, -2.6759e-01,  1.7664e+00, -9.9624e-02,  4.7496e-01,\n",
      "         6.9642e-02, -2.1368e+00,  7.9374e-01, -5.5203e+00,  4.8129e-01,\n",
      "        -1.0102e+00,  8.2718e-01,  1.5013e+00, -1.0100e+00,  3.5627e-01,\n",
      "         2.6693e-01,  1.1420e+00,  4.2318e-01,  5.7889e-01,  1.1072e+00,\n",
      "        -7.4493e-01,  1.2885e+00, -5.6180e-02,  9.1780e-01,  1.2238e+00,\n",
      "        -1.3920e-01,  9.6843e-01,  1.3501e+00,  1.4324e-01,  1.0604e-01,\n",
      "         1.8346e+00,  4.2647e-01,  1.8760e+00,  8.9095e-01, -5.7517e-02,\n",
      "         5.6991e-01, -6.0158e-01,  8.6025e-01,  1.6438e+00, -9.4556e-01,\n",
      "        -1.9220e-02,  7.6514e-01,  1.0607e+00,  3.0908e-01,  4.7915e-01,\n",
      "         8.7699e-01,  7.6960e-01,  6.0051e-01, -5.4710e-01,  1.1519e+00,\n",
      "        -8.7169e-01,  6.2725e-02, -1.0859e+00, -8.7554e-01,  4.0872e-01,\n",
      "         7.1285e-01, -6.6166e+00,  3.3395e-01,  7.6852e-01,  2.9042e-01,\n",
      "         5.6989e-01, -2.4736e-02,  1.3602e+00, -1.3145e+00,  1.8350e+00,\n",
      "        -5.3056e-01,  2.5626e-01,  1.5585e+00,  1.8006e-01, -9.3937e-01,\n",
      "         3.9297e-01,  1.3727e+00,  4.2944e-01,  3.2830e-01, -4.6919e-01,\n",
      "         5.4563e-01, -3.7496e-01, -3.7835e-01, -9.0336e-01, -3.4103e+00,\n",
      "         8.5031e-01,  7.8649e-01,  5.8404e-01, -4.0685e-01,  9.6981e-01,\n",
      "        -1.0057e+00, -7.1698e-01,  3.4586e-01,  8.2681e-01,  4.1154e-01,\n",
      "        -8.6799e-01, -5.5565e-01, -1.3887e-01, -1.9732e+00,  3.6281e-02,\n",
      "         5.9633e-01,  7.3253e-01,  9.6559e-01,  6.8234e-02,  4.9578e-01,\n",
      "         9.9528e-01,  5.1229e-01,  9.2529e-01, -2.0807e-01, -5.4094e-02,\n",
      "        -4.4207e-01,  2.6495e-01, -7.4914e-01,  7.5913e-01, -6.8668e-01,\n",
      "         1.1849e+00,  9.0520e-01,  9.3572e-01, -1.3293e+00, -4.3167e-01,\n",
      "        -5.7133e-01,  1.4036e+00,  2.1308e-01,  6.5404e-01, -1.7365e-02,\n",
      "        -8.4618e-01,  2.2319e+00, -4.9450e-02, -1.6063e+00,  4.7520e-03,\n",
      "        -4.4709e-01,  5.0307e-01,  7.5218e-02,  6.3111e-01,  4.7923e-01,\n",
      "         5.4027e-01,  2.5166e+00, -3.5219e-01, -4.0207e-01,  5.0740e-01,\n",
      "         3.4605e-01,  1.7799e-01,  1.2761e+00,  2.8777e-01,  4.4599e-01,\n",
      "         1.2572e+00,  8.0343e-01, -2.9797e-01,  2.9971e-01,  4.0434e-01,\n",
      "        -9.8361e-01, -4.2700e-01, -6.7614e-02,  4.8425e-01,  3.8787e-01,\n",
      "        -2.3912e-01,  5.1971e-01, -6.6085e-01,  4.5770e-01,  1.8515e+00,\n",
      "         1.6647e-01,  2.8341e-01,  1.1015e+00, -7.3609e-01, -3.7830e-01,\n",
      "        -1.5824e+00,  9.6258e-01, -1.4095e-01,  1.1925e+00,  2.5191e-02,\n",
      "         1.8540e-01, -6.6274e-01,  8.7834e-02,  8.1499e-01,  1.2707e+00,\n",
      "        -2.2013e-01, -5.5799e-01, -3.8914e-01, -8.5091e-01,  7.3627e-01,\n",
      "        -1.1208e+00, -6.9713e-01,  3.9798e-01,  6.0518e-01,  1.3940e+00,\n",
      "         9.5319e-01,  2.2207e+00,  5.5534e-01,  6.1154e-01, -8.0124e-01,\n",
      "        -1.3220e+00,  4.5755e-01, -7.9152e-01,  2.0185e+00, -1.7607e+00,\n",
      "        -1.3880e+00,  4.5412e-01,  5.7813e-01,  1.8177e-01, -2.8100e-01,\n",
      "        -4.4995e-01, -1.4581e-01,  6.8641e-01, -4.0304e-01, -7.5418e-02,\n",
      "         1.2711e+00,  6.0542e-01,  3.6461e+00,  6.9536e-01,  7.7113e-01,\n",
      "         3.6895e-01,  1.5052e+00,  9.1533e-01,  1.8394e-01,  1.1039e+00,\n",
      "         1.0684e+00,  7.5712e-01,  8.4750e-01,  2.3906e-01,  6.5527e-01,\n",
      "         7.3225e-01,  9.9825e-01,  2.8741e-01,  7.5106e-01, -1.1820e+00,\n",
      "         2.9928e-01, -4.7607e-02,  7.5062e-01,  1.7898e+00, -9.2333e+00,\n",
      "         1.4117e-01,  2.3692e-01,  6.0577e-01,  1.1130e+00,  2.4859e-01,\n",
      "         4.9566e-01, -1.1746e+00,  6.4144e-01,  1.9337e+00,  3.8587e-01,\n",
      "         7.3971e-01,  8.2984e-01,  1.2595e+00,  1.1714e+00,  1.0665e+00,\n",
      "        -1.1296e+00,  1.1678e+00,  7.0291e-01, -8.8490e-02,  3.7747e-01,\n",
      "         1.2508e+00,  9.1084e-01,  6.0961e-01,  6.0514e-01, -7.2627e-01,\n",
      "         4.8476e-01, -4.1116e-02], device='cuda:0')), ('backbone.model.layer2.0.downsample.0.weight', tensor([[[[-1.3920e-01]],\n",
      "\n",
      "         [[ 4.3258e-02]],\n",
      "\n",
      "         [[-2.5287e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9265e-02]],\n",
      "\n",
      "         [[-5.9821e-03]],\n",
      "\n",
      "         [[ 5.4859e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2418e-02]],\n",
      "\n",
      "         [[ 5.8764e-02]],\n",
      "\n",
      "         [[-1.2432e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.0063e-02]],\n",
      "\n",
      "         [[-2.8535e-02]],\n",
      "\n",
      "         [[-2.3265e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4753e-02]],\n",
      "\n",
      "         [[ 1.5536e-02]],\n",
      "\n",
      "         [[ 2.8598e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.5263e-03]],\n",
      "\n",
      "         [[ 4.0757e-02]],\n",
      "\n",
      "         [[ 5.0744e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4614e-01]],\n",
      "\n",
      "         [[-4.4233e-02]],\n",
      "\n",
      "         [[ 9.0213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8612e-02]],\n",
      "\n",
      "         [[ 8.5788e-02]],\n",
      "\n",
      "         [[-4.7920e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0390e-04]],\n",
      "\n",
      "         [[ 1.7024e-02]],\n",
      "\n",
      "         [[-3.3435e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3420e-02]],\n",
      "\n",
      "         [[-9.7308e-02]],\n",
      "\n",
      "         [[ 2.0660e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4245e-02]],\n",
      "\n",
      "         [[ 4.0574e-02]],\n",
      "\n",
      "         [[ 3.4845e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8961e-02]],\n",
      "\n",
      "         [[ 2.3442e-02]],\n",
      "\n",
      "         [[ 2.0956e-02]]]], device='cuda:0')), ('backbone.model.layer2.0.downsample.1.weight', tensor([-3.2739e-02,  2.7011e+00,  1.1133e+00,  3.5505e+00,  2.0692e+00,\n",
      "         5.6712e+00,  1.6304e+00,  2.3363e+00,  6.8484e+00,  1.4895e+00,\n",
      "         2.1920e+00,  1.1584e+00,  1.7123e+00,  5.4948e+00,  2.8731e+00,\n",
      "         4.3251e+00,  1.7501e+00,  1.0582e-01,  3.7248e+00,  2.2383e+00,\n",
      "         3.0193e+00,  1.5975e+00,  3.6493e+00,  2.3523e+00,  8.6685e-01,\n",
      "         3.5803e+00,  2.4683e+00,  2.7051e+00,  2.5829e-01,  3.2965e+00,\n",
      "         2.2138e+00,  2.3771e+00,  3.2153e+00, -1.7865e-01,  2.7627e+00,\n",
      "         2.2978e+00,  7.5215e-02,  2.5493e+00,  1.6123e+00,  1.9208e+00,\n",
      "         2.8177e+00,  4.1984e+00,  4.0122e+00,  1.4263e+00,  3.3768e+00,\n",
      "         1.5248e+00,  2.1337e+00,  7.8702e-01,  4.3136e-01,  3.3435e+00,\n",
      "         1.5621e+00,  7.4470e-01,  3.0308e+00,  6.7016e-01,  3.7323e+00,\n",
      "         4.1218e+00,  1.6219e+00,  6.0170e-01,  4.6103e+00,  1.7205e+00,\n",
      "         4.6531e+00,  8.9326e-01,  1.5763e+00,  2.4102e+00,  5.0438e+00,\n",
      "         3.0961e+00,  2.9533e+00,  1.2640e+00,  2.9428e+00,  2.6957e+00,\n",
      "         9.1022e-01, -2.6795e-02,  7.2164e-01,  1.7064e+00,  3.0849e+00,\n",
      "         9.9171e-01,  1.7983e+00,  5.2484e-01,  3.2669e+00,  1.7677e+00,\n",
      "         1.2837e+00,  3.0056e+00,  2.7071e+00,  2.1326e+00,  2.1920e+00,\n",
      "         4.2404e+00,  3.0104e+00,  3.2033e+00, -1.1758e-02,  2.0175e+00,\n",
      "         7.4286e+00,  3.0273e+00, -3.1092e-03,  4.0113e+00,  3.8020e+00,\n",
      "         3.0862e+00,  6.1200e+00,  1.4916e+00,  2.4507e+00,  5.2796e+00,\n",
      "         2.5316e+00,  3.2079e+00,  1.7213e+00,  4.4364e+00,  6.3150e-01,\n",
      "         2.6174e+00, -5.6397e-01,  3.1358e+00,  1.7314e+00,  1.5793e+00,\n",
      "         1.7939e+00,  2.6429e+00,  3.4713e+00,  1.8937e+00,  2.9255e+00,\n",
      "         1.8970e-01,  3.8830e+00,  1.7481e+00,  1.9846e+00,  2.4842e+00,\n",
      "         3.8777e-02,  4.0833e-01,  2.6369e+00,  7.1681e-01,  7.2905e-01,\n",
      "         3.3753e+00,  1.4420e+01,  2.8145e+00,  9.6734e-01,  7.8030e+00,\n",
      "         2.0043e+00,  4.9302e+00,  3.3395e-01,  3.3497e+00,  6.8489e+00,\n",
      "         3.2974e+00,  2.4894e+00,  1.4306e+00,  3.5146e-01,  4.2628e-01,\n",
      "         2.6656e+00,  5.0850e+00,  1.7349e+00,  5.8801e+00,  9.7619e-01,\n",
      "         2.3893e+00,  1.3794e+00, -6.9845e-01,  1.7041e-01,  7.6743e+00,\n",
      "         1.3441e+00,  2.4624e+00,  2.2772e+00,  1.5704e+00,  3.6886e+00,\n",
      "         4.4507e+00,  3.8369e+00,  3.0166e+00,  1.9126e+00, -1.6666e+00,\n",
      "         1.1055e+00, -1.0224e+00, -2.5466e-01,  1.5484e+00,  2.6629e+00,\n",
      "         9.4709e-01,  2.1575e+01,  5.3176e-01,  1.8679e+00,  1.5419e+00,\n",
      "         3.6430e+00,  4.2501e-01,  1.7122e+00,  1.6976e+00,  2.6308e+00,\n",
      "         2.7345e+00,  2.9433e+00,  8.5603e-01,  1.1367e+00,  6.3618e+00,\n",
      "         5.2481e+00,  1.7072e+00,  3.0726e+00,  6.9912e+00,  5.5512e+00,\n",
      "         4.6981e-01,  3.1606e+00,  6.2584e+00,  1.9913e+00,  5.1600e+00,\n",
      "         1.8138e+00,  1.1187e+00,  9.6463e+00,  1.5665e+00,  1.5021e+00,\n",
      "         8.7520e-01,  2.6238e+00,  2.5464e+00,  4.6382e-01,  2.7543e+00,\n",
      "         3.6454e+00,  3.1490e+00,  3.0840e+00,  1.2382e+00,  2.7480e+00,\n",
      "         1.5906e+00,  4.6213e+00,  2.1426e+00, -4.8379e-02, -1.0581e-01,\n",
      "         1.6112e+00,  3.9652e+00,  3.9676e+00, -3.8236e-02,  9.0916e-01,\n",
      "         4.9404e+00,  4.1178e+00,  3.3515e+00,  1.9860e+00,  2.4064e+00,\n",
      "         5.0057e+00,  1.4690e+00,  2.3592e+00,  3.1575e+00,  1.4949e+00,\n",
      "         8.7968e-01,  2.2911e+00,  1.2898e+00,  2.4502e+00,  4.6029e+00,\n",
      "         5.0931e+00,  1.3531e+00,  2.5676e+00,  2.0065e+00,  1.1590e+00,\n",
      "         9.0906e-01,  2.2585e+00,  1.0986e+00,  4.7554e+00,  1.0683e+00,\n",
      "         1.3298e+00,  1.1727e+00,  1.8245e-01,  4.2143e+00,  3.4030e+00,\n",
      "         1.6936e+00,  4.4811e-01,  6.9556e-02,  2.5054e+00,  2.9682e+00,\n",
      "         3.4996e+00,  3.7284e+00,  4.2943e+00,  2.4577e+00,  1.5455e+00,\n",
      "         3.0336e-02,  6.9086e-02,  1.6596e+00,  2.0474e+00,  1.4920e+00,\n",
      "         7.8698e+00,  2.1573e+00,  1.3599e+00,  1.1582e+00,  3.4109e+00,\n",
      "         1.5323e+00,  1.5145e+00,  1.1744e+00,  2.0716e+00,  7.7177e-01,\n",
      "         1.0830e+00,  1.4885e+00,  4.5740e+00,  3.0208e+00,  3.9137e+00,\n",
      "         1.3329e+00, -2.0621e-02,  3.5449e+00,  1.6097e+00,  1.0874e+00,\n",
      "         6.9354e+00,  9.6106e-02,  1.6916e+00,  4.9346e+00,  1.4016e+00,\n",
      "         2.8372e+00,  5.0679e+00,  8.6254e-01,  3.3427e+00, -3.3560e-02,\n",
      "         2.2764e+00,  1.5611e+00,  8.8315e+00,  2.7473e+00,  1.9670e+00,\n",
      "         3.4863e+00,  1.1680e-01,  1.7351e+00,  1.6078e+00,  1.3597e+00,\n",
      "         1.4115e+00,  1.8378e+00,  4.6243e+00,  2.9279e+00,  3.3365e+00,\n",
      "         2.0899e+00,  3.0438e+00,  2.8573e+00,  1.7288e+00,  4.3536e+00,\n",
      "         1.6441e-01,  1.5300e+00,  1.0585e-01,  1.7027e+00,  3.2498e+00,\n",
      "         3.3506e+00,  1.1713e+01,  1.6912e+00,  2.8698e+00,  3.6744e+00,\n",
      "         4.2602e+00,  2.4296e+00,  4.5036e+00,  2.5838e+00,  7.7513e+00,\n",
      "         1.3281e-02,  2.7949e+00,  1.2772e+00,  1.6285e+00,  1.5841e+00,\n",
      "         1.6492e+01,  4.5232e+00,  1.1252e+00,  5.0910e+00,  1.8455e+00,\n",
      "         2.8329e+00, -4.8078e-03,  1.1787e+00,  1.3704e-01,  4.5276e+00,\n",
      "         4.7890e+00,  2.4450e+00,  9.2891e-01,  1.2535e+00,  2.6709e+00,\n",
      "         3.5633e+00,  3.1634e+00,  1.0601e+01,  6.1966e-01,  9.4874e-01,\n",
      "         4.0783e+00,  1.8760e+00,  2.0396e+00,  3.6638e+00,  1.0401e+00,\n",
      "         5.2889e+00,  2.8561e-01,  3.3141e+00,  3.0834e+00,  3.5482e+00,\n",
      "         2.7971e+00,  2.6221e+00,  2.0296e+00,  2.6759e+00,  2.8957e+00,\n",
      "         1.8435e+00,  8.6142e-01,  1.5417e+00,  2.6951e+00,  1.3829e+00,\n",
      "         1.1186e+00,  1.0769e+01,  2.0117e+00,  3.4360e+00,  9.2972e-01,\n",
      "         2.0163e+00,  1.0677e+00,  2.2165e+00,  4.6521e+00,  4.5202e+00,\n",
      "         1.9076e+00,  2.2632e+00,  4.5269e-01,  2.9258e+00,  1.2815e+00,\n",
      "         2.6826e+00,  1.3226e+00,  2.5890e+00, -2.9174e-02,  2.3662e-02,\n",
      "         2.1423e+00,  1.9731e+00,  4.9438e+00,  2.1027e-02,  2.3294e+00,\n",
      "         3.5240e+00,  3.3788e+00,  1.2313e+00,  3.8938e+00,  3.5538e+00,\n",
      "         6.0367e+00,  2.2408e+00,  3.1636e+00,  4.3215e+00,  1.4677e+00,\n",
      "         5.1732e-02,  2.6604e+00,  2.9625e+00,  1.3962e+00,  2.7432e+00,\n",
      "         1.9966e+00,  3.3818e+00,  2.6384e+00,  3.8184e+00, -1.7860e-02,\n",
      "         2.7729e-02,  3.7896e+00,  9.9325e-01,  7.6798e-02,  3.1156e+00,\n",
      "         2.0989e+00,  2.7023e-02,  8.6935e-02,  4.2185e+00,  5.2146e+00,\n",
      "         4.4869e+00,  9.6959e-01,  1.7833e+00,  2.3404e+00,  2.1255e+00,\n",
      "         1.0035e+00,  3.1608e-01, -6.1732e-01,  2.8457e+00,  3.3871e+00,\n",
      "         3.1234e+00,  4.6561e+00,  1.7584e+00,  3.1268e-01,  3.5295e+00,\n",
      "         2.9150e+00,  2.8380e+00,  3.7620e+00,  3.8924e+00,  4.0239e-02,\n",
      "         1.9667e+00,  3.1729e+00,  1.0922e+00,  2.9591e+00,  2.6986e+00,\n",
      "         1.3225e-01,  1.0938e+00,  3.9545e+00,  9.0275e-01,  1.8156e+00,\n",
      "         1.5500e-01,  1.5511e+00,  3.4699e+00,  1.5152e+01,  1.6638e+00,\n",
      "         4.2455e+00,  3.5082e+00,  2.0500e+00,  8.2782e-01,  5.2980e+00,\n",
      "         2.2748e+00,  1.5353e+00,  2.0409e+00,  2.8557e+00,  4.0504e+00,\n",
      "         2.2591e+00,  1.2433e+00, -1.7409e-01,  2.6247e+00,  2.0259e+00,\n",
      "         6.1022e-01,  1.2896e+00,  4.6470e+00,  4.1860e+00,  1.5639e+00,\n",
      "         2.0675e+00,  2.3797e+00,  5.3487e+00,  7.4534e-01,  3.3267e+00,\n",
      "         3.3097e+00,  1.8960e+00,  3.5867e+00,  3.8115e+00,  2.0956e+00,\n",
      "         1.4725e+00,  1.5774e+00,  2.3280e+00,  1.2815e+00,  1.2100e+00,\n",
      "         3.3091e+00,  2.2951e+00,  1.2587e+00,  7.2210e-01,  7.5943e+00,\n",
      "         3.7169e-02,  1.1851e+00,  9.8514e-01,  1.4180e+00,  4.7884e+00,\n",
      "         2.3131e+00,  8.2929e-01,  1.3737e+00,  7.2930e+00,  3.5713e-02,\n",
      "         1.2283e+00,  1.9385e+00], device='cuda:0')), ('backbone.model.layer2.0.downsample.1.bias', tensor([ 1.4662e+00,  3.3312e-01,  2.2945e+00,  1.2007e-01,  8.2862e-01,\n",
      "        -2.8029e+00,  6.2198e-01,  1.1247e+00, -2.3557e-01,  1.6016e+00,\n",
      "        -1.1942e+00,  1.1650e+00, -6.0478e-01, -1.7196e+00,  7.9190e-01,\n",
      "        -6.3432e-01,  1.4246e+00,  1.1843e+00,  2.6145e+00,  2.5874e-01,\n",
      "         1.4258e+00,  1.0583e+00,  7.0614e-02, -3.6489e-01,  8.0846e-01,\n",
      "         3.0643e-01,  1.7596e+00, -5.9738e-01,  2.6044e+00, -9.5382e-01,\n",
      "         1.6601e+00, -2.6177e-01,  2.6592e+00, -8.2097e-02,  4.2893e-01,\n",
      "         8.7054e-01, -3.5829e-02, -1.0747e-01,  5.6012e-01,  1.6797e+00,\n",
      "        -5.9809e-02, -1.0788e+00,  3.2850e+00,  1.1992e+00,  1.2813e+00,\n",
      "         8.3040e-01,  8.9093e-01,  1.6291e+00,  1.4434e-01,  1.2068e-01,\n",
      "         1.4974e+00,  7.4335e-01,  2.2760e+00,  9.2718e-01, -1.0040e+00,\n",
      "        -1.5230e+00,  6.0642e-02,  1.8876e+00,  1.5082e+00,  1.0951e+00,\n",
      "        -6.4415e-01,  7.2802e-01,  2.3917e+00,  1.2685e+00,  8.0264e-01,\n",
      "        -1.4356e+00, -2.7182e+00,  1.0201e+00, -5.5858e-01,  9.7570e-01,\n",
      "         5.3913e-01, -6.0671e-02,  1.3595e+00,  8.8758e-01, -5.6950e-01,\n",
      "         1.0016e+00,  2.3426e-01,  3.7199e-01, -2.1865e+00,  1.3308e+00,\n",
      "         9.2781e-01, -2.4985e-02,  1.0255e+00, -6.1580e-02,  3.5191e-01,\n",
      "         3.4697e-01, -1.0031e+00, -3.5505e+00, -3.9435e-01,  4.0027e-01,\n",
      "        -6.4298e+00, -5.6909e-01,  2.0333e+00, -2.3881e+00, -7.1724e-01,\n",
      "        -4.2313e-01, -1.1946e-01,  1.0995e+00, -1.1050e+00, -3.1858e-01,\n",
      "         1.7508e+00,  1.1291e+00, -8.5287e-01,  3.9303e-01,  8.8647e-01,\n",
      "        -1.2941e-01, -4.6957e-01,  1.1286e+00,  1.5478e+00, -3.7515e-02,\n",
      "         9.6553e-01, -1.2229e+00, -1.8540e+00,  1.6017e+00,  1.1714e+00,\n",
      "        -9.7210e-02, -1.9347e+00, -1.2344e-01,  2.2733e+00, -1.5972e+00,\n",
      "        -7.4609e-01,  1.6660e-02,  3.2790e-01,  1.2293e+00,  1.5935e+00,\n",
      "         1.9038e-01, -4.6747e+00,  1.7424e+00,  7.9569e-02, -4.5236e+00,\n",
      "        -8.8732e-01, -7.8449e-01,  1.0245e+00, -7.8367e-01,  1.1738e-01,\n",
      "        -7.6636e-01,  4.2368e-01,  1.8868e+00,  8.4301e-01,  1.7182e-01,\n",
      "        -1.1057e+00,  1.5327e+00,  4.2679e-01, -1.2878e+00,  1.5875e+00,\n",
      "         1.6587e+00,  1.5894e+00,  4.4307e-01,  8.9400e-01,  1.3286e+00,\n",
      "         1.4133e+00,  1.5882e+00,  3.1315e+00,  6.1942e-01,  1.6151e-01,\n",
      "        -1.5488e+00,  1.3020e+00,  2.1478e+00,  7.1642e-01,  9.5138e-01,\n",
      "         3.1905e-02,  1.4132e+00,  1.8755e+00,  4.3262e-01,  1.2840e+00,\n",
      "         1.5793e+00, -3.9040e+00,  4.7858e-01, -4.0047e-01,  1.3982e+00,\n",
      "         7.8675e-01,  1.1315e+00,  1.8163e+00,  1.2299e-02, -1.1815e+00,\n",
      "        -1.5183e+00,  1.2438e+00,  1.7396e-01,  1.3030e+00, -1.7769e-01,\n",
      "         8.3467e-01,  5.9658e-01, -3.5963e-02, -1.6350e+00, -4.4623e+00,\n",
      "         3.6729e-01,  5.2227e-01,  5.0672e-01, -4.3601e-01,  1.9429e-01,\n",
      "        -2.3844e+00, -8.8763e-02, -2.8764e+00,  9.6314e-02,  2.0560e+00,\n",
      "         1.2229e+00,  1.6848e+00,  7.8317e-01, -3.4765e-01,  3.7056e+00,\n",
      "        -1.1017e+00, -5.9016e-02, -2.5689e-01,  7.8792e-01,  1.0978e+00,\n",
      "         5.2486e-01, -1.3211e+00,  1.1115e+00,  1.3015e+00,  1.5485e+00,\n",
      "         2.2464e+00, -8.7652e-01, -2.9577e+00,  7.5478e-01,  7.6512e-01,\n",
      "        -2.3839e+00, -1.2915e+00, -2.7132e+00, -2.1637e+00, -7.0818e-01,\n",
      "        -1.1214e-01, -4.9317e-01, -3.3283e-01,  8.4129e-01,  1.5024e+00,\n",
      "        -4.1027e-01,  1.8788e-01,  6.1316e-01, -2.1413e-01, -5.6990e-01,\n",
      "        -1.8110e-01, -1.2486e-01,  4.0264e-01,  8.1462e-01,  6.0697e-01,\n",
      "         7.3324e-01,  9.8087e-01,  1.2006e+00,  8.6701e-01,  9.4966e-01,\n",
      "         2.0266e+00,  1.2579e+00,  1.7048e-01,  1.0434e+00, -1.0250e+00,\n",
      "         7.9268e-01,  2.6408e+00,  8.7609e-01,  1.6487e+00, -1.3613e+00,\n",
      "        -1.7787e+00, -1.2188e+00, -1.3951e+00,  1.3996e-01,  1.2827e+00,\n",
      "         1.4675e+00,  8.6522e-01, -1.4539e-01, -1.3884e+00,  5.0664e-01,\n",
      "        -3.2974e+00, -1.0610e+00,  8.8281e-01,  1.6316e+00,  5.2176e-01,\n",
      "         8.6399e-01, -1.5874e+00,  1.5752e+00,  8.8962e-01,  1.4462e+00,\n",
      "         1.2497e+00,  1.3683e+00, -7.1327e-01, -7.7495e-01, -2.2570e+00,\n",
      "         1.7164e+00,  6.6561e-02,  1.6487e+00,  1.8167e+00,  2.6800e-01,\n",
      "        -2.7736e+00,  6.5234e-01, -5.2576e-01, -6.5364e-01,  1.4704e+00,\n",
      "        -3.1046e-02, -1.7694e+00,  7.3175e-01, -2.4662e+00,  1.6106e+00,\n",
      "         1.1152e+00,  1.8039e+00,  1.0204e+00,  1.2804e+00,  8.3012e-01,\n",
      "         1.3040e-01, -1.1141e+00, -3.2333e-01,  9.4493e-01,  1.0394e+00,\n",
      "         1.3423e+00, -2.4896e-02, -5.1994e-01,  7.0315e-01, -9.8758e-01,\n",
      "         3.8695e-01,  1.6311e+00, -1.0891e+00,  1.0227e+00, -1.5139e+00,\n",
      "        -1.8420e+00,  9.3148e-01, -1.1559e+00,  2.4795e+00, -1.6152e+00,\n",
      "         1.2984e+00, -9.0706e+00,  3.1156e-01, -1.3936e+00, -1.6388e+00,\n",
      "        -7.2524e-01,  1.2999e+00,  1.5664e+00, -2.3811e-01, -8.7200e-01,\n",
      "         1.5156e-01,  3.4451e-02,  2.4861e+00,  5.3948e-01,  1.0277e-01,\n",
      "         5.3278e-02, -2.7521e+00, -9.8249e-03, -4.6680e-01, -2.4947e-01,\n",
      "         5.2851e-01, -3.8499e-01,  2.1732e+00, -1.7427e+00,  1.2530e+00,\n",
      "        -1.7205e+00,  1.3889e-02,  1.3433e+00,  1.5711e+00,  7.9721e-01,\n",
      "        -2.5604e-01,  9.0541e-01, -5.5125e+00,  2.0431e+00,  9.6762e-01,\n",
      "         1.1938e+00,  1.3369e-01, -9.3057e-01, -1.9761e+00,  1.9516e+00,\n",
      "         1.0132e-01,  2.1059e-01, -3.0720e-01, -1.3526e+00, -2.7396e-02,\n",
      "        -1.2975e+00, -9.4604e-03,  1.2839e+00,  5.7005e-01,  9.3288e-01,\n",
      "         6.0701e-01,  1.6276e+00,  2.0297e-01,  1.4150e+00,  3.9850e-02,\n",
      "         7.1516e-02, -2.1934e+00,  6.5841e-01, -1.6260e-01,  1.2598e-01,\n",
      "         4.7472e-01,  8.6054e-01, -1.4188e+00, -7.0318e-01, -2.9227e+00,\n",
      "         1.3922e+00,  2.0075e+00, -4.2727e-01,  2.2827e+00,  6.2678e-01,\n",
      "        -6.1530e-01,  1.1930e+00,  8.1490e-01,  1.0092e+00, -1.5774e-01,\n",
      "         1.0401e+00,  1.7709e+00, -1.0008e-01,  8.3930e-01,  7.2350e-01,\n",
      "        -1.2504e+00,  5.1632e-02,  2.5352e+00, -1.2187e+00, -1.7186e+00,\n",
      "        -1.0371e+00,  1.5539e+00, -1.7602e-01, -2.8821e+00,  1.1901e+00,\n",
      "        -8.9714e-01,  5.5429e-01,  3.1823e+00,  1.0861e+00, -6.9410e-01,\n",
      "         2.5165e+00, -2.9382e+00,  5.9030e-01, -1.3122e+00,  7.9877e-01,\n",
      "         1.6404e+00, -3.4205e-01,  2.4325e-01, -8.0951e-01, -9.1543e-01,\n",
      "         7.8596e-01,  1.5379e+00,  1.4163e+00,  9.5384e-01,  7.1578e-01,\n",
      "        -1.4653e+00,  1.9815e-01,  3.4285e-01, -6.6789e-02,  2.9644e-01,\n",
      "         1.0784e+00,  1.0200e+00, -7.6180e-01, -2.6377e+00, -9.8124e-01,\n",
      "         8.2918e-01, -2.9691e+00, -9.4201e-01, -6.8480e-01, -1.0706e+00,\n",
      "         4.4842e-01,  7.7625e-02, -9.7335e-01, -2.4026e-01, -7.2817e-01,\n",
      "         1.1074e+00, -1.9237e+00,  1.1945e+00,  1.4612e+00, -5.3470e-01,\n",
      "        -1.5807e+00,  1.5626e+00, -1.3987e+00, -1.7139e-01,  4.4649e-03,\n",
      "         1.2663e+00,  4.1069e-01, -1.6591e+00, -5.8714e+00, -4.1085e-01,\n",
      "        -6.1781e-01, -2.2914e-01,  2.7799e+00,  7.1215e-01,  4.4974e-01,\n",
      "        -2.0453e-01,  1.9351e+00,  1.7638e+00, -6.4628e-01,  3.5690e-01,\n",
      "         1.3569e+00,  2.6661e+00,  4.9333e-01, -1.0900e-01,  1.5011e+00,\n",
      "         2.1255e+00,  7.3171e-01, -1.1783e+00,  2.0355e+00, -1.4523e+00,\n",
      "         7.2171e-01,  2.5612e-01, -9.6569e-02, -7.7973e-01,  1.8832e+00,\n",
      "         1.0784e+00,  6.3527e-01, -3.5240e-01, -4.1867e-01, -2.5145e-01,\n",
      "         1.4494e+00,  1.2196e+00,  7.0959e-01,  2.1452e+00,  1.1163e+00,\n",
      "         7.1705e-01, -7.2336e-01,  1.2256e+00,  2.2249e+00, -1.4227e+00,\n",
      "        -8.5531e-01,  1.8397e+00,  1.8449e+00,  1.3274e+00, -2.1221e-01,\n",
      "        -8.4513e-01,  1.8551e+00,  2.0417e+00, -1.1555e+00, -9.3590e-01,\n",
      "         9.7671e-01,  1.5253e-01], device='cuda:0')), ('backbone.model.layer2.1.conv1.weight', tensor([[[[-7.1208e-02]],\n",
      "\n",
      "         [[ 4.0799e-02]],\n",
      "\n",
      "         [[ 1.1406e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6990e-07]],\n",
      "\n",
      "         [[-2.0584e-01]],\n",
      "\n",
      "         [[-1.1116e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5885e-02]],\n",
      "\n",
      "         [[-4.7515e-02]],\n",
      "\n",
      "         [[-2.6467e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.7372e-07]],\n",
      "\n",
      "         [[ 1.0114e-01]],\n",
      "\n",
      "         [[ 4.8603e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9571e-02]],\n",
      "\n",
      "         [[ 4.4194e-02]],\n",
      "\n",
      "         [[-6.0700e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3386e-06]],\n",
      "\n",
      "         [[-3.9330e-02]],\n",
      "\n",
      "         [[-1.4925e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.6771e-02]],\n",
      "\n",
      "         [[ 9.6230e-02]],\n",
      "\n",
      "         [[ 4.6856e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8692e-07]],\n",
      "\n",
      "         [[ 4.3925e-02]],\n",
      "\n",
      "         [[-1.4971e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7222e-02]],\n",
      "\n",
      "         [[-3.2712e-03]],\n",
      "\n",
      "         [[ 4.2790e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.2774e-07]],\n",
      "\n",
      "         [[-3.8975e-02]],\n",
      "\n",
      "         [[-2.4785e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4901e-02]],\n",
      "\n",
      "         [[ 4.9066e-03]],\n",
      "\n",
      "         [[-6.2396e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5563e-07]],\n",
      "\n",
      "         [[-1.0124e-01]],\n",
      "\n",
      "         [[ 7.6349e-03]]]], device='cuda:0')), ('backbone.model.layer2.1.bn1.weight', tensor([2.7963, 1.4807, 3.2186, 3.8779, 2.2763, 1.5781, 2.5374, 2.0274, 2.1254,\n",
      "        2.0726, 2.6967, 1.1769, 2.1917, 2.9028, 2.1061, 1.5712, 4.8172, 1.7801,\n",
      "        2.3305, 1.8804, 1.3707, 2.3472, 2.4419, 2.3963, 2.5802, 1.7289, 7.4525,\n",
      "        1.5467, 1.6810, 2.4365, 2.1430, 2.3562, 2.0898, 1.8603, 2.6200, 2.6481,\n",
      "        1.7822, 1.5173, 1.9484, 1.7651, 1.2735, 1.9048, 2.0350, 1.3439, 1.2905,\n",
      "        2.4395, 2.5872, 2.5914, 1.8516, 1.2112, 2.0882, 1.5786, 1.7906, 2.1635,\n",
      "        1.4491, 2.0385, 2.6344, 2.1038, 1.5583, 2.5336, 2.1546, 1.6318, 2.5240,\n",
      "        1.2420, 2.3705, 2.2609, 2.4633, 1.9454, 1.2956, 1.8542, 2.1096, 1.3950,\n",
      "        2.0469, 2.3939, 2.5996, 2.2015, 1.1296, 1.5466, 1.5799, 1.5908, 3.5469,\n",
      "        1.8307, 3.2651, 3.0546, 1.4346, 2.0385, 2.0620, 2.5240, 2.0525, 1.3457,\n",
      "        1.7376, 2.0316, 1.8102, 2.0156, 1.7798, 2.3330, 1.7866, 2.8689, 1.6756,\n",
      "        1.8886, 1.8848, 1.6041, 2.3510, 1.6524, 1.7988, 2.5263, 0.7924, 1.6921,\n",
      "        1.9042, 1.9570, 2.1635, 1.8580, 1.5632, 1.4245, 1.7273, 1.6268, 2.2759,\n",
      "        2.0657, 2.8535, 1.9216, 2.2493, 1.9185, 2.3742, 2.6744, 2.1453, 1.8920,\n",
      "        2.1691, 2.4774], device='cuda:0')), ('backbone.model.layer2.1.bn1.bias', tensor([ 1.4466e+00,  1.3653e+00, -1.5486e+00, -3.0071e+00, -1.2278e-01,\n",
      "         7.9534e-02,  7.8720e-01, -3.0614e+00, -3.0232e-01,  3.4797e-01,\n",
      "        -2.8688e+00,  1.3315e+00, -2.4656e-01, -7.8004e-01, -4.0506e-01,\n",
      "        -1.7086e+00, -7.9976e-01, -7.6275e-01,  2.5768e-01, -1.7857e+00,\n",
      "        -8.5062e-01, -3.2159e+00, -6.3335e-01, -9.0335e-02, -8.8182e-02,\n",
      "         1.1639e+00, -3.1562e+00, -1.8160e+00,  1.6114e+00, -2.3555e-01,\n",
      "        -2.6678e+00, -5.6148e-01,  9.5718e-01, -2.1194e+00, -3.3098e-01,\n",
      "        -3.9871e-02, -1.8219e+00, -1.1992e+00,  5.6626e-01, -5.5666e-01,\n",
      "         9.8221e-02, -2.1368e+00,  2.2642e-01,  1.7353e-01,  7.6880e-01,\n",
      "         2.2891e-01, -9.8506e-01, -3.1876e+00, -2.0045e+00, -3.1120e-04,\n",
      "         4.6742e-01,  7.1150e-01,  2.2822e-02, -3.0200e+00, -6.0963e-01,\n",
      "        -8.8773e-01, -1.5008e+00, -1.1813e+00,  1.9635e+00, -9.5776e-01,\n",
      "        -1.3287e+00,  2.2552e-01, -8.2502e-02, -1.8738e+00, -1.5815e+00,\n",
      "        -8.4408e-01, -3.5549e+00, -1.4560e-01,  6.1872e-01, -2.2749e-01,\n",
      "        -1.7157e+00, -2.9295e-01, -9.2586e-01, -2.2672e-01,  1.6840e-01,\n",
      "        -3.0156e+00,  9.3028e-01, -1.1181e-01, -4.9884e-01, -3.8534e-01,\n",
      "        -3.3860e+00, -9.4449e-01,  1.0766e+00, -3.6876e-01,  4.2811e-01,\n",
      "         2.2184e-01, -3.3568e+00,  7.4144e-01, -9.1788e-01, -2.0602e+00,\n",
      "        -9.8428e-01, -6.2544e-01, -7.0767e-01,  1.7810e-01, -1.7412e+00,\n",
      "        -3.9990e-01,  4.8414e-01, -8.7979e-01,  7.6643e-02, -2.1764e+00,\n",
      "        -2.3276e+00,  9.0054e-01,  1.2647e-01,  4.7541e-01, -2.8590e+00,\n",
      "        -1.7723e+00, -5.0603e-02,  8.0450e-01, -2.4050e-01,  7.3706e-01,\n",
      "        -2.4951e+00, -1.3044e+00,  7.9180e-02,  8.8719e-01, -2.9511e+00,\n",
      "         9.2614e-02,  4.2875e-01, -1.8084e+00, -3.3991e-01, -1.8815e+00,\n",
      "         4.6907e-01, -3.9751e-01, -3.7863e+00, -9.7480e-01, -1.2641e+00,\n",
      "        -6.5815e-01, -2.7597e+00, -5.7840e-01], device='cuda:0')), ('backbone.model.layer2.1.conv2.weight', tensor([[[[-0.0211, -0.0477, -0.0202],\n",
      "          [ 0.0191, -0.0074, -0.0436],\n",
      "          [ 0.0139,  0.0095, -0.0385]],\n",
      "\n",
      "         [[ 0.0191,  0.0136,  0.0082],\n",
      "          [-0.0174,  0.0146,  0.1208],\n",
      "          [-0.0076, -0.0023,  0.0424]],\n",
      "\n",
      "         [[ 0.0633,  0.0083,  0.0279],\n",
      "          [ 0.0154,  0.0142,  0.0476],\n",
      "          [ 0.0789,  0.0691,  0.0504]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0464, -0.0311,  0.0291],\n",
      "          [ 0.0004,  0.0153, -0.0453],\n",
      "          [-0.0419,  0.0516, -0.0166]],\n",
      "\n",
      "         [[ 0.0141,  0.0382,  0.0434],\n",
      "          [-0.0289,  0.0578,  0.0410],\n",
      "          [-0.0470, -0.0539, -0.0107]],\n",
      "\n",
      "         [[-0.0214,  0.0916,  0.0224],\n",
      "          [-0.0504, -0.0687, -0.0395],\n",
      "          [ 0.0628,  0.0928, -0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0215, -0.1318,  0.0304],\n",
      "          [ 0.0061, -0.2426, -0.0467],\n",
      "          [-0.0085,  0.1016,  0.0631]],\n",
      "\n",
      "         [[ 0.0058, -0.0324, -0.1917],\n",
      "          [ 0.0498, -0.0122, -0.1451],\n",
      "          [ 0.1162,  0.0787, -0.0357]],\n",
      "\n",
      "         [[ 0.0411,  0.0279,  0.0261],\n",
      "          [ 0.0251,  0.0280,  0.0907],\n",
      "          [-0.0068, -0.0498,  0.0497]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0111, -0.0123, -0.0343],\n",
      "          [-0.0079, -0.2506, -0.0808],\n",
      "          [ 0.1261, -0.1199,  0.0790]],\n",
      "\n",
      "         [[-0.0113, -0.0199, -0.0128],\n",
      "          [ 0.0015, -0.1391,  0.0173],\n",
      "          [-0.0187, -0.0130,  0.0126]],\n",
      "\n",
      "         [[-0.0425,  0.0318,  0.0168],\n",
      "          [ 0.0957,  0.1445,  0.0625],\n",
      "          [-0.0146, -0.0599,  0.0110]]],\n",
      "\n",
      "\n",
      "        [[[-0.0572, -0.0098,  0.0359],\n",
      "          [-0.0175, -0.0784, -0.0416],\n",
      "          [-0.0050, -0.0356, -0.0557]],\n",
      "\n",
      "         [[ 0.0716,  0.1091,  0.0246],\n",
      "          [ 0.0030, -0.0440, -0.1129],\n",
      "          [-0.0175,  0.0380, -0.0133]],\n",
      "\n",
      "         [[-0.0205, -0.0426,  0.0286],\n",
      "          [ 0.1381,  0.1201,  0.0914],\n",
      "          [ 0.0419,  0.0334,  0.0773]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0136, -0.0065, -0.1230],\n",
      "          [-0.0190,  0.0328,  0.1658],\n",
      "          [ 0.0920,  0.1097,  0.0014]],\n",
      "\n",
      "         [[-0.0058,  0.0129,  0.0495],\n",
      "          [ 0.0304, -0.0613,  0.0434],\n",
      "          [ 0.0625,  0.0650, -0.0629]],\n",
      "\n",
      "         [[-0.0106, -0.0024,  0.0654],\n",
      "          [-0.0108,  0.0205,  0.0081],\n",
      "          [ 0.0065,  0.0594,  0.0869]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0200, -0.0525, -0.0145],\n",
      "          [-0.0115, -0.2936,  0.0877],\n",
      "          [ 0.0012, -0.1097,  0.0525]],\n",
      "\n",
      "         [[-0.0631, -0.0223, -0.0041],\n",
      "          [-0.1238, -0.1522,  0.1024],\n",
      "          [-0.0432, -0.0591,  0.0270]],\n",
      "\n",
      "         [[-0.0171,  0.0037,  0.0417],\n",
      "          [-0.0599,  0.0725,  0.1139],\n",
      "          [ 0.0308,  0.0283,  0.0792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0310,  0.0738, -0.0027],\n",
      "          [-0.0356,  0.0816,  0.1166],\n",
      "          [-0.0122,  0.0520, -0.0035]],\n",
      "\n",
      "         [[-0.0062, -0.0690, -0.0191],\n",
      "          [ 0.0630, -0.1161,  0.0145],\n",
      "          [-0.0299,  0.0433,  0.1179]],\n",
      "\n",
      "         [[ 0.0156, -0.0025,  0.0114],\n",
      "          [-0.0018, -0.0315,  0.1325],\n",
      "          [-0.0107,  0.0092,  0.0596]]],\n",
      "\n",
      "\n",
      "        [[[-0.0283, -0.0225, -0.0526],\n",
      "          [-0.0054,  0.0059,  0.0052],\n",
      "          [-0.0080, -0.1187,  0.0164]],\n",
      "\n",
      "         [[ 0.0482,  0.0021, -0.0204],\n",
      "          [-0.0619,  0.0722, -0.0370],\n",
      "          [-0.1231,  0.1738,  0.0456]],\n",
      "\n",
      "         [[ 0.0472, -0.0305, -0.0478],\n",
      "          [-0.0882, -0.0469,  0.0091],\n",
      "          [-0.0307, -0.1309, -0.0561]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0084, -0.0331, -0.0005],\n",
      "          [-0.0074,  0.0216, -0.0538],\n",
      "          [ 0.0249, -0.0939, -0.1052]],\n",
      "\n",
      "         [[ 0.0028,  0.0321,  0.0429],\n",
      "          [ 0.0885, -0.0757,  0.0417],\n",
      "          [ 0.0890, -0.0824,  0.0961]],\n",
      "\n",
      "         [[ 0.0214, -0.0220, -0.0023],\n",
      "          [ 0.0322,  0.0391,  0.0320],\n",
      "          [ 0.0408,  0.0743, -0.0246]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0585, -0.0332,  0.0129],\n",
      "          [ 0.0968,  0.0160,  0.0471],\n",
      "          [-0.0214,  0.0621,  0.0333]],\n",
      "\n",
      "         [[ 0.0237,  0.0470,  0.0972],\n",
      "          [-0.0871,  0.0423,  0.1314],\n",
      "          [-0.0566,  0.0528,  0.0616]],\n",
      "\n",
      "         [[-0.0651, -0.0447,  0.0354],\n",
      "          [-0.0517,  0.0446,  0.1071],\n",
      "          [ 0.0003,  0.0072,  0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0330, -0.0146,  0.0424],\n",
      "          [ 0.0948, -0.0266,  0.0032],\n",
      "          [ 0.0131, -0.0211, -0.0127]],\n",
      "\n",
      "         [[-0.0079, -0.0077, -0.0651],\n",
      "          [-0.0268, -0.0627, -0.0419],\n",
      "          [ 0.0124, -0.1505, -0.1105]],\n",
      "\n",
      "         [[-0.0192,  0.1122,  0.0306],\n",
      "          [ 0.0531, -0.0725, -0.0051],\n",
      "          [-0.0879, -0.0288, -0.0032]]]], device='cuda:0')), ('backbone.model.layer2.1.bn2.weight', tensor([2.4630, 2.3990, 2.5384, 2.2259, 3.2885, 1.6490, 2.4192, 2.9999, 1.7369,\n",
      "        2.8978, 3.2402, 2.4004, 2.3489, 2.0790, 1.4635, 2.1317, 2.3882, 1.7116,\n",
      "        2.7667, 2.1499, 2.3669, 1.7359, 1.4175, 1.6218, 1.8692, 2.4789, 1.7392,\n",
      "        2.2216, 1.7413, 1.6163, 2.0984, 1.7253, 2.0846, 2.3938, 2.3226, 2.5546,\n",
      "        1.5866, 2.3967, 1.8207, 1.3779, 1.9622, 2.1001, 1.6506, 2.3061, 2.0708,\n",
      "        2.2775, 1.8257, 2.4021, 2.4587, 2.3057, 1.9357, 2.1473, 3.5111, 1.9857,\n",
      "        1.7744, 1.7119, 2.0294, 2.5292, 2.1704, 2.6607, 2.4563, 4.1119, 1.3442,\n",
      "        2.0500, 1.3585, 2.5023, 1.1861, 2.1202, 1.8290, 1.4105, 2.1658, 2.4142,\n",
      "        1.9240, 1.8155, 2.5274, 2.2318, 2.5050, 1.8814, 1.8406, 2.2357, 2.5335,\n",
      "        1.7294, 2.6681, 2.9143, 2.2941, 1.7454, 2.0093, 1.7076, 1.9080, 1.4604,\n",
      "        2.1776, 2.5097, 1.8451, 1.6364, 1.8910, 2.0441, 2.0498, 1.9414, 1.9301,\n",
      "        2.7402, 1.9375, 1.8810, 2.0456, 1.7579, 2.0691, 1.8154, 1.8784, 1.9177,\n",
      "        2.1405, 2.3574, 1.4262, 1.8220, 1.3778, 2.4319, 2.7258, 1.7797, 2.4666,\n",
      "        1.7357, 3.0922, 2.4248, 2.3939, 1.9402, 1.8279, 1.7519, 3.2987, 2.3488,\n",
      "        2.3261, 2.1310], device='cuda:0')), ('backbone.model.layer2.1.bn2.bias', tensor([-2.9496,  0.2227, -1.7529,  0.1352, -1.1702,  1.1935, -2.3078, -0.0483,\n",
      "        -1.8907,  1.2571,  0.7828,  0.9941, -0.6311, -1.0811,  0.8574, -1.6915,\n",
      "        -1.0765,  0.7641, -0.6709, -2.5409, -1.2832,  1.3186, -0.0999, -1.4872,\n",
      "        -3.0797,  0.3449,  0.4840,  0.7355, -1.4562, -0.5829,  0.6535, -0.2702,\n",
      "        -2.8599,  1.0143,  0.0664, -1.1527,  0.1545, -1.5421, -1.1693,  1.1555,\n",
      "        -0.5297, -1.3744,  1.2661, -0.5513, -0.8627,  1.1091, -1.0918,  0.1271,\n",
      "        -1.3752, -1.8309,  1.5315, -0.6099, -1.4871,  1.6547, -1.3771, -0.6163,\n",
      "         0.3779,  0.8320, -2.0474,  0.2080, -1.0694, -1.9522,  0.4643, -2.1945,\n",
      "         0.4554, -1.3259,  0.7541, -1.8723,  0.1450,  1.1721, -3.2052, -0.1413,\n",
      "         0.5139,  0.1243, -1.5526, -1.9554,  0.0289, -2.6241, -0.2150,  0.4996,\n",
      "        -2.6455,  0.6104,  0.1847, -3.3322,  1.4646, -0.1191, -1.8661, -0.8136,\n",
      "        -0.8831,  0.4912,  0.0707, -2.8699, -1.3456, -0.8598, -0.3515,  1.7579,\n",
      "        -2.5627,  0.4397,  1.0500, -0.7471,  0.2436,  0.3774, -2.0730,  0.3199,\n",
      "        -0.5398,  0.5928, -1.9123,  0.5816, -0.1172, -2.1307,  0.2222,  0.1248,\n",
      "        -0.3435, -2.1249, -0.0230, -0.0196,  0.8508, -1.2917,  0.3283, -2.0193,\n",
      "         0.2073, -1.2642,  0.2927, -1.4780, -3.5346,  1.3716,  0.6984, -2.2283],\n",
      "       device='cuda:0')), ('backbone.model.layer2.1.conv3.weight', tensor([[[[-0.0231]],\n",
      "\n",
      "         [[-0.0955]],\n",
      "\n",
      "         [[ 0.0204]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1098]],\n",
      "\n",
      "         [[-0.1635]],\n",
      "\n",
      "         [[-0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0217]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         [[ 0.0493]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0627]],\n",
      "\n",
      "         [[ 0.0038]],\n",
      "\n",
      "         [[ 0.0086]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0002]],\n",
      "\n",
      "         [[-0.1335]],\n",
      "\n",
      "         [[-0.0739]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0702]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[ 0.0111]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0432]],\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         [[-0.0226]],\n",
      "\n",
      "         [[-0.0057]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0050]],\n",
      "\n",
      "         [[ 0.0130]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         [[-0.0223]]],\n",
      "\n",
      "\n",
      "        [[[-0.0536]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.1463]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0274]],\n",
      "\n",
      "         [[ 0.0505]],\n",
      "\n",
      "         [[-0.0507]]]], device='cuda:0')), ('backbone.model.layer2.1.bn3.weight', tensor([ 3.4573e+00,  5.6236e-01, -4.1266e+00,  7.2433e-01,  3.4651e-02,\n",
      "         2.6664e-02,  2.4844e+00,  9.4162e-01, -6.3927e-01, -1.8457e+00,\n",
      "        -2.1123e-01,  2.8683e+00, -3.0488e+00, -1.0418e-01, -2.3043e-01,\n",
      "         1.3478e-01, -2.7870e+00, -2.3106e+00, -1.3027e+01, -1.8402e-01,\n",
      "         8.8408e-01,  7.3213e-01,  7.2974e-01, -1.7498e-01,  4.0356e+00,\n",
      "        -6.5109e+00,  1.5971e+00, -4.8956e-02, -3.7552e+00, -2.6074e+00,\n",
      "         1.9047e+00, -4.0317e-02,  2.2296e+00,  8.3217e+00,  6.7441e-01,\n",
      "        -7.9957e-01,  4.3501e+00, -1.4135e-02,  2.4439e+00, -7.2447e-01,\n",
      "         3.2812e+00,  3.5427e-03, -6.7761e+00, -1.5254e+00,  9.1105e-02,\n",
      "         2.5481e+00,  2.3823e+00, -2.6598e+00,  3.2810e+00, -8.2729e-02,\n",
      "         2.4355e+00, -1.9415e+00,  1.4000e+00, -2.5690e+00,  3.2185e-02,\n",
      "        -1.1476e-02, -2.5410e-01,  2.7317e+00, -1.1278e+01,  4.3319e-02,\n",
      "        -2.1874e-02, -2.7412e+00,  2.9323e+00,  2.3237e+00,  3.3771e+00,\n",
      "         1.0210e-01, -1.9397e-01,  8.8463e-01,  1.2114e+00,  1.3170e+00,\n",
      "        -3.2835e+00, -5.5215e+00,  2.3290e+00, -5.4782e-01, -3.4598e-01,\n",
      "        -4.0016e+00, -1.2783e-02, -2.2577e+00, -3.3710e-02,  2.1120e-02,\n",
      "        -1.8382e+00, -4.5028e-01, -8.3953e-01, -2.2117e-01,  3.6045e-01,\n",
      "         4.2683e-01, -1.5743e-02, -5.7698e-03, -3.0018e+00, -1.8791e-02,\n",
      "        -9.5166e-01,  1.6129e-02,  2.5643e+00, -2.1278e-01,  1.3087e+00,\n",
      "        -1.1936e-01, -1.1402e+00, -6.3374e+00, -3.6441e+00,  2.8786e-01,\n",
      "         2.8031e-01, -8.3086e-01, -1.1894e+00,  5.6749e-01,  5.6247e+00,\n",
      "        -8.0153e-01, -3.9186e+00,  1.1559e+00, -2.6328e+00, -7.2306e-01,\n",
      "        -8.9686e-01,  1.2157e-01,  2.3536e-01,  2.4298e+00,  8.3806e-01,\n",
      "         2.2364e+00, -2.7117e-02, -3.0153e-01,  2.6293e+00, -2.6812e-02,\n",
      "        -3.2505e+00, -2.8923e+00, -6.6606e-01,  2.4772e+00, -3.3553e+00,\n",
      "         4.9619e-01, -1.7405e-01,  2.6808e+00,  1.6977e+00, -1.5708e+00,\n",
      "         1.2587e+00,  4.7782e-02, -2.7142e+00, -3.3421e-03,  2.8212e-01,\n",
      "         1.5684e+00,  9.9568e-01, -1.1779e+00,  4.3985e+00,  2.2888e+00,\n",
      "        -6.2573e-03, -5.5719e+00, -1.8551e+00, -1.7052e-01, -2.6829e+00,\n",
      "         3.6252e+00,  3.5536e+00, -3.8827e+00,  2.5260e+00,  8.9283e-01,\n",
      "        -2.5715e+00,  8.8996e+00, -3.3078e+00,  3.4547e-02,  1.3777e-02,\n",
      "        -1.0400e-01,  1.4096e+01,  2.4924e-01,  9.3792e-03,  5.6324e+00,\n",
      "         1.7464e+00, -8.6536e-01, -3.0063e+00,  1.1781e+00, -2.5916e+00,\n",
      "        -3.3334e+00,  1.1576e+01,  2.3640e+00, -3.2659e+00, -6.6199e+00,\n",
      "         3.5622e-01,  2.2484e+00,  1.0439e+00,  4.0642e-01,  1.0252e-01,\n",
      "        -1.5078e-01,  9.1269e-01,  1.7815e+00,  3.5236e+00, -8.4713e-02,\n",
      "        -9.8839e+00,  3.4248e+00, -4.4142e-02,  1.4357e-01, -1.6915e-01,\n",
      "        -1.7045e+00, -9.5336e-02, -5.1801e+00,  2.0273e-02,  2.0419e-01,\n",
      "        -6.7858e-01, -4.1437e+00,  7.0516e-02,  3.2506e+00, -2.7320e+00,\n",
      "         2.2419e+00, -5.7369e-01,  3.8964e-01, -4.5245e+00,  3.0559e+00,\n",
      "        -3.1628e-01,  1.4359e-02,  1.9227e+00,  1.4739e+00, -1.2282e-01,\n",
      "        -5.4496e-03, -1.4045e+00,  9.8231e-01,  2.6233e+00, -2.2981e+00,\n",
      "        -8.2236e-01, -3.6016e-02,  5.2460e-01, -2.3567e+00, -7.6085e-01,\n",
      "         8.2825e-01,  2.9603e-02, -6.1483e-02, -1.0653e-01, -1.1048e-02,\n",
      "        -1.7899e-01, -2.7152e-02, -9.2607e-03, -2.2607e+00,  2.0436e+00,\n",
      "        -2.8212e+00,  1.5578e-01, -1.2971e+00,  1.3551e+00,  1.2477e-01,\n",
      "        -1.1229e-02,  8.9316e-04, -3.7261e-02,  1.3371e+00,  3.1317e+00,\n",
      "         3.6917e+00,  1.5832e+00, -3.2111e+00,  1.9179e-02,  2.4666e+00,\n",
      "        -1.8842e+00,  2.5863e-01,  3.2277e+00, -1.4160e+00,  2.0593e+00,\n",
      "         1.5642e-02, -2.2442e+00,  1.2354e+00,  1.5607e+00,  3.3666e-02,\n",
      "         1.4402e-01, -5.5927e-03, -1.2437e-02, -1.5213e-03,  2.3523e+00,\n",
      "        -3.2801e+00, -2.2976e+00,  7.0443e-05,  2.2683e-02,  1.1155e-01,\n",
      "         2.4192e-01, -6.7929e-01, -3.1946e+00, -1.4506e+00,  1.5656e-01,\n",
      "        -1.4491e-02, -2.0105e+00,  7.8490e-01,  4.2646e+00,  2.5724e+00,\n",
      "        -3.4302e+00, -2.7527e+00,  1.4589e+00, -1.9330e+00,  2.1687e-01,\n",
      "        -1.4236e+00,  3.2506e+00, -4.0976e-01,  5.5731e+00, -3.7845e+00,\n",
      "         2.3341e-01,  1.1062e+00,  3.9251e-01,  2.6562e-02,  1.1019e+00,\n",
      "         4.6374e-03, -2.2640e-01, -2.4142e+00,  4.1446e-01,  2.3352e+00,\n",
      "        -1.1246e+00,  1.0393e+00, -2.4538e+01,  8.1165e-01, -6.5685e-01,\n",
      "         4.4141e-01, -2.7334e-02,  4.5584e-01,  4.2918e-01,  1.4989e+00,\n",
      "        -3.5068e-03, -2.4614e-02,  1.0598e-01, -3.5372e-01, -1.5138e-01,\n",
      "         1.4105e-03, -5.0746e-01, -3.5819e-02,  9.0768e-01, -5.8001e-02,\n",
      "         1.9902e+00, -3.4320e+00, -2.0787e+00,  1.4754e+00,  1.9611e-01,\n",
      "         5.3731e+00, -4.8376e+00, -2.1140e-02,  4.4894e-02,  7.0826e-01,\n",
      "        -1.8032e-02,  5.6542e-01, -7.3830e-01,  3.3043e-01,  2.5956e+00,\n",
      "         7.4657e+00,  1.7049e-02,  3.6028e+00,  3.0964e-01,  1.8329e+00,\n",
      "        -1.6398e+00, -9.4079e-01, -1.1807e+00,  1.7654e-01,  4.0723e+00,\n",
      "        -6.5830e-01, -4.4690e+00,  1.3339e+00,  1.6507e+00,  3.2991e+00,\n",
      "         2.6363e-01, -5.2455e-01, -2.2479e+00,  3.5886e+00, -2.7232e+00,\n",
      "        -7.0447e-01, -6.9091e-01, -7.3668e-02,  2.4298e+00,  3.0328e+00,\n",
      "         1.2937e+00,  1.3613e+00,  3.6027e-01, -5.6955e-01, -2.0698e+00,\n",
      "         2.1972e-01,  2.8168e+00, -1.7331e-02, -6.3945e-01,  2.2391e-01,\n",
      "        -6.7132e-03, -1.4163e-02,  9.2588e-01,  6.0031e-01,  5.6323e-01,\n",
      "         2.3295e+00, -4.7878e+00,  1.2407e+00, -3.0849e+00, -3.0075e+00,\n",
      "        -4.9385e+00, -2.9642e+00,  2.5841e+00, -5.7932e-01,  9.2421e-01,\n",
      "        -1.0190e+00,  2.3981e+00,  5.8838e-02,  6.1468e-02, -4.7870e-02,\n",
      "         3.4522e+00,  1.2592e+00,  5.1354e+00, -7.8083e-01, -2.2804e+00,\n",
      "         2.4620e-01, -6.9021e-01, -2.2580e-04,  3.4999e+00, -2.1917e+00,\n",
      "        -2.4179e+00,  9.9815e-01,  1.5398e+00,  3.2508e+00,  5.1653e-02,\n",
      "        -1.6236e-02,  5.5802e+00,  4.2767e-01,  1.0555e-02,  5.7716e-02,\n",
      "        -7.6172e-01, -1.4034e+00,  6.0359e-01,  6.0178e-01, -6.3459e-01,\n",
      "        -4.2185e+00, -8.3275e-01,  1.1475e+01, -2.7760e+00, -1.5440e-01,\n",
      "         1.0450e+01, -9.0650e-02,  8.4674e-01,  1.0135e-02, -2.9815e+00,\n",
      "         3.2024e+00, -2.4237e-01,  7.2913e-01,  4.1005e+00,  8.3280e-01,\n",
      "         7.8195e-01, -3.1046e+00,  5.6455e+00, -1.0456e+01,  1.1899e-02,\n",
      "        -9.0614e-01, -3.6139e+00, -1.3839e+00,  6.7826e-01,  2.6897e+00,\n",
      "        -2.8821e+00,  5.7299e+00, -1.8538e+00, -5.2231e-01, -3.4442e-02,\n",
      "        -5.2338e-01, -1.3742e+00, -8.4564e-03, -2.4631e+00,  1.3957e-02,\n",
      "        -3.5397e-02, -1.7456e-01,  4.2589e-02, -2.8770e-02, -3.7677e+00,\n",
      "         4.7468e-01, -4.8706e-02,  4.5388e-01,  4.1633e-01,  4.7829e-01,\n",
      "         2.7783e+00, -2.3960e+00, -1.3048e-01,  1.6289e+00,  1.5898e+00,\n",
      "         5.7274e+00, -1.9091e-01, -9.1275e-02,  1.6001e+01,  7.2665e-03,\n",
      "         1.2950e+00,  3.4612e-01, -2.1706e+00, -2.8998e+00,  6.2802e-01,\n",
      "         3.6223e+00,  2.1601e-01, -1.4223e+00, -1.8501e-02,  4.2752e-01,\n",
      "        -3.9906e+00, -4.1625e+00, -2.4442e+00,  6.1871e+00, -2.8835e+00,\n",
      "        -2.3867e+00, -1.8702e+00,  2.7311e-02, -4.6491e-01,  2.1747e+00,\n",
      "         2.0553e+00, -1.7798e-01,  1.3785e-02, -4.0757e+00,  8.8342e-01,\n",
      "         4.6844e-01,  8.1824e-01, -2.7010e-01,  5.6578e-01, -2.3322e-03,\n",
      "         9.4081e-02, -4.5608e+00, -2.5651e+00, -1.7410e+00, -2.8219e+00,\n",
      "        -7.1415e-01, -3.7489e-02, -3.4621e+00,  3.1690e+00, -4.0365e-02,\n",
      "        -3.5478e+00, -3.6968e+00, -2.8169e+00, -1.6455e+00, -1.9186e-02,\n",
      "         2.0452e-01,  3.1770e+00,  3.2584e+00,  7.4265e-02, -2.9182e+00,\n",
      "         4.4100e+00, -1.0846e+00], device='cuda:0')), ('backbone.model.layer2.1.bn3.bias', tensor([-3.9757e-01, -1.5368e-01, -1.9053e+00, -1.4472e-01, -6.2918e-03,\n",
      "        -4.9819e-02,  4.8095e-01,  1.9882e-01, -7.1606e-01,  2.4985e-01,\n",
      "         5.7262e-02, -8.1078e-01, -1.0714e-01, -7.6874e-02, -2.2175e-02,\n",
      "        -1.5624e-02, -1.0658e+00, -1.8747e+00, -1.3667e+01,  2.9291e-03,\n",
      "        -1.0293e-01, -1.5651e-01,  5.9951e-02, -2.7505e-02,  4.0804e-01,\n",
      "        -4.6841e-02,  2.5704e-01, -1.8171e-02, -2.1027e+00,  4.8749e-01,\n",
      "        -7.9008e-02, -3.6419e-02, -1.1962e+00, -8.7108e-01, -2.8046e-01,\n",
      "        -4.5517e-01, -2.0481e+00, -1.9575e-02,  2.6444e-01, -3.8017e-01,\n",
      "        -6.4595e-01, -5.5522e-04,  1.1921e-01, -7.9997e-01, -5.3449e-03,\n",
      "         9.2589e-03, -1.0128e+00, -2.4248e+00, -6.3457e-01, -9.6929e-02,\n",
      "        -3.3171e-01,  7.9856e-01, -4.2841e-01, -3.7185e-01, -2.6009e-02,\n",
      "         4.3222e-03, -9.2544e-02, -1.3085e+00, -1.7481e+01,  1.4989e-02,\n",
      "        -3.2850e-02, -1.5924e-01, -5.8901e-01, -1.4984e+00,  5.9128e-01,\n",
      "        -4.6479e-02, -1.6210e-01, -3.0446e-01,  4.4559e-01, -4.4912e-01,\n",
      "         2.8507e+00, -8.5541e-01,  5.5060e-01, -1.8903e-01, -7.8910e-02,\n",
      "        -9.1031e-03, -1.1378e-02, -2.0060e+00,  5.6769e-02, -4.2795e-03,\n",
      "        -5.8690e-01, -1.5360e-01, -4.8882e-01, -1.1273e-01, -6.4403e-02,\n",
      "        -2.6270e-01, -1.2744e-02, -2.9609e-02,  2.5543e-01, -1.5006e-02,\n",
      "        -3.0468e-01,  2.8466e-03, -5.8908e-01, -1.6203e-01,  1.2019e-01,\n",
      "        -5.9880e-02, -1.7572e-01, -4.0538e+00,  1.0645e+00, -2.7343e-01,\n",
      "        -1.3694e-01, -7.0253e-01, -7.1276e-02, -2.8742e-01,  1.1668e+00,\n",
      "        -4.6314e-01,  1.4866e-01, -1.4294e-01, -2.1406e+00, -2.8615e-01,\n",
      "        -3.2758e-01,  7.8085e-02, -2.2667e-01, -3.7332e-01, -7.4118e-01,\n",
      "         1.2502e+00, -8.0933e-03,  1.4010e-01, -4.1979e-01, -2.6036e-02,\n",
      "         1.2451e+00, -9.7940e-01, -1.2769e+00, -4.3643e-01,  1.4104e-01,\n",
      "        -2.7896e-01,  2.2133e-01, -7.8166e-01, -4.6131e-01, -2.7661e+00,\n",
      "        -4.2733e-01, -5.4613e-02, -1.6312e+00, -1.7166e-02, -5.9383e-01,\n",
      "        -3.5649e-01, -2.3820e-01, -1.1917e+00, -8.7155e-01, -4.4410e-01,\n",
      "        -1.7881e-02, -1.6465e+01, -1.3347e+00, -2.8235e-02,  8.0818e-03,\n",
      "        -8.2592e-01, -1.1562e+00,  3.4374e+00, -3.7346e-01, -4.4435e-01,\n",
      "        -5.3454e-01,  1.7794e+00, -2.3711e+00, -6.3877e-02, -9.6509e-03,\n",
      "         1.4432e-01, -8.2320e+00, -2.8448e-01, -4.0282e-04,  1.7950e+00,\n",
      "         7.6701e-01, -3.6501e-02,  1.0273e-01, -5.7834e-01, -8.9946e-01,\n",
      "        -9.5609e-01, -2.3813e+00, -9.2717e-01, -2.2549e+00, -1.8441e+00,\n",
      "         1.5112e-01,  8.9924e-02, -8.9365e-01,  5.2026e-02, -1.6953e-02,\n",
      "        -5.3391e-02, -3.1044e-01, -2.7263e-02, -1.0220e+00, -1.0714e-02,\n",
      "        -2.6536e+00, -5.0837e-01, -4.3534e-03, -4.9392e-02, -2.4547e-01,\n",
      "        -1.1322e+00, -1.7724e-02, -1.5391e+01, -7.9142e-04, -1.0255e-01,\n",
      "        -4.2036e-01, -1.1281e+00, -1.1068e-01, -2.0805e+00, -1.0943e+00,\n",
      "         2.4889e-01, -3.7233e-01, -2.0423e-01, -4.0734e-01, -1.9293e+00,\n",
      "         3.0323e-02, -1.5642e-02, -1.2185e+00,  4.8443e-02, -2.9004e-02,\n",
      "        -2.0517e-02, -1.5483e+00, -5.1608e-01, -1.2864e+00, -8.0215e-01,\n",
      "        -6.4938e-01, -3.6474e-02, -2.1343e-01, -1.3665e+00, -8.6043e-01,\n",
      "         2.3200e-01, -5.6398e-02, -6.4152e-02, -3.2381e-02, -1.7980e-02,\n",
      "        -8.7532e-02,  5.8769e-03, -7.1511e-03, -1.2508e+00, -5.4788e-02,\n",
      "         2.0873e+00, -2.7090e-01, -8.5015e-01,  2.4622e-01, -7.7072e-04,\n",
      "        -1.7649e-03,  1.4243e-02, -1.7885e-02, -1.3471e+00, -9.5354e-01,\n",
      "        -1.1624e+00, -3.4794e-01, -1.6600e-01, -7.7410e-03,  1.3506e+00,\n",
      "        -3.1122e-01, -7.5456e-02, -1.8530e-01, -1.2751e+00, -3.1576e+00,\n",
      "         1.0401e-02,  9.6701e-01, -8.7121e-01, -7.5517e-01, -1.0931e-02,\n",
      "        -5.9877e-02, -9.6070e-03,  1.2196e-03, -3.2439e-02, -1.6212e+00,\n",
      "        -2.5287e+00, -7.5404e-01,  3.6613e-03, -3.3966e-02, -2.5936e-02,\n",
      "        -1.3094e-01, -1.2287e+00, -2.3392e+00, -1.4374e-01, -5.0155e-03,\n",
      "        -1.1484e-02, -9.1967e-01, -2.1874e-01,  9.1431e-01,  8.4518e-01,\n",
      "         1.0702e-01, -8.5627e-01, -3.5147e-01, -1.2665e+01, -8.2864e-02,\n",
      "        -3.8243e-01, -1.0920e+00, -2.3981e-01,  1.0978e+00,  3.5986e+00,\n",
      "        -4.1724e-02, -1.1303e+00, -1.6798e-01, -3.2877e-03, -4.7907e-01,\n",
      "        -2.2667e-03, -2.1355e-01,  8.0926e-01, -3.9147e-01,  6.9910e-01,\n",
      "        -1.8711e-01, -9.9307e-01, -1.9099e+00, -5.1819e-01, -5.5837e-01,\n",
      "        -2.5607e-01, -6.5671e-01, -2.9483e-01, -4.2445e-03, -1.2913e+00,\n",
      "        -3.6089e-02, -3.0820e-02,  2.1823e-02, -1.1292e-01,  1.8634e-02,\n",
      "         5.0456e-03, -1.9627e-01, -2.7601e-02, -3.4109e-01, -5.1115e-02,\n",
      "        -5.9616e-01, -1.1570e+00,  7.3590e-01, -6.7162e-01, -1.0236e-01,\n",
      "        -1.2161e+01, -1.7429e+00, -3.8018e-02, -5.2219e-02, -5.0343e-01,\n",
      "         1.8980e-03, -2.8100e-01, -1.1969e+00, -2.0909e-01, -2.3248e-01,\n",
      "        -8.5497e-01, -1.1176e-02, -2.0919e+00, -1.2241e-01, -4.4760e-01,\n",
      "         8.2679e-01,  1.8494e-01,  6.0836e-01, -2.1549e-01, -1.0326e+00,\n",
      "        -2.7911e-01, -6.2824e-01, -1.8804e+00,  9.1052e-01, -1.5302e+01,\n",
      "        -2.0268e-01, -1.9853e-01, -4.6668e-02, -1.8647e+01, -5.2762e-01,\n",
      "        -7.1742e-01, -1.5413e-01, -6.8315e-01, -1.6779e+00, -9.0579e-01,\n",
      "        -1.6772e+01, -9.2337e-01, -3.2173e-01,  5.9405e-02, -6.8512e-01,\n",
      "        -3.1671e-01,  6.9525e-01, -4.1775e-02,  7.1332e-02, -1.7733e-01,\n",
      "        -3.5534e-02, -8.4297e-03, -1.0519e+00, -2.7362e-01, -7.0279e-01,\n",
      "        -3.3918e-01,  9.1977e-01, -1.0845e+00, -1.3629e+00, -2.9812e-01,\n",
      "         1.1154e+00, -1.3250e-01, -6.4018e-01, -9.3658e-01,  1.1203e+00,\n",
      "        -2.5907e-01, -7.7782e-01,  1.8323e-02, -8.2381e-02, -1.0538e-01,\n",
      "        -4.4082e+00, -1.0337e+00,  2.3928e+00, -5.6336e-01,  1.4732e-01,\n",
      "        -5.9272e-01, -3.3814e-01,  1.1781e-03, -1.4896e+00, -2.7777e-01,\n",
      "        -9.1131e-03, -2.2753e-01,  4.7717e-03,  1.1587e+00, -1.5336e-02,\n",
      "         1.8304e-02, -1.4198e-01, -1.5619e-01, -1.8902e-03, -3.7279e-02,\n",
      "        -4.3593e-01, -6.5854e-01, -5.5442e-01, -4.8995e-01, -1.9663e-01,\n",
      "         6.0178e-01, -5.6047e-01, -1.3201e+01,  5.9266e-01, -1.1412e-01,\n",
      "        -1.7185e+01,  7.5365e-03, -2.5935e-02, -1.2486e-02, -2.0237e+00,\n",
      "        -1.1283e+00, -1.1209e-01,  4.2113e-01, -1.8157e-02, -8.6583e-01,\n",
      "        -6.2743e-01, -2.5413e+00, -2.1236e-01, -1.5087e+01,  4.9716e-04,\n",
      "        -1.3610e+00,  2.8813e-01, -3.3612e-01, -7.8296e-02, -1.6814e+00,\n",
      "        -7.0836e-01, -5.8917e-02,  5.1042e-01, -3.1351e-01, -2.0848e-02,\n",
      "        -2.1687e-02, -7.5200e-02, -6.1064e-02, -3.0179e+00, -6.3219e-03,\n",
      "         8.0090e-03, -1.7351e-01, -1.9831e-02, -2.1928e-02, -2.1095e+00,\n",
      "        -3.8035e-01, -7.9840e-02, -3.6880e-01, -3.7827e-01, -5.4425e-01,\n",
      "        -4.1783e+00,  8.3691e-01, -1.6016e-01, -1.8716e+00, -1.5604e-01,\n",
      "        -9.7162e-01, -8.6521e-02, -6.1300e-02, -3.4737e-01, -1.3461e-02,\n",
      "        -1.3491e+00, -1.6565e-01,  3.1560e-01, -9.6641e-01, -1.5932e-01,\n",
      "        -1.9298e+00,  1.0995e-01, -1.1836e+00,  1.1035e-02, -1.1980e-01,\n",
      "        -1.1910e+00, -2.8095e+00, -1.9011e-01, -4.8042e-01, -9.3004e-01,\n",
      "        -9.5486e-01, -2.9091e-01,  2.1515e-02, -2.5364e-02, -3.3804e-02,\n",
      "         4.5117e-01,  6.4495e-02, -7.3850e-03,  3.2547e+00, -4.4966e-01,\n",
      "        -5.6766e-02,  1.3415e-01, -8.3776e-02,  8.6386e-02,  1.3001e-03,\n",
      "        -3.7424e-02, -1.3979e+01, -2.0824e+00, -6.8803e-01, -2.7001e+00,\n",
      "        -6.2857e-01, -2.6599e-02, -2.0484e+00, -1.4938e+00,  4.0327e-02,\n",
      "        -1.7955e+00, -1.7813e+00,  1.3951e-01, -9.2568e-01, -1.9321e-02,\n",
      "         6.6908e-02, -6.2934e-01, -8.2832e-01, -9.3723e-02,  2.5432e+00,\n",
      "         8.7647e-01, -6.0654e-01], device='cuda:0')), ('backbone.model.layer2.2.conv1.weight', tensor([[[[-0.0258]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[-0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[-0.0744]]],\n",
      "\n",
      "\n",
      "        [[[-0.0512]],\n",
      "\n",
      "         [[ 0.0649]],\n",
      "\n",
      "         [[-0.0720]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1060]],\n",
      "\n",
      "         [[-0.0591]],\n",
      "\n",
      "         [[-0.0738]]],\n",
      "\n",
      "\n",
      "        [[[-0.0204]],\n",
      "\n",
      "         [[-0.0364]],\n",
      "\n",
      "         [[-0.0338]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0414]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[ 0.0123]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0006]],\n",
      "\n",
      "         [[-0.0858]],\n",
      "\n",
      "         [[-0.0065]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0315]],\n",
      "\n",
      "         [[-0.0169]],\n",
      "\n",
      "         [[-0.0442]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0160]],\n",
      "\n",
      "         [[ 0.0056]],\n",
      "\n",
      "         [[-0.0100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0563]],\n",
      "\n",
      "         [[-0.0193]],\n",
      "\n",
      "         [[ 0.0454]]],\n",
      "\n",
      "\n",
      "        [[[-0.0103]],\n",
      "\n",
      "         [[ 0.1501]],\n",
      "\n",
      "         [[-0.0437]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0124]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         [[ 0.0316]]]], device='cuda:0')), ('backbone.model.layer2.2.bn1.weight', tensor([2.4784, 0.5545, 1.7838, 2.1182, 2.4709, 0.6087, 2.3136, 2.3792, 0.9516,\n",
      "        3.3976, 1.1411, 3.1005, 2.6115, 2.4658, 1.1138, 1.3615, 1.7123, 2.1650,\n",
      "        1.3287, 1.0420, 1.0096, 2.2702, 2.0224, 1.0566, 1.4019, 1.7891, 1.6062,\n",
      "        1.6037, 1.9492, 2.1620, 1.4818, 0.7251, 1.3431, 1.6739, 1.1273, 2.3257,\n",
      "        1.3165, 0.7803, 2.4435, 1.4981, 1.6764, 2.4481, 0.8833, 0.7693, 1.3065,\n",
      "        1.7714, 0.8127, 1.7916, 1.2219, 1.5892, 5.1242, 0.8574, 1.6043, 0.8965,\n",
      "        1.3448, 2.4498, 0.8099, 2.6066, 2.5665, 0.3389, 2.3127, 2.4275, 1.8047,\n",
      "        0.3584, 1.7101, 1.2784, 1.8943, 1.4860, 1.6508, 1.6759, 1.2222, 1.5714,\n",
      "        1.5144, 1.3272, 1.5561, 1.6858, 2.0525, 1.4307, 1.4172, 1.6491, 1.0709,\n",
      "        2.2255, 1.6621, 1.2208, 1.9675, 1.3820, 1.5288, 0.7555, 1.0325, 0.8226,\n",
      "        1.5454, 1.4687, 1.6286, 2.1952, 1.6849, 2.2683, 2.9762, 1.6724, 1.0199,\n",
      "        0.9062, 1.9773, 1.1788, 1.0233, 0.7643, 2.0649, 1.5390, 1.6988, 2.9782,\n",
      "        2.6333, 0.7080, 1.4565, 0.9708, 1.2795, 1.7655, 1.1694, 1.6254, 0.9229,\n",
      "        0.9747, 1.2770, 1.4576, 1.4332, 1.3823, 1.3433, 2.4007, 3.3628, 1.6965,\n",
      "        2.9364, 0.5337], device='cuda:0')), ('backbone.model.layer2.2.bn1.bias', tensor([-3.0981, -0.6809, -1.1825, -1.5954, -3.3285,  0.1082, -1.8729, -1.1749,\n",
      "        -0.1901, -2.1079, -1.1933, -1.5338, -4.2381, -2.2627,  0.1462,  0.0552,\n",
      "        -1.4485, -1.3798, -0.5582, -0.3261,  0.1295, -2.1052, -2.5913,  0.1650,\n",
      "         1.1732, -1.5604, -1.6733,  0.0525, -1.7713, -3.2983,  0.1277,  0.3033,\n",
      "        -1.6310, -0.2772,  0.4227, -0.6826, -0.1038, -0.0074, -0.4725, -2.1791,\n",
      "        -1.8164, -2.8468,  0.2461,  0.2967, -1.3734, -0.6877,  0.6298, -1.1782,\n",
      "        -0.7466,  1.3493, -0.2265, -0.2876, -0.3393, -1.1051, -0.7000,  2.2874,\n",
      "        -0.2694, -1.3564, -3.2901,  0.1520, -3.1237, -1.1458, -1.4924,  0.1044,\n",
      "        -1.8765, -0.0953, -0.4870, -0.5579, -2.0200, -0.7726,  0.3323,  0.3765,\n",
      "        -1.8430,  0.2912,  0.0916, -0.3741,  2.0991, -0.6612, -1.4032, -0.6571,\n",
      "         0.4187, -2.1202, -1.7078,  0.2899, -3.1460, -0.1294, -0.4181,  0.4247,\n",
      "         0.0786,  1.2562, -1.6658, -0.1774,  0.0286, -0.2913, -0.4889, -3.4396,\n",
      "         1.8560, -3.1085, -0.0507,  0.3834, -3.4946, -0.0183, -0.0313,  0.2452,\n",
      "        -0.3696,  1.3627, -2.4704, -1.4562, -2.3016,  0.0579, -0.1716, -0.5627,\n",
      "        -0.0718, -1.8799,  0.7571, -0.1240,  0.1140,  0.7025,  0.8006, -1.4302,\n",
      "        -1.0264,  0.3034, -1.5083,  0.9064, -1.4393, -1.1587, -5.0514, -0.1018],\n",
      "       device='cuda:0')), ('backbone.model.layer2.2.conv2.weight', tensor([[[[-1.0361e-02, -2.2203e-02,  6.1756e-03],\n",
      "          [-2.8853e-02,  6.3716e-02, -2.1564e-02],\n",
      "          [-6.5319e-03, -9.8661e-05, -7.3703e-03]],\n",
      "\n",
      "         [[-5.5121e-02,  4.9610e-02, -1.4520e-02],\n",
      "          [ 3.4722e-03,  2.0497e-02,  5.5298e-02],\n",
      "          [ 1.5448e-03, -3.4382e-02, -4.9978e-03]],\n",
      "\n",
      "         [[-1.9632e-02, -5.3378e-02,  4.4554e-03],\n",
      "          [-5.8882e-02,  5.3980e-03, -3.7819e-02],\n",
      "          [-2.9080e-02, -2.8406e-02, -1.7864e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3943e-02, -2.0288e-02, -3.8252e-02],\n",
      "          [-6.8416e-02,  4.6609e-02, -4.4219e-02],\n",
      "          [-7.1652e-02, -1.0338e-01, -3.1177e-02]],\n",
      "\n",
      "         [[-9.1977e-03, -2.6572e-02, -4.3124e-02],\n",
      "          [-4.3808e-02, -4.9592e-02, -3.7406e-02],\n",
      "          [-1.5634e-02, -3.2134e-02, -2.4564e-02]],\n",
      "\n",
      "         [[ 9.2528e-03,  3.6909e-02,  2.1322e-02],\n",
      "          [ 2.9623e-02, -9.4605e-02,  5.0634e-02],\n",
      "          [ 3.6112e-03, -2.7156e-03, -1.0266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1937e-02, -2.4779e-02, -7.2063e-03],\n",
      "          [-5.9721e-02,  4.8791e-02, -9.6025e-02],\n",
      "          [-6.2835e-02, -5.3277e-02, -5.6675e-02]],\n",
      "\n",
      "         [[-7.9422e-03, -7.1849e-02, -2.1801e-02],\n",
      "          [ 1.2816e-02, -8.8504e-03,  1.3741e-02],\n",
      "          [ 4.8102e-02,  1.5202e-01,  7.1614e-02]],\n",
      "\n",
      "         [[ 2.4763e-02,  9.3100e-02,  3.3478e-02],\n",
      "          [ 5.2519e-02,  8.1564e-02,  3.3749e-02],\n",
      "          [-3.8050e-02, -1.2515e-01, -4.5437e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.4559e-02,  2.2181e-03,  2.0131e-02],\n",
      "          [-1.4897e-03, -5.4804e-02, -3.8885e-02],\n",
      "          [ 5.9412e-03, -3.2472e-02,  2.3276e-03]],\n",
      "\n",
      "         [[-2.9573e-02, -6.0096e-03, -1.8078e-02],\n",
      "          [-3.9200e-02,  6.1339e-03, -4.4849e-02],\n",
      "          [-8.9222e-03, -8.8422e-03, -4.0353e-02]],\n",
      "\n",
      "         [[-3.5902e-02,  9.2743e-02, -3.9658e-02],\n",
      "          [ 1.3163e-02,  8.3129e-02, -3.1913e-02],\n",
      "          [-4.5928e-02,  8.7334e-02, -3.9222e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4615e-02, -5.3774e-03, -2.5414e-03],\n",
      "          [ 1.7755e-02,  2.5465e-03, -2.2334e-02],\n",
      "          [ 1.5954e-03,  1.6913e-02, -9.0237e-03]],\n",
      "\n",
      "         [[-6.6170e-02,  5.3650e-02, -6.2802e-03],\n",
      "          [-3.0794e-02, -3.9246e-02,  2.6995e-02],\n",
      "          [-4.1633e-03, -6.1663e-02,  4.8206e-02]],\n",
      "\n",
      "         [[ 2.4689e-02, -1.4409e-02, -1.6062e-02],\n",
      "          [ 1.3141e-02, -1.7919e-02,  9.6651e-03],\n",
      "          [ 2.0150e-02,  1.4682e-02,  5.2289e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2491e-02, -4.2045e-02,  1.9555e-02],\n",
      "          [-9.0739e-02, -6.1131e-02,  8.6229e-02],\n",
      "          [-2.4550e-02, -3.3064e-02,  7.4883e-02]],\n",
      "\n",
      "         [[-1.9215e-02,  6.1994e-03,  3.9802e-02],\n",
      "          [-4.1397e-03, -2.9128e-02, -2.4151e-02],\n",
      "          [ 6.6139e-03,  1.4622e-02, -8.1646e-03]],\n",
      "\n",
      "         [[ 1.3529e-02, -3.7081e-02, -4.1355e-03],\n",
      "          [ 2.3365e-02, -1.5152e-02,  2.6928e-02],\n",
      "          [ 2.8737e-02,  1.0750e-02,  2.9361e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.3271e-03, -3.6191e-03, -4.5228e-02],\n",
      "          [ 4.1270e-02,  4.9410e-02,  4.9547e-03],\n",
      "          [ 2.1048e-02,  2.4163e-02,  2.6308e-02]],\n",
      "\n",
      "         [[ 4.8300e-03, -2.4347e-03,  9.4471e-04],\n",
      "          [-3.9373e-02, -1.5288e-01, -1.6056e-02],\n",
      "          [-9.4788e-02, -1.5175e-01, -5.8375e-02]],\n",
      "\n",
      "         [[-3.9184e-02, -2.0424e-02, -4.2184e-02],\n",
      "          [ 2.6060e-02, -2.1676e-02,  4.8196e-02],\n",
      "          [-8.4462e-03,  4.8595e-02,  3.7022e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0749e-02, -2.8296e-02, -5.5208e-02],\n",
      "          [-5.4119e-02, -2.3544e-02, -9.5444e-02],\n",
      "          [-4.2122e-02, -1.2381e-01, -1.5266e-02]],\n",
      "\n",
      "         [[ 7.6803e-02,  6.2548e-02,  5.6617e-02],\n",
      "          [ 4.9320e-02,  3.5314e-02,  2.8117e-02],\n",
      "          [ 2.7324e-02,  2.7061e-02,  3.3356e-02]],\n",
      "\n",
      "         [[-9.7827e-03, -3.4981e-02, -1.1517e-02],\n",
      "          [ 5.7093e-03, -1.9743e-02, -2.5570e-02],\n",
      "          [-1.4001e-02, -7.1102e-02, -6.8236e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4856e-03, -7.7559e-02, -4.6625e-02],\n",
      "          [-3.2715e-02,  7.2385e-03, -7.1132e-02],\n",
      "          [-2.7422e-02,  2.4733e-03, -5.6342e-02]],\n",
      "\n",
      "         [[ 7.0347e-02,  3.4049e-02,  8.4694e-03],\n",
      "          [-9.3058e-03, -5.8286e-03, -1.4427e-02],\n",
      "          [ 5.0368e-02,  1.3086e-01,  3.5621e-02]],\n",
      "\n",
      "         [[-7.3561e-02, -9.8452e-03, -3.3207e-02],\n",
      "          [ 1.4623e-02,  5.7660e-02,  2.4192e-02],\n",
      "          [ 1.9078e-02,  3.4967e-02,  2.3176e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5975e-02, -4.4717e-02, -3.4905e-02],\n",
      "          [ 3.3016e-03,  8.3707e-02,  5.3538e-02],\n",
      "          [ 1.1855e-03,  3.2469e-02,  1.5197e-02]],\n",
      "\n",
      "         [[-2.8507e-02, -4.1007e-02, -4.6694e-02],\n",
      "          [-3.8230e-02, -6.8556e-02, -5.3450e-02],\n",
      "          [-3.3190e-02, -1.9787e-02,  2.3645e-04]],\n",
      "\n",
      "         [[-1.2333e-01, -7.5726e-02, -1.1621e-01],\n",
      "          [-1.5829e-01, -5.5007e-02, -1.7472e-01],\n",
      "          [-1.4187e-01, -1.4472e-01, -1.1350e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4836e-02,  3.7817e-02,  4.0951e-02],\n",
      "          [ 1.2985e-02, -9.8133e-03,  1.4569e-02],\n",
      "          [-8.0374e-03,  3.2373e-02,  2.3200e-02]],\n",
      "\n",
      "         [[ 1.6339e-02,  5.2785e-02,  8.8356e-02],\n",
      "          [-1.6925e-02, -2.1348e-02,  2.1071e-02],\n",
      "          [-6.9675e-03,  6.4186e-02,  2.8696e-02]],\n",
      "\n",
      "         [[ 8.4286e-03,  3.2897e-02,  4.5724e-02],\n",
      "          [-9.3579e-03, -5.5406e-02, -2.4064e-02],\n",
      "          [-2.2210e-03,  2.4480e-04,  1.4270e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8250e-03, -8.1372e-02, -6.7268e-02],\n",
      "          [-8.3487e-02, -7.7744e-02, -7.5969e-02],\n",
      "          [-5.0758e-02, -9.3397e-02, -6.9582e-02]],\n",
      "\n",
      "         [[ 7.5432e-03, -1.9935e-02,  9.1555e-04],\n",
      "          [-4.0147e-02, -2.2404e-03,  1.5512e-02],\n",
      "          [-5.9639e-02,  1.1122e-02, -3.8223e-02]],\n",
      "\n",
      "         [[ 3.7420e-02, -5.6771e-04, -9.1690e-04],\n",
      "          [-2.8274e-02, -5.6394e-02, -1.1695e-02],\n",
      "          [-2.6845e-02, -2.4143e-02,  3.0564e-02]]]], device='cuda:0')), ('backbone.model.layer2.2.bn2.weight', tensor([2.4570, 1.0272, 2.0697, 1.6433, 2.7637, 3.6787, 3.3469, 2.7678, 1.8090,\n",
      "        1.4583, 1.3661, 2.1688, 2.3121, 1.1749, 1.2366, 2.2472, 2.1808, 0.6463,\n",
      "        1.6125, 1.9202, 1.9373, 0.9459, 2.8045, 2.2683, 1.1795, 2.2527, 2.0335,\n",
      "        2.3411, 2.1545, 1.3083, 4.7682, 1.8907, 2.2511, 2.1918, 1.8015, 1.9759,\n",
      "        3.2912, 1.1595, 5.9367, 2.4930, 0.9916, 1.3967, 1.5869, 1.8557, 3.6706,\n",
      "        2.0933, 0.9408, 2.3737, 0.0650, 0.0476, 0.3841, 8.5548, 1.5597, 1.6252,\n",
      "        1.5673, 1.6076, 2.4419, 2.5357, 1.0259, 1.7296, 3.5344, 0.0447, 3.5290,\n",
      "        0.9524, 2.0200, 1.6819, 1.7142, 0.9856, 3.4680, 2.2853, 2.6700, 0.9782,\n",
      "        1.9904, 4.4904, 2.2833, 2.0499, 0.3879, 1.9330, 1.4482, 2.1580, 1.0900,\n",
      "        1.3028, 2.5049, 2.5904, 3.1299, 1.3949, 3.1476, 1.2244, 1.8326, 0.7647,\n",
      "        2.5729, 2.7028, 0.6898, 2.2831, 1.5224, 2.1629, 2.5870, 1.0940, 0.7150,\n",
      "        0.9478, 0.5864, 1.6867, 1.2997, 2.7586, 0.9704, 0.9858, 1.1168, 1.5682,\n",
      "        1.1051, 0.8172, 6.0005, 1.5480, 1.1286, 1.0246, 2.1106, 1.7889, 1.1963,\n",
      "        0.3811, 5.5156, 3.1732, 1.5917, 0.8148, 0.0565, 4.7456, 1.0771, 1.2207,\n",
      "        2.7771, 0.8791], device='cuda:0')), ('backbone.model.layer2.2.bn2.bias', tensor([-1.7213e+00, -7.2443e-01,  2.6464e-01,  8.3243e-01, -5.3584e-01,\n",
      "        -7.4509e-01, -3.5465e+00,  1.3892e-03, -3.2027e-01,  6.3371e-01,\n",
      "        -6.1449e-02, -1.7804e+00, -2.7883e+00,  1.0833e+00,  1.0362e+00,\n",
      "        -2.0328e+00, -4.7978e-01,  4.7296e-01, -2.5268e-02, -1.7885e+00,\n",
      "         4.8008e-01, -1.7760e+00,  1.7100e+00,  5.8369e-01, -1.4075e+00,\n",
      "         6.7636e-01,  3.8111e-01, -2.1580e-01,  8.6449e-01, -1.3388e+00,\n",
      "        -2.3396e+00,  5.0714e-01, -2.6328e-01,  6.9529e-01,  1.9902e-01,\n",
      "        -2.3499e+00, -3.3255e-02, -1.3601e+00, -2.0645e+00,  6.2905e-01,\n",
      "        -1.6023e+00,  3.3048e-01,  5.3221e-01,  7.0955e-01, -6.2022e-01,\n",
      "        -2.6017e-02, -1.6462e+00,  1.3331e+00, -1.3717e+00, -1.0452e+00,\n",
      "        -2.8453e-01, -3.8816e+00, -1.3842e+00,  1.2326e+00,  3.8218e-01,\n",
      "        -1.4540e+00,  4.5411e-01,  1.0612e-01, -1.7266e+00,  8.6405e-01,\n",
      "        -1.8012e+00, -1.1433e+00, -1.1911e+00,  1.1227e+00, -7.4212e-01,\n",
      "         5.6241e-01, -1.1808e+00,  3.8613e-01, -3.8721e-02, -1.9563e+00,\n",
      "        -2.7154e+00,  5.3356e-01,  2.8615e-01,  1.1374e+00, -3.6684e+00,\n",
      "         1.2877e-01,  2.4152e-03,  1.1299e+00,  1.4581e-01, -1.0596e+00,\n",
      "         1.4729e+00, -6.4395e-01, -1.9666e+00, -6.4094e-01,  1.1815e+00,\n",
      "        -1.8572e-01, -1.7352e+00, -1.1927e+00, -2.1785e-01, -1.3617e+00,\n",
      "         1.0497e+00,  1.1670e+00, -8.8076e-01, -3.5258e-01, -4.6813e-01,\n",
      "        -1.3480e+00, -2.5765e+00,  6.4580e-01,  2.8536e-01, -4.5187e-01,\n",
      "        -6.8680e-01, -6.3279e-01, -3.8293e-01, -5.8905e-01, -1.5707e+00,\n",
      "         6.9974e-01,  5.9852e-01,  1.2720e-01,  8.6674e-01,  2.7288e-01,\n",
      "        -2.6285e+00, -2.3762e+00, -1.6512e+00,  1.5401e-01, -2.1165e-01,\n",
      "        -1.4153e-02,  1.6514e-01, -1.6780e-01, -6.0987e+00, -2.2146e+00,\n",
      "         5.1991e-01, -6.0335e-01, -1.3473e+00, -4.4168e+00,  2.8707e-01,\n",
      "         2.9805e-01, -3.6119e-01, -2.0262e+00], device='cuda:0')), ('backbone.model.layer2.2.conv3.weight', tensor([[[[-0.0546]],\n",
      "\n",
      "         [[ 0.0126]],\n",
      "\n",
      "         [[-0.0090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0585]],\n",
      "\n",
      "         [[ 0.0296]],\n",
      "\n",
      "         [[-0.2411]]],\n",
      "\n",
      "\n",
      "        [[[-0.0266]],\n",
      "\n",
      "         [[-0.0829]],\n",
      "\n",
      "         [[-0.0329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0339]],\n",
      "\n",
      "         [[-0.0444]],\n",
      "\n",
      "         [[-0.0167]]],\n",
      "\n",
      "\n",
      "        [[[-0.0514]],\n",
      "\n",
      "         [[ 0.0117]],\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[ 0.0448]],\n",
      "\n",
      "         [[-0.2488]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0209]],\n",
      "\n",
      "         [[ 0.0071]],\n",
      "\n",
      "         [[ 0.0916]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1416]],\n",
      "\n",
      "         [[ 0.1610]],\n",
      "\n",
      "         [[-0.1141]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0106]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[-0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1091]],\n",
      "\n",
      "         [[ 0.0312]],\n",
      "\n",
      "         [[-0.0485]]],\n",
      "\n",
      "\n",
      "        [[[-0.0283]],\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0058]],\n",
      "\n",
      "         [[-0.1827]],\n",
      "\n",
      "         [[-0.0022]]]], device='cuda:0')), ('backbone.model.layer2.2.bn3.weight', tensor([ 2.3075e-03, -1.0563e+00, -1.1297e-02,  1.6085e+00,  2.9123e+00,\n",
      "        -3.0159e+00,  7.8737e-01,  1.8012e-01,  3.2508e+00,  7.8941e-01,\n",
      "         4.7591e+00, -1.6448e+00,  1.3530e-01, -1.5572e+00, -4.8714e+00,\n",
      "        -9.6602e-01,  6.4177e-01, -7.3299e-01, -4.7307e+00, -2.2685e-01,\n",
      "         1.3845e-01,  9.6803e-02,  1.6347e+00,  2.8614e-01, -1.0638e-02,\n",
      "         6.2179e+00, -8.7644e-01,  3.0529e+00,  2.1048e-02, -7.3075e+00,\n",
      "         1.4947e+00, -3.0866e+00, -5.5253e-01, -4.9166e-03, -5.4400e-01,\n",
      "         2.8376e+00,  1.1521e-03, -3.9829e+00, -1.2007e+00,  9.3377e-01,\n",
      "        -1.6675e-02, -2.0521e+00,  7.5446e+00,  1.3584e-01,  3.3911e+00,\n",
      "         9.1644e-01,  3.8429e-01, -3.7752e-04, -8.4654e-01,  4.3804e-01,\n",
      "         1.2356e-01, -2.3242e+00, -9.4448e-01, -8.7056e-03, -9.1201e-01,\n",
      "         1.1303e+00,  6.4498e-01, -2.4634e-02,  8.8025e+00,  2.7952e+00,\n",
      "        -4.1968e-01, -8.2134e-01, -1.2124e+00,  4.1112e-01,  3.9011e+00,\n",
      "        -1.0552e+00, -1.8046e+00, -2.8069e-01, -2.9903e+00,  7.3285e-01,\n",
      "        -3.0767e+00,  9.6946e-03,  2.2120e-01,  2.6036e+00,  1.5383e+00,\n",
      "         1.3064e-02, -3.8789e+00,  8.6016e-01, -4.2008e+00,  2.3140e+00,\n",
      "         1.9757e+00, -3.2820e+00, -2.3099e+00, -5.1387e+00, -1.3372e+00,\n",
      "         2.4183e-02,  2.4724e+00,  1.5239e+00, -5.0090e-03,  4.6114e+00,\n",
      "         5.4190e+00,  3.9359e+00,  7.5482e-02, -2.9228e+00,  3.0252e-01,\n",
      "        -1.6852e+00, -5.8435e-01,  3.0783e+00, -2.1072e+00,  1.6113e+00,\n",
      "         2.5171e+00, -8.6728e-01, -8.7666e-01,  1.5630e+00, -5.1391e-03,\n",
      "        -6.5662e-01, -2.3733e-02, -8.8534e-01, -4.0904e-01, -4.2174e+00,\n",
      "         2.0929e+00,  3.2551e+00,  1.7708e+00, -1.3163e+00, -1.6445e+00,\n",
      "         1.8201e+00, -2.7390e+00, -5.1252e+00, -1.1645e+00,  2.1446e+00,\n",
      "        -1.0449e+00,  1.1826e-02, -1.6588e+00,  1.0652e+00, -5.5368e-01,\n",
      "        -3.2970e+00,  1.2703e+01,  4.9071e-01, -1.0276e+00, -1.0175e+01,\n",
      "        -1.7828e+00,  9.2836e-01, -1.9517e-01,  1.1057e+00,  5.0410e+00,\n",
      "        -4.4390e-01, -4.4817e-01,  7.0870e-01, -1.3248e-01,  4.1932e-01,\n",
      "        -3.6725e+00, -1.0800e-01, -2.1273e+00,  2.2279e+00,  1.2355e+00,\n",
      "         3.5027e-01, -4.6082e-02, -5.0389e-02, -3.1963e-01, -3.5195e+00,\n",
      "         4.3543e-01, -1.3630e+01, -4.5660e-01, -2.1794e+00, -3.7148e-01,\n",
      "        -5.1034e+00,  8.2612e+00,  4.1647e-01,  3.2561e+00, -4.8052e+00,\n",
      "         1.1227e+00, -7.3745e-01,  5.6804e-02,  2.6032e+00,  6.9123e-01,\n",
      "         4.5583e-01, -1.4079e+01,  1.1527e+00, -2.2343e+00,  7.0378e-02,\n",
      "         2.7092e+00,  9.2401e-01,  4.4741e-01, -9.9732e-01,  1.0139e+00,\n",
      "        -1.8139e+00, -1.8395e+00, -1.8291e-02,  1.0378e-01,  2.0124e+00,\n",
      "         2.6748e+00, -4.6575e-03, -1.0542e+00,  3.3695e+00, -5.8576e+00,\n",
      "         6.3993e-02, -3.6282e+00, -3.6483e-01, -6.6419e+00,  7.0779e-01,\n",
      "        -2.0716e+00,  5.7660e-02,  7.1465e+00, -2.4859e+00,  5.2879e-01,\n",
      "        -5.5434e-02,  2.8195e-01,  1.4607e+00,  4.9944e-02, -1.4848e-01,\n",
      "         3.3627e+00, -2.7695e+00,  1.8133e+00,  3.1807e-01,  2.6179e+00,\n",
      "        -3.1226e+00,  4.4633e+00, -2.4794e-01,  1.4778e-02, -1.9981e-02,\n",
      "        -1.9695e-01, -1.2473e+00,  2.5957e+00,  7.6220e-02, -5.0360e-02,\n",
      "        -7.7732e-01,  1.0598e+00, -1.2712e+00,  3.1003e+00,  3.2195e+00,\n",
      "        -7.2355e-01,  4.4073e+00, -9.5743e+00,  9.3450e-01,  8.8193e-01,\n",
      "         4.6714e+00, -4.3856e+00, -5.0165e+00, -1.3632e+00, -1.3669e+00,\n",
      "         4.7190e+00,  4.0709e+00,  3.9389e+00, -3.7052e-01, -5.2480e-01,\n",
      "         5.2303e-01, -1.8644e-02, -2.8303e-02,  1.3592e+00, -1.3604e+00,\n",
      "         5.7483e-01,  5.4301e-01,  6.4480e-01, -2.8539e+00, -1.9462e+00,\n",
      "         3.1549e+00, -1.2310e-01,  4.5207e-02,  5.6563e-01, -1.3391e+00,\n",
      "        -1.3235e+00, -1.3670e+00,  9.4833e-01, -2.4555e+00,  2.3609e-01,\n",
      "         3.6326e-01, -2.5621e-02, -3.5824e+00,  4.3858e+00, -6.0261e+00,\n",
      "         7.8718e+00,  3.7465e+00, -6.2409e-01, -2.8203e+00, -2.4288e+00,\n",
      "         3.1938e+00,  2.6822e+00,  8.5046e-01,  4.0025e-02, -8.5210e-03,\n",
      "        -3.2370e-01,  8.4306e-01, -2.4365e+00,  2.4073e+00, -1.2464e+00,\n",
      "         3.1347e-01,  2.5860e-01, -2.8367e+00,  3.9534e+00,  2.8735e+00,\n",
      "        -6.5498e+00,  7.8436e-02,  4.2818e-01, -1.6526e+00, -1.3077e+00,\n",
      "        -4.4025e+00, -2.0603e+00, -4.7052e+00, -5.6065e-01, -7.7702e-01,\n",
      "         5.2772e-02,  1.2571e+00, -2.1300e+01,  4.9785e-01, -1.7901e+00,\n",
      "        -1.6455e+00, -2.9393e+00,  1.0931e-01, -1.5730e+00, -3.2241e-02,\n",
      "         3.5844e+00,  2.6952e+00,  1.8484e+00,  4.1862e-01,  7.9711e-01,\n",
      "         1.2519e+00, -3.1314e-02,  2.9282e+00,  1.1878e+00,  6.0814e+00,\n",
      "        -6.0395e-02,  2.0428e-02, -2.2831e-03, -5.0254e-02,  3.7194e-01,\n",
      "         1.5209e-01, -3.7090e+00,  4.8571e+00,  6.3380e+00, -1.1268e+00,\n",
      "         4.1987e+00, -9.1555e-01, -1.5334e+00,  2.9142e+00, -8.0122e+00,\n",
      "        -4.3505e-02,  6.0270e+00,  5.3888e-03, -2.6992e+00, -2.6046e-01,\n",
      "         6.4173e+00,  4.1957e+00, -3.9417e-01,  6.7121e-01, -2.5139e-01,\n",
      "        -3.1972e+00, -7.2229e-03,  1.3715e-02,  3.8724e-02, -4.0082e+00,\n",
      "        -2.9904e-01, -5.0464e-02, -6.1333e-03, -4.0204e+00,  3.0842e-02,\n",
      "        -5.5992e+00,  4.9855e-02, -1.0921e+01,  1.7548e-02, -7.9910e-02,\n",
      "        -3.8586e+00, -8.4615e-02,  3.1543e+00, -2.4630e-02,  5.4083e-01,\n",
      "         2.1999e+00, -3.2166e-02,  2.0955e+00, -4.2851e+00, -2.1580e-01,\n",
      "        -6.2213e+00,  3.1514e+00, -9.7181e-01, -1.6262e+00,  6.7602e-01,\n",
      "         7.7824e-02,  6.5741e+00,  4.9008e-01, -1.1634e+00, -1.3641e-02,\n",
      "         1.7400e+00, -1.1707e+01,  1.3604e-01, -6.2717e-01, -4.2162e+00,\n",
      "        -2.0077e+00, -1.6725e+00,  3.3979e+00,  1.9076e+00,  4.0903e+00,\n",
      "        -2.3843e+00, -6.1780e-01,  5.1021e-01, -5.6202e-02, -9.3818e-01,\n",
      "        -2.6031e+00, -1.8752e-01, -3.2209e+00,  1.4201e-01,  2.8504e-01,\n",
      "         1.7278e-01, -7.4711e-01,  1.8012e+00, -2.3324e-02, -3.3290e+00,\n",
      "        -1.6703e+00,  5.6896e-03,  1.8502e+00,  7.6134e-01, -1.9982e+00,\n",
      "         5.5980e+00,  4.5511e-01,  5.8074e+00, -4.0024e+00, -4.5398e+00,\n",
      "        -2.5634e-02,  3.5174e+00,  6.3210e-01,  1.7309e+00,  3.2005e+00,\n",
      "        -2.9239e-01,  3.1550e+00, -8.9400e-01,  2.7297e+00,  1.6067e-02,\n",
      "        -4.2798e-02, -5.6124e+00, -4.1503e+00,  9.8143e-01,  1.3400e-02,\n",
      "         6.5925e-01,  4.0881e-01,  5.4554e-02,  6.4821e+00, -1.5799e+00,\n",
      "         5.1838e+00,  4.9462e-02, -1.9555e+00, -3.2416e+00,  1.7662e+00,\n",
      "         1.1221e+00, -1.5263e-02, -9.7444e-01, -1.9899e+00, -2.7136e+00,\n",
      "        -2.9510e+00,  3.8055e+00,  3.4087e+00, -1.7285e+00,  7.3173e+00,\n",
      "        -2.7165e+00,  3.4941e+00, -7.1802e-01, -9.4637e-01,  2.4079e-03,\n",
      "        -5.8023e-02,  1.9886e+00, -3.0550e+00,  1.0060e+00, -1.8336e+00,\n",
      "        -2.4946e+00, -6.3114e-01, -1.5763e+00, -1.3276e+00,  2.6261e-02,\n",
      "        -1.3009e-03,  2.2621e+00, -1.1741e+00,  1.9860e+01, -3.7529e+00,\n",
      "        -4.3153e-01, -1.6589e+00,  1.5747e+00,  5.2439e-02,  8.6179e+00,\n",
      "         5.4748e-02,  4.5991e+00,  2.1247e-01,  9.6626e-01, -8.2299e-01,\n",
      "        -4.7377e-02, -3.3177e-02,  7.6994e-02, -2.8453e-02,  7.8441e-02,\n",
      "        -6.3937e-03,  1.2268e+00, -7.1413e+00,  2.0405e+00, -1.1331e+00,\n",
      "        -1.1406e-02, -7.3819e-02, -7.3907e-01,  4.8379e-01,  1.1880e-01,\n",
      "        -8.7572e-01, -2.4248e+00, -1.1224e+00,  5.9710e+00,  4.6771e+00,\n",
      "         2.4224e+00,  4.5415e+00,  6.5239e-01, -1.5087e+00,  9.8070e-01,\n",
      "        -2.5814e+00, -3.4410e+00, -5.3548e-02,  6.0397e-02, -4.2016e+00,\n",
      "        -2.8348e+00, -3.3870e-01, -6.5031e-01, -1.1252e+00,  6.2583e-01,\n",
      "         4.5565e+00, -5.0897e-01,  1.7096e-02,  7.1500e+00,  2.5865e-02,\n",
      "        -8.9279e-02,  2.7734e+00], device='cuda:0')), ('backbone.model.layer2.2.bn3.bias', tensor([-3.0372e-02, -3.6013e-01, -6.8196e-02, -2.2203e+00,  1.2409e-01,\n",
      "        -2.3568e+00, -1.8070e-01, -1.9079e-01, -1.4981e+00, -2.6416e-01,\n",
      "        -1.9984e+00,  8.7115e-02, -1.0519e+00, -6.9086e-01, -3.3878e+00,\n",
      "        -4.0999e-01, -2.4861e-01, -3.2607e-02, -1.0992e+01, -2.2642e-02,\n",
      "        -1.7191e-01, -7.0627e-03, -2.6331e+00, -1.2686e-01, -7.9855e-03,\n",
      "        -1.3327e-03, -3.3190e-01, -9.7689e-01, -6.3842e-02, -1.2553e+00,\n",
      "        -1.0920e+00, -1.7186e+00, -1.8839e-01, -2.2864e-03, -1.6255e-01,\n",
      "        -9.4523e-01, -3.0810e-03,  8.0320e-01,  4.4345e-01, -3.1529e-01,\n",
      "         2.8992e-02, -6.2195e-01,  3.2976e-01, -4.5258e-02, -1.8993e-01,\n",
      "        -5.4002e-01, -1.7962e-01,  3.6499e-02, -4.1448e-01, -2.1725e-01,\n",
      "        -9.4910e-02,  4.3304e-01, -7.4113e-01, -1.3904e-02, -6.2818e-01,\n",
      "        -6.6420e-01, -3.4935e-01, -3.6205e-03, -1.2615e+01, -6.6266e-01,\n",
      "        -3.9240e-01,  1.0186e-01,  4.2504e-01, -2.7924e-01,  6.1389e-01,\n",
      "        -7.6397e-01, -1.0026e+00, -6.0520e-03, -3.2574e-02, -2.5448e-01,\n",
      "         2.5747e-01,  1.4394e-03,  1.7595e-01, -1.6025e+00,  2.0070e-01,\n",
      "        -3.3928e-02, -4.6293e-01, -1.5185e-01, -8.1172e-02, -8.8399e-01,\n",
      "        -2.3846e-01, -1.6094e+00, -9.9956e-01,  5.6732e-01,  8.2727e-01,\n",
      "        -2.1931e-03, -5.4499e-01, -8.1644e-01, -1.3701e-02, -4.3567e-01,\n",
      "        -1.0140e+00, -1.6087e-02, -2.8529e-01, -1.1001e+00,  1.9680e-01,\n",
      "        -7.9523e-01,  3.9061e-01, -1.6304e+00,  4.5140e-01, -6.3498e-01,\n",
      "        -1.9264e+00, -3.9787e-01, -7.2370e-02, -4.8354e-01, -2.5905e-02,\n",
      "         4.1456e-02, -2.7620e-02, -2.0597e-01, -8.5054e-02,  1.4053e+00,\n",
      "        -3.3019e-01,  2.5910e-01, -2.0508e-01, -5.0115e-01, -6.4962e-01,\n",
      "         2.9390e-01, -1.7182e-02, -5.2617e-01, -2.5609e-01, -9.1918e-02,\n",
      "         2.6830e-02, -5.3812e-02, -7.3486e-02,  2.7355e-01, -8.6916e-02,\n",
      "        -1.1806e+00, -1.5138e+01, -3.9432e-02,  6.0595e-02, -1.3560e+01,\n",
      "        -5.8420e-01, -7.9510e-01, -8.5106e-02, -4.6310e-01, -8.5066e-01,\n",
      "        -2.6373e-02, -2.4734e-01, -2.3703e-01, -1.6794e-02,  5.7961e-02,\n",
      "         4.8424e-01, -1.6162e+00, -1.8706e-02, -4.1187e-01,  1.4474e-01,\n",
      "         8.4120e-03,  1.0706e-03, -1.6626e-02, -4.2950e-02, -1.3116e+00,\n",
      "        -1.3859e-01,  4.3919e+00, -9.8508e-02, -8.5629e-01, -1.4450e-01,\n",
      "         6.3491e-01, -1.2915e+01, -1.8956e-01,  7.3832e-01,  9.6894e-02,\n",
      "        -6.7027e-01, -3.3946e-01,  9.7727e-02, -1.3398e+00, -1.7314e-01,\n",
      "        -1.1981e-01, -3.0772e+00, -2.1538e-01, -2.3514e+00, -5.1901e-01,\n",
      "        -2.7884e-01, -6.5771e-01, -1.3161e-02, -6.3647e-01, -4.8694e-01,\n",
      "        -6.1949e-01, -1.3548e+00, -3.4081e-03,  4.4947e-02, -3.0448e+00,\n",
      "        -1.2398e+01, -3.0199e-03, -8.0409e-01, -1.7933e+00, -5.2533e+00,\n",
      "        -1.0323e-02, -1.0670e+00, -7.7091e+00, -7.5040e+00, -6.9344e-01,\n",
      "        -8.1075e-02, -8.6093e-03, -2.8792e-01,  3.5854e-01, -3.5779e-01,\n",
      "         1.9653e-02, -8.5348e-02, -5.6702e-01, -5.3925e-02, -2.7699e-01,\n",
      "        -8.9490e-01, -1.4788e+00, -1.2728e+00, -8.9845e-02, -2.6879e+00,\n",
      "        -2.7008e-01, -1.2292e+00, -8.1369e-02, -1.9312e-03,  2.4360e-01,\n",
      "        -2.2317e-01, -8.9805e-01, -1.3640e+00, -5.3204e-02,  1.4198e-02,\n",
      "        -1.1192e+01, -8.6034e-01, -1.0807e+00, -4.6175e-01, -3.4344e+00,\n",
      "        -9.0865e-01, -3.7147e+00, -2.8972e+00,  1.8889e-01, -3.9178e-01,\n",
      "         1.8314e+00, -7.4801e-01,  1.9897e+00, -2.6939e-01, -8.6277e-01,\n",
      "        -1.1678e-01, -9.3973e-01, -1.1693e+00,  8.7210e-05,  8.4642e-02,\n",
      "        -4.6281e-01, -4.6014e-02, -3.8063e-03, -2.0824e-01,  3.1415e-01,\n",
      "        -3.0200e-01,  5.4646e-02,  2.0714e-01,  7.1641e-01, -1.5527e+00,\n",
      "        -2.0475e-01, -4.6649e-02, -1.9682e-01, -2.0925e-02, -9.8950e-02,\n",
      "        -2.3815e-01, -6.1852e-01, -3.7741e-01, -1.6682e-01,  1.7631e-02,\n",
      "        -6.8135e-02, -5.2822e-02, -1.2100e-01, -8.2552e-01, -1.4093e+00,\n",
      "        -5.1001e+00, -1.2296e+00, -3.5127e-01,  1.2953e+00, -3.3230e-01,\n",
      "        -1.1670e+00, -3.0493e+00, -1.5088e-01, -2.6013e-02, -2.3546e-03,\n",
      "         1.6469e-01, -2.0270e-01, -1.4429e+00,  1.6484e+00, -6.9622e-01,\n",
      "         1.1562e-01, -7.7979e-02, -3.4068e+00,  3.9940e+00,  1.0447e+00,\n",
      "         1.2214e-01, -1.9789e-01, -8.5253e-02, -8.8361e-01, -1.8327e+00,\n",
      "        -3.3868e+00, -7.6771e-01,  2.0130e-01, -1.3689e-01, -9.6543e-02,\n",
      "         8.6055e-02, -1.3123e+00, -6.4639e+00, -1.3420e-01, -5.9109e-01,\n",
      "        -1.1414e+00,  1.8750e-01,  9.5925e-03, -7.3728e-02, -5.0857e-03,\n",
      "        -9.8685e-01, -1.3349e+00, -5.4089e-01,  1.0172e-01, -1.4626e-01,\n",
      "        -5.0641e-01, -1.0678e-02, -3.1280e+00, -8.6254e-01, -5.2471e+00,\n",
      "         7.1509e-02, -6.7478e-02, -4.3003e-03, -1.3887e-01, -2.2069e-01,\n",
      "        -2.5537e+00, -8.4826e+00, -5.0078e+00, -6.6043e+00, -1.4126e+00,\n",
      "        -1.7746e+00, -7.4018e-02, -6.5916e-01, -1.1868e+00, -2.1826e+00,\n",
      "        -5.3139e-03, -1.8992e+00, -3.5540e-02,  2.4421e-01, -1.3484e-01,\n",
      "        -2.4825e+00, -1.4624e+00, -1.5217e-01, -6.0436e-01, -6.3116e-01,\n",
      "        -1.7783e+00, -1.4102e-02, -9.3415e-03, -3.3054e-02, -5.6544e+00,\n",
      "        -3.6573e-01, -1.6446e-01, -1.2689e-03, -4.7525e+00, -8.3913e-02,\n",
      "        -7.5256e+00, -2.5887e-04, -2.2441e+01, -1.9541e-02, -1.0053e-02,\n",
      "        -3.5866e+00, -6.1721e-02, -1.1609e+00, -6.1921e-02, -1.8144e-01,\n",
      "        -7.7356e-01,  1.3956e-03, -1.3600e+00, -6.0244e-01, -4.8730e-01,\n",
      "        -3.6182e+00, -4.6267e-01, -2.0486e-01,  4.4281e-01, -2.7344e-01,\n",
      "        -2.5574e-01, -1.0398e+00, -8.1560e-02, -3.4355e-01, -1.9042e-02,\n",
      "        -8.5807e-01, -3.9662e+00, -2.0422e-02, -5.1950e-01, -1.0407e+00,\n",
      "        -6.1617e-01,  1.1326e+00, -6.1308e-02, -1.5307e+00,  2.7584e-01,\n",
      "        -1.3252e-01, -1.4480e-01, -1.0489e-01, -2.5622e-01, -2.4433e-01,\n",
      "        -1.5598e+00,  1.4975e-02, -2.3559e+00, -1.6417e-01,  8.8580e-02,\n",
      "        -2.5226e-01, -7.1118e-01,  2.0529e-01, -2.7014e-02, -1.9274e+00,\n",
      "        -1.2333e+00, -7.0003e-02,  5.2058e-01, -2.2588e-01, -2.2215e+00,\n",
      "         9.5516e-03, -1.3955e-01, -9.3184e-01,  7.2043e-03, -2.8692e-01,\n",
      "        -1.0306e-01, -6.3916e-01, -2.4915e+00, -1.5243e-01, -6.5366e-01,\n",
      "        -7.7562e+00, -4.1175e-01, -5.6904e-02, -7.4505e-01, -1.4333e-03,\n",
      "        -4.7284e-03, -1.6486e+00,  3.1967e+00, -9.0597e-02, -2.6379e-02,\n",
      "        -8.3936e-02, -9.9854e-02, -6.7147e-02, -1.4503e+01, -1.0833e+00,\n",
      "         1.1697e+00, -3.8925e-02, -1.2052e+00, -1.1279e+00, -1.0290e+00,\n",
      "        -1.0740e+00,  1.7657e-03,  2.1856e-01, -3.9210e-01, -1.6678e+00,\n",
      "         6.1059e-01, -2.1236e+00,  4.5593e-01, -9.7067e-01,  9.4548e-01,\n",
      "        -2.1914e+00, -4.2849e-01, -5.1202e-01, -4.4609e-01, -2.9257e-02,\n",
      "        -8.3492e-02, -1.1122e+00, -2.0330e+00, -1.9028e-01, -2.0054e+00,\n",
      "         9.9116e-01,  3.3685e-02, -8.3585e-01,  7.1650e-01, -1.0844e-02,\n",
      "        -1.2094e-02, -2.0127e-01, -5.5460e-01,  4.0645e+00, -1.2410e+00,\n",
      "        -1.1087e-01, -1.4255e+00,  1.7603e-01, -2.8454e-02,  6.1961e+00,\n",
      "        -6.9184e-01, -4.9010e-02, -1.5702e-01, -1.5014e+00, -6.2341e-01,\n",
      "        -2.6633e-01, -8.1102e-02, -5.2898e-02, -7.8254e-02, -7.2802e-02,\n",
      "        -9.8168e-03, -6.5324e-01,  4.6638e+00, -3.5006e+00, -4.1009e-01,\n",
      "         2.9861e-03, -1.2865e-01, -5.8529e-01,  6.5772e-02,  4.3343e-03,\n",
      "        -4.5907e-01, -1.4184e+00, -3.9634e-01, -2.3799e-01, -9.1257e-01,\n",
      "        -7.0451e-01, -3.5064e-01, -2.3913e-01, -6.6952e-01,  3.9689e-01,\n",
      "        -1.6824e+00, -2.9218e-01, -2.0490e-01, -2.2598e-01, -5.7747e-01,\n",
      "         6.7744e-02, -9.0197e-02, -1.6389e-01, -1.0672e+00, -2.9549e-01,\n",
      "         1.2283e+00, -3.2539e-01, -3.8547e-02, -7.1450e-02, -2.5624e-02,\n",
      "        -7.4278e-02,  7.7715e-01], device='cuda:0')), ('backbone.model.layer2.3.conv1.weight', tensor([[[[ 0.0274]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         [[ 0.0119]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0371]],\n",
      "\n",
      "         [[ 0.0883]],\n",
      "\n",
      "         [[ 0.0358]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0114]],\n",
      "\n",
      "         [[ 0.0669]],\n",
      "\n",
      "         [[ 0.0608]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         [[ 0.0224]]],\n",
      "\n",
      "\n",
      "        [[[-0.0141]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         [[-0.0069]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2101]],\n",
      "\n",
      "         [[-0.0435]],\n",
      "\n",
      "         [[-0.0898]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0282]],\n",
      "\n",
      "         [[ 0.0628]],\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1690]],\n",
      "\n",
      "         [[ 0.0150]],\n",
      "\n",
      "         [[ 0.0187]]],\n",
      "\n",
      "\n",
      "        [[[-0.1192]],\n",
      "\n",
      "         [[ 0.0116]],\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0483]],\n",
      "\n",
      "         [[ 0.1317]],\n",
      "\n",
      "         [[ 0.0216]]],\n",
      "\n",
      "\n",
      "        [[[-0.0850]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         [[ 0.1323]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1142]],\n",
      "\n",
      "         [[ 0.0723]],\n",
      "\n",
      "         [[ 0.0171]]]], device='cuda:0')), ('backbone.model.layer2.3.bn1.weight', tensor([1.0925, 1.7373, 2.0978, 3.3289, 5.2793, 2.1381, 2.0259, 1.7136, 2.0694,\n",
      "        2.1511, 2.0869, 2.4931, 1.7814, 1.5570, 1.6621, 5.9601, 1.9484, 2.7741,\n",
      "        2.9652, 2.9120, 2.3752, 2.5658, 1.5301, 2.1865, 1.6270, 1.8290, 2.2078,\n",
      "        2.6696, 2.2498, 1.8030, 2.1894, 2.3468, 1.7680, 2.2242, 1.9801, 2.4021,\n",
      "        2.6702, 2.8821, 2.8103, 1.7367, 1.7840, 2.7143, 2.0588, 2.1039, 1.4793,\n",
      "        2.3198, 1.7516, 1.6068, 3.3329, 2.8838, 2.2007, 2.6359, 2.2944, 1.4743,\n",
      "        4.7057, 1.2779, 1.6847, 2.8183, 1.7077, 2.4179, 0.6769, 2.8050, 2.6300,\n",
      "        1.6188, 1.9959, 1.3267, 1.9532, 2.4336, 1.4520, 1.7735, 2.3662, 1.4285,\n",
      "        1.6844, 3.7941, 1.6070, 1.8211, 1.7839, 0.8087, 2.9441, 2.8830, 2.1188,\n",
      "        2.2922, 1.3849, 1.1835, 1.8011, 2.0171, 2.0599, 1.9230, 2.3073, 2.2823,\n",
      "        2.2196, 2.1270, 2.0582, 2.4802, 1.9053, 1.8676, 1.9032, 1.8502, 2.5834,\n",
      "        1.4722, 3.4655, 2.2381, 1.8782, 2.0647, 2.2968, 2.0850, 1.8610, 2.5684,\n",
      "        2.5906, 1.9841, 2.6740, 1.4404, 1.6930, 1.7989, 1.7478, 2.1159, 1.9067,\n",
      "        1.9951, 1.6172, 1.7641, 2.4866, 2.0190, 1.2287, 1.6630, 1.8753, 1.7355,\n",
      "        2.4744, 3.4971], device='cuda:0')), ('backbone.model.layer2.3.bn1.bias', tensor([-0.2175, -0.1410,  0.2103, -1.8191, -0.6176, -1.8859,  0.0376,  0.2678,\n",
      "         0.9710, -2.0555, -0.4539, -2.4380,  0.3451,  0.6392, -1.8881, -0.4723,\n",
      "         1.1293, -3.9236,  0.5846, -0.6995, -1.2219,  0.0094,  0.9074, -3.1203,\n",
      "        -0.4553, -0.7191,  0.2639,  0.7852, -2.2556, -0.7041, -0.9777, -2.8155,\n",
      "         1.6122, -1.9459, -0.0943, -2.2412,  1.6138, -0.1749, -1.9090, -1.3190,\n",
      "        -2.7071, -0.1883,  0.0503, -0.0227, -1.2146, -1.2171, -0.6901,  1.2852,\n",
      "         1.5627,  0.7523, -2.5152, -0.4427, -1.9648,  0.2043, -2.1295, -1.0958,\n",
      "         0.2887, -2.8814, -0.3937,  0.3605,  0.0809, -5.6805, -4.3974, -1.1320,\n",
      "        -0.4527, -1.2320, -0.4115,  0.4159,  0.9477, -1.8042, -2.9002,  1.3321,\n",
      "        -0.7937, -2.9179,  0.1239, -0.9257, -0.0442, -1.8806, -1.9009, -1.0796,\n",
      "        -2.4138, -0.8840, -0.0690,  0.9192, -1.8706, -1.3127, -0.5155,  1.7244,\n",
      "         1.0018, -0.4730, -2.7697,  0.0331, -0.0634, -0.2792, -2.2881,  1.1930,\n",
      "         0.5477,  0.1176, -4.9398, -0.1859, -1.1381, -1.6101,  0.3075, -1.4548,\n",
      "        -2.1860, -1.5336,  0.2797,  1.3492, -2.7043,  0.6155,  0.2910, -0.3491,\n",
      "         1.1703,  0.2075, -0.3598, -1.1892, -1.3321, -0.3077, -0.9411, -0.3844,\n",
      "        -0.7089, -1.3520,  0.6115, -1.4380,  1.5359, -1.9564, -0.7221, -0.6796],\n",
      "       device='cuda:0')), ('backbone.model.layer2.3.conv2.weight', tensor([[[[ 1.1427e-02, -6.7076e-02,  1.7370e-02],\n",
      "          [ 2.2245e-02,  2.2217e-02,  2.9655e-02],\n",
      "          [ 2.3897e-02, -6.0134e-02, -4.9463e-03]],\n",
      "\n",
      "         [[ 4.0253e-02,  7.0585e-02, -2.0271e-02],\n",
      "          [-4.3750e-03,  1.6787e-01,  1.3973e-03],\n",
      "          [-1.4949e-02,  4.5996e-02,  1.0137e-02]],\n",
      "\n",
      "         [[ 6.1529e-02, -4.0182e-02, -4.1348e-02],\n",
      "          [ 8.6703e-02, -4.5270e-02, -8.7461e-02],\n",
      "          [ 4.6815e-02,  3.3868e-02,  1.2742e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1486e-02, -5.5195e-02, -4.9737e-02],\n",
      "          [ 4.5743e-02, -1.9695e-02, -1.3098e-01],\n",
      "          [ 6.4697e-02,  2.3231e-02, -5.6115e-02]],\n",
      "\n",
      "         [[-1.0495e-02,  8.9052e-02, -7.7461e-02],\n",
      "          [-6.4816e-03,  9.5931e-02, -1.2489e-02],\n",
      "          [ 6.7890e-05,  6.8347e-02, -1.6424e-02]],\n",
      "\n",
      "         [[-1.5447e-02,  2.0509e-02,  1.4870e-02],\n",
      "          [-6.5631e-04,  2.9518e-02,  4.4989e-02],\n",
      "          [-3.4970e-02, -1.5307e-02, -2.1034e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8936e-03, -1.6246e-03, -1.7904e-02],\n",
      "          [-2.7907e-02, -5.9859e-02, -1.9867e-02],\n",
      "          [-1.5280e-02, -3.6888e-02, -5.3823e-03]],\n",
      "\n",
      "         [[ 7.2002e-03, -1.2090e-02,  2.3013e-02],\n",
      "          [ 3.1492e-02, -3.8068e-02,  1.6500e-02],\n",
      "          [ 4.4727e-02, -1.1728e-02,  5.0263e-02]],\n",
      "\n",
      "         [[-3.8438e-02, -4.1569e-03,  7.9764e-02],\n",
      "          [ 9.8878e-03,  1.5087e-02,  3.7444e-02],\n",
      "          [ 6.5027e-02,  2.6889e-02,  1.3076e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9181e-02, -3.5646e-02, -6.2300e-02],\n",
      "          [ 4.7427e-02, -1.7139e-02, -1.8297e-02],\n",
      "          [ 6.1461e-02,  2.7680e-02,  1.2661e-02]],\n",
      "\n",
      "         [[-4.3361e-02, -5.6541e-02,  1.2083e-02],\n",
      "          [-1.2630e-02, -5.3582e-02,  2.1885e-02],\n",
      "          [-2.2714e-02, -4.6463e-02, -3.8505e-03]],\n",
      "\n",
      "         [[-1.1076e-02,  2.0971e-03, -5.7394e-03],\n",
      "          [-1.0688e-02,  9.1333e-04,  1.5980e-02],\n",
      "          [-3.7414e-03,  2.5449e-02,  4.7309e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6329e-02,  2.6720e-02, -2.8752e-02],\n",
      "          [-4.1491e-02, -4.8799e-03, -5.0840e-02],\n",
      "          [-4.2526e-02,  1.3796e-03, -2.5517e-02]],\n",
      "\n",
      "         [[ 1.4862e-02,  2.2865e-02,  1.3827e-02],\n",
      "          [ 3.1606e-02,  8.6311e-02,  2.0593e-02],\n",
      "          [ 2.3899e-02, -3.0004e-03, -7.1238e-03]],\n",
      "\n",
      "         [[ 2.4462e-02,  4.8369e-03,  1.9657e-03],\n",
      "          [-6.2982e-03, -3.0429e-02,  1.6307e-02],\n",
      "          [-3.5398e-02, -2.6175e-03,  4.9476e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1973e-02, -2.9184e-02, -6.6564e-03],\n",
      "          [ 6.0660e-04,  1.4431e-03,  3.5108e-02],\n",
      "          [ 1.1198e-02,  5.5122e-03,  5.4988e-02]],\n",
      "\n",
      "         [[ 1.8184e-03,  4.8830e-02,  4.8523e-02],\n",
      "          [-3.7605e-02,  1.6713e-02, -7.9722e-03],\n",
      "          [-1.7204e-02,  5.0038e-03, -1.5581e-02]],\n",
      "\n",
      "         [[ 7.7825e-03,  7.4771e-03, -6.2076e-03],\n",
      "          [ 3.7002e-03,  2.6140e-02,  1.2999e-02],\n",
      "          [-1.2169e-02, -1.0044e-02, -1.6803e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.6043e-02,  8.4767e-02,  2.3667e-02],\n",
      "          [-4.4055e-02, -2.5298e-01, -1.3680e-02],\n",
      "          [-2.3762e-02, -9.0293e-03,  4.2188e-02]],\n",
      "\n",
      "         [[-6.5245e-02, -1.1241e-01, -8.8372e-02],\n",
      "          [-2.7429e-02,  1.3535e-01, -4.2949e-02],\n",
      "          [-8.7624e-02, -6.1948e-02, -9.1809e-02]],\n",
      "\n",
      "         [[-1.2551e-02, -6.7373e-02, -1.5221e-02],\n",
      "          [ 7.5013e-02, -3.1797e-03, -1.7925e-02],\n",
      "          [ 3.6378e-02,  1.0535e-02, -7.2830e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2017e-02,  2.6587e-02, -6.0070e-04],\n",
      "          [-2.1537e-02,  5.9976e-02,  5.2686e-02],\n",
      "          [-1.1711e-02, -1.6165e-02,  4.6500e-02]],\n",
      "\n",
      "         [[ 8.3580e-02,  1.2803e-01,  1.1755e-01],\n",
      "          [ 5.7101e-03, -8.5015e-02,  8.9248e-02],\n",
      "          [ 8.8390e-02,  1.8534e-01,  1.1651e-01]],\n",
      "\n",
      "         [[ 2.8083e-02,  3.6117e-02, -3.3773e-02],\n",
      "          [ 5.5596e-02, -1.1165e-02, -5.3525e-02],\n",
      "          [-2.0877e-02,  1.5204e-02, -7.1408e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6881e-02,  5.5649e-02, -1.4510e-03],\n",
      "          [ 5.3952e-02, -7.9618e-02,  5.4977e-02],\n",
      "          [ 7.0217e-02,  1.0690e-01,  6.8987e-02]],\n",
      "\n",
      "         [[ 1.5700e-02,  2.1718e-03,  1.3118e-02],\n",
      "          [-1.5827e-02,  4.6924e-02,  1.7490e-02],\n",
      "          [ 6.3182e-03,  9.3197e-02,  1.3747e-02]],\n",
      "\n",
      "         [[ 3.6119e-02,  9.2193e-02,  9.5079e-02],\n",
      "          [ 1.6545e-01, -7.4675e-02,  8.4281e-02],\n",
      "          [ 1.1876e-01,  1.4606e-01,  2.2443e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3107e-01, -9.2410e-02, -3.8463e-02],\n",
      "          [-1.0427e-01, -2.5349e-02,  3.0748e-02],\n",
      "          [ 1.0266e-01,  6.9203e-03,  1.6390e-02]],\n",
      "\n",
      "         [[ 2.5365e-02, -1.0747e-03,  1.1038e-02],\n",
      "          [ 3.2864e-02, -8.8452e-02,  1.8762e-03],\n",
      "          [ 2.6643e-02, -1.8603e-02, -4.3254e-02]],\n",
      "\n",
      "         [[ 2.7194e-02,  1.1043e-02, -7.5994e-02],\n",
      "          [-1.8912e-02,  6.2102e-02, -1.4584e-02],\n",
      "          [-8.3947e-02, -6.4752e-03,  6.3529e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3037e-02, -9.3480e-03, -2.8921e-02],\n",
      "          [ 1.0964e-03, -5.9702e-02,  4.3296e-02],\n",
      "          [-2.1851e-02, -1.9015e-02, -1.6419e-02]],\n",
      "\n",
      "         [[ 4.6271e-04, -1.5532e-02,  1.5513e-02],\n",
      "          [-4.7129e-02, -6.9391e-03, -2.9038e-02],\n",
      "          [-1.0644e-02, -4.3069e-02,  1.4477e-02]],\n",
      "\n",
      "         [[ 2.1743e-03, -2.8934e-02, -1.0375e-01],\n",
      "          [ 7.3973e-02,  7.2373e-02, -9.2731e-02],\n",
      "          [-1.3718e-02,  4.8270e-02, -2.2242e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7660e-02,  9.4762e-03,  2.0076e-02],\n",
      "          [-4.5980e-03, -6.2027e-02, -5.6482e-02],\n",
      "          [ 2.2770e-02, -4.6314e-02, -8.1293e-02]],\n",
      "\n",
      "         [[ 2.6767e-02,  3.7439e-02, -1.7815e-02],\n",
      "          [ 1.5619e-03, -1.8415e-02, -3.9672e-02],\n",
      "          [-6.7121e-03, -2.8206e-02,  1.0577e-02]],\n",
      "\n",
      "         [[-1.6349e-03,  2.0421e-02, -2.3470e-02],\n",
      "          [-6.0596e-03,  9.4141e-03, -3.4885e-02],\n",
      "          [-3.3662e-02,  1.2831e-02,  1.1888e-02]]]], device='cuda:0')), ('backbone.model.layer2.3.bn2.weight', tensor([5.6973, 1.4595, 4.9349, 0.9037, 1.8089, 2.2966, 1.6035, 1.4311, 1.9212,\n",
      "        2.3541, 1.6359, 2.3673, 1.7614, 2.0006, 2.4492, 2.1449, 1.9942, 3.3423,\n",
      "        2.0320, 1.8560, 2.2645, 2.6611, 2.8884, 2.5297, 1.9502, 1.7748, 1.5308,\n",
      "        1.8790, 2.2449, 1.6429, 2.1567, 2.7782, 1.9212, 1.4536, 1.9646, 1.7024,\n",
      "        2.2376, 3.3123, 3.6080, 3.3567, 1.9995, 2.0012, 2.5472, 1.6632, 2.9029,\n",
      "        2.3859, 2.3126, 2.1615, 1.8135, 1.5382, 1.6492, 1.6071, 1.5610, 2.3820,\n",
      "        1.8358, 2.5951, 2.0943, 1.3812, 2.1657, 2.7511, 1.1433, 1.6891, 1.2060,\n",
      "        2.0534, 2.3314, 1.5009, 1.5339, 2.4177, 2.3173, 2.0321, 1.9600, 2.6468,\n",
      "        2.3410, 1.7522, 2.3572, 1.8445, 3.3686, 6.7940, 3.4588, 2.4813, 1.5082,\n",
      "        1.9451, 1.3924, 1.1392, 4.8822, 1.7821, 1.6086, 2.1699, 1.9579, 3.1126,\n",
      "        2.1522, 1.7614, 2.0615, 2.3754, 1.6669, 2.3752, 1.9068, 2.5200, 2.7019,\n",
      "        1.6936, 2.3574, 2.7168, 1.6967, 2.3914, 2.8423, 1.2903, 2.1509, 1.9346,\n",
      "        2.7823, 1.9584, 1.6940, 1.8365, 1.7942, 2.3304, 1.9005, 2.6611, 2.5722,\n",
      "        3.6369, 1.3871, 2.6636, 1.2618, 2.1588, 1.6951, 1.4474, 1.7397, 1.2142,\n",
      "        1.3627, 1.8978], device='cuda:0')), ('backbone.model.layer2.3.bn2.bias', tensor([-1.2953, -1.0587, -3.7921,  0.7452, -0.4832,  0.0544, -0.9491,  1.2543,\n",
      "        -0.0943, -2.5885,  1.1547, -0.5674, -2.3448,  0.6461,  0.1568, -0.1771,\n",
      "         1.4691, -0.8383, -0.6757, -0.9115, -1.1751,  1.0095, -1.7023, -0.2988,\n",
      "        -0.4014,  0.2940,  0.0917, -1.6943,  1.2027, -1.4499, -0.4716, -0.4812,\n",
      "        -1.0946,  0.5865, -0.9406,  0.3156, -1.8390,  1.5232, -1.6613,  1.0459,\n",
      "        -0.6680,  1.6317, -0.0367, -1.7253, -0.1689, -2.6954,  0.6930, -1.5351,\n",
      "        -1.4601, -0.0385, -0.7783,  0.1553,  0.9965, -3.7415,  0.0958, -0.5914,\n",
      "         1.1690,  0.5166, -1.3872, -2.4223,  0.3925, -0.1606,  0.5775, -2.1815,\n",
      "        -0.9498,  0.5056,  1.1586, -3.5100,  0.3422, -0.9083,  0.9102, -2.4963,\n",
      "        -0.3403, -1.7312,  0.0954, -0.1505, -0.1330, -1.0747, -0.1111, -3.8868,\n",
      "        -0.3602, -1.4243,  0.5525,  0.4478,  2.3460, -1.7992,  0.8209, -0.5945,\n",
      "        -1.4645, -1.0956,  1.7941,  0.3732, -0.2824,  0.0540, -1.1420,  0.4216,\n",
      "        -0.5868, -0.3998, -3.0720,  1.5097,  0.5402, -3.5326, -0.0371, -1.4277,\n",
      "        -2.2384, -0.0521, -1.7322, -0.4089, -1.2765, -1.1429,  0.1264,  1.1980,\n",
      "        -1.2850, -0.1435, -0.4353,  1.9006, -2.7378,  0.3209, -0.6855, -1.0223,\n",
      "         0.0096, -2.5517,  0.1829, -0.3753,  0.5695,  0.6817, -0.8821,  0.4595],\n",
      "       device='cuda:0')), ('backbone.model.layer2.3.conv3.weight', tensor([[[[-0.0281]],\n",
      "\n",
      "         [[-0.0247]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0617]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.0028]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0155]],\n",
      "\n",
      "         [[ 0.0293]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.0880]],\n",
      "\n",
      "         [[-0.0391]]],\n",
      "\n",
      "\n",
      "        [[[-0.0214]],\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         [[-0.0471]],\n",
      "\n",
      "         [[ 0.0113]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0194]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[-0.0268]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0098]],\n",
      "\n",
      "         [[ 0.0054]],\n",
      "\n",
      "         [[-0.0139]]],\n",
      "\n",
      "\n",
      "        [[[-0.0022]],\n",
      "\n",
      "         [[-0.0232]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0447]],\n",
      "\n",
      "         [[-0.0735]],\n",
      "\n",
      "         [[-0.0432]]],\n",
      "\n",
      "\n",
      "        [[[-0.0984]],\n",
      "\n",
      "         [[-0.0169]],\n",
      "\n",
      "         [[ 0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0097]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0900]]]], device='cuda:0')), ('backbone.model.layer2.3.bn3.weight', tensor([ 2.2927e+00, -5.5295e-01,  4.1106e+00, -1.1403e+00,  5.8369e-01,\n",
      "        -6.7262e-01,  3.0167e+00, -1.3787e+00, -1.3556e+00,  2.5492e+00,\n",
      "         3.2538e-02,  4.0289e+00, -5.2314e+00, -3.7278e-01,  8.5332e-01,\n",
      "        -4.0987e-01,  3.4347e+00, -4.1894e+00, -5.3795e+00,  5.0132e-01,\n",
      "         8.9160e-01,  1.2794e+00, -8.0445e-01, -1.2094e-01,  2.0856e+00,\n",
      "        -6.3076e+00, -2.8567e+00, -2.6939e-01, -2.6804e+00, -2.7558e+00,\n",
      "         2.6487e+00,  7.9964e-01, -1.6141e+00, -3.0181e+00, -1.3071e+00,\n",
      "        -1.2200e+00,  3.9826e+00, -7.4884e-01,  3.1953e+00, -8.7915e-01,\n",
      "        -3.0102e+00, -1.6233e-01,  2.0131e+00,  7.3057e-01, -4.2768e-01,\n",
      "        -3.7504e+00, -1.1230e+00,  4.0228e+00, -4.3535e+00,  2.8373e-01,\n",
      "        -5.2134e-01,  2.1783e+00, -1.9359e+00,  2.3349e+00,  6.3065e-02,\n",
      "         6.6062e-02,  4.7911e-01, -1.3536e+00,  3.2902e+00,  7.4484e-01,\n",
      "         1.3009e-01, -3.1081e+00, -3.2290e+00, -2.0881e+00, -3.4023e+00,\n",
      "        -2.0654e-01, -2.4660e-01, -9.8869e-01,  7.1386e-01, -1.5823e+00,\n",
      "         4.5318e+00, -4.3781e+00, -2.6921e+00,  1.5390e+00,  7.8984e-01,\n",
      "         2.2337e+00,  8.9214e-01, -3.8941e+00,  1.5497e-01,  6.0471e-01,\n",
      "        -1.7901e+00,  5.9305e-01, -1.3472e+00,  2.3799e-01,  8.6442e-01,\n",
      "         8.1712e-01,  2.0358e-02,  1.3318e-01,  6.7488e-01,  8.4175e-02,\n",
      "        -3.1942e-01, -7.1012e-03, -3.0176e+00,  3.9333e-01, -5.6605e+00,\n",
      "         1.4414e-01, -2.7497e+00,  5.7301e+00,  2.0586e+00,  3.4745e-01,\n",
      "         7.8385e-01, -1.0170e+00,  1.4807e+00,  4.8993e-01,  2.2015e+00,\n",
      "         9.7875e-01, -1.0772e+00, -1.6635e+00,  2.7052e+00, -1.2283e+00,\n",
      "        -1.1434e+00, -7.2135e-01, -1.9328e-01, -3.1013e+00,  1.3661e+00,\n",
      "        -2.7626e+00,  3.2617e-01,  1.0344e+00,  3.5256e+00, -4.0763e-01,\n",
      "         2.9410e+00, -4.2463e+00, -9.9652e-01, -3.8094e+00, -3.4270e+00,\n",
      "         1.1271e+00,  6.6557e+00, -1.2726e+00,  1.9917e+00,  4.0288e+00,\n",
      "        -2.8014e+00,  6.0342e-01, -2.4550e+00,  1.4020e-01, -2.7235e-01,\n",
      "         1.3243e+00,  1.4789e+00, -1.3457e+00,  9.8213e-01,  1.1031e+00,\n",
      "         6.9948e-01, -2.2557e+00,  3.0210e+00,  6.4807e-01, -2.4604e+00,\n",
      "         4.0090e+00, -3.5734e+00,  1.2867e+00, -1.5050e+00,  9.4281e-01,\n",
      "         2.9258e+00, -1.4646e+01, -3.5509e+00,  6.2393e-01,  2.6792e-01,\n",
      "         2.6767e+00,  4.4661e+00,  1.1501e+00,  1.2894e+00, -6.9733e+00,\n",
      "        -3.2658e+00, -9.2315e-01, -3.5704e+00,  2.5478e+00, -2.4941e+00,\n",
      "         3.2731e+00,  1.2887e+01,  3.2975e+00, -3.7774e+00, -4.5900e+00,\n",
      "        -8.6994e-01, -3.6574e+00,  1.1341e+00,  6.3948e-01,  1.7116e-01,\n",
      "         2.9143e-01, -1.3354e+00, -3.7943e+00,  3.3736e+00,  2.7110e-01,\n",
      "         9.8864e+00, -2.4562e+00,  3.4327e-03,  1.5123e-01, -7.1238e-01,\n",
      "         2.3684e+00,  5.7193e-01, -5.1689e+00,  6.6295e-01, -2.9558e-01,\n",
      "        -7.2844e-01, -5.7924e-01, -7.1731e-01, -5.2042e+00,  2.0453e+00,\n",
      "        -2.5157e+00,  6.7824e-01,  6.2773e-01,  1.1476e+00,  4.6714e+00,\n",
      "         6.2701e-01, -7.2237e-01, -2.2064e+00, -9.5020e-01,  8.6185e-01,\n",
      "         9.1053e-01,  7.1237e-01, -7.9342e-01,  2.6614e+00, -4.7029e+00,\n",
      "        -1.3849e+00,  7.0132e-01, -4.9001e-01, -2.5490e+00,  9.1642e-01,\n",
      "         2.9017e+00,  1.2722e-01,  2.7467e-01,  8.4825e-02,  7.2161e-02,\n",
      "        -4.0466e-02,  4.1050e-01,  5.3114e-01, -9.0114e-01, -2.4406e+00,\n",
      "         3.2452e+00, -9.4014e-01, -1.3089e+00,  1.8514e+00, -4.0290e-01,\n",
      "         4.4284e-01,  5.7300e-01, -1.4073e+00,  1.4120e+00,  4.0084e+00,\n",
      "         3.5247e+00, -1.5722e+00, -2.4262e+00,  8.0949e-01, -2.6947e+00,\n",
      "        -2.0613e+00, -7.6062e-01,  3.9328e+00,  3.7505e+00,  4.7395e+00,\n",
      "        -4.4148e-01, -1.3903e+00,  1.7682e+00,  1.3394e+00, -2.4875e-01,\n",
      "        -6.3461e-01,  2.8475e-01, -2.0638e-01, -1.4211e-01, -2.2422e+00,\n",
      "         4.2504e+00,  3.6237e+00, -5.6466e-02,  4.2098e-01, -7.2320e-01,\n",
      "         1.6703e+00, -1.6941e+00, -3.2140e+00,  2.1435e+00,  5.7353e-01,\n",
      "        -5.6573e-01,  3.8169e+00,  6.9602e-01, -8.3875e-01, -1.8848e+00,\n",
      "        -3.8755e+00,  2.9534e+00,  1.7095e+00, -5.5336e-01,  6.6646e-01,\n",
      "         1.8545e+00, -2.6635e+00,  8.4705e-01,  5.3516e+00, -4.7362e+00,\n",
      "        -1.4686e+00,  1.7414e+00,  9.6873e-01,  2.4739e-01,  2.2414e+00,\n",
      "        -4.1505e-01, -3.2386e-01, -2.8511e+00,  2.8217e+00, -3.7207e+00,\n",
      "         1.8759e+00,  2.0473e+00, -2.1271e+01, -7.4784e-01,  1.5277e+00,\n",
      "        -5.7215e-01, -5.1360e-02,  2.6538e+00, -4.4615e-01,  1.5374e+00,\n",
      "         1.3638e-01,  3.2596e-02,  4.8267e-01, -1.3587e+00,  2.3905e-01,\n",
      "         2.3418e-01, -1.0297e+00,  2.1510e-01,  1.5953e+00,  7.6661e-01,\n",
      "        -2.6410e+00,  1.8695e+00, -3.3138e+00,  9.8879e-01,  2.3075e-01,\n",
      "        -3.1905e+00,  5.6811e+00, -1.5484e-01, -5.8313e-01, -9.4209e-01,\n",
      "         1.8496e-01,  8.7639e-01,  1.1923e+00,  8.4373e-01, -4.4820e+00,\n",
      "         3.1975e+00,  5.7185e-01, -3.4355e+00,  3.0476e-01, -2.3871e+00,\n",
      "         1.4392e+00, -1.4746e+00, -1.6787e+00,  3.1563e-01, -5.2009e+00,\n",
      "        -1.1148e+00, -1.0094e+00,  1.0074e+00, -4.1230e+00,  3.5337e-01,\n",
      "         3.1993e-01, -1.1622e+00,  2.1106e+00, -2.6958e+00, -3.0786e+00,\n",
      "         4.6101e+00, -7.6235e-01,  3.4846e+00,  1.5695e+00, -3.1331e+00,\n",
      "         1.2256e+00, -1.2253e+00,  9.4020e-01, -1.8511e+00, -1.3410e+00,\n",
      "         3.5697e-01, -4.2734e+00,  1.9833e-01,  6.8816e-01,  4.3025e-01,\n",
      "         5.4613e-01, -3.6649e-01, -1.1256e+00,  1.5127e+00,  1.0242e+00,\n",
      "        -2.3281e+00,  6.3451e+00, -2.9085e+00, -2.3424e+00, -4.2955e+00,\n",
      "         4.4402e+00, -7.5300e+00, -9.4642e-03,  5.2915e-01,  2.0121e+00,\n",
      "         1.7771e+00, -4.2852e+00, -2.6419e-01, -3.1109e-01,  5.2036e-02,\n",
      "         3.5042e+00, -1.0156e+00, -3.1234e+00,  8.9994e-01, -3.4373e+00,\n",
      "         2.5550e-01, -6.1075e-01,  5.3215e-01,  3.8835e+00,  2.7312e+00,\n",
      "         7.2414e-01,  7.8963e-01, -3.8255e+00, -3.8673e+00, -5.6314e-01,\n",
      "         5.0995e-02,  4.4518e+00, -6.5897e-01,  1.9413e-01,  4.0701e-01,\n",
      "         1.1652e+00,  1.0885e+00, -1.5204e+00,  8.5320e-01, -1.2456e+00,\n",
      "        -2.7138e+00, -1.9499e+00, -5.6929e-01, -3.2834e+00,  1.7798e-01,\n",
      "        -6.5918e+00, -2.7645e-01,  9.7011e-01,  2.7065e-01, -4.2888e+00,\n",
      "         2.3529e+00,  1.2300e+00,  9.3503e-01, -1.4064e+00, -8.0939e-03,\n",
      "         1.1155e+00, -4.1198e+00,  3.4273e+00, -3.4874e+00, -2.2112e-01,\n",
      "         1.7395e+00, -2.8007e+00, -2.6474e+00,  1.5153e+00, -4.3003e+00,\n",
      "        -4.5206e+00,  3.7533e+00,  2.3572e+00, -8.1211e-01,  2.6653e-02,\n",
      "        -7.7604e-01,  1.4721e+00,  1.0953e-01, -5.1864e+00, -4.8470e-01,\n",
      "        -1.0950e+00, -7.3751e-01, -3.3045e-04, -3.5832e-03, -3.3688e+00,\n",
      "         3.7470e+00,  2.0473e-01,  7.1799e-01,  5.1716e-01,  5.9023e-01,\n",
      "        -3.5424e+00, -3.0251e+00, -5.1387e-01, -3.5028e+00,  2.1799e+00,\n",
      "        -3.3429e+00,  8.1119e-01, -1.0870e-01,  1.4751e+01,  3.6766e-01,\n",
      "        -9.8958e-01,  7.4331e-01,  2.8997e+00,  3.5030e+00,  1.3648e+00,\n",
      "        -6.9605e+00, -7.7395e-01,  1.4039e+00,  6.2684e-02,  8.8519e-02,\n",
      "        -1.7427e+00,  3.8455e+00,  3.3453e+00,  4.7943e+00, -2.0955e+00,\n",
      "        -5.0259e+00,  2.9736e+00, -1.0166e+00, -1.0885e+00,  2.2754e+00,\n",
      "        -1.6291e-02,  3.2005e+00,  8.1461e-03,  1.4042e+00, -2.2449e-01,\n",
      "        -2.9871e-01,  4.3792e-01, -5.6949e-02, -8.9813e-01, -1.5550e-02,\n",
      "        -8.9971e-02,  3.0064e-01,  1.7684e+00, -6.5002e-01, -1.9918e+00,\n",
      "         1.9316e-01, -4.9817e-01,  3.5463e+00, -3.8782e+00, -9.4149e-01,\n",
      "         4.0489e+00, -1.9577e+00,  2.1727e+00, -1.4189e+00,  1.7378e-03,\n",
      "         8.6178e-01, -3.2682e+00, -3.3703e+00,  8.7049e-01,  3.4826e+00,\n",
      "        -2.0825e+00,  1.1424e+00], device='cuda:0')), ('backbone.model.layer2.3.bn3.bias', tensor([-1.0450e-01, -7.6160e-02, -2.4103e-01, -8.1215e-01, -3.2384e-01,\n",
      "        -8.8076e-03, -1.4549e-01, -3.4506e-01, -6.9065e-01,  2.6746e-01,\n",
      "        -8.1530e-04,  9.8053e-01, -2.0066e+00, -3.2920e-01, -1.6361e+00,\n",
      "        -1.4268e-01, -1.5971e+00, -3.6274e-01, -4.8698e-01, -3.2348e-01,\n",
      "        -5.4906e-01, -2.8163e-01, -6.6505e-01, -5.5429e-02, -4.8057e-01,\n",
      "        -5.0277e-01, -1.3001e+00, -2.8641e-01, -9.1332e-01,  5.7959e-01,\n",
      "         1.8871e-01, -1.0905e-01, -1.0253e+00, -1.1831e+00, -1.1819e+00,\n",
      "        -1.5434e+00, -2.0826e-02, -6.7558e-01,  1.0438e+00, -8.5010e-01,\n",
      "        -4.6085e-01, -9.2286e-02,  1.8049e+00, -4.1934e-01, -6.1816e-01,\n",
      "        -8.8657e-01, -1.0008e+00, -1.5802e+00, -1.5935e+00, -3.6120e-01,\n",
      "        -3.2281e-01, -6.5347e-01, -2.0796e-01, -7.7272e-01, -6.5494e-02,\n",
      "         3.1228e-02, -3.6723e-01, -3.7492e-01, -6.4306e-02, -2.9623e-01,\n",
      "        -2.0829e-01, -4.1095e-01, -3.3032e+00, -1.1320e+00, -1.5989e-01,\n",
      "        -8.8040e-02, -1.1467e-01, -5.7700e-01, -2.3180e-01, -1.0060e+00,\n",
      "        -5.2398e-01, -2.7931e-01,  6.8891e-01, -5.4718e-01, -1.2137e-01,\n",
      "        -1.8889e-01, -6.8811e-01, -6.2632e-01, -7.5173e-01, -2.3684e-01,\n",
      "        -1.9077e+00, -5.6958e-01, -1.9314e+00, -2.1946e-01, -1.2248e+00,\n",
      "        -2.1364e-01, -1.3299e-01, -7.8088e-02, -6.7441e-01, -1.3692e-01,\n",
      "        -9.3645e-01, -2.6344e-02, -2.3033e+00, -6.4290e-01, -5.5240e+00,\n",
      "        -2.7014e-01, -8.1828e-02, -9.2518e-01, -1.2424e-01, -2.3025e-01,\n",
      "        -1.0382e+00, -2.7288e-01,  6.2430e-02, -6.0154e-01, -9.1322e-01,\n",
      "        -2.7134e-01, -4.7766e-01, -7.7186e-01, -6.9872e-01,  1.0903e-01,\n",
      "        -1.4373e-01, -5.2305e-01, -5.6118e-02, -6.6929e-01, -7.8047e-01,\n",
      "         6.6026e-01, -2.9190e-01, -1.5699e-01, -1.9145e-01, -3.6929e-01,\n",
      "        -1.1630e+00, -1.7069e+00, -8.3355e-01, -6.8265e-02, -2.2510e+00,\n",
      "        -2.2098e-01,  1.1297e+00, -2.5653e-01, -9.0567e-01, -6.4318e-01,\n",
      "        -1.8282e+00, -4.7045e-01,  1.2361e-01, -9.1059e-02, -2.0660e-01,\n",
      "         4.7020e-02, -8.9220e-01,  9.3902e-02, -7.6539e-01, -9.5716e-01,\n",
      "        -4.3028e-01, -3.8260e+00,  7.9352e-02, -1.2131e-01,  7.0425e-02,\n",
      "        -6.6731e-01, -2.6524e+00, -4.6433e-01, -3.2448e-01, -5.7473e-01,\n",
      "        -9.0223e-01, -7.3552e-01, -4.5722e+00, -4.0272e-01, -2.1088e-01,\n",
      "        -4.9074e-01,  2.1114e+00, -6.4359e-01, -4.3209e-01,  1.0546e+00,\n",
      "        -1.5274e+00, -5.5943e-01, -2.7365e-01, -2.7012e+00, -5.5060e-01,\n",
      "         5.9692e-01,  1.8774e+00, -1.2696e+00, -2.1099e+00, -8.6836e-01,\n",
      "        -8.7138e-01, -1.6356e+00, -2.2511e-01, -6.3496e-03, -3.6212e-01,\n",
      "        -3.3056e-01, -1.1485e+00, -7.3922e-01,  2.6376e-01, -5.5623e-02,\n",
      "         2.9164e+00, -9.7618e-02, -2.5021e-02, -8.1503e-02, -1.3872e-01,\n",
      "        -2.8739e-01, -4.3879e-01,  1.9088e+00, -3.1627e-01, -2.1298e-01,\n",
      "        -2.7152e-01, -1.5386e-01,  3.7772e-02, -4.4823e-01, -1.4829e+00,\n",
      "         1.6676e-01, -6.0110e-01, -4.4781e-01, -3.8255e-01, -3.7508e+00,\n",
      "        -7.7940e-02, -6.3277e-01, -9.3857e-01, -1.0344e-01, -1.2868e+00,\n",
      "        -3.0703e-01, -3.6034e-01, -2.9668e-01, -2.1072e-01, -2.6887e+00,\n",
      "        -4.6215e-01, -5.3043e-01, -2.0962e-01,  1.0761e+00, -1.9667e-01,\n",
      "         4.6253e-01, -9.1583e-02, -2.4514e-01, -4.1616e-02, -4.9188e-02,\n",
      "        -4.6749e-02, -2.2969e-01, -1.2608e+00, -6.0472e-01, -1.1494e+00,\n",
      "        -1.2949e+00, -2.6886e-01, -6.6662e-01, -1.9119e-01, -3.7639e-01,\n",
      "        -9.3985e-01, -1.0123e-01, -3.7854e-01, -4.3852e-01, -1.0058e+00,\n",
      "        -3.2849e-01, -2.9001e-01, -2.0522e-01, -4.3721e-01, -6.1771e-01,\n",
      "        -7.1272e-01, -3.4168e-01, -7.4467e-02,  1.5250e-01, -1.5599e+00,\n",
      "        -1.9065e-01, -5.3051e-01, -1.0076e+00, -7.7971e-01, -4.5368e-01,\n",
      "        -8.4828e-01, -1.3967e-01,  1.7337e-02,  5.2293e-02, -5.6607e-01,\n",
      "        -4.6035e-01, -1.2137e-01, -1.0750e-02, -3.9210e-01, -1.6820e+00,\n",
      "        -1.0903e+00, -2.0608e-01,  5.2856e-01, -3.4192e-01, -5.6050e-01,\n",
      "        -4.0615e-01,  4.5338e-01, -4.2487e-01, -3.8196e-01, -4.4682e-01,\n",
      "         9.1157e-01, -1.7488e+00, -9.2518e-01, -5.5146e-01, -4.6396e-01,\n",
      "        -4.6214e-01, -6.5550e-02, -1.5281e+00, -9.3768e-01,  7.3433e-01,\n",
      "        -6.8716e-01, -1.1951e+00, -3.7638e-01, -2.9709e-01, -1.4884e+00,\n",
      "        -5.1852e-02, -5.7532e-01, -6.0385e-01, -1.5555e+00, -1.6274e+00,\n",
      "        -1.4593e+00, -3.6112e-01, -1.2803e+01, -9.4132e-01, -6.0722e-01,\n",
      "        -6.4438e-01, -8.5746e-02, -7.1017e-01, -3.1394e-01, -6.5053e-01,\n",
      "        -9.6207e-02, -1.0919e-01, -3.4669e-01, -6.7322e-01, -6.1149e-02,\n",
      "        -3.0211e-01, -5.5101e-01, -1.7456e-01, -7.5929e-01, -1.0390e+00,\n",
      "        -1.2856e+00, -8.9916e-01, -6.8450e-01, -8.8378e-01, -1.4509e-01,\n",
      "         9.6108e-01, -3.7589e+00, -8.0569e-01, -7.4971e-01, -6.9237e-01,\n",
      "        -7.7758e-01, -4.2677e-01, -9.6922e-01, -2.0572e-01, -1.0861e+00,\n",
      "        -9.6315e-01, -4.6512e-01, -1.5710e+00, -7.7069e-02, -2.2223e-01,\n",
      "         3.1690e-01, -2.5333e-01,  2.4276e-01, -2.3138e-01,  3.2271e-01,\n",
      "        -5.0731e-01, -3.5126e-01, -3.4376e-01, -1.1532e+00,  2.5084e-01,\n",
      "        -3.7508e-01,  2.8093e-01, -8.3613e-02,  5.4124e-01, -1.2397e+00,\n",
      "         2.3454e-01, -7.2127e-01, -6.7844e-02, -8.6274e-01,  9.4626e-01,\n",
      "         3.7880e-02, -5.0812e-01, -4.2201e-01, -5.3416e-01, -1.2338e-01,\n",
      "        -2.7846e-01, -2.1080e-02, -5.8903e-02, -4.6329e-01, -1.6272e-01,\n",
      "        -7.3813e-01, -3.4966e-01, -1.8098e-01, -4.8009e-01, -6.3279e-01,\n",
      "        -1.1229e+00,  3.5315e-02, -2.7369e-01, -1.0850e+00, -6.2442e-01,\n",
      "        -1.9613e+00, -1.2497e+00, -2.2761e-03, -3.4488e-01, -2.8392e-01,\n",
      "         5.7549e-03, -3.6429e-02,  4.1751e-02, -7.6363e-02, -7.5640e-03,\n",
      "        -2.5342e+00, -1.9131e+00, -1.5191e+00, -4.2478e-01,  8.9636e-01,\n",
      "        -3.7505e-03, -3.0907e-01, -4.0257e-01,  9.2930e-02, -1.2881e+00,\n",
      "        -5.0257e-01, -6.9435e-01, -6.7992e-01,  1.0386e+00, -2.0809e-01,\n",
      "        -7.7550e-02, -1.9842e+00, -1.2801e-01, -2.1842e-01, -4.7177e-01,\n",
      "        -3.1844e-01, -5.5747e-01, -3.4728e-01, -5.3484e-01, -8.6808e-01,\n",
      "         1.8829e-01, -8.2167e-01, -6.1256e+00, -1.8075e+00, -1.4063e-01,\n",
      "         1.1109e+00, -2.2181e-01, -4.4846e-01, -1.0413e-01, -1.2700e+00,\n",
      "        -8.7958e-01, -6.1455e-01, -2.6531e-01, -4.9000e-01, -8.8517e-03,\n",
      "        -5.6332e-01, -9.4647e-01,  7.3135e-02,  1.5795e+00, -1.9373e-01,\n",
      "        -1.7538e-01, -3.2860e-01,  2.4148e-01,  2.6699e-01,  5.2800e-01,\n",
      "         2.6873e-01, -4.4490e-01, -1.0285e+00, -6.5958e-01, -3.7464e-02,\n",
      "        -6.7504e-01, -1.0118e+00, -8.4557e-02, -1.5422e+00, -1.2366e+00,\n",
      "        -4.1008e-01, -3.7316e-01, -1.3764e-02, -1.6502e-02,  6.3490e-01,\n",
      "         4.3623e-01, -9.5499e-02, -8.2774e-01, -5.8855e-01, -3.2662e-01,\n",
      "        -6.6577e-01,  2.6557e-01, -5.6351e-01, -9.4349e-02, -3.5260e-01,\n",
      "        -4.3118e-01, -3.8161e-01, -4.3645e-02, -2.3791e+00, -5.3519e-01,\n",
      "        -5.5591e-01, -8.3301e-01, -1.6772e+00, -1.7523e+00, -1.2681e+00,\n",
      "        -7.8885e-01, -2.1193e-01, -6.3782e-01, -3.4354e-01,  7.4975e-04,\n",
      "        -1.3132e+00, -1.0781e+00, -9.5478e-01, -6.3118e-01, -5.8454e-01,\n",
      "        -8.2792e-01,  5.2473e-01, -1.0988e+00, -9.7936e-01, -5.1197e-01,\n",
      "         2.2269e-04, -4.9923e+00, -1.0161e-01, -1.2407e+00, -9.0680e-01,\n",
      "        -1.7663e-01, -4.5357e-01, -3.4322e-01, -6.5401e-01, -1.0824e+00,\n",
      "        -1.0917e-01, -1.6560e-01, -2.4170e+00, -3.9576e-01, -2.4489e+00,\n",
      "        -5.2399e-01, -1.4512e-01, -6.2009e-01, -7.1596e-01, -5.2846e-01,\n",
      "        -4.9967e-01, -1.2557e+00, -9.9176e-01, -3.7481e-01, -6.6773e-02,\n",
      "        -3.5419e-01, -1.0024e+00, -2.0498e+00,  6.5031e-02, -9.2537e-01,\n",
      "        -8.1080e-01, -1.4488e-01], device='cuda:0')), ('backbone.model.layer3.0.conv1.weight', tensor([[[[-0.0290]],\n",
      "\n",
      "         [[-0.3052]],\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1204]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[-0.0375]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0221]],\n",
      "\n",
      "         [[-0.1422]],\n",
      "\n",
      "         [[ 0.0219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0023]],\n",
      "\n",
      "         [[-0.0157]],\n",
      "\n",
      "         [[-0.1060]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0396]],\n",
      "\n",
      "         [[-0.0360]],\n",
      "\n",
      "         [[-0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[-0.0769]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0064]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[-0.0022]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[-0.0041]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0597]],\n",
      "\n",
      "         [[-0.0468]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0536]],\n",
      "\n",
      "         [[ 0.0099]],\n",
      "\n",
      "         [[ 0.0571]]],\n",
      "\n",
      "\n",
      "        [[[-0.0946]],\n",
      "\n",
      "         [[ 0.0367]],\n",
      "\n",
      "         [[-0.0448]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[-0.0938]],\n",
      "\n",
      "         [[ 0.0231]]]], device='cuda:0')), ('backbone.model.layer3.0.bn1.weight', tensor([1.3818, 2.4005, 1.9929, 1.7261, 2.0373, 1.5541, 2.0843, 2.0068, 1.6865,\n",
      "        1.6545, 1.3007, 1.7019, 1.8481, 1.8224, 2.0687, 1.2496, 1.9884, 2.1074,\n",
      "        2.3025, 2.4671, 1.4962, 1.6718, 1.6511, 2.7960, 1.7271, 1.6658, 1.2855,\n",
      "        2.3966, 1.9463, 1.5989, 1.9017, 1.7207, 1.7209, 2.3627, 1.8639, 1.5323,\n",
      "        1.7866, 1.7605, 1.1550, 2.2844, 1.3311, 1.6372, 1.4570, 1.4548, 2.1674,\n",
      "        1.8206, 2.2512, 2.2904, 1.7831, 1.8667, 1.1885, 2.0444, 1.6935, 1.8113,\n",
      "        1.4770, 1.4331, 1.3031, 1.8630, 2.2280, 1.8482, 1.7039, 2.2486, 2.3825,\n",
      "        1.5759, 1.5421, 2.3403, 1.5411, 2.5369, 2.0754, 2.5003, 1.6215, 2.7755,\n",
      "        1.8534, 1.6234, 1.8611, 2.0627, 2.1524, 2.3170, 2.1483, 1.4962, 1.6539,\n",
      "        1.9989, 1.6124, 1.5981, 1.5681, 1.6554, 1.5498, 1.4285, 1.5385, 3.1633,\n",
      "        1.8503, 1.3620, 2.9588, 2.6918, 0.7936, 1.5792, 1.7348, 1.7531, 1.3222,\n",
      "        2.1056, 2.1848, 1.2509, 1.7157, 1.6442, 1.9561, 2.4229, 1.9871, 1.7777,\n",
      "        2.0029, 3.5708, 0.8472, 3.0185, 1.6280, 1.8177, 2.3080, 1.6331, 2.6793,\n",
      "        1.9600, 1.9849, 1.6115, 2.2543, 1.9918, 1.4026, 1.3293, 1.8530, 1.5077,\n",
      "        1.9958, 1.6113, 2.1345, 1.9164, 1.4857, 1.3583, 1.4114, 1.5574, 1.5625,\n",
      "        2.6150, 1.7100, 1.9051, 1.9030, 1.1057, 1.2707, 1.3287, 1.3257, 1.3029,\n",
      "        1.7837, 2.0772, 2.7040, 1.9172, 2.2969, 1.5484, 1.4882, 1.3389, 3.0068,\n",
      "        1.6652, 1.5900, 1.8609, 2.2470, 1.8382, 1.7412, 2.0527, 1.4503, 1.3322,\n",
      "        3.2296, 1.5163, 1.3606, 1.9568, 1.6668, 2.2362, 1.6155, 1.4497, 1.8261,\n",
      "        1.8008, 2.2063, 1.8974, 1.3557, 1.9936, 1.9088, 1.4903, 1.5899, 2.5538,\n",
      "        1.9106, 1.3701, 1.4578, 1.7859, 2.4634, 1.4167, 1.6494, 2.0281, 2.2022,\n",
      "        2.7596, 1.7287, 1.6847, 1.6502, 1.5325, 1.9613, 2.1516, 2.1222, 1.7415,\n",
      "        1.6669, 2.0140, 1.4430, 1.7394, 1.5477, 1.4993, 3.2575, 1.7638, 2.2680,\n",
      "        1.6489, 2.2096, 1.7237, 2.4649, 1.9973, 1.3591, 1.6465, 2.1585, 1.8575,\n",
      "        1.4351, 1.8186, 1.1529, 1.2969, 1.0219, 1.8872, 1.3161, 1.9931, 0.8925,\n",
      "        2.0073, 1.7165, 2.1107, 2.2083, 2.1055, 2.9398, 2.2467, 1.4778, 1.6046,\n",
      "        1.7304, 2.3741, 2.8529, 2.2870, 1.2072, 3.4187, 1.5230, 1.8687, 1.6737,\n",
      "        2.4732, 2.4726, 2.2325, 2.1713, 1.0857, 1.6770, 1.4385, 1.5873, 2.1689,\n",
      "        1.7741, 2.3038, 1.6080, 1.4287], device='cuda:0')), ('backbone.model.layer3.0.bn1.bias', tensor([-5.3549e-01, -1.3850e+00, -1.6246e+00, -2.3286e+00, -1.8782e+00,\n",
      "        -6.0011e-01, -2.5596e+00, -1.6396e+00, -6.9549e-01, -2.4908e+00,\n",
      "         1.0530e-01, -7.8171e-02, -8.4186e-01, -1.5046e+00, -1.3964e+00,\n",
      "        -6.0002e-01, -1.4791e+00, -4.0096e+00, -2.2138e+00, -2.4667e+00,\n",
      "         3.2927e-01, -3.5939e-01, -8.4399e-01, -3.0849e+00, -1.1779e+00,\n",
      "        -1.5739e+00,  1.8917e-01, -9.7749e-01, -5.6238e-01, -1.7486e+00,\n",
      "        -1.0285e+00, -1.4462e+00, -1.0488e+00, -1.7560e+00, -4.7522e-01,\n",
      "        -7.1113e-01, -2.2037e+00, -1.3278e+00, -6.3974e-01, -2.4015e+00,\n",
      "         2.1284e-01, -2.7109e+00, -1.6244e+00, -2.7868e-01, -6.5474e-01,\n",
      "        -9.8571e-01, -4.0171e-01, -1.8694e+00, -7.7027e-01, -1.1721e+00,\n",
      "        -1.5051e+00, -1.4543e+00, -2.3714e-01, -4.8320e-01, -9.0775e-01,\n",
      "        -3.5612e-01, -1.5303e-01, -1.1828e+00, -2.9714e+00, -3.4224e-01,\n",
      "        -2.4098e+00, -1.9919e+00, -7.6372e-01, -6.4830e-01, -1.4187e-01,\n",
      "        -2.8337e-01, -2.5934e-01, -1.5181e+00, -2.5757e+00, -1.8276e+00,\n",
      "        -2.2482e+00, -1.7081e+00, -1.0252e+00, -2.4075e+00, -7.3528e-01,\n",
      "        -9.5940e-01, -1.4263e+00, -1.2747e+00, -1.5032e+00,  1.1319e-01,\n",
      "        -1.8541e+00, -7.6887e-01, -1.0465e+00, -1.0500e+00, -2.5514e+00,\n",
      "        -1.8760e-01, -4.5588e-01, -1.6288e-01, -1.0280e+00, -1.9370e+00,\n",
      "        -1.2792e+00, -7.1010e-02, -4.3763e+00, -3.7278e+00, -4.2135e-01,\n",
      "        -5.4612e-01, -8.9776e-01, -1.3897e+00, -1.1246e-01, -1.3730e+00,\n",
      "        -1.1988e+00,  1.4921e-01, -1.3715e+00, -1.6765e+00,  5.7892e-01,\n",
      "        -1.4446e+00, -2.0118e+00, -1.4179e+00, -1.8389e+00, -2.7892e+00,\n",
      "        -1.6784e+00, -2.5272e+00, -3.8766e-01, -1.4696e+00, -7.3134e-01,\n",
      "        -9.5269e-01, -5.1012e-01, -3.1354e+00, -1.4432e+00, -5.7277e-01,\n",
      "        -1.3399e+00, -1.4853e+00, -2.8380e-01,  6.8512e-02, -1.8946e+00,\n",
      "        -3.0583e-01, -1.5291e+00, -2.1347e+00, -1.2131e+00, -3.2671e-01,\n",
      "         2.8840e-01, -9.3176e-01, -2.8119e-01, -6.5585e-01, -2.7735e+00,\n",
      "        -1.5937e+00, -1.0579e+00, -4.4954e-01, -1.8332e+00,  3.2354e-01,\n",
      "        -3.0750e-01,  3.1995e-01, -1.1689e+00, -5.7984e-01, -7.6337e-01,\n",
      "        -2.8360e+00, -1.8503e+00, -1.5128e+00, -2.6746e+00, -1.5481e+00,\n",
      "        -1.6132e+00,  4.8510e-01, -3.1454e+00, -1.6073e-01, -1.2214e+00,\n",
      "        -1.1697e+00, -1.3831e+00, -2.8847e+00, -1.9114e-01, -2.0113e+00,\n",
      "        -1.0946e+00, -7.7182e-01, -1.1798e+00, -2.0714e+00, -3.2528e-01,\n",
      "        -1.0541e+00, -1.5468e+00, -2.3059e+00, -1.5889e+00, -1.0735e+00,\n",
      "        -1.0174e+00, -1.5846e+00, -1.4898e+00, -1.0086e+00,  9.4509e-01,\n",
      "        -1.8271e+00, -1.7397e+00,  7.9101e-01, -8.8241e-01, -1.9971e+00,\n",
      "        -8.6809e-01, -7.4346e-01, -1.5044e+00, -1.0378e+00, -2.1347e+00,\n",
      "        -7.9677e-01, -1.4380e+00, -1.4580e+00, -9.2806e-01, -1.9891e+00,\n",
      "        -1.6576e+00,  6.0133e-01, -6.5299e-04,  3.9139e-02, -1.4727e+00,\n",
      "        -1.2954e+00, -2.2995e+00, -1.0160e+00, -8.9763e-01, -1.5543e+00,\n",
      "        -1.8227e+00, -3.5680e-01, -4.5975e-01, -1.0744e+00, -3.1714e+00,\n",
      "        -3.8814e-01, -1.7796e+00, -7.6655e-01, -2.0616e+00, -7.4710e-01,\n",
      "        -3.1296e+00, -2.1727e+00,  8.9834e-01, -1.1946e+00, -4.8159e-01,\n",
      "        -1.6434e+00, -2.6362e-01, -1.8958e-01,  1.8791e-01, -1.5014e+00,\n",
      "        -1.3158e-01, -2.2779e+00, -1.5637e-01, -1.8549e+00,  8.3054e-01,\n",
      "        -1.4831e+00, -2.4135e+00, -2.2083e+00, -2.6825e+00, -9.7973e-01,\n",
      "        -2.7029e+00, -2.2681e+00, -6.4452e-01, -7.3881e-01, -4.5343e-01,\n",
      "        -1.8319e+00, -2.1304e+00, -7.6061e-01, -2.3178e+00, -2.5425e+00,\n",
      "        -6.4342e-01, -2.5049e+00, -1.5478e+00, -1.1527e+00, -1.1501e+00,\n",
      "        -2.6219e+00, -1.2835e+00,  3.9172e-01, -4.9119e-01, -2.5988e-01,\n",
      "        -1.7261e+00, -1.0508e+00, -1.2308e+00, -1.2267e+00, -1.4844e+00,\n",
      "        -8.5897e-01], device='cuda:0')), ('backbone.model.layer3.0.conv2.weight', tensor([[[[-2.3330e-02,  1.3749e-02, -2.0991e-02],\n",
      "          [-3.0048e-02,  1.9823e-02,  2.7604e-03],\n",
      "          [ 8.0429e-03,  4.4661e-03, -1.8055e-02]],\n",
      "\n",
      "         [[ 3.1061e-02, -1.1023e-01, -6.2896e-02],\n",
      "          [-9.3494e-02, -1.5337e-01, -1.1371e-01],\n",
      "          [-6.3223e-02, -2.1529e-01, -1.1982e-01]],\n",
      "\n",
      "         [[ 3.2827e-02, -7.0539e-03, -1.2319e-03],\n",
      "          [ 1.1752e-02,  5.2173e-03,  2.3580e-02],\n",
      "          [ 5.8188e-04, -2.8852e-03, -1.5252e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2823e-02,  2.5860e-02,  4.4502e-02],\n",
      "          [-2.4704e-02, -4.5595e-02,  6.9792e-04],\n",
      "          [-5.2458e-02, -5.6758e-02, -4.0394e-02]],\n",
      "\n",
      "         [[ 3.9448e-02,  2.7733e-02,  7.1700e-02],\n",
      "          [ 3.8692e-02,  6.7443e-02,  5.8163e-02],\n",
      "          [ 2.9803e-02,  2.3441e-02,  4.3101e-02]],\n",
      "\n",
      "         [[ 5.4555e-02, -5.7310e-02, -7.1439e-03],\n",
      "          [-1.2024e-02, -3.3045e-02, -4.7406e-02],\n",
      "          [ 1.9995e-02, -2.8558e-03,  1.1004e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9770e-02,  4.8554e-03, -2.5810e-02],\n",
      "          [-3.8796e-02, -2.4218e-02, -5.1247e-02],\n",
      "          [-1.0010e-01, -8.3773e-02, -5.1251e-02]],\n",
      "\n",
      "         [[ 2.1118e-02,  5.1124e-02,  5.9232e-02],\n",
      "          [ 9.4653e-02,  4.2381e-02,  6.5558e-02],\n",
      "          [ 9.2166e-02,  8.8554e-02,  5.1775e-02]],\n",
      "\n",
      "         [[-1.3232e-02,  6.5246e-03, -1.0733e-02],\n",
      "          [ 2.6461e-02,  5.7768e-02,  5.1077e-02],\n",
      "          [ 3.1192e-02,  5.6701e-02,  3.6919e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8807e-02,  7.3878e-02,  1.7204e-02],\n",
      "          [ 3.8570e-03,  6.5806e-02,  5.1977e-02],\n",
      "          [-4.7130e-02, -1.0205e-03, -9.9053e-03]],\n",
      "\n",
      "         [[ 1.4808e-02, -7.7037e-03, -1.2222e-02],\n",
      "          [-4.2083e-02, -7.4875e-02, -1.5762e-02],\n",
      "          [-7.2704e-02, -5.5499e-02, -5.5227e-02]],\n",
      "\n",
      "         [[ 1.8562e-02, -6.7928e-03, -1.0830e-02],\n",
      "          [-1.9527e-02, -7.1786e-02, -6.9376e-03],\n",
      "          [-2.8776e-03, -4.8825e-02, -3.2739e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2869e-02,  5.3698e-02,  6.6712e-02],\n",
      "          [ 8.3122e-02,  6.5281e-02,  9.0602e-02],\n",
      "          [ 6.3596e-02,  1.3354e-01,  9.2067e-02]],\n",
      "\n",
      "         [[ 1.1064e-02, -1.3220e-02, -8.2529e-03],\n",
      "          [-2.1986e-02, -9.2613e-02, -4.2092e-02],\n",
      "          [ 2.2488e-02, -9.2076e-02, -6.4365e-02]],\n",
      "\n",
      "         [[ 3.0329e-02,  8.1470e-02,  6.5200e-02],\n",
      "          [ 4.5597e-03, -6.7672e-03,  4.3849e-02],\n",
      "          [-7.2471e-03, -2.3645e-02, -2.1651e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9276e-02, -6.7762e-03, -4.1073e-02],\n",
      "          [-4.2894e-02, -1.7100e-02,  1.8957e-02],\n",
      "          [-2.0169e-02, -4.5453e-02, -4.1598e-02]],\n",
      "\n",
      "         [[-1.6830e-02, -2.5403e-02, -4.1790e-04],\n",
      "          [-3.5964e-02,  1.2683e-03,  6.7549e-03],\n",
      "          [ 4.3253e-02,  3.2593e-02,  3.6527e-02]],\n",
      "\n",
      "         [[-1.4133e-02, -4.9107e-02,  5.0107e-03],\n",
      "          [-4.6777e-02, -8.4056e-02, -2.0366e-02],\n",
      "          [-6.1236e-02, -6.9905e-02, -2.5334e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.9680e-02,  1.1085e-01,  1.2000e-01],\n",
      "          [ 1.2128e-01, -3.2214e-02,  1.3268e-01],\n",
      "          [ 9.2624e-02,  8.8550e-02,  7.6184e-02]],\n",
      "\n",
      "         [[-1.2680e-01, -1.6773e-01, -1.6257e-01],\n",
      "          [-2.9500e-01, -3.0910e-01, -2.7058e-01],\n",
      "          [-2.5487e-01, -2.2068e-01, -1.5026e-01]],\n",
      "\n",
      "         [[ 2.9042e-02,  1.8501e-02,  5.2416e-02],\n",
      "          [ 4.2540e-02,  8.7026e-02,  3.9777e-02],\n",
      "          [ 5.0570e-02,  5.2144e-02,  3.4114e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1413e-02,  1.4871e-02,  4.8572e-02],\n",
      "          [ 6.5825e-02,  4.1889e-02,  2.1117e-02],\n",
      "          [-2.3682e-02, -4.4766e-02, -3.3801e-02]],\n",
      "\n",
      "         [[-3.3957e-02, -2.5945e-02, -4.0854e-02],\n",
      "          [ 2.4744e-02, -4.0596e-02,  7.1095e-03],\n",
      "          [-1.4280e-03,  3.1312e-02, -7.4854e-03]],\n",
      "\n",
      "         [[-1.4057e-02,  1.9890e-03,  3.1197e-03],\n",
      "          [ 5.5037e-02, -3.9364e-02,  7.1327e-03],\n",
      "          [ 2.1515e-02,  5.8202e-02,  4.5174e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2420e-03,  8.0913e-03,  2.8650e-02],\n",
      "          [-3.1239e-02, -1.4904e-02,  1.4698e-03],\n",
      "          [ 1.8555e-02,  8.4930e-04,  5.3623e-02]],\n",
      "\n",
      "         [[-4.5858e-02, -9.6714e-03,  2.2297e-02],\n",
      "          [ 5.3952e-02, -2.9093e-02, -3.0939e-02],\n",
      "          [ 2.9152e-02,  3.0492e-02,  6.1778e-02]],\n",
      "\n",
      "         [[ 1.3378e-01,  2.0232e-01,  9.2511e-02],\n",
      "          [ 1.0479e-01,  8.8445e-02,  1.4869e-01],\n",
      "          [ 5.9779e-02,  7.2932e-02,  6.3863e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9452e-04,  3.9184e-02,  2.8184e-02],\n",
      "          [-4.5438e-02,  1.6477e-02, -4.9009e-02],\n",
      "          [-3.1339e-02, -5.6705e-02, -3.7872e-02]],\n",
      "\n",
      "         [[-7.3454e-03,  4.3204e-02,  1.3448e-02],\n",
      "          [-4.7564e-02, -4.2085e-03, -2.7744e-02],\n",
      "          [ 1.8874e-03, -4.8578e-02,  1.2682e-02]],\n",
      "\n",
      "         [[ 4.3183e-03, -1.7338e-02, -3.7154e-03],\n",
      "          [-3.7131e-02, -1.0494e-01, -4.7659e-02],\n",
      "          [-7.0058e-02, -7.7497e-02, -3.0451e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9818e-03,  2.2126e-02,  3.7010e-02],\n",
      "          [-2.5567e-02, -2.6465e-02,  3.5896e-02],\n",
      "          [ 1.4248e-02,  6.5722e-03,  3.7818e-02]],\n",
      "\n",
      "         [[-1.4503e-02,  5.1375e-04, -4.5367e-02],\n",
      "          [-4.7281e-02,  1.8946e-02, -3.4604e-02],\n",
      "          [-2.3065e-02, -4.9321e-02, -4.3732e-02]],\n",
      "\n",
      "         [[ 9.1071e-02,  5.0323e-02,  5.3092e-02],\n",
      "          [ 4.7183e-02, -8.0551e-02,  4.4472e-02],\n",
      "          [ 1.8287e-02,  1.2229e-02,  1.6121e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2883e-02,  8.8764e-02,  1.5848e-02],\n",
      "          [-3.1045e-03, -2.5651e-02,  1.0305e-02],\n",
      "          [-6.7127e-02, -9.6404e-02, -4.0220e-02]],\n",
      "\n",
      "         [[ 1.3473e-02,  2.1478e-02, -2.4523e-03],\n",
      "          [-1.1124e-03, -1.7383e-02, -1.2540e-03],\n",
      "          [-4.7135e-02, -3.4955e-02,  1.0995e-02]],\n",
      "\n",
      "         [[-7.6981e-02, -1.7742e-01, -1.3096e-01],\n",
      "          [ 2.5057e-02, -2.6312e-02, -6.8279e-03],\n",
      "          [ 3.7551e-02,  2.2853e-02,  3.0979e-02]]]], device='cuda:0')), ('backbone.model.layer3.0.bn2.weight', tensor([1.9794, 2.4785, 2.3989, 2.2265, 3.3271, 3.0045, 3.8320, 2.5598, 1.3481,\n",
      "        2.5990, 2.8583, 3.6317, 2.7333, 3.0132, 3.0797, 2.5523, 3.1617, 2.7068,\n",
      "        2.1381, 3.1929, 2.6072, 1.9646, 2.3381, 2.5981, 3.0953, 2.1861, 2.2640,\n",
      "        2.7742, 2.7633, 2.4308, 2.5673, 2.3734, 2.3714, 3.0107, 2.5475, 2.3895,\n",
      "        2.9655, 3.2151, 2.5048, 2.1225, 2.9208, 2.5650, 2.5173, 2.1144, 2.9072,\n",
      "        2.5494, 2.8688, 2.8362, 3.1828, 2.7717, 2.7916, 2.6848, 2.9785, 2.9026,\n",
      "        2.2002, 2.2965, 2.3520, 3.0812, 2.5037, 2.1269, 2.7396, 2.6614, 2.5977,\n",
      "        2.1692, 2.7664, 2.3781, 2.6769, 2.6369, 2.6426, 3.0058, 2.8170, 3.0475,\n",
      "        2.7012, 3.3292, 3.0206, 3.5348, 2.8055, 2.7541, 2.6222, 2.9008, 2.5099,\n",
      "        2.4422, 2.0299, 2.8736, 3.1078, 2.5207, 2.4896, 2.7031, 2.4799, 2.6036,\n",
      "        2.4790, 2.6483, 2.2601, 2.7657, 2.3967, 2.4945, 2.1961, 1.8840, 2.1864,\n",
      "        3.6253, 2.9548, 2.6648, 2.2894, 2.4184, 2.9611, 2.4793, 2.5560, 2.1931,\n",
      "        2.8726, 3.1119, 2.7535, 3.0861, 2.1142, 3.0997, 2.4422, 2.8405, 2.1731,\n",
      "        2.9403, 3.3174, 2.3898, 2.4116, 2.7210, 2.3691, 2.4276, 2.2008, 2.5933,\n",
      "        2.0804, 2.1113, 2.1133, 2.5962, 2.3476, 2.3996, 2.0707, 2.7015, 2.2120,\n",
      "        3.2902, 2.5917, 2.7115, 2.2127, 2.5380, 2.8711, 2.6667, 2.4816, 2.5813,\n",
      "        2.3225, 2.2720, 2.7166, 2.8560, 3.3239, 2.2040, 3.2092, 2.9285, 2.4895,\n",
      "        2.6075, 2.6992, 2.1177, 2.4470, 2.2213, 2.1388, 2.7571, 2.2836, 2.4342,\n",
      "        2.5783, 4.0081, 2.2663, 2.4175, 2.7602, 2.3833, 2.8929, 1.9788, 2.9588,\n",
      "        2.7378, 1.9208, 2.5757, 2.5153, 2.0720, 3.4902, 3.2542, 3.6290, 5.3415,\n",
      "        3.1127, 3.4105, 2.7898, 1.4108, 1.6364, 2.2583, 2.3605, 1.7560, 2.7943,\n",
      "        1.7679, 2.5667, 3.0117, 2.4226, 2.4656, 3.0474, 2.6352, 2.0751, 2.4129,\n",
      "        2.5428, 2.2931, 2.4351, 3.9104, 2.5914, 3.1353, 3.2945, 2.7529, 2.1639,\n",
      "        1.7216, 2.5069, 1.8568, 2.3596, 2.9778, 2.9164, 2.8303, 2.6746, 2.3713,\n",
      "        2.3701, 2.6238, 3.3482, 2.5029, 2.2235, 3.3644, 2.5343, 2.2769, 2.4689,\n",
      "        2.5054, 3.0362, 2.6833, 2.4235, 2.4458, 2.1112, 3.1123, 3.0293, 2.6214,\n",
      "        2.6289, 3.0982, 2.3420, 3.1709, 2.4449, 2.4941, 2.9095, 2.6963, 2.1873,\n",
      "        2.8779, 2.5635, 2.3742, 3.0699, 2.2821, 2.9976, 4.5371, 2.3645, 2.7306,\n",
      "        2.7226, 1.6442, 2.2537, 2.8295], device='cuda:0')), ('backbone.model.layer3.0.bn2.bias', tensor([-5.9156e-01, -2.0443e-01, -2.5677e-01, -1.3915e+00,  4.3628e-01,\n",
      "         3.7143e-01,  4.8889e-01,  4.2592e-01, -2.1715e+00,  1.6333e-01,\n",
      "         2.0908e-01,  8.6869e-02,  5.4837e-02,  6.3667e-01,  6.8399e-01,\n",
      "         7.4638e-01,  1.2130e-01,  9.9107e-02,  2.1591e-02,  8.4331e-01,\n",
      "         1.5174e-01, -8.0766e-01, -3.6746e-01, -9.4662e-01, -1.9317e-01,\n",
      "         4.5152e-01,  3.3458e-01,  4.4652e-02, -6.6162e-01, -5.9431e-01,\n",
      "        -3.7740e-01,  7.2911e-01,  5.2142e-01,  5.2623e-01,  4.5101e-01,\n",
      "        -7.7519e-01, -4.4288e-02, -1.3065e-01,  9.4442e-02,  1.8845e-01,\n",
      "         2.7407e-01, -1.3969e+00, -1.3610e+00,  6.2860e-02,  3.2115e-01,\n",
      "         3.1777e-01, -1.3000e+00, -2.1504e-01,  3.6836e-01,  9.7051e-01,\n",
      "        -7.2617e-03,  5.3855e-01, -2.8411e-01, -2.7585e-01, -7.7133e-01,\n",
      "        -7.2881e-01, -5.8382e-01, -5.3860e-01, -4.2237e-01,  1.6487e-01,\n",
      "        -3.6118e-03, -3.5838e-01, -1.4981e-01, -4.2242e-01, -8.0584e-01,\n",
      "        -2.1588e-01, -8.6025e-01, -6.1865e-01, -3.1695e-01, -6.1921e-01,\n",
      "         6.4198e-01, -3.0555e-01, -7.6996e-01,  1.3907e-01,  3.7670e-01,\n",
      "        -1.9912e-01, -3.4139e-01,  1.9129e-01, -2.4996e+00, -7.1242e-01,\n",
      "         3.1013e-01,  1.4918e-01, -3.8684e-01,  2.1456e-01, -1.4448e-01,\n",
      "         3.8367e-01,  2.5923e-01,  3.6138e-01,  2.2417e-02,  3.4328e-01,\n",
      "         2.5043e-01, -1.4443e-01, -3.4157e-01, -9.1719e-01, -6.9595e-01,\n",
      "         1.0922e-01,  3.0445e-01, -1.2386e-01,  4.8021e-03,  9.9656e-02,\n",
      "         3.4755e-01,  1.5979e-01,  4.7755e-01, -1.0175e-02,  9.3755e-02,\n",
      "         5.0878e-01, -1.8696e+00,  6.8907e-02, -1.1885e+00, -5.8767e-01,\n",
      "        -5.6727e-01, -1.3482e+00,  4.0221e-01, -5.9934e-01, -5.0918e-01,\n",
      "        -6.3169e-01, -4.0639e-01,  3.8141e-01,  1.9546e-01,  3.6471e-02,\n",
      "         5.2028e-01,  3.1515e-01, -5.3181e-01, -1.4485e-01,  4.8656e-01,\n",
      "         4.1031e-01, -1.1393e+00,  2.9859e-01, -1.6551e-01, -4.9150e-01,\n",
      "         1.0255e-01, -3.4509e-01, -3.1055e-02, -2.5530e-01,  3.3812e-01,\n",
      "        -4.4858e-01, -5.2522e-02, -1.6826e-01, -2.4397e-01,  3.8229e-02,\n",
      "         2.2632e-01, -1.9515e-01, -4.0876e-01,  7.6982e-01,  8.1725e-02,\n",
      "        -3.1773e-01, -6.0390e-01, -3.8339e-02, -6.3867e-02, -9.7373e-02,\n",
      "        -1.2923e-01,  2.2948e-01, -4.3351e-03, -8.4017e-02,  8.1752e-02,\n",
      "        -3.9789e-01,  9.1900e-02,  1.2198e-01,  8.9437e-02, -3.3779e-01,\n",
      "        -8.8421e-01, -5.9639e-02,  5.9517e-01,  8.2184e-01, -1.8440e-01,\n",
      "        -2.1702e-01,  1.7867e-01,  2.7692e-02,  6.2369e-02,  7.7357e-02,\n",
      "         3.4885e-01, -1.2572e+00, -5.7932e-03, -7.4562e-02,  3.6568e-01,\n",
      "         5.6116e-03, -3.2001e-01, -1.6160e-01,  9.2267e-01, -7.2403e-01,\n",
      "         5.8313e-01,  8.5610e-01,  3.8056e-01, -2.1782e+00,  1.9667e+00,\n",
      "        -1.6424e-01,  4.5223e-04, -6.8438e-01,  2.5431e-01,  5.2780e-02,\n",
      "        -8.7699e-01, -1.7513e+00,  4.1600e-01, -5.4076e-01,  4.8753e-01,\n",
      "         1.9701e-01,  3.9321e-01,  2.3334e-01, -8.8361e-01, -6.6764e-02,\n",
      "         2.3901e-01,  3.3566e-01,  1.1546e-01,  5.3106e-01,  1.7551e-01,\n",
      "         5.2536e-02,  1.1116e-01, -1.7173e+00, -1.9687e-01, -1.2650e+00,\n",
      "         2.6804e-01,  5.9014e-01, -7.0351e-01, -3.4452e-01, -1.8340e-01,\n",
      "        -2.8956e-01, -1.1856e-01, -5.1600e-01,  8.4102e-02,  9.4279e-02,\n",
      "        -6.5928e-02,  2.3595e-02, -8.9216e-01, -2.7125e-01, -1.0124e+00,\n",
      "        -1.4994e-01,  4.8747e-01, -1.1452e-01,  1.1420e+00,  3.4802e-01,\n",
      "        -8.8472e-01,  5.8024e-01, -5.4239e-02, -8.1834e-02, -3.1481e-01,\n",
      "        -1.1927e-01, -2.0503e-01, -8.3474e-01, -2.1493e-01,  8.8331e-02,\n",
      "         5.5211e-01, -1.8695e-01,  4.1600e-01, -1.9251e-01, -1.9048e-01,\n",
      "        -1.5933e+00,  5.1294e-01, -1.9242e-01,  6.3469e-01,  9.5598e-01,\n",
      "         5.1396e-01,  7.8017e-01,  3.5819e-01, -2.5130e+00,  6.0891e-01,\n",
      "         5.1556e-01], device='cuda:0')), ('backbone.model.layer3.0.conv3.weight', tensor([[[[-0.0105]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         [[ 0.0061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[-0.0425]],\n",
      "\n",
      "         [[-0.1052]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1052]],\n",
      "\n",
      "         [[ 0.0328]],\n",
      "\n",
      "         [[-0.0594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0480]],\n",
      "\n",
      "         [[-0.0216]],\n",
      "\n",
      "         [[ 0.0751]]],\n",
      "\n",
      "\n",
      "        [[[-0.0451]],\n",
      "\n",
      "         [[ 0.0574]],\n",
      "\n",
      "         [[-0.0053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0741]],\n",
      "\n",
      "         [[ 0.0688]],\n",
      "\n",
      "         [[-0.2329]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0827]],\n",
      "\n",
      "         [[ 0.0173]],\n",
      "\n",
      "         [[ 0.0789]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0906]],\n",
      "\n",
      "         [[ 0.0584]],\n",
      "\n",
      "         [[ 0.0178]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0096]],\n",
      "\n",
      "         [[ 0.0500]],\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[-0.1631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0087]],\n",
      "\n",
      "         [[-0.0331]],\n",
      "\n",
      "         [[-0.0409]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[-0.0647]],\n",
      "\n",
      "         [[-0.0037]]]], device='cuda:0')), ('backbone.model.layer3.0.bn3.weight', tensor([-2.2544, -6.5997,  2.5872,  ...,  3.4501, -2.6730, -5.9061],\n",
      "       device='cuda:0')), ('backbone.model.layer3.0.bn3.bias', tensor([-0.1048,  3.2123, -0.6145,  ..., -0.5720,  1.0802,  1.0210],\n",
      "       device='cuda:0')), ('backbone.model.layer3.0.downsample.0.weight', tensor([[[[-0.0791]],\n",
      "\n",
      "         [[-0.0194]],\n",
      "\n",
      "         [[ 0.0657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0588]],\n",
      "\n",
      "         [[ 0.0321]],\n",
      "\n",
      "         [[ 0.0419]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045]],\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         [[ 0.1066]]],\n",
      "\n",
      "\n",
      "        [[[-0.0898]],\n",
      "\n",
      "         [[-0.0126]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0318]],\n",
      "\n",
      "         [[ 0.0727]],\n",
      "\n",
      "         [[ 0.0610]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2326]],\n",
      "\n",
      "         [[-0.0248]],\n",
      "\n",
      "         [[ 0.0651]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0019]],\n",
      "\n",
      "         [[ 0.0101]],\n",
      "\n",
      "         [[-0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.0115]],\n",
      "\n",
      "         [[-0.0073]],\n",
      "\n",
      "         [[ 0.0426]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0885]],\n",
      "\n",
      "         [[-0.0664]],\n",
      "\n",
      "         [[ 0.0964]]],\n",
      "\n",
      "\n",
      "        [[[-0.0120]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0203]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[ 0.0493]]]], device='cuda:0')), ('backbone.model.layer3.0.downsample.1.weight', tensor([1.1918, 2.3943, 1.5797,  ..., 2.6591, 2.2162, 2.5378], device='cuda:0')), ('backbone.model.layer3.0.downsample.1.bias', tensor([2.2924, 0.5938, 0.3299,  ..., 0.7247, 0.5221, 0.7599], device='cuda:0')), ('backbone.model.layer3.1.conv1.weight', tensor([[[[-0.0389]],\n",
      "\n",
      "         [[-0.0129]],\n",
      "\n",
      "         [[ 0.0807]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[ 0.0162]],\n",
      "\n",
      "         [[ 0.0179]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0370]],\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[-0.0544]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0166]],\n",
      "\n",
      "         [[ 0.0546]],\n",
      "\n",
      "         [[ 0.0091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0969]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[ 0.1459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0085]],\n",
      "\n",
      "         [[ 0.0031]],\n",
      "\n",
      "         [[ 0.0423]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0683]],\n",
      "\n",
      "         [[ 0.0436]],\n",
      "\n",
      "         [[-0.1244]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0388]],\n",
      "\n",
      "         [[ 0.0106]],\n",
      "\n",
      "         [[ 0.0088]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0212]],\n",
      "\n",
      "         [[ 0.1061]],\n",
      "\n",
      "         [[ 0.0178]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0746]],\n",
      "\n",
      "         [[ 0.0533]],\n",
      "\n",
      "         [[-0.0185]]],\n",
      "\n",
      "\n",
      "        [[[-0.1187]],\n",
      "\n",
      "         [[-0.0200]],\n",
      "\n",
      "         [[ 0.0591]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1015]],\n",
      "\n",
      "         [[-0.0405]],\n",
      "\n",
      "         [[-0.1304]]]], device='cuda:0')), ('backbone.model.layer3.1.bn1.weight', tensor([4.5300, 3.6900, 2.9296, 3.1876, 1.9662, 1.5145, 1.7285, 1.9012, 2.6346,\n",
      "        3.2120, 3.0098, 1.6250, 2.4632, 1.6906, 1.3772, 1.8133, 1.5520, 2.3810,\n",
      "        4.4742, 3.8852, 3.9936, 6.1225, 3.8670, 5.1981, 1.7710, 4.9629, 1.5761,\n",
      "        1.5875, 1.5915, 2.1069, 1.2029, 2.0090, 3.4889, 1.9143, 1.5382, 3.1900,\n",
      "        3.6936, 2.7784, 2.0459, 2.0856, 2.8994, 2.5289, 2.7597, 3.1623, 2.9048,\n",
      "        2.9179, 1.5189, 2.2217, 2.4996, 1.5601, 2.2931, 3.2776, 2.0049, 4.1057,\n",
      "        1.5387, 1.4701, 3.7245, 3.5880, 2.0041, 2.3405, 1.5866, 2.8203, 2.3793,\n",
      "        0.8341, 2.8125, 1.5463, 1.7648, 2.5802, 2.4534, 3.0302, 2.2517, 1.5955,\n",
      "        2.5219, 2.5268, 3.7824, 3.2633, 1.5169, 1.5200, 2.9266, 1.5710, 1.7155,\n",
      "        2.0248, 1.8607, 2.0134, 4.2187, 2.0214, 2.7093, 2.0144, 2.3990, 1.9586,\n",
      "        3.2994, 2.2865, 2.0215, 2.8592, 1.8380, 5.6081, 1.8163, 1.7623, 2.4864,\n",
      "        1.1395, 1.7632, 1.6191, 1.7665, 1.7156, 0.1950, 2.8373, 2.9261, 2.1242,\n",
      "        3.1949, 2.8334, 2.6765, 1.9888, 1.6092, 3.1110, 1.9927, 1.4757, 2.3510,\n",
      "        2.2208, 3.0052, 3.0279, 3.5410, 1.9603, 1.9437, 2.2832, 1.8481, 1.7898,\n",
      "        4.0641, 2.3941, 2.4154, 1.5994, 4.0100, 1.8230, 1.7616, 1.5111, 3.4343,\n",
      "        2.8541, 2.5348, 2.7720, 2.2176, 0.8402, 1.9032, 2.2962, 2.8110, 2.8526,\n",
      "        1.6864, 2.9249, 2.3280, 1.5658, 1.7060, 3.0742, 2.3073, 2.5423, 3.8308,\n",
      "        3.4067, 1.7016, 2.2208, 2.4313, 1.9161, 2.2282, 1.5775, 2.4883, 2.6939,\n",
      "        1.8222, 2.0068, 1.6078, 4.6842, 1.6222, 2.2502, 1.5033, 3.3694, 1.3089,\n",
      "        1.4110, 1.9951, 1.6360, 1.9484, 3.4111, 2.0646, 1.6076, 1.7612, 1.7086,\n",
      "        2.4504, 1.8427, 1.6937, 3.5341, 3.7005, 2.0735, 2.2027, 4.0442, 1.8939,\n",
      "        2.3202, 3.5209, 3.2277, 2.0657, 2.4049, 1.6875, 2.3672, 2.5507, 2.6007,\n",
      "        1.2073, 2.4552, 2.3894, 1.4040, 1.8213, 1.7182, 1.6706, 1.7292, 1.5858,\n",
      "        1.6274, 2.0300, 1.7620, 1.7800, 3.2749, 2.2589, 1.9535, 1.5989, 2.1621,\n",
      "        1.9521, 3.0687, 3.1307, 3.1596, 3.0456, 4.4984, 3.2288, 3.0053, 2.8506,\n",
      "        4.3691, 2.9253, 7.9440, 2.4359, 4.0261, 1.3621, 4.1813, 1.5151, 1.6060,\n",
      "        1.8521, 1.5008, 2.1833, 1.9357, 0.8967, 2.2790, 1.2216, 1.9987, 2.2395,\n",
      "        1.2601, 3.2404, 1.8188, 1.5367, 2.8400, 1.3524, 1.9940, 2.2460, 2.9282,\n",
      "        1.6608, 1.7835, 2.0634, 2.4385], device='cuda:0')), ('backbone.model.layer3.1.bn1.bias', tensor([ 0.9421,  0.8397, -3.4965, -2.9692, -1.8407,  0.2488, -1.4208, -0.7138,\n",
      "         0.1937, -0.4340, -1.1457, -2.8745, -0.5557, -2.3838,  0.7473, -0.2034,\n",
      "        -3.3671,  0.6819, -0.0688, -1.9988, -2.4336,  2.2252, -1.2766,  0.7529,\n",
      "        -0.6193, -2.3280, -0.6300, -1.1136, -0.7947, -1.2847,  0.6108, -1.5260,\n",
      "        -2.0036,  1.3701, -1.7486, -1.9711, -2.2222, -0.3757,  0.9813, -2.3573,\n",
      "        -0.7174,  1.0837, -1.0297,  0.0303, -0.9485, -0.8997, -3.5270, -1.0049,\n",
      "        -0.8264, -0.2794, -0.2934, -0.5844, -1.9700, -4.3034, -0.8820, -1.3506,\n",
      "        -0.1121,  0.6029, -3.1291, -0.9815,  0.2157, -1.2558, -3.2197, -0.1760,\n",
      "        -4.0048, -0.0462, -1.3129, -1.7261,  0.2701, -3.7921,  2.6382,  0.0407,\n",
      "        -1.7687, -1.9640, -1.6901, -1.2556,  0.5704,  0.4520, -1.6259, -2.5201,\n",
      "         0.5371, -1.5351, -1.9708, -0.1346, -1.1925, -0.6024,  0.1602,  1.3956,\n",
      "        -0.2852, -0.4891, -1.3662, -0.7344, -3.4432, -0.7095, -0.3152, -3.8438,\n",
      "        -1.1368,  0.0865, -1.1348,  0.7327, -0.3708, -0.4890, -1.3273,  0.2099,\n",
      "        -1.8608, -0.6921, -1.4407,  0.3750, -0.4113, -1.6793, -0.9941, -2.5124,\n",
      "         1.0207, -0.8188, -0.9750, -2.5811, -3.2161, -1.1167, -1.4355,  0.2765,\n",
      "        -3.3413, -2.5954, -2.8465, -0.3784, -0.3922,  0.0774, -0.8125, -0.4636,\n",
      "        -1.9814, -1.4088, -0.6757, -1.3654,  0.6247, -0.4952, -3.1394,  0.4723,\n",
      "        -0.3654,  0.0441, -3.2075, -1.1493, -0.5080, -4.0548, -0.7638, -0.4706,\n",
      "        -1.0187,  1.5847, -0.0820, -1.4575, -3.0014,  1.8440,  1.0416, -0.2418,\n",
      "        -0.2756,  0.1243, -2.0435, -2.6841, -0.2900, -0.0225, -1.4929,  0.9410,\n",
      "        -1.1598,  1.1262, -1.5495, -0.1701, -3.1885,  0.3467, -2.0173,  0.6162,\n",
      "        -0.5305, -1.6219, -0.4629,  1.0916, -0.4269, -0.5441, -1.7776, -2.8325,\n",
      "         0.2596,  0.0433, -1.8619, -4.0128, -0.6599,  0.6147, -1.7202, -1.4808,\n",
      "         0.2645, -2.3819,  0.7695, -0.0388, -2.9107, -0.8483, -0.4905, -0.6892,\n",
      "        -0.4986, -2.8601, -0.6190, -0.2680, -1.1945, -0.6605, -3.5311,  2.3792,\n",
      "        -4.1291, -2.1390,  0.4873, -1.9623, -1.2197, -0.3019, -0.8374, -0.3911,\n",
      "        -3.2980,  0.9244, -2.4552,  0.2345, -0.8460, -0.5764,  1.1694,  0.0164,\n",
      "        -0.1744,  0.0498, -2.3897, -2.5927, -2.4714, -2.0355, -2.2547, -1.7988,\n",
      "        -0.3256,  1.4965,  0.9051, -0.5459, -1.0448, -1.4143, -3.6740, -1.8247,\n",
      "        -1.0343,  0.1974, -0.3890,  0.6471, -2.8056, -0.8956, -3.5039, -0.9700,\n",
      "        -0.6316, -1.2514, -0.6394, -0.8135, -2.1725, -1.8535,  1.5476, -0.8077,\n",
      "         0.0956,  0.0954, -3.5108,  0.4975,  0.0544,  1.4920, -3.6052, -2.3216],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.conv2.weight', tensor([[[[-1.0569e-03, -1.1655e-02, -3.6572e-02],\n",
      "          [ 1.1646e-02,  9.6438e-03, -1.8771e-02],\n",
      "          [ 7.4627e-04, -3.0688e-02, -5.4393e-03]],\n",
      "\n",
      "         [[ 1.9654e-02,  5.3084e-03, -1.1607e-02],\n",
      "          [-1.4723e-02,  5.6322e-02,  3.4617e-02],\n",
      "          [ 3.9644e-02, -1.9067e-02, -2.4182e-02]],\n",
      "\n",
      "         [[ 5.0307e-02, -2.1990e-02, -2.0607e-02],\n",
      "          [ 1.0209e-02,  8.5472e-03, -6.2557e-03],\n",
      "          [-3.0898e-02, -2.1137e-02,  2.6006e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1666e-02,  8.7013e-02, -5.8883e-02],\n",
      "          [-8.7601e-02,  2.4003e-02, -9.2656e-02],\n",
      "          [-4.7234e-02,  8.8015e-02, -3.1330e-02]],\n",
      "\n",
      "         [[-1.1093e-02, -1.9080e-01, -2.4098e-03],\n",
      "          [ 1.7877e-03, -1.0533e-02,  5.9489e-02],\n",
      "          [-3.8988e-02, -1.0955e-01, -1.4830e-02]],\n",
      "\n",
      "         [[ 4.0988e-02, -5.3570e-02,  1.7341e-02],\n",
      "          [ 4.8196e-02,  1.1657e-01, -5.0820e-03],\n",
      "          [-2.6799e-02,  6.5847e-02, -4.1077e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0230e-01,  9.7790e-02,  1.6434e-01],\n",
      "          [ 1.0637e-01,  1.1623e-01,  1.6060e-01],\n",
      "          [ 1.3511e-01,  1.3651e-01,  1.1071e-01]],\n",
      "\n",
      "         [[-8.6343e-02, -1.2224e-02, -4.6275e-02],\n",
      "          [-3.6791e-02, -1.3996e-01, -1.3550e-01],\n",
      "          [-6.5269e-02, -1.4018e-01, -1.0623e-01]],\n",
      "\n",
      "         [[ 8.8904e-02, -4.7713e-02, -4.7310e-02],\n",
      "          [ 1.4144e-02,  2.0591e-02, -3.9764e-02],\n",
      "          [-4.7904e-03, -8.3006e-03, -8.5651e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3430e-02,  9.2219e-03,  7.6635e-03],\n",
      "          [ 3.8118e-05,  1.5663e-02,  3.0218e-02],\n",
      "          [-4.8170e-02,  5.0926e-03,  5.4249e-02]],\n",
      "\n",
      "         [[-7.7045e-04, -1.6486e-02,  4.0103e-02],\n",
      "          [ 7.7251e-02, -4.7895e-02, -4.3376e-02],\n",
      "          [ 1.3619e-01,  5.6413e-02, -5.5296e-02]],\n",
      "\n",
      "         [[ 1.1906e-02,  2.5209e-02, -4.7202e-02],\n",
      "          [ 9.5736e-02, -4.2493e-02, -7.1928e-02],\n",
      "          [ 7.0238e-02, -2.6972e-02, -2.6995e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6621e-03, -4.8902e-03,  2.1102e-03],\n",
      "          [ 1.6529e-02,  1.4903e-04,  3.2087e-02],\n",
      "          [-8.5477e-03,  3.1598e-02,  6.7904e-05]],\n",
      "\n",
      "         [[ 3.3497e-02, -6.8091e-02,  6.8877e-03],\n",
      "          [-4.9523e-02, -6.8322e-02,  3.6292e-02],\n",
      "          [ 5.7529e-02,  7.6780e-02,  3.2050e-02]],\n",
      "\n",
      "         [[-4.0343e-02, -1.0567e-02, -4.2618e-02],\n",
      "          [-2.6565e-02, -7.2162e-04,  3.7221e-03],\n",
      "          [-5.0999e-02, -1.0744e-02,  7.1907e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8216e-02, -1.0470e-01, -4.8870e-04],\n",
      "          [ 5.3481e-02,  4.3966e-02,  4.5232e-02],\n",
      "          [ 2.8394e-02,  5.3989e-02,  3.7584e-02]],\n",
      "\n",
      "         [[ 2.2190e-02,  2.9099e-02,  1.0672e-02],\n",
      "          [ 2.0555e-02,  5.3637e-02,  9.1637e-03],\n",
      "          [ 4.0379e-02,  8.3322e-02, -9.2066e-03]],\n",
      "\n",
      "         [[ 8.1118e-02,  6.8541e-02,  3.7371e-02],\n",
      "          [ 3.2736e-02,  8.0574e-02,  1.9031e-02],\n",
      "          [ 2.8990e-02,  4.4833e-02, -3.8202e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.5831e-01, -5.3489e-01, -2.0015e-01],\n",
      "          [-2.1486e-02, -3.0427e-02, -8.4873e-03],\n",
      "          [ 9.8651e-02,  2.6570e-01,  1.6172e-01]],\n",
      "\n",
      "         [[-1.7151e-02, -4.2496e-02, -9.4475e-02],\n",
      "          [-8.2709e-02, -1.8566e-01, -1.6653e-01],\n",
      "          [-2.1637e-01, -4.7397e-01, -1.9762e-01]],\n",
      "\n",
      "         [[-7.4327e-02, -1.0149e-01, -8.6452e-03],\n",
      "          [-5.5152e-03, -1.4027e-02,  1.0946e-02],\n",
      "          [ 2.5621e-02,  7.2893e-02,  4.4424e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7167e-02,  1.6848e-02, -3.8715e-02],\n",
      "          [ 2.3930e-02,  3.9914e-03,  2.2515e-03],\n",
      "          [ 2.6239e-02,  3.6672e-02,  1.7768e-02]],\n",
      "\n",
      "         [[ 8.1975e-03,  3.7022e-02,  3.0945e-03],\n",
      "          [ 6.0874e-02,  1.9561e-03,  2.8346e-02],\n",
      "          [ 1.5682e-02,  7.4327e-02,  2.2237e-02]],\n",
      "\n",
      "         [[ 4.9202e-02, -3.5579e-02,  8.6280e-03],\n",
      "          [ 2.7047e-03,  3.2184e-02, -3.8047e-03],\n",
      "          [ 1.7404e-02,  8.4329e-02, -2.7709e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4391e-02, -7.5765e-02,  2.9966e-02],\n",
      "          [ 1.7745e-02, -3.0422e-02,  8.7122e-03],\n",
      "          [ 1.1764e-02,  5.9028e-02, -5.5824e-03]],\n",
      "\n",
      "         [[-1.0934e-02, -3.8905e-02, -1.5120e-02],\n",
      "          [-1.2345e-02,  7.8533e-02,  2.1043e-02],\n",
      "          [-8.9506e-02,  1.4922e-02, -3.7050e-03]],\n",
      "\n",
      "         [[-1.0102e-01, -6.5687e-02,  7.1834e-02],\n",
      "          [-5.5488e-02, -1.2850e-01,  1.1294e-01],\n",
      "          [-2.9003e-02,  3.3426e-02,  1.4050e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6458e-02, -2.7955e-02,  9.7322e-02],\n",
      "          [-1.4057e-01,  6.8789e-02,  1.8379e-01],\n",
      "          [-5.9705e-02, -1.7706e-02,  8.9511e-02]],\n",
      "\n",
      "         [[-1.0353e-01, -8.6599e-02,  7.3534e-02],\n",
      "          [-1.5821e-01, -1.4007e-01,  6.6191e-02],\n",
      "          [-7.6835e-02,  3.2054e-02, -1.5866e-02]],\n",
      "\n",
      "         [[-1.9111e-02, -6.8468e-02,  5.9212e-02],\n",
      "          [-7.1382e-02, -2.3609e-02,  2.5433e-02],\n",
      "          [ 5.7754e-02,  5.1761e-03,  4.7541e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1688e-01, -1.1971e-01,  1.0432e-02],\n",
      "          [-7.6365e-02, -3.6069e-02,  7.6260e-02],\n",
      "          [-7.7158e-02,  1.3399e-01,  1.4026e-01]],\n",
      "\n",
      "         [[ 9.3005e-03,  2.5446e-02,  3.4105e-02],\n",
      "          [ 1.0450e-02,  7.1148e-02,  5.1510e-02],\n",
      "          [-1.2792e-01, -1.2857e-01,  9.0199e-02]],\n",
      "\n",
      "         [[-5.8958e-02, -1.4252e-02,  8.1905e-02],\n",
      "          [-1.9989e-01, -4.1554e-02,  7.6283e-02],\n",
      "          [-6.8530e-02,  5.6793e-02,  8.7995e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8941e-02,  4.8438e-02,  6.0868e-02],\n",
      "          [-4.3206e-03, -1.9090e-02,  3.2238e-02],\n",
      "          [ 6.6573e-04, -2.9166e-02,  4.3190e-03]],\n",
      "\n",
      "         [[-5.8334e-02, -2.4546e-02,  3.2194e-03],\n",
      "          [-1.5308e-03, -8.4044e-02,  5.0086e-02],\n",
      "          [ 1.4837e-03, -4.5293e-02, -1.7716e-02]],\n",
      "\n",
      "         [[-5.7946e-02, -5.1299e-02, -2.9962e-02],\n",
      "          [ 1.7641e-02,  5.9575e-03,  3.3371e-03],\n",
      "          [-1.2719e-02,  3.1627e-03, -1.9584e-02]]]], device='cuda:0')), ('backbone.model.layer3.1.bn2.weight', tensor([ 2.0704,  2.1021,  2.3373,  2.4358,  2.3037,  1.7597,  2.2366,  1.9680,\n",
      "         1.7363,  3.3435,  2.6317,  1.4723,  2.3599,  2.0877,  2.3056,  2.7585,\n",
      "         2.8485,  2.1891,  2.0657,  2.8919,  2.2038,  2.3033,  2.3119,  2.1177,\n",
      "         2.5155,  3.4576,  3.7031,  3.9064,  2.0927,  2.5272,  2.5318,  1.8404,\n",
      "         2.9229,  3.0601,  3.1156,  2.2212,  3.1393,  3.1125,  2.9913,  1.9106,\n",
      "         2.5190,  3.1338,  2.1565,  2.1869,  1.9112,  1.9167,  2.5405,  2.1728,\n",
      "         3.5876,  2.5285,  2.3368,  3.3751,  2.5458,  1.9890,  2.4741,  2.1576,\n",
      "         4.6840,  1.3743,  2.3042,  2.8167,  2.9569,  2.2038,  2.9032,  3.3110,\n",
      "         3.0237,  2.4610,  2.7520,  3.1273,  2.4975,  3.1409,  2.5585,  2.4572,\n",
      "         2.0431,  1.9360,  2.1565,  2.2460,  2.5161,  3.3656,  2.7832,  2.3560,\n",
      "         2.5567,  2.8109,  2.7257,  5.1802,  2.8229,  2.6472,  3.4049,  2.7719,\n",
      "         2.1369,  2.0951,  2.3009,  2.1414,  2.3776,  2.0742,  2.2348,  2.7237,\n",
      "         2.5537,  2.0717,  2.6775,  2.1324,  2.7294,  2.5977,  3.3268,  1.9891,\n",
      "         2.5726,  2.9758,  2.5672,  2.5584,  2.2643,  1.8131,  2.2620,  2.5837,\n",
      "         2.7791,  2.2369,  2.2774,  2.2261,  2.7319,  1.7291,  1.8730,  1.7476,\n",
      "         2.3920,  2.4554,  2.0345,  2.2352,  2.3184,  4.5633,  2.1208,  2.0382,\n",
      "         3.2533,  2.4598,  1.8305,  2.9690,  3.3118,  2.8938,  3.0277,  1.8326,\n",
      "         2.0528,  1.8626,  2.2811,  2.1759,  2.7206,  2.0516,  2.2302,  2.4726,\n",
      "         2.3224,  2.9455,  2.3888,  2.5699,  2.5596,  1.5575,  2.4829,  2.6489,\n",
      "         1.8979,  2.3866,  1.7847,  1.5195,  2.0500,  2.1464,  2.2793,  2.0354,\n",
      "         4.3033,  3.9817,  2.4931,  2.1711,  2.3683,  2.4458,  2.7998,  2.8449,\n",
      "         1.8599,  2.5116,  2.3855,  2.3233,  2.5930,  2.7587,  2.0590,  1.8935,\n",
      "         2.2371,  2.0442,  2.4584,  1.5632,  1.9256,  2.4100,  2.0023,  2.2999,\n",
      "         2.4433,  2.8762,  2.1239,  3.1263,  2.3622,  3.6667,  2.2817,  2.0306,\n",
      "         2.0529,  2.4114,  1.9497,  3.0695,  2.1377,  2.4007,  2.7392,  3.0785,\n",
      "         1.9526,  2.6593,  1.7101,  2.2625,  2.6056,  2.3793,  3.1576,  0.8589,\n",
      "         2.1623, 14.2481,  1.7535,  2.3313,  1.8761,  1.8566,  2.4248,  1.9818,\n",
      "         2.0285,  3.5361,  1.4842,  2.5250,  2.4428,  2.0566,  2.0675,  2.8989,\n",
      "         2.4757,  2.2054,  2.6942,  2.2030,  2.2033,  2.2645,  2.5605,  1.6484,\n",
      "         2.2971,  2.0399,  1.7264,  2.1755,  2.4325,  2.0912,  2.4002,  2.2439,\n",
      "         2.0250,  4.6822,  2.2632,  1.6435,  1.9792,  2.0860,  1.9496,  2.2664,\n",
      "         2.8554,  2.6318,  2.6382,  2.0211,  2.4678,  3.2663,  2.5654,  3.5744],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.bn2.bias', tensor([ 0.4520, -0.4894, -2.0719, -1.2573, -2.6730,  0.3730, -2.0945, -1.0438,\n",
      "         0.2009, -0.5452, -1.2855, -1.9986,  0.2818, -0.1265, -1.8576, -1.4840,\n",
      "        -0.5387, -0.6423, -2.9596, -1.8901, -1.0492,  0.2413, -0.0565, -1.4100,\n",
      "        -0.6141,  0.0786, -0.1203, -0.8656, -2.2461, -0.3288, -0.7744, -2.3125,\n",
      "        -0.0073, -1.1720,  0.9114,  0.3772,  0.1431, -0.0524, -0.7505, -4.4793,\n",
      "        -0.7966, -1.0151,  0.2210, -0.2963,  0.2097, -2.0222, -1.3150, -1.0907,\n",
      "        -0.3834, -1.0760, -1.0115, -0.7289, -1.5399,  0.5255, -1.4395, -2.0144,\n",
      "        -2.6826, -2.0150, -3.1710, -0.3500, -0.1949, -1.0819,  0.5823, -0.5840,\n",
      "        -1.7431, -1.2651, -0.4412, -1.2133, -2.8716, -1.4631, -1.4910, -0.1022,\n",
      "        -0.8277, -3.0056,  0.1770, -0.7260, -0.4900, -3.6018, -2.1165, -1.2506,\n",
      "        -0.2349, -1.1076, -1.1559, -0.0342, -0.6436, -3.3886, -0.7755, -0.6793,\n",
      "        -1.3957,  0.0295, -0.2663, -0.2705, -1.3999, -1.7271,  1.0402, -2.9163,\n",
      "         0.1746, -0.2979, -1.5530, -1.5999, -0.4812, -1.7875, -2.3971, -3.0596,\n",
      "        -1.3683, -2.0022, -0.3390, -0.9240, -1.5094, -2.4695,  0.5413, -0.5589,\n",
      "        -1.8215, -0.6415, -0.4869, -0.5313, -1.3063,  0.3372, -1.6285, -0.9261,\n",
      "         0.4363, -1.8500, -2.4031, -1.4148, -2.2996, -2.2445, -1.1888,  0.4441,\n",
      "        -0.5389, -0.4054, -3.0481, -1.2118,  0.7202, -1.5307, -0.4727, -0.4361,\n",
      "        -0.4158, -0.3499, -0.4372, -2.0505, -2.1950,  0.0414, -2.0437, -1.2938,\n",
      "         0.1171,  0.1898,  0.3439, -0.4527,  0.1098, -2.4935, -0.0060, -0.3531,\n",
      "        -0.1576,  0.2071, -0.3281, -1.3501,  0.4831, -1.1355, -0.5586, -0.1566,\n",
      "        -1.3945, -2.3485, -3.2646, -1.1916, -1.1906, -2.1121,  1.8985, -0.7669,\n",
      "        -1.5270, -0.5856, -1.1315, -1.4907, -0.0324, -0.2391, -3.1627,  0.9090,\n",
      "        -0.3843, -0.4619, -0.4379, -1.3238, -0.7553,  0.0658, -1.7907, -1.2325,\n",
      "        -1.4928, -1.3485,  0.4761, -0.4506,  0.1582, -0.4360, -0.4361, -4.4919,\n",
      "        -1.1644, -1.2812, -1.4077, -1.5351,  0.0259, -1.8354,  0.4670, -1.5656,\n",
      "        -1.0174,  0.0614, -1.3280,  0.0949, -3.6344,  0.0190,  0.2467,  0.2575,\n",
      "        -1.3675, -2.6866, -0.5745, -1.1239, -0.3294, -0.6263, -2.4166, -1.7473,\n",
      "        -0.5153, -2.4608, -1.6700, -0.1480,  0.7768, -1.2190, -0.3067, -0.8808,\n",
      "        -0.5287,  1.2746, -1.6345, -1.1948, -2.9572, -1.0837, -0.9019,  0.1721,\n",
      "        -0.3728, -0.0695, -1.6809, -0.8561, -0.1525,  0.0666, -0.2680, -1.8339,\n",
      "        -1.3712, -1.9117, -1.4712,  1.1837, -1.4145, -0.6051, -0.5736, -2.1988,\n",
      "        -0.5839, -0.2765, -0.9376, -3.2155, -0.3959, -0.2802, -1.3275, -0.3025],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.conv3.weight', tensor([[[[ 0.0419]],\n",
      "\n",
      "         [[ 0.0314]],\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[-0.0077]],\n",
      "\n",
      "         [[-0.0401]]],\n",
      "\n",
      "\n",
      "        [[[-0.0612]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[ 0.1090]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0024]],\n",
      "\n",
      "         [[ 0.0204]],\n",
      "\n",
      "         [[ 0.0693]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0064]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[-0.0498]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0794]],\n",
      "\n",
      "         [[-0.0215]],\n",
      "\n",
      "         [[-0.1588]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0023]],\n",
      "\n",
      "         [[ 0.1266]],\n",
      "\n",
      "         [[-0.0314]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1446]],\n",
      "\n",
      "         [[-0.0223]],\n",
      "\n",
      "         [[-0.0118]]],\n",
      "\n",
      "\n",
      "        [[[-0.0848]],\n",
      "\n",
      "         [[ 0.1269]],\n",
      "\n",
      "         [[ 0.0082]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[-0.0570]],\n",
      "\n",
      "         [[-0.0275]]],\n",
      "\n",
      "\n",
      "        [[[-0.0401]],\n",
      "\n",
      "         [[-0.0451]],\n",
      "\n",
      "         [[ 0.0165]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0023]],\n",
      "\n",
      "         [[-0.0307]],\n",
      "\n",
      "         [[ 0.0107]]]], device='cuda:0')), ('backbone.model.layer3.1.bn3.weight', tensor([-1.4342, -1.3489,  2.7093,  ..., -3.4957,  3.4555, -2.3019],\n",
      "       device='cuda:0')), ('backbone.model.layer3.1.bn3.bias', tensor([-0.4778, -0.4485,  0.5379,  ..., -0.6582, -0.5048, -0.6375],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.conv1.weight', tensor([[[[-0.0999]],\n",
      "\n",
      "         [[-0.0818]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0902]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         [[ 0.0407]]],\n",
      "\n",
      "\n",
      "        [[[-0.0438]],\n",
      "\n",
      "         [[ 0.0117]],\n",
      "\n",
      "         [[-0.0681]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[-0.0144]],\n",
      "\n",
      "         [[ 0.0105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019]],\n",
      "\n",
      "         [[ 0.0221]],\n",
      "\n",
      "         [[ 0.0716]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0614]],\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[-0.0415]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0570]],\n",
      "\n",
      "         [[-0.0246]],\n",
      "\n",
      "         [[ 0.0607]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0196]],\n",
      "\n",
      "         [[ 0.0154]],\n",
      "\n",
      "         [[ 0.0313]]],\n",
      "\n",
      "\n",
      "        [[[-0.0220]],\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0457]],\n",
      "\n",
      "         [[ 0.0431]],\n",
      "\n",
      "         [[-0.0381]]],\n",
      "\n",
      "\n",
      "        [[[-0.0835]],\n",
      "\n",
      "         [[-0.0122]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0072]],\n",
      "\n",
      "         [[ 0.0773]],\n",
      "\n",
      "         [[ 0.0566]]]], device='cuda:0')), ('backbone.model.layer3.2.bn1.weight', tensor([1.5967, 1.9867, 5.9114, 3.3899, 2.3188, 2.5263, 1.7707, 1.6695, 3.8486,\n",
      "        3.1560, 2.1669, 2.1349, 1.7199, 3.3125, 1.8394, 5.1074, 1.4954, 2.7587,\n",
      "        9.3811, 2.9675, 3.2287, 3.3711, 2.1868, 3.5000, 2.3377, 3.2956, 5.4763,\n",
      "        3.3229, 2.4959, 1.7563, 1.3025, 3.4048, 1.3323, 2.0382, 1.9436, 1.5594,\n",
      "        1.8807, 1.7702, 1.7929, 2.1191, 2.6590, 2.5039, 2.1438, 3.4171, 3.3061,\n",
      "        2.2635, 1.6914, 2.2385, 3.7349, 2.0396, 3.2278, 2.1600, 3.1834, 1.1082,\n",
      "        2.7399, 2.9488, 2.3654, 1.7355, 1.7578, 3.5751, 2.0314, 2.0553, 4.6395,\n",
      "        2.1609, 3.8889, 1.6094, 2.5084, 1.9051, 2.1775, 2.5089, 1.6157, 1.9197,\n",
      "        1.6676, 1.8413, 3.2613, 3.7034, 3.3945, 1.7240, 1.8369, 2.5246, 1.7714,\n",
      "        2.1050, 1.7988, 1.9273, 2.1623, 2.4347, 1.4532, 2.1884, 1.5818, 2.3456,\n",
      "        3.1133, 1.8174, 4.1358, 2.1030, 2.4920, 1.4988, 6.5515, 3.0130, 2.9183,\n",
      "        4.2277, 2.4918, 2.3116, 4.1148, 3.1705, 2.7428, 3.3114, 1.9734, 1.5778,\n",
      "        1.6666, 6.1665, 2.2718, 2.3492, 2.5427, 2.4952, 2.4634, 1.5782, 1.6968,\n",
      "        2.6725, 1.8410, 1.9982, 3.9390, 2.6861, 1.5773, 1.8700, 2.3026, 2.3625,\n",
      "        3.5645, 2.1607, 2.8686, 2.6020, 2.2314, 4.0603, 2.1385, 2.5058, 1.6944,\n",
      "        2.0683, 2.3429, 2.2035, 1.7636, 1.8867, 2.3319, 2.9216, 2.2116, 2.1436,\n",
      "        3.8773, 2.1006, 4.1490, 1.7724, 2.1052, 2.2548, 2.6560, 2.4268, 1.5415,\n",
      "        3.5438, 2.1862, 2.5199, 1.8500, 2.3544, 2.8137, 2.1989, 2.8398, 7.9282,\n",
      "        2.2083, 2.4294, 2.0046, 1.0861, 2.3656, 3.0486, 1.3400, 1.7528, 1.6818,\n",
      "        1.5290, 1.6233, 1.6303, 2.3241, 1.9096, 2.0725, 2.2374, 2.3913, 1.8304,\n",
      "        2.5805, 3.4546, 1.9433, 2.4239, 2.1909, 2.3142, 1.4636, 2.8146, 1.5988,\n",
      "        2.3152, 1.5003, 1.6783, 2.0033, 2.2853, 2.3658, 2.6146, 1.5655, 2.8736,\n",
      "        2.0375, 3.7613, 1.7490, 1.8766, 1.3818, 1.4984, 2.6067, 3.1406, 3.5875,\n",
      "        1.8120, 2.1625, 2.6915, 1.5371, 2.8082, 1.7525, 2.2013, 2.5688, 1.7647,\n",
      "        1.0668, 1.5870, 1.0280, 1.0258, 1.4568, 1.3122, 1.6940, 1.6548, 1.4966,\n",
      "        2.0941, 2.3467, 1.9902, 0.6368, 4.1747, 4.9501, 2.1041, 3.0833, 3.8972,\n",
      "        2.7375, 1.7418, 2.8863, 3.7437, 3.1111, 1.3509, 1.4713, 3.1319, 5.3327,\n",
      "        2.1600, 1.4042, 2.9398, 2.3932, 2.1178, 3.3656, 1.4891, 0.8534, 1.9583,\n",
      "        2.2670, 1.2547, 1.7204, 1.4606], device='cuda:0')), ('backbone.model.layer3.2.bn1.bias', tensor([-1.9152e+00,  2.2290e-01, -1.2447e+00, -1.8340e+00, -8.3207e-01,\n",
      "         1.1020e-01, -5.2723e-02, -1.4869e+00, -3.8262e-01,  8.0865e-01,\n",
      "        -2.9824e+00, -6.7831e-01,  1.3020e-02,  7.1310e-01, -1.3254e+00,\n",
      "        -2.3395e+00, -3.0104e+00,  1.1112e-01,  2.6435e+00, -1.0367e+00,\n",
      "         3.6332e-01, -1.0468e+00, -1.1506e+00, -1.1022e+00, -1.3322e+00,\n",
      "         1.4246e+00, -2.4564e+00, -9.1170e-01, -1.2907e+00, -1.9675e+00,\n",
      "        -1.4185e+00, -1.9188e+00, -2.4690e+00, -6.2502e-01,  3.5406e-02,\n",
      "        -1.9871e-01,  3.7515e-01,  5.0573e-01, -9.1372e-01,  1.1642e+00,\n",
      "         2.7319e-01,  2.8035e-01, -2.0674e+00, -6.9401e-01, -1.0094e+00,\n",
      "        -3.8289e+00,  2.1944e-01,  7.1007e-01, -4.2999e+00,  2.8258e-01,\n",
      "        -2.9316e+00,  2.4949e-01, -1.3262e+00, -3.0173e+00, -2.0675e-01,\n",
      "        -1.6922e+00,  2.8603e-01, -3.3530e+00, -1.9905e-01, -2.6368e-01,\n",
      "        -1.9892e+00,  4.7776e-01, -3.3790e+00,  8.4813e-01, -3.6403e-01,\n",
      "        -2.2500e-01, -1.4457e+00,  2.1313e-01, -1.2212e+00, -2.6885e-01,\n",
      "        -1.9574e+00, -6.3878e-01, -2.6062e+00, -1.2133e-02, -1.9388e-01,\n",
      "        -5.9473e-01, -3.9696e-01, -1.3505e+00,  5.3656e-01, -2.9727e+00,\n",
      "         1.2810e+00,  1.0541e+00,  1.1805e+00, -3.2929e-01, -1.6179e+00,\n",
      "        -1.3118e-01, -2.0663e+00, -1.2316e+00, -1.7986e+00, -6.9152e-01,\n",
      "        -1.0090e+00, -1.9192e+00, -1.7283e+00, -2.5961e+00, -8.5511e-01,\n",
      "         1.5235e+00, -1.4780e-01, -1.6104e+00, -3.6279e-01,  2.1868e+00,\n",
      "        -1.3836e+00, -4.1517e+00,  1.9725e-01, -1.0111e+00,  2.8664e-01,\n",
      "        -2.7819e+00, -1.9255e+00,  2.9294e-01, -2.0732e+00, -1.2969e+00,\n",
      "         1.4131e-01, -1.1414e+00,  1.0923e-01, -1.1548e-01, -2.7586e+00,\n",
      "        -9.8461e-01, -6.7238e-01, -1.2984e+00,  1.2161e+00, -1.0253e+00,\n",
      "        -2.4343e+00, -2.6982e-01, -1.7554e-01,  3.6260e-01, -3.5795e+00,\n",
      "         2.7612e-02, -4.5228e-01, -1.9063e+00,  1.7975e-02,  1.1564e-01,\n",
      "        -3.4638e-01, -4.7017e+00, -2.4120e+00, -2.7796e+00, -3.3596e+00,\n",
      "         7.1143e-01,  4.4922e-01, -8.2693e-01, -1.7714e+00, -1.6241e+00,\n",
      "         1.3414e+00, -3.6527e+00,  1.5094e-01,  1.7124e+00, -6.9414e+00,\n",
      "        -1.3995e+00, -4.0581e+00, -3.0568e+00, -1.3540e+00, -2.8832e+00,\n",
      "         2.9670e+00, -2.3142e+00, -2.0605e+00, -2.6776e+00, -1.4220e+00,\n",
      "        -4.7322e-01, -1.5544e+00, -1.8154e+00, -4.4336e-01,  2.8070e-03,\n",
      "         2.2437e-01, -2.4715e+00, -6.2946e-01,  4.1325e-01,  1.1764e-01,\n",
      "        -2.8712e+00,  9.0518e-02,  3.1488e-01, -3.4003e+00, -4.6061e-01,\n",
      "        -8.1940e-01,  1.3713e+00, -1.1252e+00, -1.1979e-01,  4.4928e-02,\n",
      "        -1.3069e+00, -2.9856e+00, -5.6022e-01,  2.9491e-01, -6.2542e-01,\n",
      "        -9.0575e-01,  2.2936e+00, -1.0312e+00, -7.0473e-01, -1.3433e+00,\n",
      "        -2.2080e-01, -1.4166e-01, -4.2973e+00, -1.3394e-01, -7.6027e-02,\n",
      "         4.1910e-01, -3.0279e-01, -1.0107e+00, -1.0132e+00, -8.7094e-01,\n",
      "        -1.2152e+00, -1.1603e+00,  5.1390e+00, -1.4957e+00, -1.4581e+00,\n",
      "        -1.0433e+00,  2.9810e-01,  3.7403e-01, -1.5533e+00, -1.2997e+00,\n",
      "        -1.6096e+00, -6.9629e-01, -2.7859e-02,  8.9123e-01,  2.7504e-01,\n",
      "        -2.2270e+00, -1.4392e+00, -1.0627e-01, -1.6608e+00, -5.3382e-01,\n",
      "        -8.4077e-01,  2.9701e-01,  6.7888e-01, -3.2519e-01, -1.0299e+00,\n",
      "        -8.5510e-01, -3.1546e-01, -2.1187e-01, -9.6136e-01, -6.3044e-02,\n",
      "        -6.5074e-02, -6.6847e-01, -1.2084e-01, -8.4633e-01, -4.3190e+00,\n",
      "        -8.3079e+00, -1.3756e+00,  3.5278e-01,  9.0118e-02, -4.0783e+00,\n",
      "         5.7977e-01,  3.0619e-01, -5.6524e+00, -3.4165e-01,  1.4117e-01,\n",
      "        -8.0940e-01, -5.0793e-01, -2.3183e+00, -5.2178e-02,  1.1649e+00,\n",
      "        -2.0828e+00,  9.1538e-02, -2.6840e+00, -2.5027e+00, -5.1534e-01,\n",
      "        -1.4219e-01, -1.8382e+00,  1.2075e+00, -1.1054e+00, -9.0725e-01,\n",
      "         3.7477e-01], device='cuda:0')), ('backbone.model.layer3.2.conv2.weight', tensor([[[[ 0.0331,  0.0418, -0.0139],\n",
      "          [ 0.0519, -0.0094, -0.1320],\n",
      "          [ 0.0644,  0.0468, -0.0873]],\n",
      "\n",
      "         [[ 0.0129, -0.0053,  0.0077],\n",
      "          [ 0.0084, -0.0667, -0.0136],\n",
      "          [-0.0109, -0.0565, -0.0038]],\n",
      "\n",
      "         [[-0.0970, -0.1211, -0.0122],\n",
      "          [-0.0188, -0.1045, -0.0619],\n",
      "          [ 0.0037, -0.0639, -0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0695, -0.0217, -0.1142],\n",
      "          [ 0.0259,  0.0138, -0.2251],\n",
      "          [ 0.0010, -0.0482, -0.1083]],\n",
      "\n",
      "         [[ 0.0456,  0.0201, -0.0499],\n",
      "          [ 0.0444, -0.0132, -0.1131],\n",
      "          [ 0.0526,  0.0092, -0.0437]],\n",
      "\n",
      "         [[ 0.0130, -0.0368, -0.1599],\n",
      "          [ 0.0306, -0.0721, -0.1296],\n",
      "          [ 0.0102,  0.0220, -0.0780]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0045,  0.0063, -0.0658],\n",
      "          [-0.0040,  0.0402, -0.0071],\n",
      "          [-0.0137, -0.0057, -0.0219]],\n",
      "\n",
      "         [[ 0.0518, -0.0084,  0.0694],\n",
      "          [ 0.0136, -0.2061,  0.0372],\n",
      "          [ 0.0178, -0.0036,  0.0671]],\n",
      "\n",
      "         [[-0.0491, -0.0596,  0.0144],\n",
      "          [-0.0795, -0.1470, -0.0110],\n",
      "          [-0.0356, -0.0542, -0.0245]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0224, -0.0271,  0.0409],\n",
      "          [-0.0380,  0.1213,  0.0393],\n",
      "          [-0.0193,  0.0296,  0.0298]],\n",
      "\n",
      "         [[-0.0051, -0.0070,  0.0134],\n",
      "          [ 0.0006, -0.0830, -0.0024],\n",
      "          [ 0.0159,  0.0018,  0.0282]],\n",
      "\n",
      "         [[-0.0925, -0.0151,  0.1617],\n",
      "          [-0.1799, -0.0599,  0.2136],\n",
      "          [-0.1298,  0.0680,  0.2019]]],\n",
      "\n",
      "\n",
      "        [[[-0.0407, -0.0726, -0.1071],\n",
      "          [-0.0330, -0.0034, -0.0119],\n",
      "          [ 0.0048, -0.0018,  0.0057]],\n",
      "\n",
      "         [[ 0.0057, -0.0883,  0.0312],\n",
      "          [-0.0012,  0.0233,  0.0385],\n",
      "          [ 0.0449, -0.0622, -0.0469]],\n",
      "\n",
      "         [[ 0.0239, -0.0505,  0.0518],\n",
      "          [ 0.0148, -0.0345,  0.0188],\n",
      "          [ 0.0609, -0.0214,  0.0374]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0109, -0.0356,  0.0143],\n",
      "          [ 0.0057, -0.0317,  0.0092],\n",
      "          [ 0.0352, -0.0475, -0.0204]],\n",
      "\n",
      "         [[-0.0850,  0.0693, -0.0673],\n",
      "          [-0.1355,  0.1037, -0.1019],\n",
      "          [-0.1373,  0.0331, -0.1290]],\n",
      "\n",
      "         [[-0.0588,  0.1091, -0.0087],\n",
      "          [-0.0789,  0.0646, -0.0345],\n",
      "          [-0.0139,  0.0530, -0.0911]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0008,  0.0667,  0.0148],\n",
      "          [-0.0647, -0.0767, -0.0391],\n",
      "          [-0.0719,  0.0296, -0.0386]],\n",
      "\n",
      "         [[ 0.0399,  0.0344,  0.0808],\n",
      "          [-0.0439, -0.0230, -0.0768],\n",
      "          [-0.0085, -0.0245, -0.0083]],\n",
      "\n",
      "         [[ 0.0490,  0.0170,  0.0612],\n",
      "          [ 0.0722,  0.0529,  0.0722],\n",
      "          [ 0.0414, -0.0447, -0.0137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0406, -0.0202, -0.0821],\n",
      "          [-0.0040, -0.0141, -0.0682],\n",
      "          [ 0.0460,  0.0437,  0.0551]],\n",
      "\n",
      "         [[ 0.0023,  0.0866,  0.0411],\n",
      "          [ 0.0163,  0.0637,  0.0285],\n",
      "          [-0.0453, -0.0748, -0.0508]],\n",
      "\n",
      "         [[-0.0203,  0.0309,  0.0882],\n",
      "          [-0.0019,  0.0197, -0.0208],\n",
      "          [ 0.0696,  0.0490, -0.0069]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174,  0.0152,  0.0658],\n",
      "          [-0.0446, -0.1576,  0.0093],\n",
      "          [ 0.0545, -0.0209,  0.0266]],\n",
      "\n",
      "         [[ 0.0022,  0.0970,  0.0531],\n",
      "          [ 0.0565,  0.0766,  0.0586],\n",
      "          [-0.0039, -0.1158, -0.0400]],\n",
      "\n",
      "         [[ 0.0114, -0.0129,  0.0146],\n",
      "          [ 0.0166,  0.0531,  0.0645],\n",
      "          [ 0.0060,  0.0854,  0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0412, -0.0809, -0.0673],\n",
      "          [ 0.0618,  0.0729,  0.0646],\n",
      "          [ 0.1169,  0.1020,  0.1042]],\n",
      "\n",
      "         [[ 0.0062,  0.0938,  0.0114],\n",
      "          [-0.0315,  0.0352, -0.0172],\n",
      "          [-0.0968, -0.0830, -0.1123]],\n",
      "\n",
      "         [[-0.0335,  0.0804,  0.0828],\n",
      "          [-0.0056, -0.0236,  0.0201],\n",
      "          [-0.0287, -0.0148,  0.0223]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0234,  0.0267,  0.0167],\n",
      "          [-0.0196, -0.0275, -0.0393],\n",
      "          [-0.0048,  0.0093, -0.0417]],\n",
      "\n",
      "         [[-0.0172, -0.0227, -0.0122],\n",
      "          [ 0.0443,  0.1102,  0.0013],\n",
      "          [-0.0076, -0.0188,  0.0492]],\n",
      "\n",
      "         [[-0.0200,  0.0284, -0.0465],\n",
      "          [-0.1130, -0.0075, -0.0093],\n",
      "          [-0.1139,  0.0449, -0.0232]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0151, -0.1071,  0.0088],\n",
      "          [ 0.0140, -0.1309,  0.0088],\n",
      "          [ 0.0290, -0.0731,  0.0271]],\n",
      "\n",
      "         [[ 0.0402,  0.0542,  0.0075],\n",
      "          [ 0.0147,  0.0095,  0.0010],\n",
      "          [ 0.0109,  0.0605, -0.0214]],\n",
      "\n",
      "         [[ 0.0041, -0.0002, -0.0789],\n",
      "          [ 0.0178, -0.0397, -0.0148],\n",
      "          [-0.0408, -0.0922, -0.0017]]]], device='cuda:0')), ('backbone.model.layer3.2.bn2.weight', tensor([ 2.2114,  1.8234,  3.4551,  3.6621,  2.3080,  1.7785,  3.0569,  2.2961,\n",
      "         2.5763,  2.6562,  1.9590,  3.3849,  1.8798,  1.8516,  3.7038,  2.1092,\n",
      "         2.4650,  1.9162,  1.4057,  2.0683,  2.7975,  1.7420,  2.7612,  2.2874,\n",
      "         2.0891,  1.7388,  3.1214,  2.5368,  3.4771,  2.3724,  2.1352,  2.1895,\n",
      "         4.2674,  4.2627,  3.5714,  3.7944,  3.0096,  3.4272,  1.9087,  3.9581,\n",
      "         2.3385,  2.4967,  2.5859,  3.3620,  1.2844,  2.3257,  2.2908,  2.0392,\n",
      "         1.6305,  2.2665,  2.0724,  2.7280,  2.7357,  2.4761,  2.8637,  0.4054,\n",
      "        10.1352,  2.5971,  2.5924,  2.2262,  2.3573,  2.0791,  2.6785,  3.5410,\n",
      "         2.1959,  2.1487,  2.5899,  3.5776,  2.1734,  2.1629,  2.4866,  1.3711,\n",
      "         2.7187,  2.2844,  2.3990,  2.1106,  2.0360,  1.8900,  3.1626,  1.3433,\n",
      "         0.7260,  3.9220,  2.9941,  5.5950,  3.3190,  2.2297,  2.4446,  3.3986,\n",
      "         4.0177,  1.6837,  2.8903,  3.3973,  2.6501,  2.4258,  5.9766,  3.5246,\n",
      "         2.7438,  1.6172,  2.2324,  2.4395,  1.7559,  2.0885,  1.7777,  2.0031,\n",
      "         1.7896,  3.6807,  3.8690,  5.1284,  2.8414,  2.2452,  5.3140,  5.0200,\n",
      "         3.0312,  1.3180,  2.0010,  3.2371,  2.4812,  1.5194,  2.6472,  1.5730,\n",
      "         1.7094,  2.1163,  1.9037,  1.8361,  2.3339,  1.5101,  1.5229,  2.0586,\n",
      "         2.1331,  2.7791,  4.4018,  5.0755,  2.8208,  3.4605,  3.3071,  2.3730,\n",
      "         2.8333,  2.9095,  2.3483,  2.6475,  3.4106,  0.7148,  3.0844,  2.7259,\n",
      "         3.2623,  2.2036,  2.6322,  2.3080,  2.0846,  1.6973,  2.7064,  2.8703,\n",
      "         2.0850,  1.7782,  1.9213,  2.8563,  2.5149,  1.6198,  1.8326,  2.0265,\n",
      "         1.7400,  0.8162,  1.9846,  2.5447,  1.7969,  2.1347,  2.9943,  2.1408,\n",
      "         2.2889,  1.5303,  2.5518,  1.5807,  1.2971,  1.4261,  2.1251,  2.1322,\n",
      "         2.3716,  2.1964,  2.7697,  3.0116,  1.1154,  2.3292,  2.6964,  2.3166,\n",
      "         2.7991,  0.6044,  3.0374,  2.5645,  3.2292,  2.0899,  2.8657,  3.9078,\n",
      "         1.7134,  1.5339,  1.6969,  1.3111,  1.4087,  2.2053,  2.0449,  1.3374,\n",
      "         1.1172,  4.0103,  1.7741,  2.2345,  2.4109,  1.9175,  2.0508,  2.6836,\n",
      "         3.4760,  2.5525,  2.0293,  2.9613,  2.2232,  3.4337,  0.3542,  2.3294,\n",
      "         2.7053,  2.4873,  2.1737,  1.7397,  1.8075,  2.1524,  1.8988,  2.1438,\n",
      "         2.0787,  2.3788,  2.5409,  2.4502,  2.7128,  2.9784,  3.0396,  0.8101,\n",
      "         1.1788,  1.5049,  3.5460,  1.7700,  1.9396,  1.9314,  2.1097,  2.0233,\n",
      "         1.9602,  1.8034,  0.7968,  4.4605,  1.5877,  2.5540,  1.1812,  1.8891,\n",
      "         2.2658,  2.0119,  1.9361,  2.0105,  2.5830,  1.5831,  1.9344,  1.9840],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.bn2.bias', tensor([-8.6385e-01, -8.5536e-01,  9.9707e-01, -1.5402e+00, -9.2505e-01,\n",
      "        -7.0372e-01, -1.0793e+00, -2.8655e+00, -2.7758e-01, -2.0144e+00,\n",
      "        -8.1449e-01, -2.5370e+00, -9.3481e-01, -2.2524e+00, -9.9988e-01,\n",
      "         5.1532e-01,  2.1786e-01, -1.0188e-01, -1.8093e+00, -1.9103e-02,\n",
      "        -4.5471e+00, -7.0738e-01, -3.5246e-01, -2.9847e-01, -7.1803e-01,\n",
      "        -2.9809e+00, -9.4203e-01,  3.9010e-01, -1.7040e+00, -2.0974e+00,\n",
      "        -1.1470e+00, -6.4060e-01, -5.6347e-02, -4.0235e-01, -1.3066e+00,\n",
      "         5.9484e-01, -1.1488e+00,  4.1666e-01, -4.2246e+00, -8.8511e-02,\n",
      "        -9.5039e-01, -3.6596e-01, -8.4671e-01,  3.5237e-01, -2.1283e+00,\n",
      "         6.4229e-01, -5.4780e-01, -1.1855e+00,  4.0563e-02, -3.0927e-01,\n",
      "        -3.6849e-01, -1.0915e+00, -5.5338e-01, -3.2706e+00, -6.3695e-01,\n",
      "        -6.4578e-01,  2.1274e+00, -1.0564e+00, -8.1495e-01, -1.7562e+00,\n",
      "        -1.0060e+00, -2.8071e+00, -3.2226e-01, -1.3274e+00, -2.6083e+00,\n",
      "        -2.1833e+00, -1.6045e+00, -1.7173e+00, -1.9531e-01,  4.2121e-01,\n",
      "        -1.7421e+00,  2.1873e+00, -1.1494e+00, -7.1118e-01, -7.1582e-01,\n",
      "        -3.6665e-01, -3.0770e+00,  2.8523e-01, -1.0095e+00,  8.2216e-01,\n",
      "        -1.2567e+00,  6.8165e-02,  5.3905e-01, -1.2914e-02, -4.2182e+00,\n",
      "         3.2094e-01,  3.9842e-01, -1.8414e+00, -1.1959e+00, -3.4893e+00,\n",
      "        -3.9697e-01, -2.2651e+00, -3.6949e-01, -2.3067e+00,  5.5120e-01,\n",
      "        -1.7620e+00, -1.1803e+00,  1.4113e-01,  6.6054e-02, -5.3550e-01,\n",
      "        -2.3350e+00, -1.1034e+00, -8.8504e-01,  2.1226e-01, -1.5752e+00,\n",
      "        -2.3512e+00, -1.6811e+00, -2.7827e+00, -1.8326e+00, -6.9080e+00,\n",
      "        -2.9731e+00, -1.2168e+00, -1.4364e+00, -2.3539e+00, -5.4533e-01,\n",
      "        -1.6113e+00,  5.0683e-01,  1.4345e+00,  2.4934e-01,  1.0699e+00,\n",
      "        -1.1428e+00, -1.2276e+00, -1.0392e+00, -1.4418e+00, -1.6111e-01,\n",
      "        -2.1592e+00, -4.3404e-01, -5.7372e-02, -3.8764e+00, -8.0532e-01,\n",
      "        -1.0520e+00, -1.8280e+00, -1.0473e+00, -9.5436e-01, -6.7673e-01,\n",
      "         6.0775e-01, -1.8615e+00,  4.4003e-01, -1.1594e+00, -2.5750e+00,\n",
      "         6.3509e-01, -1.3786e+00, -1.0941e-01,  5.4422e-01, -2.5117e+00,\n",
      "        -1.4445e+00,  4.4561e-01,  2.6968e-03, -1.6087e+00, -1.2898e+00,\n",
      "        -2.2910e+00, -9.5554e-01, -2.2368e-01, -1.4648e+00, -5.7100e-01,\n",
      "        -1.5640e+00,  1.7462e-01, -2.3592e+00,  1.3310e-01,  4.8467e-01,\n",
      "        -3.3732e-01, -9.6936e-01, -7.6785e-01, -8.5709e-01, -3.7301e-01,\n",
      "         2.9892e-01, -5.3028e+00, -6.8952e-01, -3.7028e-01, -1.4517e+00,\n",
      "         5.8756e-01,  1.7619e-01, -6.7631e-01,  4.9183e-01, -8.5907e-01,\n",
      "        -6.2667e-01,  6.3926e-01, -4.9601e-01, -3.2602e+00, -1.0221e-01,\n",
      "        -1.9155e+00, -8.8528e-02, -3.9977e-01, -1.4764e-01, -7.4585e-01,\n",
      "        -1.7808e+00,  5.6698e-01, -1.2400e+00, -3.7373e-01,  8.0457e-01,\n",
      "         3.9185e-02, -3.7872e+00,  2.7406e-01,  1.1608e+00, -1.5581e+00,\n",
      "        -1.2495e+00, -4.1120e-01,  1.4069e-01,  3.3666e-01, -1.8348e+00,\n",
      "         8.1452e-02, -1.6466e+00, -2.0453e+00, -8.4152e-01, -2.9240e-01,\n",
      "        -3.7709e+00,  5.1774e-01, -8.8879e-01, -1.6874e+00, -3.0544e+00,\n",
      "        -5.0994e-01,  7.7300e-02,  1.3724e-02, -1.8293e+00, -2.7562e-01,\n",
      "         1.5900e-01, -4.6189e-01,  3.0437e-01,  3.9932e-01,  3.8440e-01,\n",
      "        -1.8998e+00, -2.9886e-01, -2.3943e+00, -2.3243e+00,  3.2090e-01,\n",
      "        -1.6544e+00,  4.8807e-01, -3.2396e-02, -3.4129e+00,  5.0152e-01,\n",
      "         4.6202e-02, -1.9897e+00, -1.6692e+00, -1.2055e+00, -2.5518e+00,\n",
      "         4.7206e-01, -5.8983e-01, -4.3595e-01, -3.3862e-01, -1.3538e-01,\n",
      "         6.2380e-02, -4.2555e-01,  2.7785e-01, -3.0015e+00, -1.1723e-01,\n",
      "         7.7730e-01, -1.4479e+00, -2.2072e+00, -6.3080e-01, -6.7254e-01,\n",
      "        -2.5154e+00, -2.6630e-01, -1.7835e+00, -2.6663e-01,  8.1486e-01,\n",
      "        -7.9629e-01], device='cuda:0')), ('backbone.model.layer3.2.conv3.weight', tensor([[[[ 0.1302]],\n",
      "\n",
      "         [[-0.0412]],\n",
      "\n",
      "         [[ 0.0721]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0035]],\n",
      "\n",
      "         [[ 0.0824]],\n",
      "\n",
      "         [[ 0.0076]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0406]],\n",
      "\n",
      "         [[ 0.1592]],\n",
      "\n",
      "         [[-0.3507]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[ 0.1111]],\n",
      "\n",
      "         [[-0.0046]]],\n",
      "\n",
      "\n",
      "        [[[-0.0281]],\n",
      "\n",
      "         [[-0.0708]],\n",
      "\n",
      "         [[-0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0066]],\n",
      "\n",
      "         [[-0.0148]],\n",
      "\n",
      "         [[-0.1116]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0523]],\n",
      "\n",
      "         [[ 0.1724]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0005]],\n",
      "\n",
      "         [[ 0.0912]],\n",
      "\n",
      "         [[-0.0426]]],\n",
      "\n",
      "\n",
      "        [[[-0.0504]],\n",
      "\n",
      "         [[ 0.0302]],\n",
      "\n",
      "         [[ 0.1641]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[-0.0029]],\n",
      "\n",
      "         [[ 0.0873]]],\n",
      "\n",
      "\n",
      "        [[[-0.0480]],\n",
      "\n",
      "         [[ 0.0078]],\n",
      "\n",
      "         [[ 0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[ 0.0576]],\n",
      "\n",
      "         [[-0.0667]]]], device='cuda:0')), ('backbone.model.layer3.2.bn3.weight', tensor([ 1.4139,  1.6582,  1.5830,  ...,  1.2578, -2.6621,  1.8908],\n",
      "       device='cuda:0')), ('backbone.model.layer3.2.bn3.bias', tensor([-0.3329, -0.6438, -0.3667,  ..., -0.5458,  0.2469, -0.6319],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv1.weight', tensor([[[[ 0.0279]],\n",
      "\n",
      "         [[-0.1005]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0278]],\n",
      "\n",
      "         [[ 0.0705]],\n",
      "\n",
      "         [[-0.0016]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0480]],\n",
      "\n",
      "         [[ 0.0446]],\n",
      "\n",
      "         [[ 0.0850]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         [[ 0.0828]],\n",
      "\n",
      "         [[-0.0328]]],\n",
      "\n",
      "\n",
      "        [[[-0.0046]],\n",
      "\n",
      "         [[-0.1167]],\n",
      "\n",
      "         [[-0.0624]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[-0.0149]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0443]],\n",
      "\n",
      "         [[ 0.0818]],\n",
      "\n",
      "         [[ 0.1084]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0365]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[ 0.0429]]],\n",
      "\n",
      "\n",
      "        [[[-0.0445]],\n",
      "\n",
      "         [[ 0.1481]],\n",
      "\n",
      "         [[-0.2798]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0206]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[ 0.0026]]],\n",
      "\n",
      "\n",
      "        [[[-0.0015]],\n",
      "\n",
      "         [[ 0.0476]],\n",
      "\n",
      "         [[ 0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0471]],\n",
      "\n",
      "         [[ 0.1067]],\n",
      "\n",
      "         [[ 0.0620]]]], device='cuda:0')), ('backbone.model.layer3.3.bn1.weight', tensor([2.0251, 1.8809, 1.7625, 2.7906, 2.6572, 5.0392, 1.8324, 1.8810, 2.5099,\n",
      "        1.5392, 2.1742, 2.1923, 3.0884, 3.0851, 2.7540, 1.9236, 2.0051, 1.4511,\n",
      "        2.3482, 1.5532, 1.9655, 1.9130, 1.6397, 1.6202, 2.7161, 2.4579, 3.7488,\n",
      "        2.4746, 2.4112, 3.5530, 1.3056, 2.3672, 3.4150, 2.4398, 2.7394, 2.5005,\n",
      "        1.8930, 3.3475, 2.1898, 1.7604, 0.8535, 1.3806, 2.6919, 1.9333, 1.4608,\n",
      "        3.6962, 2.3909, 2.3114, 1.9841, 2.0179, 1.6332, 1.6751, 2.1203, 2.2803,\n",
      "        2.8138, 2.1805, 2.9055, 2.1205, 2.9197, 2.6061, 2.7021, 1.8130, 1.9716,\n",
      "        3.0859, 2.7044, 3.0162, 2.1844, 2.1982, 1.1326, 1.8474, 1.9675, 2.0604,\n",
      "        2.3837, 2.4233, 1.7364, 2.5055, 1.8963, 2.1524, 1.9387, 2.4282, 2.6394,\n",
      "        3.0244, 3.2893, 3.4896, 3.0607, 2.8379, 4.7873, 1.7532, 1.8957, 1.9292,\n",
      "        1.8617, 1.4848, 2.5731, 2.7100, 2.3708, 2.8270, 2.0072, 2.2393, 2.9412,\n",
      "        2.2667, 2.7462, 2.6758, 2.2384, 2.4532, 3.0513, 0.9884, 5.7068, 1.8863,\n",
      "        2.7959, 1.9709, 1.7511, 4.3736, 3.2079, 3.7021, 0.9385, 1.5273, 2.3192,\n",
      "        3.3762, 2.8657, 2.1469, 2.9676, 1.5118, 1.9489, 2.0899, 1.7240, 1.7952,\n",
      "        2.8250, 1.8794, 2.5240, 4.5620, 5.0192, 2.2860, 1.4832, 2.3578, 2.5261,\n",
      "        0.9024, 1.6188, 2.6627, 2.5296, 2.5743, 3.5487, 1.9723, 2.1560, 2.8135,\n",
      "        3.3425, 2.5049, 4.2823, 0.8482, 1.5671, 2.3198, 2.9131, 3.6528, 2.3021,\n",
      "        1.8122, 2.2246, 1.3795, 1.9976, 2.5580, 2.7598, 2.4612, 1.5261, 1.8389,\n",
      "        1.6784, 2.6473, 1.9688, 1.6232, 2.8958, 2.4750, 1.5876, 3.4259, 3.0292,\n",
      "        1.4883, 3.0065, 2.2181, 2.2970, 2.4602, 1.6177, 1.9787, 2.3687, 2.2122,\n",
      "        1.9708, 3.9495, 2.0521, 2.4645, 2.2132, 1.8230, 2.7467, 2.4033, 2.1148,\n",
      "        1.3131, 1.6341, 2.3585, 1.8505, 2.0089, 1.7480, 2.5520, 2.2535, 2.7343,\n",
      "        1.4156, 1.9969, 1.8893, 3.0938, 2.6218, 2.3367, 2.1864, 2.6654, 1.7374,\n",
      "        1.8534, 2.8028, 6.2646, 3.0720, 2.5940, 1.5143, 3.4338, 4.5743, 2.4128,\n",
      "        2.8783, 3.4975, 2.4802, 3.1599, 2.4282, 2.6618, 1.6456, 3.2576, 2.2372,\n",
      "        1.9593, 3.1104, 1.6926, 2.6422, 1.7485, 1.7822, 3.6544, 2.0454, 2.3340,\n",
      "        1.6940, 2.4581, 2.2521, 2.4984, 1.6489, 1.6929, 1.6040, 1.8723, 2.3025,\n",
      "        1.5423, 2.2272, 2.3838, 2.3770, 2.7409, 2.0534, 1.8753, 1.6720, 2.7472,\n",
      "        1.6015, 1.7609, 1.0752, 2.0290], device='cuda:0')), ('backbone.model.layer3.3.bn1.bias', tensor([-2.7309, -4.2231, -0.3822, -1.4181, -0.3771, -4.6080,  0.0793, -0.3473,\n",
      "        -2.7307,  0.8960, -0.0564, -3.1220, -3.0602, -2.5107, -1.9342, -1.5050,\n",
      "        -0.0869, -1.5037, -1.1617, -0.4407, -0.4391, -0.2395, -0.4566, -1.0291,\n",
      "        -0.4488, -1.2474, -1.7212, -1.4813,  0.0851, -1.1032, -2.7400, -1.3286,\n",
      "         0.2047, -0.6152, -0.8739, -1.0081, -2.6574, -0.4942, -0.2621, -1.2695,\n",
      "        -1.0830, -0.0478, -3.9401,  0.0601, -0.3792, -1.5476, -0.5399, -0.2371,\n",
      "        -0.1686, -0.0981, -0.6775, -0.9537, -0.9847, -1.8533, -0.0248, -1.5263,\n",
      "        -3.1093,  0.4977,  0.6404, -2.1630, -2.3214, -1.0829, -2.4209,  1.5256,\n",
      "        -0.2747, -1.6809, -1.6630, -0.4149,  1.0645, -1.7861, -1.5919, -1.4597,\n",
      "        -0.6602, -0.7151, -0.0231, -2.7275, -0.1831, -0.2926, -2.6958, -3.6038,\n",
      "         0.1082, -3.2176, -0.5337, -0.6667, -1.2963, -0.2633, -1.5826, -3.8865,\n",
      "        -2.1124, -0.8448, -2.3476, -0.6015, -0.7047, -1.6587, -0.3061, -0.5763,\n",
      "        -1.0523, -3.2848,  0.5210, -3.5836, -1.6048, -1.0733, -1.1334, -0.1717,\n",
      "        -0.8983,  0.4227, -4.0163, -1.1170, -1.3133, -0.8799, -1.8417, -3.6682,\n",
      "        -1.5710, -2.0928, -2.3890, -0.9547, -0.9412, -0.9506, -4.4159, -0.8818,\n",
      "        -1.7585, -0.9128, -1.0019,  1.1641, -0.8857, -1.0387, -0.3268, -2.0396,\n",
      "        -3.5010, -2.2731, -2.7511, -0.8954, -1.7581, -0.9919, -0.7532, -3.4816,\n",
      "        -2.3124, -2.5041, -0.6557,  1.2661, -1.5271, -0.6400, -0.6124, -1.2055,\n",
      "        -2.2914, -0.5305, -2.2775, -0.3130, -1.7026, -0.5606,  0.2622, -0.5855,\n",
      "        -0.6762, -1.8129, -0.2458,  1.6469, -1.4153, -1.9691, -2.8367, -1.0005,\n",
      "        -1.6974, -1.0173, -0.0803, -1.1458, -0.8263,  0.3574, -1.8013, -0.5931,\n",
      "         0.0705, -1.2705, -2.2151, -1.9519, -2.3198, -2.7771, -1.0320, -0.3339,\n",
      "        -2.8740, -0.1641, -1.0510, -0.8072, -1.5758, -3.8578,  0.0502,  0.0720,\n",
      "        -1.1570, -0.9379, -1.1480, -3.1333, -0.4494, -0.1676, -3.3634, -4.9689,\n",
      "        -0.3228,  1.8818,  0.2609, -2.1624, -2.8534, -1.4591, -0.5188, -0.4893,\n",
      "        -1.8880, -1.5817, -1.6280,  1.5983, -2.2254, -0.7276, -0.8501, -1.9850,\n",
      "        -0.0519, -0.3877,  0.5435, -1.3328, -3.1834, -1.0089,  0.2022, -2.5690,\n",
      "         0.6607, -1.1041, -2.2819, -1.0129, -1.8393, -1.2940, -3.6075, -1.0751,\n",
      "        -1.7061, -0.5562, -2.4310, -0.4458, -2.5563,  0.2818, -3.4883, -1.3806,\n",
      "        -3.8902, -1.1514, -0.3811, -1.8396, -0.9157, -0.8499, -0.3542, -0.7183,\n",
      "        -0.6341, -1.9142, -1.6655, -1.5621,  0.5175, -0.2883, -1.7883, -0.9062,\n",
      "        -0.7977,  0.0078, -1.3303, -0.8899, -1.6441, -2.2552,  0.9061, -0.4219],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv2.weight', tensor([[[[-0.0535, -0.1016, -0.0928],\n",
      "          [-0.0424, -0.0986, -0.1171],\n",
      "          [-0.0573, -0.0095, -0.0996]],\n",
      "\n",
      "         [[-0.0654, -0.0573,  0.0255],\n",
      "          [-0.1014, -0.0125, -0.0278],\n",
      "          [ 0.0176,  0.0754, -0.0167]],\n",
      "\n",
      "         [[ 0.1417,  0.1646,  0.1362],\n",
      "          [ 0.0264,  0.0184,  0.0015],\n",
      "          [-0.0232, -0.0894, -0.0296]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0493,  0.0253,  0.0602],\n",
      "          [ 0.0271, -0.0336,  0.0258],\n",
      "          [ 0.0340, -0.0647, -0.0088]],\n",
      "\n",
      "         [[-0.0039, -0.0386,  0.0362],\n",
      "          [ 0.0073, -0.0479,  0.0785],\n",
      "          [ 0.0571,  0.0636,  0.0905]],\n",
      "\n",
      "         [[ 0.0305, -0.0217,  0.0064],\n",
      "          [-0.0037, -0.0415, -0.0596],\n",
      "          [-0.0280, -0.0258, -0.0720]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0511,  0.0476,  0.1099],\n",
      "          [ 0.0134,  0.0055,  0.0510],\n",
      "          [ 0.0748, -0.0144,  0.0283]],\n",
      "\n",
      "         [[ 0.1086,  0.0456,  0.0779],\n",
      "          [ 0.0142, -0.0542, -0.0574],\n",
      "          [ 0.0071, -0.0213, -0.0005]],\n",
      "\n",
      "         [[ 0.0614,  0.1213,  0.0935],\n",
      "          [-0.0240,  0.1253,  0.0389],\n",
      "          [-0.0093,  0.0376, -0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0416,  0.0681,  0.0391],\n",
      "          [ 0.0165,  0.0473,  0.0109],\n",
      "          [ 0.0177,  0.0157,  0.0210]],\n",
      "\n",
      "         [[-0.1266, -0.1044, -0.0993],\n",
      "          [-0.0901, -0.0724, -0.1092],\n",
      "          [-0.1053, -0.0810, -0.0756]],\n",
      "\n",
      "         [[-0.0254,  0.0526,  0.0647],\n",
      "          [-0.0006,  0.1294,  0.0567],\n",
      "          [ 0.0731,  0.1036,  0.0265]]],\n",
      "\n",
      "\n",
      "        [[[-0.0487, -0.0999, -0.0500],\n",
      "          [ 0.0006, -0.0575, -0.0331],\n",
      "          [-0.0110,  0.0112, -0.0223]],\n",
      "\n",
      "         [[-0.0361, -0.0245, -0.0140],\n",
      "          [-0.0538, -0.0378, -0.0442],\n",
      "          [-0.0093, -0.0032, -0.0273]],\n",
      "\n",
      "         [[ 0.0760,  0.0450,  0.0259],\n",
      "          [ 0.0428,  0.0951,  0.0663],\n",
      "          [ 0.0627,  0.1137,  0.0686]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0379, -0.0079, -0.0287],\n",
      "          [ 0.0037,  0.1699,  0.0165],\n",
      "          [-0.0146,  0.0286, -0.0309]],\n",
      "\n",
      "         [[ 0.0570, -0.0027,  0.0419],\n",
      "          [ 0.0497, -0.0351,  0.0212],\n",
      "          [-0.0162,  0.0050, -0.0156]],\n",
      "\n",
      "         [[ 0.0130, -0.0366, -0.0092],\n",
      "          [ 0.0086, -0.1675,  0.0026],\n",
      "          [-0.0042, -0.0734,  0.0107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0268, -0.1280, -0.0320],\n",
      "          [-0.1358, -0.1360, -0.1045],\n",
      "          [-0.1202, -0.1445, -0.1195]],\n",
      "\n",
      "         [[ 0.0048, -0.0022,  0.0097],\n",
      "          [ 0.0380,  0.1193,  0.0752],\n",
      "          [ 0.0319,  0.0769,  0.0529]],\n",
      "\n",
      "         [[-0.0569, -0.0104, -0.0470],\n",
      "          [-0.0153,  0.0938,  0.0517],\n",
      "          [ 0.0265, -0.0079, -0.0424]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0632,  0.0369, -0.0566],\n",
      "          [-0.0135,  0.0976, -0.0402],\n",
      "          [-0.0354,  0.0326, -0.0279]],\n",
      "\n",
      "         [[ 0.0038,  0.0598,  0.0075],\n",
      "          [ 0.0101,  0.0224, -0.0031],\n",
      "          [-0.0152,  0.0041,  0.0195]],\n",
      "\n",
      "         [[-0.0171,  0.1029, -0.0021],\n",
      "          [-0.0003,  0.1424,  0.0037],\n",
      "          [-0.0005,  0.1443,  0.0146]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0644,  0.0386,  0.1052],\n",
      "          [-0.0046, -0.0639,  0.0230],\n",
      "          [ 0.0084, -0.0557,  0.0277]],\n",
      "\n",
      "         [[-0.0103,  0.0619,  0.0415],\n",
      "          [ 0.0210,  0.0165,  0.0377],\n",
      "          [ 0.0444,  0.0283,  0.0639]],\n",
      "\n",
      "         [[ 0.0355, -0.0052,  0.0365],\n",
      "          [ 0.0975,  0.0423,  0.0425],\n",
      "          [ 0.0310,  0.0480, -0.0021]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0800, -0.0783, -0.0659],\n",
      "          [-0.0829, -0.0948, -0.0906],\n",
      "          [-0.0658, -0.0362, -0.0773]],\n",
      "\n",
      "         [[ 0.0467,  0.0454,  0.0558],\n",
      "          [ 0.0468, -0.0047,  0.0681],\n",
      "          [ 0.0231,  0.0833,  0.0589]],\n",
      "\n",
      "         [[ 0.0019, -0.0243, -0.0162],\n",
      "          [ 0.0125,  0.0291, -0.0249],\n",
      "          [ 0.0021, -0.0467, -0.0082]]],\n",
      "\n",
      "\n",
      "        [[[-0.0579, -0.0519, -0.0110],\n",
      "          [ 0.0150, -0.0848, -0.0605],\n",
      "          [ 0.0628,  0.0420,  0.0457]],\n",
      "\n",
      "         [[-0.0591, -0.0986, -0.1060],\n",
      "          [ 0.0035, -0.0491, -0.0141],\n",
      "          [-0.0328,  0.0301, -0.0373]],\n",
      "\n",
      "         [[-0.0108,  0.0013, -0.0206],\n",
      "          [-0.0105, -0.0725,  0.0254],\n",
      "          [-0.0129, -0.1521, -0.0966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0409,  0.0086,  0.0195],\n",
      "          [ 0.0419,  0.0125,  0.0767],\n",
      "          [-0.0020,  0.0002,  0.0304]],\n",
      "\n",
      "         [[ 0.0068,  0.0780,  0.0361],\n",
      "          [-0.0331,  0.0087, -0.0843],\n",
      "          [-0.0859, -0.0229, -0.0703]],\n",
      "\n",
      "         [[-0.0290, -0.1350, -0.0530],\n",
      "          [-0.0006, -0.0174, -0.0010],\n",
      "          [ 0.0169,  0.0983,  0.0600]]]], device='cuda:0')), ('backbone.model.layer3.3.bn2.weight', tensor([2.7639, 2.3606, 4.5588, 3.4224, 1.5517, 3.2295, 2.2590, 2.5699, 2.3219,\n",
      "        2.7078, 1.3042, 3.7578, 2.3774, 2.1916, 2.5174, 3.3032, 1.2413, 2.2071,\n",
      "        2.2611, 2.5218, 2.5807, 2.1787, 3.2626, 2.3614, 3.4540, 2.2389, 4.3291,\n",
      "        2.8772, 1.8325, 2.4495, 1.9301, 2.6842, 1.8557, 2.0133, 2.1322, 2.5408,\n",
      "        2.4704, 2.3791, 2.7639, 3.6789, 2.0614, 3.2822, 3.1797, 1.0147, 2.5087,\n",
      "        2.5986, 3.9955, 2.0886, 3.0339, 2.2370, 3.0284, 0.9308, 2.5361, 2.3164,\n",
      "        3.6857, 2.7964, 2.3749, 1.9952, 2.4285, 2.1732, 2.9577, 3.2584, 2.6783,\n",
      "        3.9530, 2.5571, 2.2880, 2.3455, 2.3588, 1.9735, 1.9142, 2.2832, 2.4372,\n",
      "        2.1715, 2.5932, 1.9534, 3.1743, 2.7418, 2.5195, 3.2733, 3.7276, 2.4665,\n",
      "        2.2980, 2.5386, 2.2023, 2.3591, 0.9977, 2.3444, 2.6412, 2.2569, 3.4546,\n",
      "        2.0822, 3.6883, 3.1628, 3.3623, 2.6409, 2.9286, 3.5910, 3.0726, 3.1428,\n",
      "        3.7242, 3.5746, 3.0999, 1.0777, 4.0333, 1.0313, 2.1547, 1.9265, 1.6037,\n",
      "        1.9350, 1.8655, 2.3739, 2.0844, 4.2484, 2.2484, 1.3338, 2.3161, 2.4433,\n",
      "        2.7439, 2.6089, 3.4441, 3.9141, 2.3506, 2.4135, 2.1360, 2.3997, 2.4153,\n",
      "        3.0245, 3.2009, 2.0041, 2.0001, 2.5322, 2.1115, 2.3324, 2.4663, 1.7166,\n",
      "        5.0472, 5.3695, 0.8651, 2.3723, 3.5916, 3.1022, 2.0848, 1.8951, 3.1582,\n",
      "        2.3273, 4.3619, 1.9538, 2.1472, 1.8886, 2.0771, 1.5958, 1.6591, 1.7961,\n",
      "        3.3678, 2.2996, 2.4607, 2.2049, 1.9404, 1.8655, 2.8556, 1.9188, 3.3799,\n",
      "        2.7270, 3.5351, 2.4638, 2.3358, 1.7099, 2.0593, 2.3772, 1.2575, 2.7883,\n",
      "        2.3689, 2.5305, 3.4048, 2.9792, 2.2526, 2.0604, 1.5141, 1.9113, 2.4221,\n",
      "        2.0440, 2.1314, 1.8527, 2.2599, 2.0974, 1.8639, 1.7755, 2.9971, 2.3034,\n",
      "        2.3745, 2.2515, 2.3902, 2.5119, 1.4061, 2.1128, 2.6678, 2.3100, 3.6073,\n",
      "        3.7851, 3.1820, 4.3201, 2.5349, 2.9431, 2.1184, 2.4610, 1.8071, 2.1070,\n",
      "        2.3645, 2.2379, 2.3138, 2.4590, 3.3708, 3.3004, 2.6158, 3.3185, 2.4307,\n",
      "        4.0407, 3.8933, 2.2316, 3.7075, 2.4051, 2.7125, 2.0756, 2.6176, 1.6336,\n",
      "        2.9514, 1.9343, 2.0638, 2.7016, 2.9118, 2.3150, 2.3964, 1.8182, 2.1556,\n",
      "        2.0661, 2.2563, 2.3761, 2.1216, 1.8672, 1.1445, 1.7803, 1.9562, 2.2317,\n",
      "        2.2373, 2.2677, 3.3803, 2.1051, 1.3243, 2.0984, 2.4461, 2.9297, 2.6883,\n",
      "        2.1902, 2.3741, 2.5711, 2.1144], device='cuda:0')), ('backbone.model.layer3.3.bn2.bias', tensor([ 1.3905,  0.0878, -1.2869, -1.8216, -3.6235, -0.1951,  0.8856,  0.2855,\n",
      "         0.4527, -0.1246, -3.1639, -0.4958, -1.1903, -0.0887, -1.0716, -0.1728,\n",
      "        -3.0125, -0.1572, -1.1348, -0.7767,  0.1106, -0.8456,  0.0241, -0.8419,\n",
      "        -0.2798, -0.6629, -0.6408, -0.3818, -2.2609, -0.6976,  0.3403, -1.0903,\n",
      "        -1.7149, -1.2531,  0.4882, -0.7583, -1.3451,  0.0933, -0.5694, -2.4933,\n",
      "         0.0847, -0.2457, -0.3674, -1.8280, -2.2974, -1.0775, -1.0557,  0.1275,\n",
      "         0.0368,  0.4830,  0.2017, -1.9681,  0.2280, -2.1037, -0.1152, -0.5425,\n",
      "        -1.1495, -2.0434,  0.6774, -1.5322, -1.9096, -0.6252,  0.2573, -0.5237,\n",
      "        -0.8142, -0.2125, -0.8077, -1.6420, -2.2967, -1.0171,  0.2974, -1.9495,\n",
      "        -0.7702, -0.5276, -2.9969, -0.7159, -0.0998, -1.1867,  0.3672, -1.2324,\n",
      "        -1.9112,  0.3994,  0.4916,  0.5247,  0.5439, -3.7560,  0.0718, -2.2616,\n",
      "        -3.5205, -1.0975, -2.4059,  0.1220, -0.5945,  0.7933, -0.4821,  0.5015,\n",
      "        -1.0196, -1.2495, -2.8158,  0.1338, -4.1672, -0.4847,  0.8108, -0.8625,\n",
      "        -2.9280, -1.9314,  0.0407,  0.0493, -0.4601,  0.2779, -0.1215, -0.4579,\n",
      "        -2.3348, -1.3769, -0.6968, -0.9739, -0.0695, -1.8355,  0.4939, -1.8967,\n",
      "        -4.4636, -1.0494, -1.2463, -0.5919, -0.9493, -1.1997, -1.5941, -2.2534,\n",
      "        -1.3733, -0.2123,  0.0046, -0.1578, -0.2890, -1.0787, -2.6427, -2.2527,\n",
      "        -2.8004, -0.9377, -0.4066, -1.8280, -2.2637, -0.3701,  2.6953, -0.6290,\n",
      "        -0.6085, -2.8985,  0.0419,  0.4855, -1.3071, -1.8321, -1.1590, -0.2857,\n",
      "         0.7530, -0.3192, -1.4527, -0.7722, -1.8301, -1.1271, -1.1265, -1.4426,\n",
      "        -1.9787, -2.0732, -0.8426, -1.6511, -1.7003, -0.8805,  1.5057, -0.4571,\n",
      "        -0.1198, -3.1307, -0.0140,  0.1780, -0.4249,  0.1165,  0.0262, -0.5343,\n",
      "        -1.4034,  1.0246, -1.9475, -1.2513, -0.1242, -0.3262,  1.4622, -0.4953,\n",
      "        -0.4238,  2.1012, -1.9394, -1.0951,  0.3562, -0.8891, -1.5312, -0.3276,\n",
      "        -1.8324,  1.2905, -0.7081, -0.9715, -1.8951, -0.3372, -1.2994, -1.1907,\n",
      "        -0.8230, -0.0143,  0.0072, -0.0251, -0.7959, -2.4927, -0.3244,  0.4052,\n",
      "        -1.1389, -1.8446, -1.3663, -0.2841, -1.3765, -0.4424, -0.5442, -3.1047,\n",
      "        -4.3386, -2.7227, -1.3698, -1.9908,  0.1740, -1.4143, -1.2714, -1.1291,\n",
      "        -1.5925, -1.0875,  0.0092, -1.7108, -0.5274, -1.1804, -1.0430, -0.6578,\n",
      "         0.2163,  0.4419, -0.0054, -2.5083,  0.7615,  0.3567,  0.3423, -4.2560,\n",
      "        -1.7885, -0.4242, -0.2423, -0.4666, -1.8809, -0.8867, -0.0615,  1.6369,\n",
      "        -1.4073, -0.6959, -0.3606, -0.7385, -1.0913,  0.0235, -1.7620, -1.7633],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.conv3.weight', tensor([[[[-0.1310]],\n",
      "\n",
      "         [[ 0.0424]],\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[ 0.0274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0554]],\n",
      "\n",
      "         [[ 0.0792]],\n",
      "\n",
      "         [[ 0.0245]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[ 0.0037]]],\n",
      "\n",
      "\n",
      "        [[[-0.0101]],\n",
      "\n",
      "         [[ 0.0160]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0942]],\n",
      "\n",
      "         [[-0.0118]],\n",
      "\n",
      "         [[ 0.0698]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0489]],\n",
      "\n",
      "         [[ 0.0021]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.1299]]],\n",
      "\n",
      "\n",
      "        [[[-0.0268]],\n",
      "\n",
      "         [[ 0.0872]],\n",
      "\n",
      "         [[-0.0210]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0707]],\n",
      "\n",
      "         [[ 0.0605]],\n",
      "\n",
      "         [[-0.0301]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[ 0.0444]],\n",
      "\n",
      "         [[-0.0076]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0528]],\n",
      "\n",
      "         [[ 0.0039]],\n",
      "\n",
      "         [[ 0.0372]]]], device='cuda:0')), ('backbone.model.layer3.3.bn3.weight', tensor([ 2.1156, -2.0873, -3.8347,  ..., -3.0713, -6.4074,  2.5510],\n",
      "       device='cuda:0')), ('backbone.model.layer3.3.bn3.bias', tensor([-0.3309, -0.2575, -0.0464,  ..., -0.2761, -0.0222, -0.4712],\n",
      "       device='cuda:0')), ('backbone.model.layer3.4.conv1.weight', tensor([[[[ 0.0647]],\n",
      "\n",
      "         [[-0.0823]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[ 0.0323]],\n",
      "\n",
      "         [[ 0.0051]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0211]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[ 0.0988]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0335]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174]],\n",
      "\n",
      "         [[-0.0161]],\n",
      "\n",
      "         [[ 0.0617]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[ 0.0471]],\n",
      "\n",
      "         [[ 0.0458]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0070]],\n",
      "\n",
      "         [[-0.0303]],\n",
      "\n",
      "         [[-0.0235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0934]],\n",
      "\n",
      "         [[ 0.0240]],\n",
      "\n",
      "         [[ 0.0623]]],\n",
      "\n",
      "\n",
      "        [[[-0.0457]],\n",
      "\n",
      "         [[-0.0363]],\n",
      "\n",
      "         [[-0.0099]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.0690]],\n",
      "\n",
      "         [[ 0.0495]]],\n",
      "\n",
      "\n",
      "        [[[-0.0425]],\n",
      "\n",
      "         [[-0.0748]],\n",
      "\n",
      "         [[-0.0328]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0045]],\n",
      "\n",
      "         [[-0.0798]],\n",
      "\n",
      "         [[-0.0530]]]], device='cuda:0')), ('backbone.model.layer3.4.bn1.weight', tensor([0.9811, 1.7768, 2.5331, 1.8560, 1.9585, 2.3710, 3.7276, 1.9664, 0.6484,\n",
      "        1.9101, 2.5548, 1.4840, 3.2212, 2.3145, 2.1420, 3.2629, 3.8055, 1.8097,\n",
      "        4.1647, 2.8327, 2.5156, 2.3782, 2.7534, 1.5460, 2.2133, 3.3903, 2.3520,\n",
      "        3.5845, 2.1176, 1.4945, 2.3085, 1.4295, 1.7488, 3.2725, 1.6276, 2.6237,\n",
      "        2.1439, 2.0292, 2.4036, 2.8267, 1.8723, 5.5341, 2.4138, 1.4957, 2.5611,\n",
      "        1.4383, 2.0002, 1.4921, 2.4446, 2.3594, 1.1782, 4.3713, 2.6635, 2.5235,\n",
      "        2.0339, 1.8083, 3.2813, 0.5036, 2.1258, 3.1208, 1.9562, 1.7206, 1.8084,\n",
      "        4.2399, 1.9106, 1.9061, 1.8549, 2.4678, 2.3341, 2.7524, 0.4946, 2.1477,\n",
      "        2.3274, 1.3863, 2.1973, 2.4397, 3.2466, 2.3630, 1.6289, 1.5500, 2.0993,\n",
      "        1.7594, 1.7637, 2.4481, 1.7140, 2.2075, 1.7510, 0.7242, 2.5045, 1.6731,\n",
      "        2.5923, 3.0458, 0.7848, 2.4626, 2.7238, 1.7556, 1.7990, 0.7272, 1.1130,\n",
      "        1.6618, 1.5672, 3.9393, 2.5825, 1.8441, 1.8583, 1.4117, 4.6411, 2.0135,\n",
      "        3.9958, 1.8557, 1.2173, 2.5266, 2.2553, 1.6368, 1.9023, 2.1753, 2.0462,\n",
      "        0.5415, 1.4849, 2.0580, 2.3070, 2.5737, 1.4835, 0.6643, 5.8700, 3.0083,\n",
      "        1.7111, 1.7353, 3.6116, 2.7653, 3.8204, 2.0068, 3.4339, 4.0962, 1.8368,\n",
      "        2.1826, 1.4832, 1.3440, 1.5371, 1.6928, 1.7015, 1.5575, 1.1828, 1.8936,\n",
      "        2.6123, 2.4972, 3.1597, 0.5948, 1.7720, 1.2843, 1.8794, 1.8440, 1.3679,\n",
      "        1.9790, 1.6595, 2.5982, 2.7744, 0.5163, 2.0453, 1.6973, 1.4125, 1.1051,\n",
      "        2.5215, 1.9592, 2.4128, 1.9771, 2.4867, 2.4472, 1.9193, 1.6053, 2.4665,\n",
      "        2.0686, 1.2733, 1.3047, 2.3386, 2.1789, 1.5729, 2.9321, 1.4503, 0.7838,\n",
      "        2.1380, 2.5611, 2.1747, 2.9327, 1.5346, 2.0081, 3.1817, 1.4108, 2.6398,\n",
      "        2.3621, 2.4482, 2.0356, 1.4234, 4.0228, 3.2651, 2.4484, 2.7088, 1.3019,\n",
      "        2.3131, 4.4103, 2.2291, 1.6919, 4.8255, 2.1432, 2.0713, 2.2528, 2.4267,\n",
      "        1.9783, 2.6441, 2.3157, 2.9891, 0.8599, 0.5134, 3.4514, 3.1319, 1.8975,\n",
      "        1.3496, 1.6977, 0.6854, 2.5755, 4.4363, 2.7299, 1.8261, 1.8031, 0.6173,\n",
      "        1.5916, 3.4630, 2.2783, 3.4837, 1.5092, 3.6016, 2.0254, 2.4042, 1.5901,\n",
      "        0.9798, 1.4110, 1.4984, 1.7478, 1.8956, 1.4383, 1.5604, 1.8537, 1.3998,\n",
      "        2.0110, 0.9570, 1.7612, 1.6253, 2.2220, 2.0595, 1.9580, 2.3027, 4.8373,\n",
      "        1.8110, 2.9105, 1.1256, 1.4557], device='cuda:0')), ('backbone.model.layer3.4.bn1.bias', tensor([ 2.2361e-01, -4.6058e-01, -2.6824e+00, -2.4042e+00, -1.8751e+00,\n",
      "        -1.2681e+00, -8.7691e-01, -1.0552e+00, -1.6648e+00, -2.0111e+00,\n",
      "        -1.7020e+00, -4.6706e-01, -2.5226e+00, -7.6697e-01, -5.9487e-01,\n",
      "        -1.4510e+00, -2.9641e+00, -1.4937e+00, -2.1500e+00,  1.3701e-01,\n",
      "        -3.3780e-01, -1.8673e+00, -1.1482e+00, -2.9064e+00, -5.0935e-01,\n",
      "        -2.3244e-01, -1.6323e+00, -8.7306e-02, -1.7315e+00, -1.3410e-01,\n",
      "        -1.0151e+00, -3.0012e+00, -2.5833e+00, -1.0621e+00, -9.0457e-01,\n",
      "        -2.1042e+00, -1.3664e+00, -2.8663e+00, -3.2947e-01, -8.6316e-01,\n",
      "        -2.3305e+00, -7.5817e-01, -1.0946e+00, -2.5593e+00, -1.0819e+00,\n",
      "        -1.0561e+00, -1.1033e+00, -3.3896e-01, -1.0084e-01,  7.4042e-01,\n",
      "        -7.7511e-02, -1.0469e+00, -1.1859e+00, -1.4533e+00, -2.4127e+00,\n",
      "        -1.2087e+00, -1.4010e+00, -1.8598e-01, -1.1328e-01, -3.7885e+00,\n",
      "        -4.4579e-01, -7.9415e-01,  5.3732e-02, -1.3550e+00, -2.0279e+00,\n",
      "        -1.4162e+00, -1.5829e+00, -1.2672e+00, -1.5707e+00, -2.1050e+00,\n",
      "         4.4760e-01, -8.1413e-01, -2.1103e+00,  7.0843e-01, -1.5332e+00,\n",
      "        -7.5547e-01, -2.4887e+00, -2.6343e+00, -7.1872e-01, -6.5421e-01,\n",
      "        -6.0591e-01, -1.9484e+00, -5.7475e-01, -1.9577e+00, -9.1715e-01,\n",
      "        -1.8235e+00, -1.2163e+00, -8.2261e-01, -1.3578e+00, -1.3154e+00,\n",
      "        -1.7110e+00, -1.7216e+00, -1.8547e+00, -1.0424e+00, -1.6252e+00,\n",
      "        -1.8544e+00, -1.2316e+00, -1.7791e+00, -3.3839e-01, -1.4712e+00,\n",
      "        -1.0906e+00, -1.9979e+00, -2.2611e+00, -1.0293e+00, -2.2198e+00,\n",
      "        -4.5631e-01, -2.6765e+00, -4.5535e+00, -3.5602e+00, -9.3913e-01,\n",
      "        -1.1238e+00, -2.5213e+00, -1.9452e+00, -2.0555e+00, -5.0498e-02,\n",
      "        -9.3776e-01, -1.4841e+00,  5.8358e-01, -1.7793e+00, -7.4832e-01,\n",
      "        -8.7303e-01, -9.2144e-01, -5.4390e-01, -2.9743e-01, -4.1117e+00,\n",
      "        -1.1043e+00, -1.5423e+00, -1.8544e+00, -1.8407e+00, -2.4634e+00,\n",
      "        -8.3598e-02, -1.2864e+00, -1.9898e+00, -1.3730e+00, -4.1070e+00,\n",
      "        -1.7401e+00,  3.1828e-01, -1.7661e+00, -8.8020e-01, -1.9326e+00,\n",
      "        -1.0160e+00, -6.4942e-01,  1.1963e-01, -9.5541e-01, -8.7678e-01,\n",
      "        -1.2093e+00, -1.9996e+00,  4.7022e-01, -1.0080e+00, -1.8550e+00,\n",
      "        -1.1948e+00, -1.6949e+00, -2.0962e+00, -1.3768e-01, -1.8325e+00,\n",
      "        -1.1180e+00, -3.0254e-01,  8.3341e-01, -1.9903e+00, -1.2238e+00,\n",
      "        -2.1529e-01, -3.0708e-01, -7.3461e-01, -1.2328e+00, -8.3309e-01,\n",
      "        -2.7623e+00, -1.1257e-01, -1.8736e+00, -2.7357e+00, -5.4090e-01,\n",
      "        -1.4034e+00, -1.4390e+00, -2.1604e-01, -9.6673e-01, -2.1324e+00,\n",
      "        -2.7892e+00, -8.4611e-01, -3.4260e+00,  8.7944e-01,  2.6984e-02,\n",
      "        -2.1774e+00, -2.9790e+00, -1.3923e+00, -2.9432e+00, -1.7203e+00,\n",
      "        -1.3678e-01, -2.0907e+00, -2.8682e+00, -7.8128e-01, -2.2239e+00,\n",
      "        -1.4172e+00,  1.0452e-01, -1.4970e+00, -2.8421e+00,  1.1715e-01,\n",
      "        -1.1027e+00, -1.7161e+00, -1.7448e+00, -1.7506e+00, -1.7790e+00,\n",
      "         9.0025e-01, -1.5187e-01, -2.2429e+00, -1.2350e+00, -2.5084e+00,\n",
      "        -2.1854e+00,  5.9658e-03, -2.3713e+00, -7.5699e-01, -6.1564e-01,\n",
      "        -1.0064e+00, -2.4404e-01, -4.1012e-01, -4.4675e+00, -1.7143e+00,\n",
      "        -4.4617e-01, -1.3628e+00, -3.5797e-01,  6.6170e-01, -4.4024e+00,\n",
      "        -2.9766e+00, -2.6048e+00, -1.4960e+00, -9.4736e-01, -5.3321e-01,\n",
      "         1.9630e-03, -4.5596e+00, -6.8299e-01, -1.0456e+00, -4.5833e-01,\n",
      "        -1.6728e+00, -6.4019e-01, -2.6178e+00, -2.0655e-01,  2.4236e-02,\n",
      "        -8.9706e-01, -7.5929e-01, -3.0596e+00, -1.2371e+00, -8.5828e-01,\n",
      "        -1.8885e+00, -1.4650e+00,  4.6326e-01, -1.0624e+00,  1.6064e-01,\n",
      "        -6.6607e-01, -3.4341e-01, -1.6811e+00, -2.4426e+00, -8.5105e-01,\n",
      "        -1.9691e+00, -3.0985e+00,  7.7847e-02, -2.6881e+00, -1.9581e-01,\n",
      "        -1.7749e+00], device='cuda:0')), ('backbone.model.layer3.4.conv2.weight', tensor([[[[ 1.8140e-02, -2.6086e-03,  6.6929e-02],\n",
      "          [ 2.8736e-02, -6.0018e-02,  6.2548e-02],\n",
      "          [ 5.5545e-02,  5.9051e-02,  7.6355e-02]],\n",
      "\n",
      "         [[ 2.6958e-02,  7.1472e-03, -2.3798e-03],\n",
      "          [ 3.1295e-02, -4.1986e-02, -5.0167e-03],\n",
      "          [-4.5553e-03, -1.1798e-02, -8.4402e-04]],\n",
      "\n",
      "         [[-2.0592e-02,  2.8173e-02,  1.7024e-02],\n",
      "          [ 2.2506e-02,  1.2637e-01, -6.9830e-04],\n",
      "          [ 3.1603e-02, -1.3422e-02, -7.0186e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.2971e-03, -1.4774e-02,  7.4050e-03],\n",
      "          [ 1.7234e-02, -5.8618e-02, -2.5721e-03],\n",
      "          [-1.3136e-02, -1.7336e-02, -8.7691e-03]],\n",
      "\n",
      "         [[-7.3823e-03,  8.4137e-02,  1.0698e-02],\n",
      "          [ 2.2604e-02,  1.3317e-01,  3.2720e-02],\n",
      "          [-1.6691e-02,  3.6824e-02, -1.3394e-02]],\n",
      "\n",
      "         [[ 2.3134e-02,  2.5383e-02, -2.4284e-02],\n",
      "          [ 2.7154e-02,  2.4281e-02,  1.4011e-02],\n",
      "          [ 5.8671e-02,  8.4261e-02,  5.6262e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8811e-02, -1.8866e-02,  4.9950e-03],\n",
      "          [-2.4695e-02, -9.1323e-02, -1.5253e-02],\n",
      "          [ 5.4611e-03, -2.6243e-02,  1.4090e-02]],\n",
      "\n",
      "         [[ 4.3014e-03,  1.1311e-02, -4.1108e-03],\n",
      "          [-3.9374e-02, -1.8267e-02, -2.2069e-02],\n",
      "          [-3.1973e-02, -3.3089e-02, -2.2971e-02]],\n",
      "\n",
      "         [[-5.2621e-02, -1.2648e-01, -1.3176e-01],\n",
      "          [-1.1325e-01, -2.9524e-02, -9.2501e-02],\n",
      "          [-1.2166e-01, -7.4600e-02, -6.1615e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5124e-01,  1.0636e-01,  1.0248e-01],\n",
      "          [ 9.7364e-02,  5.9213e-02,  1.3638e-01],\n",
      "          [ 1.0223e-01,  7.9154e-02,  1.3023e-01]],\n",
      "\n",
      "         [[-3.5635e-02,  7.2200e-02,  2.4543e-03],\n",
      "          [-2.8691e-02,  3.7437e-02,  2.5827e-02],\n",
      "          [-7.3487e-02, -1.2518e-01, -8.0598e-02]],\n",
      "\n",
      "         [[-1.4779e-02,  2.4710e-03,  5.8145e-02],\n",
      "          [-3.2347e-02, -4.2256e-02,  2.3597e-03],\n",
      "          [-1.8044e-02,  9.0669e-03,  1.6541e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9954e-02, -4.1353e-02, -4.7041e-02],\n",
      "          [-1.6542e-04,  1.0306e-02, -4.7985e-02],\n",
      "          [-5.1466e-02, -5.2893e-02, -3.2822e-02]],\n",
      "\n",
      "         [[-1.8844e-02,  7.0999e-02, -1.6633e-02],\n",
      "          [ 6.6434e-02,  8.8203e-02,  3.7508e-02],\n",
      "          [-1.2501e-02,  4.4026e-02, -9.2774e-03]],\n",
      "\n",
      "         [[ 1.0916e-02,  7.9476e-02,  7.4798e-02],\n",
      "          [ 1.1541e-01,  1.7052e-01,  1.2300e-01],\n",
      "          [ 9.1711e-02,  9.6325e-02,  1.0526e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.9177e-02, -1.5282e-02, -3.2761e-02],\n",
      "          [-3.9921e-02, -5.1642e-02, -7.2191e-03],\n",
      "          [-3.9609e-02, -2.2482e-02,  7.7511e-04]],\n",
      "\n",
      "         [[-5.1433e-02,  4.2668e-03, -1.1063e-02],\n",
      "          [ 3.0865e-02,  1.9307e-02,  4.3768e-02],\n",
      "          [ 1.1100e-01,  1.1147e-01,  6.8598e-02]],\n",
      "\n",
      "         [[ 4.8214e-02,  2.8349e-02,  2.8280e-02],\n",
      "          [ 1.0520e-03, -1.7737e-02,  3.7326e-02],\n",
      "          [-1.9914e-02, -1.5938e-02, -1.0017e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.9145e-02,  1.4109e-03, -3.3609e-02],\n",
      "          [-2.1361e-02,  6.8451e-02,  3.2799e-03],\n",
      "          [-3.3754e-02, -1.6053e-02, -5.8114e-02]],\n",
      "\n",
      "         [[-3.1362e-02,  6.6829e-03,  7.5565e-03],\n",
      "          [ 1.1497e-02, -2.8175e-02,  2.1480e-02],\n",
      "          [-1.9236e-02,  4.1040e-02,  1.9722e-02]],\n",
      "\n",
      "         [[ 5.0385e-02,  1.4112e-02, -7.0977e-03],\n",
      "          [ 2.1889e-02, -2.7482e-02, -3.5083e-02],\n",
      "          [ 6.5584e-02,  2.0226e-02,  2.4599e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8683e-02, -1.1277e-02, -7.5367e-02],\n",
      "          [-1.3404e-02,  8.2810e-02, -1.6131e-02],\n",
      "          [-2.3790e-02, -3.5086e-02,  1.7072e-02]],\n",
      "\n",
      "         [[ 9.1211e-02,  1.0177e-01,  1.0837e-01],\n",
      "          [ 6.8752e-02,  5.1684e-02,  4.3344e-02],\n",
      "          [ 1.4962e-02, -2.4700e-02,  6.0771e-04]],\n",
      "\n",
      "         [[-6.3720e-02,  4.8304e-02, -4.7461e-03],\n",
      "          [ 1.2779e-02,  1.3370e-01,  4.4559e-02],\n",
      "          [ 5.6954e-02,  1.1786e-01,  1.0025e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.0918e-02,  6.9099e-02,  8.1389e-02],\n",
      "          [ 5.0196e-02,  3.1642e-02,  9.4789e-02],\n",
      "          [ 7.1946e-02,  1.0068e-01,  8.5690e-02]],\n",
      "\n",
      "         [[ 2.6799e-02,  2.2325e-02,  2.5380e-02],\n",
      "          [ 5.9743e-02,  7.8886e-02,  7.6196e-02],\n",
      "          [ 4.5154e-02,  8.5179e-02,  2.9177e-02]],\n",
      "\n",
      "         [[ 8.3024e-02,  9.1377e-02,  7.6623e-02],\n",
      "          [ 2.3921e-02, -3.1292e-02,  1.0035e-03],\n",
      "          [ 1.2961e-02, -2.7635e-02, -2.9030e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0119e-02,  7.1703e-02,  5.8624e-02],\n",
      "          [ 6.0473e-02,  1.0788e-01,  5.5130e-02],\n",
      "          [ 3.8647e-02,  3.7009e-02,  2.1933e-03]],\n",
      "\n",
      "         [[ 8.7974e-02,  1.0982e-01,  1.0474e-01],\n",
      "          [-2.4784e-02,  1.1921e-02,  8.4665e-03],\n",
      "          [-9.9177e-02, -1.2162e-01, -1.0429e-01]],\n",
      "\n",
      "         [[-1.6711e-03,  2.6631e-02, -2.4397e-02],\n",
      "          [ 1.8112e-02,  8.7959e-02,  3.2298e-02],\n",
      "          [ 5.7830e-02,  2.6568e-02,  3.8244e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5823e-03, -2.9764e-02, -4.7938e-02],\n",
      "          [-1.0072e-02, -7.2116e-02, -3.0204e-02],\n",
      "          [-7.5273e-02, -9.7038e-02, -2.2118e-02]],\n",
      "\n",
      "         [[-1.8962e-02,  2.1812e-02,  5.5825e-02],\n",
      "          [-5.8356e-03, -1.1711e-01,  2.4683e-02],\n",
      "          [ 4.6609e-02,  3.5208e-02,  2.4785e-02]],\n",
      "\n",
      "         [[-4.2896e-02, -3.2712e-02, -2.0775e-02],\n",
      "          [-3.2385e-03, -2.9722e-03, -3.8690e-03],\n",
      "          [-2.5180e-02,  3.3076e-02, -2.3967e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.9441e-02, -4.5364e-02, -6.7747e-02],\n",
      "          [-7.5667e-02, -2.0519e-02, -7.1823e-02],\n",
      "          [-2.5942e-02, -2.9972e-02, -4.9426e-02]],\n",
      "\n",
      "         [[ 2.6062e-02,  7.3205e-02,  3.0382e-02],\n",
      "          [-1.5172e-02,  3.8145e-02,  2.3917e-02],\n",
      "          [-2.9080e-02, -8.8450e-02, -5.5209e-02]],\n",
      "\n",
      "         [[ 3.1703e-02, -8.4651e-02,  1.1714e-03],\n",
      "          [-8.1188e-03, -1.3053e-01,  2.0090e-02],\n",
      "          [ 2.3417e-02, -1.4205e-02,  3.3489e-02]]]], device='cuda:0')), ('backbone.model.layer3.4.bn2.weight', tensor([1.9290, 2.4255, 2.5252, 0.8865, 1.9299, 2.3757, 2.5152, 2.0861, 1.9553,\n",
      "        4.1051, 1.1203, 1.6310, 2.6746, 3.7818, 3.4806, 3.0890, 3.0537, 2.2651,\n",
      "        2.5755, 2.4762, 2.4925, 2.3508, 2.7319, 0.7892, 2.3404, 3.0376, 2.9579,\n",
      "        2.6918, 2.1613, 3.2484, 0.5870, 2.5505, 2.1361, 1.7258, 1.9454, 2.2069,\n",
      "        2.0240, 1.1737, 1.7833, 2.5166, 6.8966, 3.0495, 2.4641, 2.3275, 2.3831,\n",
      "        3.3775, 3.2870, 0.1087, 2.0761, 2.3513, 2.3371, 2.2121, 2.1056, 2.5797,\n",
      "        2.0454, 2.1422, 1.7339, 3.7512, 3.4558, 3.1127, 3.4774, 2.6602, 2.6446,\n",
      "        2.7174, 2.1924, 3.1256, 4.2610, 2.4023, 3.3221, 2.4156, 0.6995, 2.6778,\n",
      "        4.5860, 2.4556, 2.9951, 1.7149, 4.8925, 1.3954, 2.1221, 1.8355, 0.0880,\n",
      "        2.7868, 3.8271, 2.3304, 3.3918, 3.1071, 2.2688, 2.6871, 1.5723, 2.6178,\n",
      "        2.8730, 0.5923, 2.9653, 3.8934, 1.9961, 3.2751, 1.5751, 1.2487, 1.9714,\n",
      "        2.1913, 2.3058, 1.7468, 1.6014, 1.7885, 1.3847, 2.1941, 2.7449, 2.1484,\n",
      "        2.4054, 2.4391, 2.5487, 2.9612, 1.7720, 2.2719, 2.6942, 1.1956, 2.3910,\n",
      "        1.9490, 2.5320, 1.8875, 3.3474, 2.7268, 2.9485, 3.5251, 3.2196, 2.3550,\n",
      "        3.5090, 0.8551, 3.3857, 2.9552, 2.4704, 2.6955, 3.4489, 3.3440, 0.8285,\n",
      "        2.8681, 2.7577, 3.0562, 2.4479, 3.2497, 2.9586, 2.1036, 0.1329, 3.1004,\n",
      "        1.5588, 1.7759, 1.7151, 2.2890, 2.1174, 2.0902, 1.5680, 1.6566, 2.1091,\n",
      "        2.4494, 0.6306, 2.2976, 2.2932, 1.9891, 2.3533, 1.8465, 2.7912, 2.0073,\n",
      "        2.4601, 2.4576, 2.4487, 0.6193, 4.0501, 2.2433, 3.8947, 3.9711, 2.6132,\n",
      "        0.6959, 2.7668, 2.6888, 2.3749, 2.6862, 0.6248, 3.1749, 2.9733, 1.7809,\n",
      "        2.0531, 2.4193, 2.4428, 2.0037, 4.4606, 0.6287, 2.9893, 2.6910, 2.1164,\n",
      "        3.3002, 2.0468, 2.3962, 2.4968, 3.5663, 3.8215, 0.7546, 3.9234, 2.2336,\n",
      "        2.3234, 2.1119, 0.8242, 1.8214, 2.1910, 1.7195, 0.8259, 2.7337, 1.7051,\n",
      "        1.7858, 2.3198, 2.3169, 2.5771, 2.5112, 1.9956, 1.9412, 2.8340, 0.9196,\n",
      "        2.6229, 3.1240, 1.5082, 3.7519, 2.2913, 3.3674, 2.4901, 2.6815, 2.4211,\n",
      "        2.9299, 3.4285, 2.5771, 2.8118, 4.1705, 2.2008, 1.0541, 2.8602, 0.5227,\n",
      "        2.9913, 3.6602, 2.3902, 4.2844, 2.6789, 2.5994, 1.7902, 2.0175, 1.6550,\n",
      "        1.7564, 2.2612, 1.9094, 1.7470, 1.8108, 2.6239, 3.5324, 3.8796, 2.0647,\n",
      "        2.1338, 1.2718, 2.9272, 5.2911], device='cuda:0')), ('backbone.model.layer3.4.bn2.bias', tensor([-1.1955e+00,  6.3973e-01, -1.3037e+00, -3.4076e+00,  2.2941e-01,\n",
      "         3.0766e-02, -3.6681e-04,  8.4713e-01, -1.4215e+00, -2.0285e+00,\n",
      "         8.3753e-01, -1.7212e+00,  3.3877e-01, -1.2257e-01, -1.3774e+00,\n",
      "        -1.3490e+00, -2.5885e+00, -4.1985e-02,  5.4244e-01,  5.3622e-02,\n",
      "         6.1403e-01, -1.6528e+00,  1.7452e-01, -3.4579e+00,  1.0263e-01,\n",
      "        -2.2546e+00,  6.0808e-01,  2.4394e-01,  8.1183e-01,  5.7884e-01,\n",
      "        -1.5534e+00, -1.0607e+00, -9.1018e-01, -6.4525e-01, -2.7474e+00,\n",
      "        -4.9070e-01,  7.6437e-03,  7.2263e-01, -1.4541e-02, -2.3515e+00,\n",
      "        -5.3183e+00, -1.1967e-01,  8.4578e-01,  6.0127e-01,  1.1511e+00,\n",
      "        -3.0282e-01, -3.0477e-01, -1.9239e+00, -9.0128e-01,  6.5976e-01,\n",
      "        -4.9639e-01, -9.0740e-01, -6.3639e-01, -1.5681e-01, -1.1309e+00,\n",
      "         4.4899e-01, -4.1025e-01, -2.8241e-01, -1.2877e+00, -1.4863e+00,\n",
      "        -2.8485e-01,  1.7526e-01, -2.8499e+00,  3.7728e-02,  7.3946e-01,\n",
      "        -1.2683e+00, -1.0289e+00, -2.7257e-01, -2.4180e+00,  4.4257e-01,\n",
      "        -2.5064e+00, -6.9685e-01, -8.5306e-01,  6.4934e-01,  7.9965e-01,\n",
      "        -6.2696e-01, -2.6494e+00, -2.3892e+00, -9.3735e-01, -5.9820e-01,\n",
      "        -2.2903e+00, -1.5885e+00,  2.1729e-01, -8.4068e-01, -2.4901e+00,\n",
      "         9.4570e-01,  1.4371e+00,  4.2790e-01,  1.0903e+00,  4.4365e-01,\n",
      "        -7.0604e-01, -1.6628e+00, -2.5014e+00, -1.8074e+00,  4.6492e-01,\n",
      "         3.9399e-01, -1.9353e-02, -4.2532e+00, -1.7325e+00,  8.0509e-01,\n",
      "        -4.7113e-01,  1.1786e-01,  3.0690e-01,  4.0461e-01, -1.5335e-01,\n",
      "         1.5426e-01,  1.0358e-01, -2.7037e+00, -5.0353e-01,  1.4703e-01,\n",
      "        -8.3110e-01, -7.5133e-01,  6.8041e-01,  1.4968e-01, -4.6977e-01,\n",
      "        -1.3784e+00,  7.2129e-02,  8.1630e-02, -1.7297e-01, -7.0310e-01,\n",
      "        -1.5538e+00,  8.0178e-01,  4.9972e-01,  4.4901e-01, -1.2734e+00,\n",
      "         1.1829e+00,  7.7164e-01, -1.2089e+00,  2.2305e-01, -1.6507e+00,\n",
      "         1.7434e-01,  3.0537e-01, -3.4401e+00, -1.4057e+00,  5.6580e-01,\n",
      "        -2.5385e-02, -1.6409e+00,  5.6369e-01, -4.2325e-01,  6.5271e-01,\n",
      "        -1.7023e+00,  8.0605e-01, -2.5662e+00, -1.8117e+00, -5.8010e-01,\n",
      "        -5.3247e-01,  1.8369e-01,  5.3969e-01, -1.1742e+00, -1.6574e-01,\n",
      "        -3.1033e-02, -8.3403e-01,  1.0960e+00,  4.2159e-01, -1.9127e+00,\n",
      "        -1.9340e+00, -6.0610e-01,  2.9684e-01,  5.4347e-01,  3.1736e-01,\n",
      "        -1.8422e+00,  3.8241e-01, -1.4477e+00,  5.2591e-01,  3.5263e-02,\n",
      "        -1.9550e+00,  5.4599e-01,  4.9164e-01, -2.5100e-01,  2.4994e-01,\n",
      "        -1.1611e+00, -1.0899e+00,  8.0953e-01, -5.1110e-01, -6.9468e-01,\n",
      "         2.6172e-01, -1.8109e+00, -1.1795e+00, -1.5197e+00,  1.2306e+00,\n",
      "        -9.0728e-02, -1.8065e+00,  9.0069e-01,  5.1133e-01, -8.9310e-01,\n",
      "        -2.4714e+00,  7.8763e-01,  1.3808e+00, -9.0965e-01, -1.9256e+00,\n",
      "         6.8808e-01, -6.1421e-01, -1.0327e+00, -3.1657e+00, -9.0986e-01,\n",
      "        -2.9769e+00,  1.0624e+00,  1.7892e-01,  9.6649e-01,  2.3145e-01,\n",
      "         3.8304e-01,  9.4275e-02, -7.2399e-01,  6.9849e-01, -3.2713e+00,\n",
      "        -1.8229e+00,  1.1741e+00,  9.1032e-01, -1.7291e+00,  2.7987e-01,\n",
      "         1.1834e+00, -1.1344e-01,  3.6593e-01,  1.9172e-01,  5.2725e-02,\n",
      "        -3.9177e+00,  1.9198e-01, -2.8869e-01, -2.3317e+00, -1.4453e+00,\n",
      "         1.6185e-01, -9.2478e-01,  8.7348e-01,  6.6765e-01, -2.6453e-01,\n",
      "         1.9214e-01, -7.3259e-01,  2.0441e-01,  3.0331e-01,  3.0444e-01,\n",
      "        -1.4018e-01, -2.4385e+00, -1.5899e+00, -3.0488e-01,  7.7978e-02,\n",
      "         3.2551e-01,  3.7460e-01, -4.2562e+00,  3.2517e-01,  1.6387e-01,\n",
      "        -1.4512e+00, -4.6640e-01, -3.7860e-01, -7.7987e-02,  2.6581e-01,\n",
      "        -8.2066e-01,  1.0645e-01,  4.1374e-02,  7.3963e-03,  5.7340e-01,\n",
      "        -1.3235e+00,  7.7334e-01, -8.5641e-01, -2.8370e+00, -2.6535e-01,\n",
      "        -8.7873e-01], device='cuda:0')), ('backbone.model.layer3.4.conv3.weight', tensor([[[[-0.0623]],\n",
      "\n",
      "         [[ 0.0902]],\n",
      "\n",
      "         [[-0.0533]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1081]],\n",
      "\n",
      "         [[ 0.0874]],\n",
      "\n",
      "         [[ 0.0007]]],\n",
      "\n",
      "\n",
      "        [[[-0.0680]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[ 0.1057]],\n",
      "\n",
      "         [[-0.0134]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0283]],\n",
      "\n",
      "         [[ 0.0917]],\n",
      "\n",
      "         [[ 0.0053]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1976]],\n",
      "\n",
      "         [[ 0.1372]],\n",
      "\n",
      "         [[-0.0512]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1032]],\n",
      "\n",
      "         [[ 0.2105]],\n",
      "\n",
      "         [[ 0.0602]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0236]],\n",
      "\n",
      "         [[ 0.1348]],\n",
      "\n",
      "         [[-0.0273]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0308]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.1571]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0976]],\n",
      "\n",
      "         [[-0.0335]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0226]],\n",
      "\n",
      "         [[ 0.0359]],\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0575]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.0873]]]], device='cuda:0')), ('backbone.model.layer3.4.bn3.weight', tensor([ 0.2602, -5.0849,  0.0143,  ..., -0.4597,  1.0728,  1.1504],\n",
      "       device='cuda:0')), ('backbone.model.layer3.4.bn3.bias', tensor([ 0.0742,  1.7853,  0.0035,  ..., -0.0539, -0.4612, -0.2921],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.conv1.weight', tensor([[[[-0.0050]],\n",
      "\n",
      "         [[-0.0752]],\n",
      "\n",
      "         [[ 0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0143]],\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[ 0.0554]]],\n",
      "\n",
      "\n",
      "        [[[-0.0449]],\n",
      "\n",
      "         [[ 0.0942]],\n",
      "\n",
      "         [[-0.0138]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0554]],\n",
      "\n",
      "         [[-0.0189]],\n",
      "\n",
      "         [[-0.0583]]],\n",
      "\n",
      "\n",
      "        [[[-0.0974]],\n",
      "\n",
      "         [[ 0.1456]],\n",
      "\n",
      "         [[ 0.0286]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0288]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         [[ 0.0783]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0233]],\n",
      "\n",
      "         [[ 0.0208]],\n",
      "\n",
      "         [[-0.1489]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.0784]],\n",
      "\n",
      "         [[-0.0182]]],\n",
      "\n",
      "\n",
      "        [[[-0.0444]],\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         [[-0.0189]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0824]],\n",
      "\n",
      "         [[-0.1188]],\n",
      "\n",
      "         [[ 0.0387]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0007]],\n",
      "\n",
      "         [[-0.0665]],\n",
      "\n",
      "         [[-0.0839]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1080]],\n",
      "\n",
      "         [[-0.0119]],\n",
      "\n",
      "         [[ 0.0531]]]], device='cuda:0')), ('backbone.model.layer3.5.bn1.weight', tensor([1.4852, 3.2729, 3.1057, 2.0673, 0.5763, 2.4739, 2.4893, 1.4658, 3.1462,\n",
      "        1.6880, 1.5507, 1.6862, 1.3080, 2.4553, 0.6846, 1.8578, 1.2479, 1.1687,\n",
      "        2.0758, 2.2189, 2.2338, 1.9127, 1.9356, 1.4173, 1.7582, 4.9320, 3.5042,\n",
      "        1.8160, 3.7318, 2.7672, 1.0707, 4.1777, 2.3917, 1.7488, 3.0752, 2.8819,\n",
      "        1.4444, 2.3230, 2.7860, 2.2147, 2.0825, 2.5044, 1.2726, 1.7923, 2.7466,\n",
      "        4.7087, 1.4169, 4.1317, 3.2424, 3.4752, 1.3938, 1.6169, 3.5631, 3.5693,\n",
      "        1.7766, 4.9925, 2.1264, 1.1651, 1.5308, 1.9155, 2.7575, 2.6886, 4.1637,\n",
      "        1.6208, 1.5765, 4.7049, 2.2442, 2.3855, 2.2063, 3.3629, 3.2180, 2.6590,\n",
      "        3.1060, 1.8445, 2.1367, 4.7130, 2.3400, 3.3061, 3.3906, 1.6378, 1.4307,\n",
      "        2.2192, 2.1112, 0.6146, 3.6153, 1.9711, 4.0864, 1.8594, 0.8910, 0.8875,\n",
      "        2.4554, 3.4581, 2.5861, 1.3246, 3.0670, 1.6468, 0.9281, 1.8438, 1.6273,\n",
      "        2.2884, 1.7332, 0.8801, 1.9482, 3.3921, 2.5850, 2.1514, 1.5718, 1.8127,\n",
      "        4.2581, 3.1335, 2.8837, 0.8873, 2.0166, 2.4763, 1.3620, 2.3134, 0.7275,\n",
      "        2.1851, 1.5166, 1.3425, 3.0358, 1.4815, 3.1026, 1.6465, 5.2060, 2.0161,\n",
      "        3.8185, 2.6601, 1.5144, 1.7694, 2.0594, 2.9870, 2.7636, 5.1804, 2.0347,\n",
      "        1.8708, 1.0707, 2.9827, 2.4023, 1.8565, 7.2270, 3.5273, 2.2581, 5.1927,\n",
      "        2.5270, 1.1333, 3.4341, 2.0126, 2.7409, 2.0246, 1.9832, 2.2076, 1.6627,\n",
      "        2.7495, 1.4019, 1.0664, 3.8186, 1.9650, 1.3981, 1.9548, 1.6031, 1.4304,\n",
      "        3.2129, 4.4563, 1.8792, 1.4943, 2.2476, 2.3710, 3.5282, 1.1253, 2.8602,\n",
      "        1.9554, 4.3865, 2.9684, 2.1124, 2.2242, 1.4172, 2.8978, 2.6657, 1.6584,\n",
      "        2.7679, 2.4428, 1.1472, 2.7886, 2.0316, 2.3835, 3.8681, 1.7310, 1.4127,\n",
      "        1.9266, 1.5777, 4.0280, 5.1983, 1.7159, 2.2629, 0.4568, 3.0747, 2.3366,\n",
      "        3.3699, 2.2933, 1.2367, 1.5433, 1.8904, 1.8471, 2.5921, 0.8374, 1.4323,\n",
      "        1.7395, 4.0891, 1.8250, 3.4978, 1.6632, 2.3644, 1.8024, 2.2218, 5.7029,\n",
      "        3.1383, 5.6155, 1.7813, 3.1792, 1.0622, 6.0300, 1.4698, 2.1041, 0.8673,\n",
      "        1.6361, 1.9967, 1.7760, 1.9182, 1.9811, 2.2388, 1.1072, 2.6161, 0.8813,\n",
      "        1.9870, 1.9682, 5.2035, 3.1700, 1.8749, 1.5456, 2.5078, 4.2062, 2.1083,\n",
      "        1.9336, 3.2969, 3.0115, 1.5607, 2.3117, 1.9631, 1.9631, 1.9776, 1.1555,\n",
      "        2.1286, 2.3548, 1.6868, 0.6115], device='cuda:0')), ('backbone.model.layer3.5.bn1.bias', tensor([-1.3011, -0.4200, -1.7635, -2.7558, -0.0386, -0.7511, -1.1376, -0.0079,\n",
      "        -4.9134, -0.6461,  0.1099, -0.9773, -0.2172, -0.2028, -0.0964, -0.7478,\n",
      "        -0.0266, -1.0643, -0.2969, -0.0819, -0.7602, -0.6540, -2.2234, -2.2738,\n",
      "        -1.2207, -1.3956, -1.1124, -1.0210, -1.7614, -1.1829, -2.5973, -0.8573,\n",
      "        -0.7110,  0.4253, -0.8747, -0.9150, -3.4887, -0.6927, -1.0752,  0.0682,\n",
      "        -1.8815, -1.2622, -0.7859, -0.0974, -2.4963, -4.1108, -1.4570, -1.8094,\n",
      "        -1.0895, -0.6166, -3.0493, -0.8116, -0.2453, -1.4946, -0.4241, -1.6790,\n",
      "        -0.4582, -1.5803, -0.4813, -1.0263, -1.7170, -1.5509, -0.1079, -1.0063,\n",
      "        -2.2815, -0.8797, -2.4329, -1.5968,  1.3513, -1.1854, -0.5786, -1.6700,\n",
      "        -1.4094, -7.3654, -0.5131, -2.0949, -0.9268, -1.0390, -1.6291, -0.0231,\n",
      "        -1.8025, -0.4152, -2.2173,  0.6338, -1.0412, -1.0602, -0.0989, -2.6227,\n",
      "         0.7320, -0.3800, -1.8882, -2.3759, -1.7956,  0.1959, -1.7078, -1.3450,\n",
      "        -0.2012, -0.8362,  0.1634, -1.2316, -1.9372, -2.0719, -0.9756, -1.5415,\n",
      "        -0.8276, -0.1411,  0.4428,  0.7902, -0.1715, -3.0367, -1.1475, -1.4936,\n",
      "        -0.5255, -1.1886, -0.6822, -1.7831, -0.3783, -2.3747,  0.5676,  1.2604,\n",
      "        -1.0312, -3.7591, -1.7766, -1.0339, -2.5566,  0.0553, -1.1926, -0.5420,\n",
      "         1.7146, -2.3438, -0.8320, -1.8776, -1.1313, -1.9702, -0.5734, -1.5204,\n",
      "        -2.1112, -3.6120, -1.8749, -0.1960, -3.0090, -0.7552, -1.3546, -2.6739,\n",
      "        -1.2191, -1.9526, -2.3310,  0.3074, -2.0417, -0.6787, -0.6221, -1.5687,\n",
      "         0.0313, -1.4623,  0.5506, -2.5682, -1.7528, -1.0403,  0.2314,  0.0711,\n",
      "        -1.9606, -1.0876, -0.3547, -1.7235, -0.1592, -1.3793, -1.0379, -1.6690,\n",
      "        -0.7828, -2.5104, -0.7588, -0.3562, -1.3058, -0.4313, -0.4636, -3.0468,\n",
      "        -2.2424, -4.5501, -3.0423, -0.7692, -2.9243, -3.7350, -0.1591, -3.6920,\n",
      "        -0.5812, -1.6842, -0.0248, -0.1319, -1.7735, -2.1610, -1.8762,  0.2511,\n",
      "        -2.5514, -1.4371, -2.3948,  0.8969, -1.8835, -1.9166, -2.8857, -2.4437,\n",
      "        -0.5069, -0.5561, -1.4166, -1.9953, -1.3496, -3.4709, -1.0109, -0.1024,\n",
      "        -2.0271, -2.8026, -2.6857, -0.2108,  0.4512, -2.3966, -1.6891, -1.6206,\n",
      "        -2.7224, -3.5393, -0.9481, -1.4672, -2.5998, -3.7795, -0.6627, -1.1810,\n",
      "        -2.8528, -0.4377, -2.3358, -0.2613, -0.6080, -1.1598, -0.8126, -0.7563,\n",
      "        -1.4620, -1.5391, -0.2947, -1.6043, -1.8136, -1.6179, -1.5761, -0.4663,\n",
      "        -0.0732, -1.8601,  0.4953, -0.4401, -1.0396, -1.5020, -4.6421, -0.4417,\n",
      "        -0.3447, -1.1976, -1.6017, -1.0919, -1.3272, -1.4845, -0.3436, -1.4302],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.conv2.weight', tensor([[[[-3.0126e-02, -6.5069e-02, -8.0060e-02],\n",
      "          [-3.1927e-02,  2.2007e-03, -3.3761e-02],\n",
      "          [-1.0773e-02, -1.9440e-02, -1.0206e-03]],\n",
      "\n",
      "         [[-1.6157e-01, -1.8362e-01, -1.4388e-01],\n",
      "          [-1.1685e-01, -8.8171e-02, -7.8696e-02],\n",
      "          [ 7.1360e-03,  1.6532e-02, -5.5012e-02]],\n",
      "\n",
      "         [[-8.8899e-03,  5.2452e-02,  2.0718e-02],\n",
      "          [-3.4356e-02, -3.1858e-02, -5.1448e-03],\n",
      "          [-4.6568e-02, -5.0200e-02, -2.9930e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1549e-01, -5.6381e-02, -1.4566e-01],\n",
      "          [-1.2336e-01, -6.9266e-02, -1.5765e-01],\n",
      "          [-1.1674e-01, -1.1551e-01, -1.6064e-01]],\n",
      "\n",
      "         [[-1.5494e-02,  4.2709e-04, -6.7384e-03],\n",
      "          [-4.4397e-02,  1.1598e-03, -6.7877e-02],\n",
      "          [-9.9168e-02, -6.8193e-02, -2.7521e-03]],\n",
      "\n",
      "         [[-4.5342e-02, -1.1574e-01, -6.2240e-02],\n",
      "          [-7.2096e-02, -1.0811e-01, -5.4723e-02],\n",
      "          [-6.3851e-02, -4.5152e-02, -4.0025e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5849e-02, -4.8172e-02, -2.9536e-02],\n",
      "          [-4.8661e-02, -1.2134e-02, -6.8635e-02],\n",
      "          [-5.5971e-02, -4.9053e-02, -7.5355e-02]],\n",
      "\n",
      "         [[ 3.9963e-02,  4.1310e-02,  4.1324e-03],\n",
      "          [ 3.8826e-02,  1.8669e-02, -7.9041e-03],\n",
      "          [ 3.2591e-02,  1.8356e-02,  1.7128e-02]],\n",
      "\n",
      "         [[ 8.9516e-02, -1.5888e-02,  3.1086e-03],\n",
      "          [ 7.8388e-02,  3.6714e-02, -3.1601e-02],\n",
      "          [-8.9336e-03, -6.2775e-02, -3.8521e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.5712e-02,  5.2993e-02,  6.0687e-02],\n",
      "          [ 9.8716e-02,  2.0923e-02,  8.8699e-02],\n",
      "          [ 1.1588e-01,  3.5768e-02,  1.2685e-01]],\n",
      "\n",
      "         [[-2.4788e-03, -1.1887e-01, -1.9854e-02],\n",
      "          [ 2.7485e-02, -2.0704e-02,  1.0353e-01],\n",
      "          [-5.8462e-03, -8.0393e-02,  3.4710e-02]],\n",
      "\n",
      "         [[-9.6639e-02, -1.0985e-01, -4.9067e-02],\n",
      "          [-1.0496e-01, -1.1225e-01, -4.3896e-02],\n",
      "          [-2.6408e-02, -7.4459e-02, -1.7601e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1364e-02, -2.5501e-02, -8.9831e-02],\n",
      "          [-5.8042e-02,  3.6634e-02, -6.8997e-02],\n",
      "          [-2.2065e-02,  6.2276e-02, -4.9969e-02]],\n",
      "\n",
      "         [[-4.9758e-03,  3.8400e-02,  6.1597e-02],\n",
      "          [ 8.7954e-02, -8.9322e-02,  8.5414e-02],\n",
      "          [ 9.2924e-02,  1.3012e-02,  1.1699e-01]],\n",
      "\n",
      "         [[-2.3428e-02,  4.3617e-02,  5.7583e-03],\n",
      "          [-5.9888e-03,  4.0091e-02,  1.2352e-02],\n",
      "          [ 3.4128e-03,  5.6933e-02, -7.1737e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7714e-02,  1.0159e-01,  3.5127e-02],\n",
      "          [ 2.1783e-02,  7.0243e-02,  4.0840e-05],\n",
      "          [-4.3435e-02, -1.1688e-02, -7.3202e-03]],\n",
      "\n",
      "         [[-3.6998e-02,  6.4952e-02, -4.6540e-03],\n",
      "          [ 5.6243e-03,  9.6173e-02, -4.0238e-02],\n",
      "          [-2.9651e-02,  1.9965e-02, -7.9273e-02]],\n",
      "\n",
      "         [[ 1.3311e-02, -5.3085e-02, -9.0291e-03],\n",
      "          [ 1.0910e-02, -6.1567e-03,  1.0043e-02],\n",
      "          [ 1.7020e-02, -1.4619e-02,  2.3666e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.3398e-02,  2.4225e-03, -9.0272e-03],\n",
      "          [ 1.4635e-02,  3.7916e-02,  4.9440e-02],\n",
      "          [ 1.3614e-02,  7.4133e-02,  5.4323e-02]],\n",
      "\n",
      "         [[-1.7996e-01, -2.0380e-01, -1.9599e-01],\n",
      "          [-1.5283e-01, -1.8972e-01, -1.8129e-01],\n",
      "          [-7.6927e-02, -9.8908e-02, -8.3891e-02]],\n",
      "\n",
      "         [[ 1.3492e-01,  1.6927e-01,  1.0088e-01],\n",
      "          [ 1.8733e-01,  2.8159e-01,  1.5529e-01],\n",
      "          [ 2.2825e-01,  2.8839e-01,  1.7665e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3918e-02, -4.4265e-02,  1.1248e-02],\n",
      "          [-2.6011e-02, -9.7481e-02, -1.6946e-02],\n",
      "          [ 3.3598e-02, -1.9091e-02,  2.6880e-02]],\n",
      "\n",
      "         [[ 9.6960e-04, -1.3991e-02,  2.1728e-02],\n",
      "          [ 4.5186e-02,  1.2742e-02,  5.6722e-02],\n",
      "          [-4.7513e-02, -1.8959e-02, -4.7290e-02]],\n",
      "\n",
      "         [[-2.0960e-01, -1.9724e-01, -2.3245e-01],\n",
      "          [-1.8212e-01, -2.1160e-01, -2.1926e-01],\n",
      "          [-2.0964e-01, -2.5554e-01, -2.7705e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1724e-02, -5.0829e-02, -4.5687e-02],\n",
      "          [-3.4457e-02, -1.3143e-01, -8.5314e-02],\n",
      "          [-2.4859e-02, -1.0578e-01, -3.4198e-02]],\n",
      "\n",
      "         [[ 3.9407e-02,  1.2718e-02, -4.3295e-02],\n",
      "          [ 2.6507e-02,  1.6522e-01,  1.2198e-02],\n",
      "          [ 4.6081e-02,  4.1927e-03,  1.4933e-02]],\n",
      "\n",
      "         [[-2.2432e-02,  3.1649e-02, -2.8396e-02],\n",
      "          [ 4.2371e-02, -1.9659e-02,  2.9343e-02],\n",
      "          [ 7.5689e-03,  3.0675e-02,  3.9486e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3335e-02, -1.3251e-02, -1.1222e-02],\n",
      "          [-1.5473e-02,  1.2936e-01,  3.7815e-02],\n",
      "          [-3.7278e-02,  6.8900e-03, -6.4999e-02]],\n",
      "\n",
      "         [[-1.8300e-02, -2.5131e-02, -1.3673e-02],\n",
      "          [-2.6743e-03,  4.0869e-02, -1.9581e-02],\n",
      "          [ 2.6616e-02,  2.6624e-03,  3.4260e-02]],\n",
      "\n",
      "         [[ 5.9158e-02,  6.2257e-02,  5.3467e-02],\n",
      "          [ 3.1171e-02,  7.9780e-02,  3.2978e-02],\n",
      "          [ 3.0387e-02,  7.7567e-02,  4.4266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2663e-02,  1.2158e-02, -4.8785e-03],\n",
      "          [-4.7927e-03,  1.8207e-02, -7.5964e-03],\n",
      "          [-3.4807e-02, -1.6773e-02, -8.7812e-03]],\n",
      "\n",
      "         [[ 2.4696e-02,  3.4358e-02,  5.6985e-03],\n",
      "          [ 1.4231e-02, -2.7495e-02, -1.7663e-03],\n",
      "          [-5.4913e-02, -2.3215e-02, -2.5171e-02]],\n",
      "\n",
      "         [[ 9.2285e-03,  3.2782e-02, -1.9081e-02],\n",
      "          [-4.1236e-02,  3.9687e-02, -3.2634e-02],\n",
      "          [-5.3521e-02, -3.5577e-02, -6.4801e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.8010e-02, -1.4536e-02,  9.0045e-03],\n",
      "          [-4.0036e-02, -4.9584e-02, -2.0707e-02],\n",
      "          [-8.7691e-03, -4.4960e-02, -4.5329e-02]],\n",
      "\n",
      "         [[-2.7639e-02,  3.5597e-02,  8.2298e-04],\n",
      "          [-2.9570e-02,  2.8251e-02,  2.6092e-04],\n",
      "          [-4.8411e-02, -3.7837e-02, -1.6720e-02]],\n",
      "\n",
      "         [[-3.7951e-02,  2.3490e-02, -2.4559e-02],\n",
      "          [-3.3889e-03, -7.6114e-02, -5.0305e-02],\n",
      "          [-4.5863e-02, -6.1375e-03, -7.1011e-02]]]], device='cuda:0')), ('backbone.model.layer3.5.bn2.weight', tensor([1.9716, 0.8850, 2.4005, 2.1577, 2.1308, 2.9592, 3.4524, 2.7000, 2.8562,\n",
      "        2.8370, 3.1491, 2.5477, 2.0466, 2.1160, 0.6116, 3.0788, 2.3723, 1.3448,\n",
      "        0.6304, 3.9090, 3.6329, 1.9093, 4.2062, 5.0781, 1.7409, 1.9834, 2.0901,\n",
      "        0.9367, 1.9504, 1.8760, 2.4362, 1.3753, 2.6462, 3.9181, 3.4102, 0.6655,\n",
      "        2.7020, 2.0169, 3.0613, 3.5904, 1.7606, 0.7473, 2.2563, 1.7484, 1.9070,\n",
      "        1.8505, 1.7893, 2.7985, 1.7277, 1.2846, 1.0214, 2.1889, 2.8349, 3.0310,\n",
      "        2.2443, 2.9965, 3.4888, 2.0211, 7.5969, 2.2658, 2.2603, 2.2425, 2.1839,\n",
      "        1.5883, 2.0338, 2.1365, 1.8545, 2.0660, 2.4273, 2.6135, 1.5769, 1.8998,\n",
      "        1.6622, 1.5335, 2.9984, 0.8109, 1.4246, 2.2967, 1.7134, 1.5401, 2.7018,\n",
      "        1.6863, 3.4730, 2.1620, 2.5948, 2.5300, 1.9416, 1.9725, 1.4079, 3.4798,\n",
      "        1.9092, 0.7117, 4.1393, 0.9295, 2.9246, 4.9912, 2.0959, 0.6856, 2.1821,\n",
      "        1.6401, 1.7920, 2.7133, 1.4849, 2.1308, 0.4994, 2.6308, 3.8449, 3.1174,\n",
      "        2.4238, 2.9080, 4.1311, 3.1961, 2.4871, 1.9249, 2.0504, 1.9636, 1.7953,\n",
      "        2.0862, 2.1926, 1.1073, 1.8730, 1.9233, 2.0000, 1.4451, 1.7231, 1.4514,\n",
      "        2.4742, 1.8367, 1.4912, 1.7367, 1.6923, 2.0633, 1.3427, 2.7889, 1.7591,\n",
      "        2.1824, 3.2854, 1.9389, 1.9780, 2.5121, 2.7075, 1.8072, 0.5674, 3.2855,\n",
      "        0.4559, 2.2576, 1.7730, 1.8034, 2.1724, 2.0259, 1.6632, 2.8649, 2.5535,\n",
      "        2.4252, 3.2703, 3.4505, 3.1492, 2.4660, 3.0812, 1.8216, 1.6820, 2.2678,\n",
      "        3.3482, 2.6256, 2.9110, 1.1086, 3.7212, 1.9233, 3.1388, 2.6216, 2.7718,\n",
      "        0.6663, 2.1705, 2.0879, 4.8184, 2.7556, 2.5098, 2.4917, 0.7492, 2.6312,\n",
      "        1.5703, 2.4590, 1.6485, 1.5919, 1.0458, 2.6056, 2.3944, 2.2940, 3.5769,\n",
      "        3.0304, 3.5413, 2.0056, 3.5789, 3.4389, 3.9773, 2.5269, 4.9488, 5.9673,\n",
      "        2.6218, 3.2439, 3.8605, 1.8095, 2.0449, 2.3099, 1.7797, 1.7532, 1.5025,\n",
      "        2.2445, 2.4861, 2.3791, 1.5928, 1.1528, 2.4567, 2.5132, 1.8339, 3.5058,\n",
      "        1.9978, 0.7220, 2.7285, 2.2432, 1.9329, 2.4716, 2.4272, 3.3063, 3.1722,\n",
      "        1.7404, 1.9045, 1.9482, 2.8016, 2.3476, 1.3035, 2.0206, 2.2605, 1.8333,\n",
      "        1.9360, 1.2660, 1.3409, 1.7566, 2.7977, 1.7741, 1.6394, 1.9602, 1.9277,\n",
      "        1.2702, 1.7798, 3.1350, 1.4802, 1.9416, 3.2474, 2.2052, 2.5035, 2.0894,\n",
      "        2.1459, 0.4560, 2.1976, 2.3609], device='cuda:0')), ('backbone.model.layer3.5.bn2.bias', tensor([-1.3165e+00,  2.2318e-01, -1.6689e+00, -1.5092e+00, -4.8535e-01,\n",
      "        -2.6391e+00, -2.8729e+00, -1.9792e+00, -8.9919e-01, -1.2269e+00,\n",
      "        -3.0718e+00,  5.1775e-01, -2.4929e-02,  5.1377e-01, -2.7939e+00,\n",
      "         1.5244e+00, -6.1665e-01,  1.5803e+00, -2.6272e-01, -3.4205e+00,\n",
      "        -4.3886e-01, -1.3925e+00, -4.7507e-01, -3.9720e+00,  1.5097e-01,\n",
      "        -4.5149e-01, -1.3196e+00,  1.1570e+00, -7.8038e-01, -4.1751e-02,\n",
      "        -2.0460e+00,  1.0115e+00,  2.1132e-01,  1.0211e+00, -2.6322e+00,\n",
      "        -4.3816e+00, -1.2400e+00,  1.0533e+00, -1.8279e+00, -3.0849e-01,\n",
      "         2.7327e-01, -2.3425e+00, -2.0411e+00,  3.8753e-01,  5.6912e-01,\n",
      "         5.0206e-01,  5.0193e-01, -2.5296e+00,  1.2367e-02, -2.3946e+00,\n",
      "        -1.6855e-02,  3.5280e-02,  1.5241e-01, -2.9044e+00, -3.3994e-01,\n",
      "        -3.4728e+00, -1.2121e+00, -2.3263e-01, -3.4758e+00, -5.6429e-01,\n",
      "        -1.7093e-01, -5.5346e-01, -6.5603e-01, -1.8963e+00, -2.2978e+00,\n",
      "        -2.4029e-01, -2.8399e-01, -9.7270e-01, -5.0282e-02, -2.6674e+00,\n",
      "         2.4178e-01,  1.0645e-01,  4.1376e-01,  5.0739e-01, -3.0469e+00,\n",
      "        -2.7392e+00, -6.5667e-01, -1.3054e+00,  6.1450e-01, -4.7044e-01,\n",
      "        -2.2291e-02, -3.0717e+00, -1.0963e-01,  7.5828e-02,  9.7700e-01,\n",
      "        -1.2450e-01,  5.9078e-02, -1.1448e+00, -5.6379e-01, -2.1466e+00,\n",
      "         5.8848e-01,  6.5726e-02, -2.8028e+00,  1.6023e+00, -1.0356e+00,\n",
      "        -2.9682e+00, -1.2291e+00, -2.3175e+00, -1.9020e+00, -2.5840e-01,\n",
      "         4.2517e-01, -3.0418e+00,  5.8659e-01,  1.4699e-01, -1.8848e+00,\n",
      "        -1.1028e+00, -7.0594e-01, -1.5908e-01,  4.2562e-02, -1.6007e+00,\n",
      "        -8.1654e-01, -2.7698e+00, -4.1602e-01, -1.4384e+00, -6.7993e-01,\n",
      "        -1.4509e+00,  1.5605e+00, -9.4451e-01, -1.0835e+00,  1.4008e+00,\n",
      "        -7.5101e-01,  3.7958e-02,  3.3173e-01,  6.7474e-01, -4.5415e-03,\n",
      "        -1.6641e+00,  9.2552e-01, -5.5846e-01, -4.1334e-01,  2.3719e-01,\n",
      "        -8.3572e-02,  3.3919e-01, -1.4241e+00, -2.6221e-01, -9.0352e-04,\n",
      "        -1.1351e-01, -3.5175e+00, -1.2253e-01, -9.2757e-02, -3.4333e-01,\n",
      "         2.5557e+00, -4.3171e-01, -5.6967e-01, -1.3110e+00, -1.0946e+00,\n",
      "        -9.8360e-01,  5.0809e-01,  3.8682e-01, -9.2565e-01, -1.7086e-02,\n",
      "         6.2748e-01, -3.2442e+00, -9.2144e-01, -4.7022e-01, -1.3433e+00,\n",
      "        -3.1152e+00, -8.6758e-01, -1.4625e+00, -2.5709e+00, -6.0150e-01,\n",
      "         1.1150e+00, -1.0314e+00, -3.6409e-01,  2.9245e-01, -1.4177e-01,\n",
      "        -3.0291e+00, -7.1323e-02, -7.7640e-01,  1.7797e-01,  2.0093e-01,\n",
      "         3.6102e-02, -1.7498e+00, -1.7112e+00, -1.1967e+00, -6.6925e-01,\n",
      "        -6.0700e-01, -1.3839e+00, -3.4458e-01, -3.3541e+00, -2.3471e+00,\n",
      "         8.4141e-01, -1.3958e+00, -5.0922e-01,  3.9804e-01, -5.0559e+00,\n",
      "        -1.0625e+00, -2.0402e+00, -2.9972e-01, -1.5043e+00, -1.2087e-01,\n",
      "        -2.5172e+00,  5.1895e-02, -3.5585e-01, -1.0090e+00,  2.9288e-01,\n",
      "        -1.4386e+00, -6.5191e-01, -9.5416e-01, -1.1769e+01, -8.9258e-01,\n",
      "        -3.5519e+00, -7.5470e-01, -5.1281e-01,  2.5805e-01, -1.4448e+00,\n",
      "         4.0360e-02, -3.8366e-01, -1.1949e+00, -5.4725e-01, -3.6571e-02,\n",
      "         7.4343e-01, -1.3566e+00, -7.1655e-02, -2.7119e-01, -1.8157e+00,\n",
      "        -1.0947e+00, -1.6670e+00,  7.1653e-01, -1.1437e+00, -7.1718e-01,\n",
      "        -1.4069e+00, -3.9423e-01, -1.3482e+00, -1.6565e+00, -5.8425e-01,\n",
      "         4.1286e-01, -4.6118e-01, -1.9203e-01,  2.5514e-01, -7.5685e-01,\n",
      "        -1.2014e+00, -9.9569e-01, -1.6138e-01, -2.4467e-01,  3.2915e-01,\n",
      "        -1.0208e+00,  5.4656e-02, -1.2629e+00, -1.4422e+00, -6.5830e-01,\n",
      "        -3.0722e-01, -4.5640e-01, -1.0746e+00, -7.2899e-01,  6.9016e-02,\n",
      "        -1.7230e+00,  1.3864e+00, -9.7743e-01, -5.4000e-01,  1.2462e-02,\n",
      "        -1.0586e+00,  4.6164e-01,  7.8305e-01, -9.1481e-01,  5.3722e-01,\n",
      "        -1.5637e+00], device='cuda:0')), ('backbone.model.layer3.5.conv3.weight', tensor([[[[-0.0103]],\n",
      "\n",
      "         [[-0.0527]],\n",
      "\n",
      "         [[-0.0538]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0881]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         [[ 0.0730]]],\n",
      "\n",
      "\n",
      "        [[[-0.0782]],\n",
      "\n",
      "         [[-0.0232]],\n",
      "\n",
      "         [[-0.0668]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0327]],\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         [[-0.0895]]],\n",
      "\n",
      "\n",
      "        [[[-0.0920]],\n",
      "\n",
      "         [[ 0.0452]],\n",
      "\n",
      "         [[-0.0893]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0923]],\n",
      "\n",
      "         [[ 0.0317]],\n",
      "\n",
      "         [[-0.0037]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0035]],\n",
      "\n",
      "         [[-0.1572]],\n",
      "\n",
      "         [[ 0.0276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1122]],\n",
      "\n",
      "         [[ 0.1002]],\n",
      "\n",
      "         [[ 0.0473]]],\n",
      "\n",
      "\n",
      "        [[[-0.0277]],\n",
      "\n",
      "         [[-0.1220]],\n",
      "\n",
      "         [[ 0.0486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0182]],\n",
      "\n",
      "         [[-0.0297]],\n",
      "\n",
      "         [[-0.1139]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0444]],\n",
      "\n",
      "         [[ 0.0152]],\n",
      "\n",
      "         [[ 0.1128]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1084]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[ 0.0568]]]], device='cuda:0')), ('backbone.model.layer3.5.bn3.weight', tensor([-2.1412, -2.1685,  1.8625,  ..., -1.5707,  4.1138,  2.2215],\n",
      "       device='cuda:0')), ('backbone.model.layer3.5.bn3.bias', tensor([-0.5192, -0.7654, -0.0873,  ..., -0.5757,  0.3450,  0.0365],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv1.weight', tensor([[[[-0.0126]],\n",
      "\n",
      "         [[ 0.0001]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0485]],\n",
      "\n",
      "         [[-0.0419]],\n",
      "\n",
      "         [[-0.0609]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0252]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[-0.0965]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         [[ 0.0572]],\n",
      "\n",
      "         [[ 0.1200]]],\n",
      "\n",
      "\n",
      "        [[[-0.0309]],\n",
      "\n",
      "         [[ 0.0305]],\n",
      "\n",
      "         [[-0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         [[ 0.0323]],\n",
      "\n",
      "         [[-0.0071]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0532]],\n",
      "\n",
      "         [[-0.0129]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1097]],\n",
      "\n",
      "         [[ 0.0653]],\n",
      "\n",
      "         [[ 0.0338]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1183]],\n",
      "\n",
      "         [[ 0.0992]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0219]],\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[ 0.0656]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0029]],\n",
      "\n",
      "         [[ 0.0039]],\n",
      "\n",
      "         [[ 0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0385]],\n",
      "\n",
      "         [[-0.0714]],\n",
      "\n",
      "         [[-0.0344]]]], device='cuda:0')), ('backbone.model.layer4.0.bn1.weight', tensor([1.8314, 1.8578, 1.8644, 1.8421, 2.5610, 2.2845, 1.9866, 2.0912, 2.4900,\n",
      "        1.9306, 2.4838, 1.6676, 3.1620, 1.6694, 1.9133, 1.8298, 3.1592, 2.5286,\n",
      "        1.3591, 1.5647, 1.5075, 1.9385, 3.1072, 1.4559, 2.7022, 1.5187, 2.1546,\n",
      "        1.8905, 2.0389, 1.7594, 2.4878, 2.1003, 2.1269, 1.6262, 1.6843, 1.7931,\n",
      "        1.7669, 1.1859, 1.5551, 2.0436, 2.6605, 1.7884, 1.7126, 1.9043, 1.5090,\n",
      "        2.0073, 2.3540, 1.5896, 3.5884, 2.6517, 1.8038, 2.6024, 1.8707, 2.3828,\n",
      "        1.8685, 2.4474, 2.4184, 2.0196, 2.1073, 2.4320, 1.9161, 2.2337, 2.3814,\n",
      "        2.0207, 2.1428, 1.9140, 1.9442, 2.4179, 2.7146, 2.6323, 1.8672, 1.9782,\n",
      "        2.2749, 1.9353, 1.9229, 1.8198, 1.9148, 1.5088, 2.0675, 2.1521, 2.1486,\n",
      "        1.8737, 3.9593, 2.0368, 1.5336, 2.4615, 1.8532, 2.0170, 2.1321, 1.9281,\n",
      "        1.6959, 2.0400, 1.7028, 2.2858, 2.0788, 3.6004, 2.2095, 1.8256, 1.9783,\n",
      "        2.2759, 1.6419, 1.7615, 1.9471, 3.1555, 1.8462, 2.0394, 2.0404, 2.4591,\n",
      "        1.5498, 2.6800, 2.1380, 2.0328, 2.2833, 1.7968, 2.2967, 2.7662, 1.8850,\n",
      "        1.8883, 2.0772, 1.8388, 2.0843, 1.8748, 2.6824, 2.5188, 1.7922, 2.0672,\n",
      "        1.9006, 1.5658, 2.2571, 1.8768, 2.8949, 2.4737, 1.8489, 4.9384, 2.0425,\n",
      "        2.4711, 4.3078, 2.2489, 2.5794, 2.2345, 2.5843, 2.0575, 3.0014, 1.4252,\n",
      "        1.8560, 2.1284, 3.0941, 2.0184, 2.5503, 1.5414, 1.9831, 1.5442, 2.2784,\n",
      "        2.2006, 1.8038, 1.9068, 1.4567, 2.3943, 2.5676, 2.3289, 1.7855, 2.3405,\n",
      "        1.7952, 2.3015, 1.8924, 1.9592, 1.9769, 1.9527, 1.9840, 2.4929, 1.7957,\n",
      "        2.3109, 1.8725, 2.4707, 1.9381, 1.7869, 1.8255, 1.9971, 2.1971, 2.1447,\n",
      "        2.5156, 1.8655, 1.5970, 1.8435, 2.0856, 1.9169, 2.9520, 1.5969, 2.0474,\n",
      "        1.9100, 2.2173, 2.0582, 1.8154, 1.9895, 1.6014, 2.1971, 1.8524, 1.9345,\n",
      "        1.8561, 2.3063, 1.2572, 2.4697, 1.5770, 2.1728, 1.9229, 1.7117, 1.8611,\n",
      "        1.4461, 2.1610, 2.1258, 2.7123, 2.4184, 1.6011, 3.2742, 2.0722, 2.1850,\n",
      "        1.5767, 1.9229, 1.8494, 1.5368, 2.3461, 2.0585, 1.8891, 1.7523, 2.4773,\n",
      "        1.7997, 2.0862, 1.9603, 1.9888, 2.7592, 2.4955, 1.1006, 3.4028, 2.8508,\n",
      "        2.4656, 2.9904, 2.6301, 3.2798, 1.9367, 2.5565, 1.8639, 2.3303, 1.5951,\n",
      "        1.7917, 2.0518, 2.1212, 1.7452, 1.7090, 2.8612, 1.6223, 3.3167, 2.2376,\n",
      "        2.3363, 2.5157, 2.3670, 2.3206, 1.9170, 2.2345, 2.7256, 2.5249, 1.8755,\n",
      "        1.4393, 1.6177, 1.5042, 1.8595, 1.7563, 1.9009, 2.2058, 1.7995, 2.0034,\n",
      "        1.7491, 1.8657, 1.8666, 1.7867, 1.6263, 2.0607, 2.2113, 1.7739, 2.0815,\n",
      "        1.9199, 1.5168, 2.1859, 2.8054, 2.2436, 1.8102, 2.2178, 1.7972, 1.6173,\n",
      "        2.9415, 2.0863, 1.8028, 1.8486, 2.6507, 1.8701, 1.5540, 1.9667, 1.8125,\n",
      "        1.8773, 1.5193, 2.7824, 1.3550, 1.8569, 2.8391, 2.3180, 1.3525, 1.8346,\n",
      "        1.7437, 1.9632, 2.2668, 2.0131, 2.8853, 2.2676, 2.1468, 1.7671, 2.1995,\n",
      "        2.3387, 2.3026, 1.7962, 1.9896, 1.3652, 1.9478, 2.1477, 1.9074, 2.1422,\n",
      "        2.1081, 1.7641, 1.7447, 1.7464, 2.5415, 1.9353, 1.7740, 1.9930, 2.3945,\n",
      "        2.0018, 1.8538, 1.9348, 1.8505, 2.1438, 1.9251, 1.9409, 1.4635, 1.7011,\n",
      "        1.7805, 1.6285, 1.6307, 1.5744, 1.6255, 2.5114, 2.0965, 1.4512, 1.6409,\n",
      "        2.2474, 2.0258, 2.2130, 1.5051, 1.9196, 1.6749, 2.5703, 1.8729, 1.7775,\n",
      "        3.6745, 1.9105, 2.7890, 2.4215, 2.6347, 2.2251, 1.9016, 2.0337, 1.9324,\n",
      "        1.9366, 1.8875, 1.7551, 1.9830, 1.7689, 1.5918, 1.7217, 1.6096, 1.5541,\n",
      "        1.6147, 1.7155, 1.8565, 1.7410, 1.6995, 1.8018, 2.4317, 1.6919, 1.7526,\n",
      "        1.9427, 2.1415, 2.2336, 2.2679, 1.3602, 2.9309, 2.7840, 1.9139, 2.3315,\n",
      "        1.8691, 2.4040, 1.9170, 2.3854, 1.5574, 1.7801, 1.7688, 1.8833, 4.1351,\n",
      "        2.0465, 2.5695, 1.3451, 1.6086, 1.3129, 2.4328, 1.4821, 2.5019, 1.7801,\n",
      "        1.6211, 2.2805, 1.9870, 2.5951, 1.9765, 1.9525, 1.8773, 1.6152, 3.5596,\n",
      "        1.7139, 2.0210, 1.6348, 2.2839, 2.1681, 2.8953, 2.0880, 2.4774, 1.7921,\n",
      "        2.2298, 2.1537, 2.5972, 1.8556, 2.4781, 2.3579, 2.3878, 2.5347, 2.5064,\n",
      "        2.9794, 1.7614, 0.9382, 3.2732, 1.7949, 2.3715, 1.6634, 2.1491, 1.9381,\n",
      "        1.8417, 3.3854, 2.0239, 2.4697, 1.9213, 2.2826, 1.9782, 1.7698, 1.7586,\n",
      "        1.8418, 1.7916, 1.5048, 1.9105, 2.0612, 2.2690, 3.1478, 2.2929, 2.0902,\n",
      "        2.3192, 2.2000, 2.4909, 2.5873, 2.6669, 1.5663, 2.1689, 2.3390, 2.3304,\n",
      "        1.6171, 1.5972, 2.2684, 2.2715, 2.6314, 1.5208, 2.1472, 1.8234, 2.0982,\n",
      "        2.1537, 1.5031, 2.4025, 2.0963, 2.1757, 2.3896, 2.4387, 2.2195, 1.8717,\n",
      "        2.0777, 1.7244, 2.7924, 2.7047, 1.9274, 1.7062, 1.9884, 1.7632, 2.7799,\n",
      "        2.2695, 2.0700, 2.0162, 2.5286, 2.2320, 1.8121, 0.9934, 2.2532],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn1.bias', tensor([-0.9996, -2.7897, -1.4111, -1.9773, -3.0503, -4.4743, -2.3001, -1.9981,\n",
      "        -2.7169, -1.6225, -3.0258, -0.5046, -2.8504, -2.1793, -1.4652, -1.2736,\n",
      "        -3.4100, -2.9174, -0.5999, -0.8509, -1.6865, -1.4168, -3.4186, -0.6015,\n",
      "        -3.5196, -3.5888, -2.1448, -2.3278, -1.8925, -1.3916, -2.5137, -1.6461,\n",
      "        -2.1925, -1.3213, -0.9442, -1.5646, -1.2388, -0.5977, -1.9568, -1.4014,\n",
      "        -2.0915, -2.4112, -1.3068, -1.7585, -0.5639, -2.2673, -3.3161, -2.5145,\n",
      "        -4.3761, -4.5281, -2.0090, -2.1996, -1.9778, -2.4119, -3.4784, -2.1598,\n",
      "        -3.4804, -2.0425, -3.1701, -1.6180, -2.8418, -2.3062, -2.9641, -1.4605,\n",
      "        -2.2890, -1.0965, -1.9730, -2.3220, -4.0837, -2.7054, -2.2302, -1.2831,\n",
      "        -2.0168, -2.1770, -2.9113, -1.0169, -2.0106, -1.7529, -2.5533, -2.0664,\n",
      "        -2.1710, -1.5145, -3.7775, -2.1574, -0.8421, -1.8253, -1.4936, -2.5463,\n",
      "        -2.3034, -1.5163, -4.5540, -1.4503, -1.4212, -2.2556, -1.9856, -2.7003,\n",
      "        -1.7085, -1.6773, -1.5688, -1.9198, -1.2569, -1.1628, -1.7710, -3.6606,\n",
      "        -1.4089, -1.4689, -1.8231, -2.9187, -3.7592, -3.2089, -2.0444, -1.4620,\n",
      "        -1.9147, -1.3590, -2.1241, -2.7468, -1.3691, -0.8564, -1.8088, -4.8912,\n",
      "        -1.4001, -1.9613, -3.5689, -1.6877, -1.3543, -1.1691, -2.1712, -0.9511,\n",
      "        -1.7271, -1.2590, -2.1970, -1.9712, -1.1546, -3.3205, -1.9197, -3.0246,\n",
      "        -4.7700, -1.9730, -2.8411, -1.6436, -2.3231, -1.5342, -2.4796, -3.7443,\n",
      "        -1.3863, -1.2541, -3.0104, -1.5383, -1.4760, -1.4337, -1.7635, -1.5664,\n",
      "        -1.7771, -2.2309, -0.9700, -1.8766, -2.9835, -2.3372, -2.7448, -2.1365,\n",
      "        -1.4536, -1.6375, -4.3185, -2.4854, -1.7552, -1.4736, -2.4015, -1.7439,\n",
      "        -1.4407, -2.5833, -1.7576, -1.4228, -0.9792, -1.5062, -1.6849, -1.5587,\n",
      "        -1.9200, -2.4084, -2.0131, -2.1149, -4.4426, -1.2813, -1.2274, -1.6428,\n",
      "        -1.8997, -2.7946, -3.1332, -1.1866, -2.6902, -1.6114, -2.1983, -1.3523,\n",
      "        -1.8820, -1.7795, -2.3846, -1.8765, -0.8388, -2.7834, -1.7199, -2.9028,\n",
      "        -0.5351, -1.9636, -0.9870, -1.1937, -2.0692, -1.7437, -1.6618, -0.9387,\n",
      "        -2.3412, -1.6485, -4.5582, -2.3570, -1.0143, -4.5586, -1.7861, -2.8052,\n",
      "        -1.3858, -4.6378, -1.5622, -0.6853, -2.4886, -1.0759, -1.3230, -1.7649,\n",
      "        -2.3319, -1.1820, -1.4666, -1.5672, -1.4049, -1.4685, -1.9107, -4.0571,\n",
      "        -3.0346, -2.3134, -2.0295, -2.7964, -1.8417, -3.0239, -0.9414, -1.8925,\n",
      "        -3.0376, -2.4380, -1.7529, -1.7097, -2.8165, -2.8836, -1.2707, -2.4509,\n",
      "        -3.2547, -0.9159, -3.6097, -2.6197, -2.5649, -2.0400, -2.5179, -2.1893,\n",
      "        -1.1007, -2.6401, -2.1536, -2.8813, -2.1624, -1.5842, -1.8486, -1.4313,\n",
      "        -1.7199, -1.3520, -1.2691, -1.8783, -1.5091, -3.7203, -1.9581, -1.5244,\n",
      "        -0.9413, -1.7772, -1.1936, -2.0990, -1.4496, -1.3994, -1.4893, -1.3456,\n",
      "        -3.4333, -1.9926, -1.7385, -2.4689, -0.9465, -1.7723, -1.4997, -0.7370,\n",
      "        -2.3799, -1.8979, -2.1280, -1.5151, -2.4297, -1.5188, -0.8447, -1.4088,\n",
      "        -1.8775, -1.6823, -3.9736, -2.1858, -0.8676, -0.8698, -2.1820, -1.6921,\n",
      "        -0.5586, -2.2900, -1.2983, -1.1886, -1.8446, -1.9717, -4.2489, -2.3368,\n",
      "        -2.7022, -2.5910, -1.9128, -3.4884, -2.1776, -2.4763, -1.8258, -0.5132,\n",
      "        -1.3820, -1.9450, -2.2405, -1.9205, -2.1902, -1.3270, -1.8252, -1.8218,\n",
      "        -2.3352, -1.3971, -0.7591, -1.2263, -3.5390, -3.8310, -1.1625, -2.9750,\n",
      "        -0.7808, -1.8728, -2.2380, -2.0794, -0.7895, -1.5877, -1.4692, -1.2173,\n",
      "        -0.9221, -1.2760, -1.4300, -2.9037, -1.7739, -2.3257, -0.6235, -2.0484,\n",
      "        -5.6271, -1.9085, -0.6323, -1.5295, -2.1286, -2.4066, -1.6659, -1.3136,\n",
      "        -3.9707, -0.9420, -1.9828, -1.2241, -1.6177, -1.7659, -1.8740, -1.8131,\n",
      "        -1.8302, -1.1093, -1.4529, -1.4931, -1.6485, -1.2036, -1.1922, -1.3290,\n",
      "        -1.8219, -1.7314, -1.8881, -1.5410, -1.2840, -1.7799, -1.7026, -1.2010,\n",
      "        -1.7169, -1.3615, -0.7786, -1.4123, -1.1086, -1.5306, -1.5485, -4.4795,\n",
      "        -2.8989, -2.0128, -1.1817, -1.8502, -1.1236, -1.5203, -1.0748, -2.2740,\n",
      "        -0.9860, -1.1201, -0.9258, -0.9914, -4.1147, -1.1996, -2.1968, -0.9262,\n",
      "        -1.3893,  0.1650, -2.2997, -2.4551, -2.1241, -1.7755, -1.3939, -1.7161,\n",
      "        -1.7027, -2.7230, -2.4250, -1.5989, -1.6886, -0.9546, -4.0159, -1.7227,\n",
      "        -2.5392, -1.9205, -2.8345, -4.2425, -2.8568, -1.4851, -4.1609, -1.5756,\n",
      "        -1.8110, -1.6828, -1.6214, -1.0412, -1.8232, -1.7326, -1.4321, -2.0069,\n",
      "        -1.8666, -2.5186, -0.9819, -3.3991, -2.8215, -1.0657, -1.3230, -1.7244,\n",
      "        -2.3584, -1.6072, -2.3355, -2.4545, -1.8892, -1.8637, -1.2456, -2.4801,\n",
      "        -1.9379, -2.0503, -2.5482, -1.6926, -3.1150, -1.2299, -1.9126, -2.2311,\n",
      "        -2.1050, -4.0005, -3.3858, -1.6611, -1.6839, -2.5462, -2.2086, -3.1975,\n",
      "        -4.9379, -1.4284, -2.0111, -2.3941, -2.5925, -0.9196, -2.7926, -3.5658,\n",
      "        -2.8009, -3.3402,  0.4292, -1.3237, -1.5337, -1.6235, -2.1949, -1.2839,\n",
      "        -3.1588, -3.1008, -2.7125, -2.4858, -2.5434, -2.9623, -2.1293, -2.0988,\n",
      "        -0.9947, -1.6477, -1.1928, -1.1239, -0.7619, -0.9237, -1.0089, -1.6383,\n",
      "        -2.1638, -0.9397, -1.1070, -1.6755, -1.4056, -1.1982, -3.3102, -1.5928],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv2.weight', tensor([[[[-0.0351,  0.0303, -0.0548],\n",
      "          [-0.0362,  0.0306,  0.0086],\n",
      "          [-0.0021,  0.0081, -0.0500]],\n",
      "\n",
      "         [[-0.0217, -0.0146, -0.0190],\n",
      "          [-0.0187, -0.0571, -0.0519],\n",
      "          [-0.0672, -0.0573, -0.0648]],\n",
      "\n",
      "         [[ 0.0260, -0.0324, -0.0193],\n",
      "          [-0.0337, -0.0042,  0.0074],\n",
      "          [ 0.0002,  0.0722,  0.0406]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0171,  0.0140,  0.0487],\n",
      "          [-0.0056, -0.0172,  0.0419],\n",
      "          [ 0.0009, -0.0308, -0.0478]],\n",
      "\n",
      "         [[-0.0013, -0.0524,  0.0210],\n",
      "          [-0.0114, -0.0642, -0.0532],\n",
      "          [ 0.0759, -0.0228,  0.0390]],\n",
      "\n",
      "         [[-0.0647, -0.0338, -0.0509],\n",
      "          [-0.1104, -0.1053, -0.1478],\n",
      "          [-0.0867, -0.0835, -0.1230]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1026,  0.0995,  0.1088],\n",
      "          [ 0.1158,  0.0779,  0.1169],\n",
      "          [ 0.0924,  0.0955,  0.0800]],\n",
      "\n",
      "         [[ 0.0893,  0.0746,  0.0379],\n",
      "          [ 0.0761,  0.0253,  0.0727],\n",
      "          [ 0.0862,  0.1329,  0.0718]],\n",
      "\n",
      "         [[ 0.0365,  0.0136,  0.0276],\n",
      "          [ 0.0206,  0.1414,  0.0382],\n",
      "          [ 0.0077,  0.0414,  0.0552]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0146,  0.0299,  0.0347],\n",
      "          [-0.0230, -0.0207,  0.0031],\n",
      "          [-0.0045, -0.0235, -0.0055]],\n",
      "\n",
      "         [[ 0.0615,  0.0012,  0.0842],\n",
      "          [ 0.1011,  0.0756,  0.1252],\n",
      "          [ 0.0542,  0.0405,  0.0940]],\n",
      "\n",
      "         [[-0.0441, -0.0362, -0.0301],\n",
      "          [-0.0462, -0.1070, -0.0869],\n",
      "          [-0.0378, -0.0917, -0.0617]]],\n",
      "\n",
      "\n",
      "        [[[-0.0207, -0.0558, -0.0224],\n",
      "          [-0.0005, -0.0081, -0.0142],\n",
      "          [-0.0262, -0.0108, -0.0461]],\n",
      "\n",
      "         [[ 0.0085,  0.0309, -0.0150],\n",
      "          [ 0.0486,  0.0471, -0.0045],\n",
      "          [ 0.0243,  0.0875,  0.0048]],\n",
      "\n",
      "         [[ 0.0268,  0.0351,  0.0100],\n",
      "          [ 0.0169, -0.0034,  0.0321],\n",
      "          [ 0.0531,  0.0951,  0.0313]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0517,  0.0463,  0.0427],\n",
      "          [ 0.0076,  0.0274,  0.0184],\n",
      "          [ 0.0444,  0.0223,  0.0057]],\n",
      "\n",
      "         [[-0.0644, -0.0241, -0.0240],\n",
      "          [ 0.0019, -0.0936, -0.0199],\n",
      "          [ 0.0394,  0.0254,  0.0617]],\n",
      "\n",
      "         [[-0.0135, -0.0515, -0.0114],\n",
      "          [-0.0695, -0.0683, -0.0621],\n",
      "          [-0.0277, -0.1349, -0.0220]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0409,  0.1068,  0.1475],\n",
      "          [ 0.1104,  0.0972,  0.1054],\n",
      "          [ 0.0891,  0.0944,  0.0828]],\n",
      "\n",
      "         [[ 0.0262,  0.0263,  0.0691],\n",
      "          [ 0.0207,  0.0082, -0.0351],\n",
      "          [-0.0084, -0.0622, -0.0207]],\n",
      "\n",
      "         [[-0.0057,  0.1236,  0.0769],\n",
      "          [ 0.0344,  0.0663,  0.0020],\n",
      "          [ 0.0211,  0.0294,  0.0225]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0764, -0.0281, -0.0439],\n",
      "          [-0.0531, -0.0035, -0.0549],\n",
      "          [-0.0457, -0.0618, -0.0774]],\n",
      "\n",
      "         [[ 0.0305, -0.1280, -0.0603],\n",
      "          [-0.0326, -0.1136, -0.1351],\n",
      "          [-0.0856, -0.0791, -0.1000]],\n",
      "\n",
      "         [[ 0.0929,  0.0847,  0.0672],\n",
      "          [ 0.1049,  0.1314,  0.1101],\n",
      "          [ 0.0897,  0.1426,  0.1459]]],\n",
      "\n",
      "\n",
      "        [[[-0.0370, -0.0300, -0.0697],\n",
      "          [-0.0541, -0.0205, -0.0892],\n",
      "          [-0.0847, -0.1028, -0.0414]],\n",
      "\n",
      "         [[-0.0779, -0.1249, -0.1001],\n",
      "          [-0.1006, -0.1459, -0.1090],\n",
      "          [-0.1054, -0.0939, -0.1360]],\n",
      "\n",
      "         [[ 0.0150,  0.0026, -0.0144],\n",
      "          [-0.0122, -0.0205,  0.0189],\n",
      "          [ 0.0343,  0.0362,  0.0530]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0071,  0.0162,  0.0470],\n",
      "          [-0.0078,  0.0285,  0.0559],\n",
      "          [-0.0086,  0.0612,  0.0189]],\n",
      "\n",
      "         [[ 0.0180,  0.0663,  0.0420],\n",
      "          [ 0.0252,  0.0165,  0.0828],\n",
      "          [ 0.0569,  0.1275,  0.0522]],\n",
      "\n",
      "         [[-0.0009,  0.0152,  0.0649],\n",
      "          [ 0.0772,  0.0518,  0.0954],\n",
      "          [ 0.0677,  0.1427,  0.1512]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0967,  0.1483,  0.1771],\n",
      "          [ 0.1083,  0.0994,  0.1345],\n",
      "          [ 0.1165,  0.1563,  0.1115]],\n",
      "\n",
      "         [[ 0.0970,  0.1156,  0.0903],\n",
      "          [ 0.0846,  0.1106,  0.0894],\n",
      "          [ 0.0721,  0.0801,  0.0336]],\n",
      "\n",
      "         [[-0.0065,  0.0015,  0.0220],\n",
      "          [ 0.0294,  0.0219,  0.0025],\n",
      "          [-0.0140, -0.0018,  0.0153]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0336,  0.0169,  0.0653],\n",
      "          [ 0.0205,  0.0432,  0.0483],\n",
      "          [ 0.0315,  0.0314,  0.0062]],\n",
      "\n",
      "         [[-0.0580, -0.1349, -0.0763],\n",
      "          [-0.1236, -0.0209, -0.0890],\n",
      "          [-0.1184, -0.1413, -0.1080]],\n",
      "\n",
      "         [[ 0.0453,  0.0628,  0.0480],\n",
      "          [ 0.0500,  0.0030,  0.0290],\n",
      "          [ 0.0590,  0.0263, -0.0064]]]], device='cuda:0')), ('backbone.model.layer4.0.bn2.weight', tensor([2.5348, 2.3447, 2.0033, 2.0314, 2.5776, 2.4908, 1.8956, 2.3614, 2.3521,\n",
      "        2.1670, 2.2263, 2.3317, 2.4407, 1.9646, 1.8071, 2.1475, 3.0960, 3.9641,\n",
      "        2.8229, 2.7850, 0.8820, 3.0654, 3.6467, 3.0639, 2.9901, 3.0124, 2.8475,\n",
      "        3.2683, 3.2007, 2.8840, 3.0533, 3.1059, 2.2590, 2.2039, 2.0652, 2.7271,\n",
      "        2.0144, 3.2792, 1.9420, 2.1105, 2.4109, 2.3264, 2.2552, 2.6191, 2.0144,\n",
      "        2.6368, 2.9921, 2.5541, 1.8699, 2.3123, 2.3344, 1.9881, 2.0423, 1.9334,\n",
      "        2.0522, 1.9814, 2.3799, 3.3159, 2.2704, 2.5003, 2.4687, 2.0015, 2.1468,\n",
      "        2.0613, 4.1725, 2.9301, 3.7826, 3.6878, 4.3583, 3.1253, 3.4494, 0.8388,\n",
      "        2.9495, 3.6991, 3.2246, 3.2706, 3.0442, 2.9915, 3.6594, 3.9195, 2.8512,\n",
      "        3.2470, 3.1185, 3.5035, 3.6425, 3.4040, 3.0764, 3.0781, 3.1151, 3.1446,\n",
      "        3.0097, 3.9437, 2.9593, 3.4013, 3.6873, 0.7473, 2.9561, 2.5561, 2.9431,\n",
      "        3.0051, 3.2377, 2.5567, 2.9987, 2.8816, 3.0106, 2.6325, 2.8410, 0.8951,\n",
      "        3.4704, 2.8539, 2.5856, 3.4866, 3.0773, 3.9844, 2.7481, 3.7198, 3.3012,\n",
      "        5.2067, 3.5440, 0.0691, 3.0979, 3.4952, 3.8911, 3.4236, 3.3386, 3.9671,\n",
      "        3.1791, 3.5892, 1.9341, 2.5307, 1.9174, 2.3888, 1.9823, 3.7027, 2.2240,\n",
      "        2.5999, 2.8676, 2.2963, 3.4012, 2.0340, 2.3797, 2.7386, 2.8120, 1.7316,\n",
      "        3.7279, 3.5032, 4.0268, 0.7768, 3.0464, 3.8496, 4.6632, 3.5624, 3.9630,\n",
      "        3.5212, 3.6343, 3.7650, 5.5648, 3.4471, 3.9345, 3.6952, 3.4944, 5.5411,\n",
      "        3.4262, 3.5853, 3.7916, 3.9809, 3.1936, 3.8035, 3.5380, 3.0577, 3.5062,\n",
      "        3.0743, 0.0465, 3.5290, 2.9848, 3.0803, 2.7934, 2.8627, 3.1504, 3.2252,\n",
      "        2.9850, 0.8654, 3.2313, 4.4704, 2.8715, 3.0273, 3.1422, 2.8227, 2.9969,\n",
      "        3.6665, 3.2751, 3.0394, 3.0968, 2.8980, 2.9241, 2.9975, 3.1332, 2.7664,\n",
      "        2.4324, 2.6101, 2.7444, 2.6029, 2.4217, 2.5410, 2.9128, 2.6102, 3.3068,\n",
      "        0.8750, 2.1604, 2.8228, 2.7268, 2.4672, 2.8601, 2.4507, 2.2043, 2.0106,\n",
      "        2.2348, 2.6372, 2.1206, 2.2260, 2.4786, 2.2714, 2.1088, 2.3551, 3.1469,\n",
      "        0.0669, 3.4781, 4.0842, 3.7326, 3.1222, 3.4043, 3.8470, 4.0010, 3.4922,\n",
      "        3.4541, 3.7219, 3.7004, 3.3638, 3.2784, 3.7137, 2.3365, 2.0552, 2.4059,\n",
      "        1.9499, 2.2557, 2.4693, 3.1659, 2.8186, 2.3019, 2.2419, 2.0412, 2.0610,\n",
      "        2.4013, 2.3580, 2.1255, 2.0197, 3.0612, 2.5078, 2.6525, 3.0730, 3.3219,\n",
      "        2.8339, 2.8784, 2.6540, 2.7914, 2.5504, 2.7326, 2.8662, 3.0708, 2.2504,\n",
      "        0.9427, 2.8593, 2.9167, 2.7074, 3.1012, 3.0496, 3.1539, 3.0545, 2.6452,\n",
      "        2.6230, 2.8026, 2.7809, 2.7227, 1.0998, 2.9379, 3.2662, 2.6948, 2.6886,\n",
      "        2.0090, 2.0987, 2.8491, 2.2035, 1.8679, 2.5925, 2.3490, 2.1789, 2.8924,\n",
      "        2.1531, 2.5898, 2.5709, 2.2514, 2.2794, 2.0887, 2.3079, 3.2238, 3.1588,\n",
      "        3.6737, 3.3604, 2.8046, 3.6042, 3.4309, 3.4933, 3.1338, 2.9667, 3.5088,\n",
      "        2.8406, 4.3427, 0.7924, 3.7095, 3.8465, 2.8989, 3.1205, 2.7959, 3.1491,\n",
      "        2.4951, 2.8564, 3.3901, 3.4197, 2.7984, 0.9304, 3.0155, 3.1426, 2.6438,\n",
      "        2.6778, 2.9128, 2.8521, 2.8072, 3.3848, 3.4417, 3.0172, 2.9333, 3.5360,\n",
      "        3.1527, 3.4204, 2.6315, 3.0389, 3.0747, 2.9496, 0.8313, 3.2911, 3.4127,\n",
      "        3.3973, 2.9125, 1.9133, 2.4203, 2.9096, 2.9374, 2.4704, 1.8373, 2.1278,\n",
      "        3.2718, 2.1398, 2.4610, 1.9109, 3.0565, 2.6065, 2.5745, 2.4759, 2.2937,\n",
      "        3.4456, 2.1446, 2.3480, 2.2236, 2.5306, 2.0083, 2.0663, 2.3990, 1.9612,\n",
      "        2.7240, 2.8435, 2.7655, 2.0734, 2.5438, 2.0046, 3.5161, 3.3411, 2.9278,\n",
      "        3.7273, 2.4800, 2.4765, 1.0458, 2.9934, 2.8711, 3.6068, 3.0336, 2.6521,\n",
      "        2.9305, 2.7865, 2.8600, 3.1801, 2.3531, 2.0834, 3.4561, 2.7511, 2.1852,\n",
      "        2.2029, 2.6559, 2.0196, 2.7689, 2.7792, 2.0936, 2.5012, 2.6113, 2.7676,\n",
      "        2.5128, 2.2967, 2.0147, 2.2018, 2.4062, 3.3085, 2.6661, 2.1879, 2.4057,\n",
      "        2.4783, 2.4399, 2.5898, 2.4493, 2.5509, 2.2552, 1.9356, 2.3371, 2.4797,\n",
      "        2.3170, 3.5704, 2.1519, 1.9309, 2.9361, 2.2527, 2.6678, 2.0314, 2.1913,\n",
      "        3.2419, 3.5262, 2.3497, 1.9281, 2.0828, 2.1785, 2.0414, 3.3933, 4.1416,\n",
      "        3.5085, 3.3177, 2.8395, 0.7920, 3.2675, 4.7876, 3.3158, 3.1851, 3.1935,\n",
      "        2.7493, 3.0195, 3.5091, 3.1858, 3.0499, 2.7935, 3.0371, 2.7859, 3.3021,\n",
      "        2.6417, 2.7111, 3.7549, 3.1178, 3.0392, 3.2865, 3.5454, 3.0530, 2.9080,\n",
      "        0.7493, 4.6898, 2.8869, 2.7874, 2.9684, 2.7963, 0.8702, 3.0165, 2.6629,\n",
      "        4.0718, 3.1877, 3.4334, 3.1840, 3.3018, 3.1303, 3.3862, 3.1479, 2.9812,\n",
      "        2.8498, 3.0441, 3.7133, 3.4395, 3.1894, 2.9481, 2.9327, 3.1152, 3.7516,\n",
      "        3.5204, 3.9538, 0.8711, 2.9599, 3.2466, 3.7338, 3.7428, 3.2154],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn2.bias', tensor([-1.7765, -0.8833, -1.0429, -1.4926, -2.4476, -1.6161, -0.8783, -0.6644,\n",
      "        -1.0538, -0.5843, -1.0836, -0.4260, -1.5425, -0.4182, -1.1482, -1.6096,\n",
      "        -0.7188, -1.2788, -0.6816, -0.6130, -4.5884, -0.7414, -0.7272, -0.9410,\n",
      "        -0.7843, -0.4868, -0.7728, -0.5505, -1.1632, -0.5114, -0.8480, -0.6789,\n",
      "        -0.8473, -1.0260, -1.1601, -1.3010, -0.9098, -1.3574, -2.2023, -1.0929,\n",
      "        -0.5289, -0.4999, -0.6194, -0.6962, -1.2396, -0.9654, -1.0119, -0.9156,\n",
      "        -1.2372, -1.9056, -1.1444, -1.2510, -0.7821, -1.3725, -0.5733, -1.1924,\n",
      "        -1.1904, -1.1211, -1.4374, -1.4232, -0.8382, -0.8730, -1.1935, -0.8223,\n",
      "        -1.1133, -0.3390, -0.6807, -0.6417, -1.2532, -0.3931, -0.7146, -3.3881,\n",
      "        -0.8703, -0.6067, -0.7796, -0.7652, -0.9643, -0.8355, -0.9055, -0.8956,\n",
      "        -0.5817, -0.8879, -0.8521, -0.9648, -0.6684, -0.7892, -0.7534, -0.5815,\n",
      "        -0.6385, -0.9478, -0.6663, -1.2679, -0.5957, -1.1935, -0.5942, -3.0708,\n",
      "        -0.6506, -0.5788, -0.4806, -0.4024, -0.6019, -0.2544, -0.3840, -0.4847,\n",
      "        -0.7998, -0.6041, -0.7725, -4.1187, -1.4985, -0.8494, -0.4149, -0.4486,\n",
      "        -0.9088, -0.9069, -0.8334, -0.9912, -1.0669, -1.7130, -1.0474, -1.5351,\n",
      "        -0.7441, -1.1434, -1.3014, -1.0752, -0.8347, -0.9586, -0.7930, -0.7564,\n",
      "        -1.3234, -0.9501, -0.6626, -1.5999, -0.7811, -1.5318, -1.4742, -1.5518,\n",
      "        -1.3045, -1.0811, -2.0722, -1.2624, -0.4534, -1.5879, -1.5301, -1.6608,\n",
      "        -0.3605, -0.4000, -0.2853, -4.2169, -0.2619, -0.2796, -0.8397, -0.1366,\n",
      "        -0.3485, -0.2976,  0.0532, -0.6401, -1.3516, -0.2932, -0.1957, -0.6688,\n",
      "        -0.7061, -1.5037, -0.6724, -0.6276, -0.9271, -0.8460, -0.7433, -0.6545,\n",
      "        -0.7817, -0.9931, -0.8928, -0.8371, -2.0725, -0.6511, -0.6252, -0.5136,\n",
      "        -0.9985, -0.7484, -0.5647, -0.6921, -0.7053, -4.0568, -0.9097, -1.0733,\n",
      "        -1.0500, -0.7646, -0.7770, -0.7330, -1.1969, -0.9122, -1.5775, -0.7106,\n",
      "        -0.9920, -1.0563, -0.8650, -1.1305, -0.8775, -0.5451, -0.5251, -0.9636,\n",
      "        -1.0972, -0.6786, -0.7091, -0.5624, -0.9358, -0.3864, -1.0273, -3.1687,\n",
      "        -1.4106, -1.7563, -1.4817, -0.5543, -1.8609, -1.7239, -0.6428, -1.4874,\n",
      "        -1.0508, -1.8188, -1.2512,  0.2032, -1.0135, -1.3166, -1.3863, -1.0823,\n",
      "        -0.9141, -1.9460, -0.9861, -1.0010, -0.5974, -0.5805, -0.5333, -0.7243,\n",
      "        -0.8451, -0.4753, -0.7196, -0.6115, -0.5541, -0.6587, -1.3612, -1.2031,\n",
      "        -1.2774, -0.9909, -0.8991, -0.9019, -1.8300, -1.3299, -0.8568, -1.6682,\n",
      "        -0.7938, -1.3533, -0.4450, -1.3978, -1.2952, -1.7635, -0.6237, -1.2229,\n",
      "        -1.2598, -0.6866, -0.4795, -1.2004, -1.3276, -0.7965, -0.8052, -1.0104,\n",
      "        -1.0351, -1.0152, -0.8419, -0.9534, -1.0798, -0.5044, -3.0359, -0.9749,\n",
      "        -0.6472, -0.7001, -1.1619, -0.9981, -0.9258, -1.2552, -0.5678, -1.1774,\n",
      "        -0.6152, -0.6631, -0.4474, -3.4435, -0.7755, -1.0101, -0.7191, -0.8182,\n",
      "        -1.1374, -0.2981, -1.8010, -1.1023, -1.1211, -1.6068, -1.5230, -1.6246,\n",
      "        -1.4016, -0.8934, -1.1917, -1.6265, -0.6809, -1.2182, -0.5447, -1.9627,\n",
      "        -0.7972, -0.5583, -0.7175, -0.6731, -0.5393, -0.6287, -0.9542, -0.8897,\n",
      "        -1.1055, -0.1640, -0.6660, -0.5313, -0.4071, -3.4776, -0.9390, -0.7041,\n",
      "        -0.8802, -0.8632, -1.0301, -1.0596, -0.4794, -0.9029, -0.8088, -1.2818,\n",
      "        -0.5894, -3.3695, -0.8199, -0.5208, -0.6516, -0.6640, -1.0299, -0.7393,\n",
      "        -0.7803, -1.0080, -0.7222, -0.5773, -0.6805, -0.8214, -1.1469, -0.9629,\n",
      "        -0.5374, -0.6859, -0.7537, -0.6814, -2.6941, -0.5167, -0.7797, -0.6886,\n",
      "        -1.3474, -1.0532, -2.5460, -1.4179, -1.5901, -1.4046, -1.3458, -1.7044,\n",
      "        -1.4336, -0.9493, -1.4705, -1.6837, -1.5287, -2.2345, -1.6561, -1.5207,\n",
      "        -1.0233, -1.6471, -1.0863, -0.6190, -1.4483, -1.1910, -0.7599, -0.8654,\n",
      "        -1.6294, -1.3995, -1.5697, -1.4568, -1.7439, -1.4516, -0.7167, -0.9567,\n",
      "        -1.5004, -1.1372, -0.7469, -1.1204, -0.8216, -0.6722, -4.7611, -0.5636,\n",
      "        -1.0150, -1.5465, -1.1942, -0.6005, -0.9141, -0.6436, -0.9489, -0.6173,\n",
      "        -0.8744, -1.6971, -1.6910, -0.9322, -1.0892, -0.2637, -2.3178, -2.0867,\n",
      "        -1.1232, -1.6409, -1.6167, -1.2349, -1.3580, -1.2897, -1.4566, -0.9762,\n",
      "        -0.4539, -1.0271, -0.2994, -1.4674, -0.8276, -1.7204, -1.6303, -1.1458,\n",
      "        -1.1930, -1.1318, -1.2072, -1.5621, -1.4367, -1.2828, -1.6344, -1.0117,\n",
      "        -0.3716, -1.1085, -1.0510, -0.7881, -1.4860, -1.4116, -0.3242, -1.2438,\n",
      "        -1.2422, -1.9109, -2.2078, -1.3432, -1.3035, -1.1173, -1.0982, -1.1951,\n",
      "        -1.1862, -1.1692, -0.8714, -0.8877, -0.6640, -3.3223, -0.9404, -1.4355,\n",
      "        -1.1263, -0.8925, -1.1889, -0.8066, -0.8860, -0.7776, -1.2517, -1.1408,\n",
      "        -0.8114, -0.5888, -0.5430, -1.0475, -0.6138, -0.9081, -1.0296, -1.1186,\n",
      "        -1.2764, -1.0699, -0.7722, -0.8573, -0.8410, -3.3895, -1.2882, -0.8511,\n",
      "        -0.7552, -0.6611, -0.9950, -3.4016, -0.7258, -0.6359, -2.0727, -1.5242,\n",
      "        -1.4238, -1.0857, -1.2631, -1.2010, -0.9616, -0.9182, -0.8008, -0.4650,\n",
      "        -0.7754, -1.1708, -0.6139, -0.5375, -0.6357, -0.7016, -0.5916, -0.6461,\n",
      "        -0.9640, -1.6404, -4.4988, -0.3682, -0.4919, -1.1425, -0.6332, -1.4307],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.conv3.weight', tensor([[[[-1.1125e-01]],\n",
      "\n",
      "         [[-3.9483e-02]],\n",
      "\n",
      "         [[ 7.4000e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7045e-02]],\n",
      "\n",
      "         [[ 5.2433e-02]],\n",
      "\n",
      "         [[-3.2876e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.2342e-02]],\n",
      "\n",
      "         [[-4.5983e-02]],\n",
      "\n",
      "         [[ 1.8164e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7445e-02]],\n",
      "\n",
      "         [[ 6.1139e-02]],\n",
      "\n",
      "         [[ 1.5066e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1137e-02]],\n",
      "\n",
      "         [[ 5.3812e-02]],\n",
      "\n",
      "         [[ 1.7362e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3272e-04]],\n",
      "\n",
      "         [[-1.1901e-01]],\n",
      "\n",
      "         [[ 2.4371e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.1120e-02]],\n",
      "\n",
      "         [[ 4.4639e-02]],\n",
      "\n",
      "         [[-1.0469e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.5344e-02]],\n",
      "\n",
      "         [[-2.0878e-02]],\n",
      "\n",
      "         [[ 1.0435e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3318e-03]],\n",
      "\n",
      "         [[-4.0739e-02]],\n",
      "\n",
      "         [[-1.2891e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.7942e-03]],\n",
      "\n",
      "         [[ 1.6873e-02]],\n",
      "\n",
      "         [[-1.8642e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2573e-02]],\n",
      "\n",
      "         [[ 2.7993e-02]],\n",
      "\n",
      "         [[ 4.5955e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6195e-02]],\n",
      "\n",
      "         [[-3.0345e-03]],\n",
      "\n",
      "         [[-6.6719e-02]]]], device='cuda:0')), ('backbone.model.layer4.0.bn3.weight', tensor([ 3.0456, -2.1132, -3.0351,  ..., -3.5985, -2.3328,  2.8157],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.bn3.bias', tensor([-0.2181,  0.0491,  0.3907,  ...,  0.3867,  0.2487,  0.1650],\n",
      "       device='cuda:0')), ('backbone.model.layer4.0.downsample.0.weight', tensor([[[[-2.5743e-02]],\n",
      "\n",
      "         [[ 2.0493e-02]],\n",
      "\n",
      "         [[-1.1936e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6353e-01]],\n",
      "\n",
      "         [[-2.6518e-02]],\n",
      "\n",
      "         [[-1.5096e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5896e-04]],\n",
      "\n",
      "         [[ 2.9651e-03]],\n",
      "\n",
      "         [[-8.6959e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0906e-02]],\n",
      "\n",
      "         [[-3.0955e-02]],\n",
      "\n",
      "         [[-2.0388e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8118e-02]],\n",
      "\n",
      "         [[ 2.1359e-02]],\n",
      "\n",
      "         [[-1.0336e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1156e-02]],\n",
      "\n",
      "         [[ 1.4221e-01]],\n",
      "\n",
      "         [[ 6.1775e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.0722e-02]],\n",
      "\n",
      "         [[-6.2133e-02]],\n",
      "\n",
      "         [[-3.2831e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3882e-03]],\n",
      "\n",
      "         [[-6.7392e-02]],\n",
      "\n",
      "         [[-1.8883e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2286e-02]],\n",
      "\n",
      "         [[-1.2046e-01]],\n",
      "\n",
      "         [[-3.2034e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2632e-01]],\n",
      "\n",
      "         [[-4.7911e-02]],\n",
      "\n",
      "         [[-8.9775e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6833e-02]],\n",
      "\n",
      "         [[-6.2321e-02]],\n",
      "\n",
      "         [[-6.3908e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6825e-01]],\n",
      "\n",
      "         [[-4.6186e-02]],\n",
      "\n",
      "         [[ 9.1116e-03]]]], device='cuda:0')), ('backbone.model.layer4.0.downsample.1.weight', tensor([2.2027, 1.8375, 2.3178,  ..., 2.3435, 1.7922, 2.8509], device='cuda:0')), ('backbone.model.layer4.0.downsample.1.bias', tensor([-1.4447, -0.9765, -1.5430,  ..., -1.8776, -0.7044, -1.5631],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv1.weight', tensor([[[[ 0.0659]],\n",
      "\n",
      "         [[-0.0184]],\n",
      "\n",
      "         [[ 0.0104]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[-0.1383]],\n",
      "\n",
      "         [[-0.0099]]],\n",
      "\n",
      "\n",
      "        [[[-0.0306]],\n",
      "\n",
      "         [[-0.0382]],\n",
      "\n",
      "         [[ 0.0438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0271]],\n",
      "\n",
      "         [[-0.1581]],\n",
      "\n",
      "         [[ 0.0711]]],\n",
      "\n",
      "\n",
      "        [[[-0.0321]],\n",
      "\n",
      "         [[ 0.0678]],\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0696]],\n",
      "\n",
      "         [[-0.0562]],\n",
      "\n",
      "         [[-0.0355]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0007]],\n",
      "\n",
      "         [[-0.0214]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         [[-0.0938]],\n",
      "\n",
      "         [[ 0.1091]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0063]],\n",
      "\n",
      "         [[ 0.0725]],\n",
      "\n",
      "         [[ 0.0211]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0077]],\n",
      "\n",
      "         [[ 0.0530]],\n",
      "\n",
      "         [[ 0.0106]]],\n",
      "\n",
      "\n",
      "        [[[-0.0526]],\n",
      "\n",
      "         [[ 0.0758]],\n",
      "\n",
      "         [[-0.0616]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.0387]],\n",
      "\n",
      "         [[-0.0376]]]], device='cuda:0')), ('backbone.model.layer4.1.bn1.weight', tensor([3.5802, 3.0815, 3.6061, 2.5156, 2.6140, 2.5180, 2.5625, 2.2622, 3.1301,\n",
      "        2.5879, 0.7952, 2.3449, 6.2648, 2.7186, 3.1997, 3.7691, 3.0661, 2.3174,\n",
      "        2.3623, 2.1085, 2.1533, 2.4128, 2.5667, 2.3366, 3.4406, 2.6268, 2.3390,\n",
      "        3.8522, 3.2979, 2.4012, 3.8371, 0.6469, 0.5874, 2.3534, 2.7144, 2.7434,\n",
      "        2.5910, 2.1433, 2.0997, 2.6050, 2.1462, 3.0212, 4.2486, 2.4258, 1.9761,\n",
      "        2.4585, 2.5520, 2.3704, 2.6984, 5.0215, 2.3042, 2.7667, 2.8113, 2.3687,\n",
      "        2.5293, 2.7474, 3.3481, 3.3394, 2.3388, 2.1294, 0.6256, 2.3908, 2.4416,\n",
      "        2.6193, 3.1818, 3.5457, 3.1039, 3.5465, 3.1677, 2.7209, 3.1761, 1.0530,\n",
      "        3.5315, 3.8737, 4.8387, 4.3558, 2.7072, 4.7335, 2.9562, 3.1265, 2.9000,\n",
      "        2.5391, 2.2087, 2.1093, 2.1717, 2.2170, 2.9801, 2.5762, 2.6718, 2.1156,\n",
      "        3.8921, 2.3381, 2.9445, 0.6288, 2.3926, 3.8924, 2.9517, 2.3458, 2.8235,\n",
      "        2.8528, 3.1002, 4.1061, 0.7297, 3.9795, 3.1865, 3.3063, 2.6355, 2.2614,\n",
      "        2.4635, 3.3568, 2.6316, 2.9907, 2.5144, 2.3129, 2.4004, 2.6545, 3.6656,\n",
      "        2.4478, 0.7527, 2.4536, 5.6691, 3.5236, 2.7316, 3.6511, 4.1919, 3.4528,\n",
      "        2.6223, 2.4218, 2.6517, 3.7746, 4.0089, 2.8248, 3.5227, 3.8196, 2.5849,\n",
      "        4.1667, 2.7041, 0.1302, 2.4949, 4.1402, 2.5772, 2.9518, 5.4739, 4.8536,\n",
      "        3.1272, 2.2508, 3.7294, 2.7383, 2.4029, 3.9913, 4.4109, 0.6043, 3.0391,\n",
      "        3.0839, 2.5032, 2.4291, 2.5322, 2.1877, 2.2171, 3.0718, 2.0884, 1.9518,\n",
      "        1.9411, 1.5749, 1.9666, 1.8881, 1.6873, 1.6478, 1.6923, 2.4635, 1.7089,\n",
      "        1.7686, 2.1087, 1.9884, 1.4891, 2.1309, 0.5877, 2.2345, 4.7271, 2.5175,\n",
      "        2.8035, 3.6245, 5.7142, 2.9057, 3.2237, 2.8029, 2.2418, 2.8769, 2.9279,\n",
      "        2.6265, 2.4017, 2.9831, 2.4729, 3.1174, 3.0339, 2.4911, 2.6573, 0.6334,\n",
      "        2.3942, 2.4668, 2.4990, 4.7815, 3.0491, 2.4758, 2.2980, 2.8786, 2.5915,\n",
      "        2.3564, 2.5679, 3.4073, 3.1276, 2.8228, 5.7291, 2.5399, 4.0181, 3.9819,\n",
      "        4.6618, 7.7891, 3.1846, 0.6949, 2.5325, 5.2135, 4.6511, 2.2663, 1.8374,\n",
      "        2.7572, 2.4612, 2.2675, 2.4944, 2.1218, 3.9863, 2.5309, 0.6740, 3.6435,\n",
      "        3.3575, 2.5054, 4.3865, 2.2826, 2.0239, 2.0304, 2.6475, 2.8781, 2.6938,\n",
      "        3.5689, 3.3721, 5.2899, 3.7332, 2.7735, 3.4759, 2.8386, 2.3073, 0.7349,\n",
      "        2.8215, 2.3779, 3.4438, 3.1583, 5.2803, 0.7758, 3.2736, 3.2201, 3.4679,\n",
      "        3.9977, 2.0007, 3.1021, 2.3786, 2.5721, 2.8421, 3.4092, 4.0832, 2.7113,\n",
      "        3.8935, 4.9442, 2.6808, 3.1142, 4.1257, 4.4653, 3.3262, 3.5853, 4.5352,\n",
      "        3.5589, 2.8728, 2.6997, 2.8411, 2.5505, 2.9675, 3.2327, 2.7834, 0.7200,\n",
      "        2.8850, 3.0212, 2.6504, 5.4159, 3.6905, 3.2329, 2.9148, 2.3823, 4.2825,\n",
      "        4.3233, 3.9903, 3.0417, 2.4439, 0.1034, 4.1674, 2.8764, 2.3225, 1.9279,\n",
      "        2.5508, 2.8952, 3.1378, 1.8914, 2.2177, 3.8885, 2.2813, 2.8811, 2.6381,\n",
      "        2.2784, 0.6753, 6.2899, 1.7229, 2.2095, 2.9464, 2.7580, 3.5550, 2.7004,\n",
      "        3.2913, 3.0061, 2.5952, 3.8766, 2.0457, 5.4649, 4.2876, 2.8553, 0.6453,\n",
      "        2.7629, 4.0856, 2.8048, 0.6775, 3.4056, 3.1417, 2.8293, 2.6468, 2.1787,\n",
      "        2.5710, 2.3920, 2.1565, 2.1037, 2.4901, 3.0357, 2.3005, 2.6247, 2.8475,\n",
      "        1.7551, 4.2764, 2.4583, 2.6584, 1.9858, 5.0535, 2.1835, 3.1437, 2.6678,\n",
      "        2.7100, 2.3720, 4.0244, 2.5495, 2.5212, 3.1025, 0.6173, 3.0154, 0.6979,\n",
      "        3.6917, 2.8196, 5.4145, 2.7806, 2.1054, 3.1164, 2.1305, 2.1858, 2.2415,\n",
      "        3.4135, 3.0992, 2.8257, 2.5266, 2.6979, 1.8916, 3.0710, 4.0214, 2.9640,\n",
      "        2.8196, 0.6244, 2.9456, 2.5951, 2.5475, 3.6980, 2.7166, 2.2442, 3.7081,\n",
      "        2.7488, 3.8089, 2.5763, 3.1494, 2.3528, 2.1062, 2.1359, 2.3939, 0.6767,\n",
      "        2.8449, 4.6315, 2.0835, 1.9049, 1.9343, 1.8235, 2.1967, 2.3233, 1.8368,\n",
      "        8.8802, 3.8322, 2.2930, 2.3682, 3.2962, 2.2887, 2.1632, 1.9851, 0.5960,\n",
      "        2.2588, 1.8282, 2.5226, 2.2499, 2.0641, 2.4520, 2.4219, 2.4248, 2.6924,\n",
      "        3.3690, 2.2081, 7.8368, 2.9351, 0.6620, 2.4396, 3.7949, 2.8026, 2.9480,\n",
      "        3.3543, 3.6182, 4.2425, 3.4175, 2.2707, 3.9314, 4.5351, 4.7103, 4.3448,\n",
      "        2.5064, 2.3644, 3.0797, 1.3196, 0.9019, 2.5401, 2.4541, 2.5652, 2.6415,\n",
      "        2.2345, 1.6491, 2.1195, 1.8726, 2.3335, 2.1493, 4.3363, 4.4295, 3.1952,\n",
      "        2.3628, 2.8939, 2.1546, 2.8146, 2.3845, 2.7543, 1.8018, 3.2521, 0.6032,\n",
      "        2.1992, 2.7949, 3.8290, 4.0590, 2.3760, 2.7911, 2.9403, 3.8818, 4.2112,\n",
      "        2.5820, 2.4390, 3.0768, 3.1249, 3.0577, 2.6909, 0.6911, 2.8674, 2.6149,\n",
      "        5.2874, 3.8124, 3.1055, 3.5933, 0.7554, 2.8523, 2.1884, 2.8063, 2.8299,\n",
      "        2.2038, 4.3653, 3.1036, 4.2710, 3.8129, 2.6147, 2.9479, 3.5189],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn1.bias', tensor([-1.3066, -1.0343, -1.0440, -0.8812, -0.8340, -0.6520, -1.0145, -0.8190,\n",
      "        -1.0969, -0.5424, -3.0376, -0.9152, -3.1128, -0.7843, -0.9736, -1.2407,\n",
      "        -1.0977, -0.6157, -0.7340, -0.6171, -0.6788, -0.2581, -1.0163, -0.6366,\n",
      "        -1.0370, -0.5282, -1.2311, -1.0522, -1.0267, -1.0475, -1.1342, -2.5035,\n",
      "        -2.7653, -1.0539, -1.3448, -0.8629, -1.0912, -0.6318, -0.4191, -0.9962,\n",
      "        -1.6530, -1.1555, -1.4059, -1.2566, -0.3118, -1.0034, -0.9571, -0.6243,\n",
      "        -1.2140, -1.9096, -0.9028, -0.7752, -0.7955, -0.5370, -0.7218, -0.8365,\n",
      "        -1.3929, -1.0514, -0.3167, -0.9347, -2.2207, -0.7868, -0.5280, -0.7880,\n",
      "        -0.6300, -0.7821, -0.8443, -0.9563, -4.3106, -0.6163, -0.7798, -3.0029,\n",
      "        -0.4262, -1.0221, -1.5025, -0.7061, -0.4077, -1.5685, -0.6600, -0.6718,\n",
      "        -1.2649, -0.9545, -0.8267, -0.9299, -0.7750, -0.7181, -1.2141, -1.0055,\n",
      "        -1.6199, -0.7026, -1.6682, -0.8461, -1.8095, -1.9028, -0.6619, -1.2936,\n",
      "        -1.0218, -0.4410, -1.3485, -0.5657, -0.6866, -0.5320, -4.4934, -1.3317,\n",
      "        -1.0644, -1.0736, -0.9863, -1.9052, -0.4413, -0.9260, -0.6377, -0.9009,\n",
      "        -0.8565, -0.5617, -2.0629, -0.7526, -1.3763, -0.8613, -4.7778, -0.7027,\n",
      "        -2.2219, -1.2074, -1.0725, -1.4510, -1.2727, -1.4022, -0.5888, -0.5701,\n",
      "        -0.9651, -0.7652, -1.3435, -0.9693, -1.5639, -1.3436, -0.8142, -1.1971,\n",
      "        -0.9643, -3.8843, -2.7559, -0.9250, -0.8450, -0.8957, -2.3845, -1.9991,\n",
      "        -1.2474, -0.5727, -1.6655, -0.7360, -0.4633, -1.0483, -1.1817, -2.8612,\n",
      "        -0.9503, -0.9522, -1.2512, -1.0526, -1.1126, -0.6298, -0.6665, -1.0615,\n",
      "        -0.7277, -0.8016, -1.0186, -0.5989, -0.7876, -0.8993, -0.7824, -2.3743,\n",
      "        -1.5602, -1.2338, -0.5364, -0.6277, -1.0744, -1.2248, -0.3731, -1.2312,\n",
      "        -3.2187, -0.5264, -1.4521, -0.6441, -0.7017, -1.2262, -1.8288, -0.7549,\n",
      "        -1.3500, -0.7576, -0.8904, -0.8110, -0.8437, -0.7747, -0.7543, -0.6900,\n",
      "        -1.1013, -1.0689, -1.1914, -0.8680, -1.1080, -3.6125, -1.0543, -0.8177,\n",
      "        -0.8271, -2.4493, -1.2472, -0.7769, -0.9473, -1.3836, -0.6889, -0.8100,\n",
      "        -0.8334, -0.9851, -1.1922, -0.8343, -2.5154, -0.9577, -1.1707, -1.8766,\n",
      "        -1.4298, -3.8945, -1.1068, -4.4121, -0.7969, -1.9158, -1.7364, -0.4177,\n",
      "        -0.8293, -1.1174, -0.7598, -0.8918, -0.9324, -0.6643, -1.7760, -1.0923,\n",
      "        -1.8881, -1.7088, -2.0812, -1.1467, -1.4481, -1.0584, -0.6662, -0.7049,\n",
      "        -0.7444, -1.0055, -1.0364, -1.1320, -2.0287, -1.5461, -1.5044, -0.8821,\n",
      "        -0.7887, -0.7882, -1.1781, -3.9932, -0.7455, -0.7884, -1.0557, -0.9361,\n",
      "        -1.7897, -4.6601, -0.7765, -1.3787, -1.3301, -1.3985, -2.1939, -0.8464,\n",
      "        -0.5764, -0.8972, -0.4457, -0.9902, -1.3131, -0.7386, -1.4863, -1.8584,\n",
      "        -0.6894, -1.0094, -1.3773, -2.3793, -1.3608, -1.4994, -1.4696, -1.5360,\n",
      "        -0.5111, -0.8377, -1.0052, -0.6077, -1.2265, -0.8819, -0.9158, -4.0952,\n",
      "        -0.7662, -0.8325, -0.9448, -2.3880, -1.9977, -1.2267, -0.6557, -0.4781,\n",
      "        -1.0066, -1.9372, -1.3572, -1.0636, -0.7886, -2.5106, -1.1766, -0.6773,\n",
      "        -1.4443, -0.2602, -1.0402, -1.4859, -1.8195, -0.6495, -0.7158, -1.3494,\n",
      "        -0.8267, -1.4814, -0.8903, -0.9434, -3.3417, -2.3511, -0.6962, -1.0364,\n",
      "        -0.9862, -0.6891, -1.7284, -0.7128, -1.5244, -0.9383, -0.8123, -1.5912,\n",
      "        -0.7778, -2.6068, -1.1515, -1.0040, -3.5144, -0.7202, -1.9008, -1.1794,\n",
      "        -3.1138, -0.8144, -0.8847, -0.7155, -0.9456, -0.5780, -0.7691, -0.8922,\n",
      "        -0.5416, -0.5780, -0.7326, -1.3682, -0.7898, -1.0313, -0.7490, -1.0464,\n",
      "        -1.8314, -0.5334, -0.8413, -0.5646, -1.8407, -0.6052, -0.8657, -1.0110,\n",
      "        -0.8260, -1.1981, -1.5060, -0.7894, -1.0614, -0.9075, -3.0117, -1.1137,\n",
      "        -3.7366, -1.4148, -0.3166, -1.8581, -0.7616, -0.3516, -1.0344, -0.6740,\n",
      "        -0.3506, -0.4924, -1.1083, -1.2293, -0.8462, -0.6827, -1.1244, -1.5409,\n",
      "        -1.1150, -1.2337, -0.8269, -0.9751, -3.3032, -0.6633, -0.7963, -0.8292,\n",
      "        -1.4751, -0.9243, -0.5353, -0.5744, -1.0372, -1.3509, -0.7507, -1.0184,\n",
      "        -0.8934, -0.8065, -0.6539, -0.7287, -2.9527, -0.9650, -1.5301, -0.5646,\n",
      "        -0.5568, -0.3950, -0.5643, -0.6403, -1.0975, -0.9927, -3.9110, -1.5360,\n",
      "        -0.8617, -0.6989, -1.3792, -0.7029, -0.6922, -0.4327, -2.1103, -0.4887,\n",
      "        -0.8029, -1.3854, -0.6307, -0.7792, -0.7910, -0.9072, -0.7871, -0.8986,\n",
      "        -1.0854, -0.5726, -3.8156, -0.9734, -3.9074, -0.7324, -1.5568, -1.2896,\n",
      "        -1.0326, -1.4942, -1.0142, -1.3678, -0.9438, -0.6537, -1.4423, -1.6607,\n",
      "        -1.1805, -2.3200, -0.6120, -0.8011, -1.6398,  0.7714, -6.5013, -0.7158,\n",
      "        -0.6711, -0.8156, -0.7555, -0.6955,  1.6232,  0.7877,  1.1923, -0.1952,\n",
      "        -0.3705, -1.1081, -1.5651, -0.8247, -1.0604, -0.9834, -0.7491, -0.9401,\n",
      "        -1.1005, -0.9798, -1.4937, -0.9931, -2.4113, -0.3427, -0.6384, -1.1996,\n",
      "        -1.6631, -0.4658, -0.7688, -0.6562, -1.1137, -1.1701, -0.9928, -0.5745,\n",
      "        -1.0018, -0.9262, -0.9002, -0.9701, -4.5659, -1.1920, -1.0370, -2.7529,\n",
      "        -1.0619, -1.2704, -1.0960, -4.7947, -1.0091, -0.9150, -1.3841, -0.8132,\n",
      "        -0.6012, -1.9677, -0.5698, -1.3811, -1.0377, -1.1995, -1.1617, -1.3362],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv2.weight', tensor([[[[-0.0696, -0.0854, -0.0746],\n",
      "          [-0.0531, -0.0015, -0.0653],\n",
      "          [-0.0543, -0.0882, -0.0768]],\n",
      "\n",
      "         [[-0.0078,  0.0253, -0.0619],\n",
      "          [-0.0829, -0.0671, -0.0401],\n",
      "          [-0.0122, -0.0259,  0.0137]],\n",
      "\n",
      "         [[-0.0132, -0.0205,  0.0093],\n",
      "          [-0.0091, -0.0612, -0.0380],\n",
      "          [ 0.0194,  0.0226, -0.0018]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0021,  0.0162, -0.0104],\n",
      "          [-0.0397, -0.0446,  0.0239],\n",
      "          [ 0.0521,  0.0593,  0.0264]],\n",
      "\n",
      "         [[ 0.0337,  0.0475,  0.0871],\n",
      "          [ 0.0890,  0.0407,  0.0703],\n",
      "          [ 0.0706,  0.0931,  0.0357]],\n",
      "\n",
      "         [[-0.0860, -0.0822, -0.1093],\n",
      "          [-0.0256, -0.0195, -0.0576],\n",
      "          [-0.0909, -0.0788, -0.0502]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0365,  0.0430,  0.0308],\n",
      "          [ 0.0795,  0.0606,  0.0521],\n",
      "          [ 0.0659,  0.0440,  0.0264]],\n",
      "\n",
      "         [[ 0.0402, -0.0455,  0.0389],\n",
      "          [ 0.0079, -0.0177,  0.0660],\n",
      "          [ 0.0506,  0.0204,  0.0301]],\n",
      "\n",
      "         [[ 0.0119,  0.0225, -0.0291],\n",
      "          [ 0.0049, -0.0162,  0.0102],\n",
      "          [ 0.0529,  0.0273,  0.0366]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0712,  0.1390,  0.0936],\n",
      "          [ 0.0832,  0.1134,  0.0935],\n",
      "          [ 0.0277,  0.0319,  0.0071]],\n",
      "\n",
      "         [[ 0.0793,  0.0598,  0.0761],\n",
      "          [-0.0352, -0.0487, -0.0027],\n",
      "          [ 0.0092,  0.0403,  0.0255]],\n",
      "\n",
      "         [[-0.0139, -0.0085,  0.0387],\n",
      "          [-0.0401,  0.0185,  0.0311],\n",
      "          [ 0.0539,  0.0422,  0.0461]]],\n",
      "\n",
      "\n",
      "        [[[-0.0087, -0.0495, -0.0209],\n",
      "          [-0.0274, -0.0347, -0.0013],\n",
      "          [-0.0363, -0.0927, -0.0194]],\n",
      "\n",
      "         [[-0.0659, -0.0621, -0.0624],\n",
      "          [-0.0801, -0.0932, -0.0672],\n",
      "          [-0.0902, -0.0445, -0.0934]],\n",
      "\n",
      "         [[ 0.0007, -0.0443,  0.0141],\n",
      "          [ 0.0313, -0.0154,  0.0534],\n",
      "          [ 0.0513, -0.0184,  0.0562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0481, -0.0947, -0.0630],\n",
      "          [-0.1227, -0.1499, -0.0819],\n",
      "          [-0.0728, -0.0873, -0.1199]],\n",
      "\n",
      "         [[-0.0210, -0.0247, -0.0153],\n",
      "          [-0.0765, -0.0115, -0.0395],\n",
      "          [-0.0507, -0.0461, -0.0611]],\n",
      "\n",
      "         [[-0.0326, -0.0480,  0.0107],\n",
      "          [ 0.0533,  0.0368,  0.0668],\n",
      "          [ 0.0099, -0.0214, -0.0038]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0321,  0.0313, -0.0136],\n",
      "          [ 0.0204,  0.0739,  0.0259],\n",
      "          [-0.0031,  0.0671,  0.0283]],\n",
      "\n",
      "         [[-0.0719, -0.0310, -0.0478],\n",
      "          [-0.0702,  0.0082, -0.0718],\n",
      "          [-0.0460, -0.0681, -0.0741]],\n",
      "\n",
      "         [[-0.0441, -0.1194, -0.0885],\n",
      "          [-0.0556, -0.0634, -0.1278],\n",
      "          [-0.0984, -0.0764, -0.0979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0930,  0.0899,  0.1297],\n",
      "          [ 0.0492,  0.0193, -0.0171],\n",
      "          [ 0.0082, -0.0267,  0.0052]],\n",
      "\n",
      "         [[ 0.0191,  0.0483,  0.0055],\n",
      "          [ 0.0546,  0.1075,  0.0402],\n",
      "          [ 0.0397,  0.1084,  0.0694]],\n",
      "\n",
      "         [[ 0.0649,  0.0709,  0.1145],\n",
      "          [ 0.0357,  0.0052,  0.0369],\n",
      "          [ 0.0445,  0.1006,  0.0229]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0031, -0.0107, -0.0073],\n",
      "          [-0.0281,  0.0149, -0.0371],\n",
      "          [-0.0670, -0.0329, -0.0544]],\n",
      "\n",
      "         [[-0.0523, -0.0828, -0.0688],\n",
      "          [-0.0584, -0.0706, -0.0450],\n",
      "          [-0.0704, -0.1069, -0.0614]],\n",
      "\n",
      "         [[ 0.0272,  0.0521,  0.0411],\n",
      "          [ 0.0885,  0.0870,  0.0451],\n",
      "          [ 0.0718,  0.1125,  0.0648]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0407, -0.0668, -0.0376],\n",
      "          [-0.0514, -0.0143, -0.0200],\n",
      "          [-0.0619, -0.0745, -0.0876]],\n",
      "\n",
      "         [[-0.0019,  0.0112, -0.0515],\n",
      "          [-0.0881, -0.1004, -0.0966],\n",
      "          [-0.0451, -0.0961, -0.0396]],\n",
      "\n",
      "         [[-0.0768, -0.0662, -0.0529],\n",
      "          [-0.0341, -0.0727, -0.0671],\n",
      "          [-0.0263, -0.0576, -0.0438]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0051, -0.0037,  0.0319],\n",
      "          [ 0.0342, -0.0111,  0.0261],\n",
      "          [ 0.0629,  0.0145,  0.0237]],\n",
      "\n",
      "         [[-0.0258,  0.0055, -0.0292],\n",
      "          [-0.0147,  0.0127,  0.0237],\n",
      "          [-0.0267,  0.0260, -0.0120]],\n",
      "\n",
      "         [[-0.0346, -0.0512, -0.0664],\n",
      "          [-0.0325,  0.0230, -0.0701],\n",
      "          [ 0.0073, -0.0350, -0.0088]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0423, -0.0605, -0.0374],\n",
      "          [-0.0456, -0.0830, -0.0779],\n",
      "          [-0.0291, -0.0555,  0.0148]],\n",
      "\n",
      "         [[-0.0170,  0.0089, -0.0636],\n",
      "          [ 0.0033, -0.0441, -0.0274],\n",
      "          [ 0.0371,  0.0076, -0.0154]],\n",
      "\n",
      "         [[-0.0664, -0.0937,  0.0064],\n",
      "          [-0.0105, -0.0889, -0.0392],\n",
      "          [-0.0770, -0.0460, -0.1120]]]], device='cuda:0')), ('backbone.model.layer4.1.bn2.weight', tensor([2.1864, 1.9280, 2.7044, 2.3575, 2.7352, 2.6606, 2.0999, 1.0829, 3.3370,\n",
      "        1.3340, 3.2443, 2.8303, 2.7262, 2.8775, 2.4398, 3.5566, 3.1597, 3.4936,\n",
      "        3.1565, 3.6323, 3.2555, 2.9758, 2.5234, 3.2622, 2.7411, 4.2296, 3.7546,\n",
      "        3.7125, 3.0454, 0.9889, 3.7742, 3.5873, 2.5223, 2.7980, 2.7927, 2.5301,\n",
      "        2.7752, 1.0456, 3.7106, 2.1523, 3.5275, 3.1583, 2.3727, 3.1535, 3.1632,\n",
      "        3.1005, 4.2142, 2.7404, 2.8433, 2.9486, 2.4443, 3.6761, 2.6147, 3.5324,\n",
      "        3.0318, 1.2856, 3.4409, 2.5919, 2.1008, 2.3011, 2.8864, 2.5634, 2.6018,\n",
      "        3.2442, 1.8974, 2.1523, 1.7223, 1.8057, 2.2793, 1.7542, 2.4861, 2.0020,\n",
      "        1.9405, 2.0337, 2.9248, 1.5728, 1.9215, 2.0185, 2.7387, 2.3957, 2.6344,\n",
      "        3.3667, 3.2538, 4.0653, 3.2675, 2.9785, 3.2579, 3.8978, 3.6865, 0.8769,\n",
      "        2.8214, 2.9553, 3.3726, 3.6476, 3.4486, 3.4726, 3.2495, 3.6588, 3.1567,\n",
      "        3.1699, 4.1796, 0.1029, 4.2862, 2.5823, 2.2962, 3.1342, 3.6080, 3.4456,\n",
      "        4.4713, 3.0771, 2.9943, 3.7801, 2.6141, 2.8937, 2.5491, 2.2995, 1.9387,\n",
      "        2.0539, 2.5894, 2.2351, 2.7963, 2.4869, 2.0458, 1.1865, 2.1041, 2.6171,\n",
      "        2.8538, 2.5816, 3.0889, 2.4337, 2.7994, 1.9032, 2.3123, 3.0631, 2.2747,\n",
      "        1.4581, 4.2745, 3.5284, 2.8094, 3.7590, 3.4285, 2.4611, 3.5714, 2.7610,\n",
      "        2.1132, 2.5640, 2.4025, 1.8994, 2.1894, 2.4209, 2.2799, 2.6607, 2.0615,\n",
      "        1.8578, 2.0621, 3.0940, 3.6223, 1.8458, 2.3871, 1.9870, 2.6067, 3.5968,\n",
      "        3.0555, 3.8167, 3.3340, 3.0700, 3.6678, 3.1269, 2.9813, 2.9063, 3.3921,\n",
      "        3.5012, 3.2306, 0.9859, 2.6967, 3.9038, 3.5402, 3.4468, 3.5044, 0.1660,\n",
      "        3.0917, 3.9799, 3.4501, 5.0615, 3.4564, 2.7300, 3.2331, 3.5529, 3.3975,\n",
      "        3.6456, 3.0327, 3.4325, 2.2354, 2.6561, 2.4361, 2.4282, 1.8808, 2.0312,\n",
      "        4.3317, 2.2149, 2.3012, 2.0849, 2.6045, 2.1979, 3.3045, 1.9502, 2.1289,\n",
      "        1.2784, 2.1611, 0.9803, 2.0989, 3.4259, 2.7871, 2.0110, 2.0029, 2.8229,\n",
      "        2.3389, 2.0551, 2.8276, 2.5189, 2.0989, 3.1358, 3.3994, 2.6951, 3.5634,\n",
      "        3.8864, 4.0430, 3.9020, 4.5365, 5.2544, 4.4061, 3.4833, 3.7093, 2.7353,\n",
      "        4.6672, 0.0928, 5.2005, 3.5366, 4.0649, 4.3468, 2.8086, 2.7992, 2.7064,\n",
      "        2.4287, 2.2421, 3.5500, 3.7944, 2.6337, 2.5705, 2.6543, 4.5468, 2.4581,\n",
      "        1.6465, 2.5721, 1.1272, 3.5963, 2.2673, 1.8943, 2.1991, 1.0571, 2.8119,\n",
      "        3.4325, 3.0235, 2.3124, 2.1737, 2.6446, 2.3345, 2.0673, 1.9337, 2.2561,\n",
      "        2.0557, 2.5382, 2.3252, 2.8637, 2.2121, 2.7045, 3.3805, 2.0615, 3.0512,\n",
      "        2.3976, 2.0652, 2.0696, 2.3624, 1.2102, 3.1079, 2.6877, 1.9189, 2.1571,\n",
      "        2.8633, 3.9168, 0.8884, 3.1606, 3.0666, 2.5747, 2.6675, 3.4044, 3.0453,\n",
      "        2.6667, 2.2284, 2.6729, 2.2711, 3.3599, 3.1457, 3.6364, 2.8005, 2.8182,\n",
      "        2.6736, 2.8625, 2.9680, 2.9114, 2.7005, 2.9383, 2.4247, 2.7493, 2.2164,\n",
      "        1.1371, 2.8145, 3.2227, 2.6100, 2.6113, 4.1444, 3.7389, 3.8578, 3.7833,\n",
      "        3.7409, 3.4039, 3.2696, 3.0337, 0.0701, 3.7720, 3.5695, 5.9179, 3.5103,\n",
      "        4.1280, 3.8489, 4.6474, 1.8655, 1.7772, 2.0756, 2.1491, 2.1487, 2.6874,\n",
      "        1.8219, 2.3571, 1.9825, 2.4192, 2.4050, 1.4154, 2.8007, 2.1861, 2.1482,\n",
      "        1.6854, 2.1643, 2.2072, 2.4855, 2.1718, 2.6376, 3.8144, 2.3959, 2.8501,\n",
      "        2.3125, 1.0627, 2.3600, 2.6915, 2.4221, 3.3584, 2.8980, 1.9830, 0.1273,\n",
      "        2.9255, 2.5885, 3.7754, 4.3181, 4.3501, 9.3819, 4.3041, 4.0945, 4.0310,\n",
      "        3.2350, 6.8520, 5.3303, 3.8957, 3.6588, 3.4015, 1.6708, 3.2161, 2.2772,\n",
      "        2.2338, 1.9515, 2.9338, 1.9752, 2.3619, 2.4178, 1.4755, 1.4740, 1.8293,\n",
      "        2.0830, 1.9569, 1.6964, 2.0180, 1.8891, 1.9150, 2.6883, 2.7362, 1.9251,\n",
      "        2.2297, 2.1454, 1.2273, 2.1417, 2.6172, 1.7390, 1.9461, 2.1652, 1.9223,\n",
      "        2.2463, 2.5527, 2.6086, 3.2779, 3.7947, 3.3413, 2.3741, 2.8616, 1.7001,\n",
      "        2.9845, 2.6164, 2.9571, 2.7818, 2.7728, 2.6704, 2.5120, 0.1375, 2.8188,\n",
      "        2.2120, 1.8039, 2.7215, 1.6274, 1.7595, 2.2603, 1.9476, 1.9816, 2.1812,\n",
      "        1.6959, 2.0890, 1.9955, 2.0775, 1.6354, 2.6198, 1.8321, 0.1276, 4.1400,\n",
      "        3.8057, 4.0206, 3.6555, 5.3820, 4.3126, 4.2908, 4.3852, 5.5130, 4.0712,\n",
      "        3.8279, 6.2307, 5.4069, 3.9134, 5.2269, 2.4986, 2.5185, 2.7570, 2.6099,\n",
      "        2.9495, 2.3051, 2.5171, 2.1321, 4.4510, 2.8135, 0.9803, 2.5634, 3.4294,\n",
      "        2.2952, 2.4761, 2.1848, 2.4029, 1.6462, 2.2430, 3.0554, 2.1726, 1.8015,\n",
      "        1.5154, 3.3903, 2.1464, 1.9146, 1.4978, 1.8399, 1.9933, 2.3742, 2.8797,\n",
      "        1.5398, 2.6587, 2.4607, 2.8120, 2.7111, 3.5261, 2.6907, 3.2259, 3.3745,\n",
      "        0.9694, 2.8597, 2.2398, 2.2938, 2.5859, 3.2250, 2.3122, 3.5269],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn2.bias', tensor([-0.2910, -0.8224, -1.0211, -0.6264, -1.1507, -0.7867, -0.5075, -3.7610,\n",
      "        -1.0820, -0.9519, -1.4940, -1.2195, -1.1806, -1.1384, -1.6249, -0.7988,\n",
      "        -0.8381, -2.3586, -1.2844, -1.9951, -1.2949, -1.0223, -0.5901, -0.5252,\n",
      "        -1.1890, -1.2951, -1.6207, -1.2028, -1.0717, -4.4066, -1.8066, -1.3652,\n",
      "        -1.1338, -0.6275, -1.6226, -1.0803, -2.0531, -4.1501, -1.8376, -0.4877,\n",
      "        -2.8594, -2.4620, -2.0433, -1.6164, -1.3265, -0.8831, -2.0438, -0.8029,\n",
      "        -1.7008, -1.8931, -1.1687, -1.7163, -1.0187,  0.3485, -1.5921, -5.0666,\n",
      "        -1.6902, -1.0038, -0.7580, -1.9643, -1.3956, -1.0800, -1.2118, -2.2051,\n",
      "        -1.0978, -1.5572, -0.6803, -3.1943, -2.9018, -2.0797, -2.1187, -1.0235,\n",
      "        -1.0924, -0.6781, -1.1260, -0.3369, -1.2918, -0.9742, -2.3949, -1.5789,\n",
      "        -0.8999, -1.8909, -1.7020, -2.7863, -1.1852, -1.4428, -1.3754, -1.3376,\n",
      "        -1.7983, -3.5400, -1.2881, -1.0638, -1.7311, -1.7959, -1.3942, -1.5163,\n",
      "        -1.2445, -1.7027, -1.9454, -1.4876, -2.0470, -1.6293, -1.6064, -0.9507,\n",
      "        -0.2792, -1.5436, -1.3140, -1.8859, -2.5796, -1.1106, -0.9595, -1.9915,\n",
      "        -0.7758, -1.0221, -1.9239, -1.4307, -0.9034, -0.8485, -1.3587, -1.9402,\n",
      "        -1.2504, -1.6061, -0.3462, -3.2746, -1.4377, -1.3694, -1.7812, -1.1532,\n",
      "        -1.1712, -0.8413, -1.2533, -3.2130, -0.3979, -2.5937, -0.3974, -3.9772,\n",
      "        -2.6724, -1.9631, -1.2717, -1.5807, -3.0875, -0.9283, -1.4287, -1.2028,\n",
      "        -1.1975, -2.1310, -2.3647, -1.2834, -2.2627, -1.0375, -1.4854, -3.5771,\n",
      "        -0.7686, -1.7626, -2.3067, -1.9882, -3.2084, -3.3659, -1.4654, -1.8835,\n",
      "        -1.5031, -0.5821, -1.0901, -1.1486, -0.3911, -0.6935, -0.2257, -0.6447,\n",
      "        -0.4271,  0.0617, -0.1320, -0.2951, -0.4146, -3.9091, -1.7401, -0.7849,\n",
      "        -0.5433, -1.2004, -0.8006, -2.4225, -0.8578, -1.2573, -1.6962, -2.2576,\n",
      "        -1.4746, -0.7573, -1.4949, -1.3136, -1.3165, -1.8412, -0.6672, -1.0251,\n",
      "        -0.8973, -1.2995, -0.8221, -0.9063, -0.1545, -0.1907, -1.9759, -0.4264,\n",
      "        -0.5889, -0.5760, -0.5318, -0.4473, -1.3704,  0.0094, -0.6014, -5.1244,\n",
      "        -0.9184, -3.3049, -0.7983, -1.5952, -1.9063, -0.6729, -0.7733, -1.5820,\n",
      "        -1.2192, -0.8635, -1.9160, -1.9302, -0.8180, -2.1327, -1.9280, -1.4532,\n",
      "        -0.4576, -0.7171, -1.6185, -1.5863, -0.3781, -1.4648, -0.7639, -0.4538,\n",
      "        -0.5503, -1.1487, -0.7711, -1.2558, -3.4236, -0.4967, -0.9692, -0.3478,\n",
      "        -1.3975, -1.0503, -1.2146, -0.7758, -0.8133, -1.7851, -1.8847, -1.0909,\n",
      "        -1.4001, -1.0400, -2.3392, -1.6838, -0.8835, -0.8552, -4.3334, -2.1614,\n",
      "        -0.7530, -0.8519, -1.4152, -3.4265, -1.3863, -2.2804, -2.4042, -1.0045,\n",
      "        -0.7006, -1.3411, -1.0611, -0.6288, -1.0700, -1.3517, -0.8298, -1.3088,\n",
      "        -0.6215, -1.5673, -1.1255, -1.6023, -2.0826, -0.9311, -2.0395, -1.5234,\n",
      "        -0.9697, -1.2327, -1.4501, -4.0407, -1.4923, -1.3861, -1.0921, -1.7348,\n",
      "        -1.4449, -1.4998, -3.5353, -1.7041, -1.9372, -0.3703, -0.9032, -1.4790,\n",
      "        -1.5853, -1.0336, -0.8604, -1.1253, -0.7204, -1.1258, -1.3427, -2.9068,\n",
      "        -0.3904, -1.4555, -1.3890, -1.0614, -1.4366, -1.3614, -1.1089, -1.6524,\n",
      "        -1.7253, -1.0669, -0.7565, -4.6977, -1.4787, -1.9068, -0.6371, -1.1122,\n",
      "        -1.2690, -1.7654, -1.8993, -1.5296, -0.5406, -1.8900, -0.8688, -0.9809,\n",
      "        -1.0298, -1.1889, -1.4032, -1.1003, -2.0522, -0.7965, -1.1826, -0.9061,\n",
      "        -1.6783, -1.4615, -1.0581, -0.8910, -2.1724, -2.6491, -3.5281, -1.4505,\n",
      "        -1.1297, -1.1228, -2.2898,  0.0534, -1.1163, -1.9961, -1.4401, -2.1114,\n",
      "        -0.9751, -0.8469, -1.3276, -0.7403, -1.0516, -2.6435, -0.9586, -1.2061,\n",
      "        -0.9734, -3.6167, -1.7422, -0.9549, -0.8377, -2.1566, -2.0534, -0.6502,\n",
      "        -1.7703, -1.8911,  1.4402, -0.6380, -0.6994, -1.4521,  0.7943, -0.3183,\n",
      "        -0.3074, -0.2983, -2.0585, -1.7731, -1.5802, -0.8530, -0.1452, -0.3159,\n",
      "         0.0196, -2.7921, -0.8810, -1.1364, -0.0793, -3.1241, -2.4747, -1.5680,\n",
      "        -1.5379, -1.6591, -1.0815, -2.7584, -1.8884, -1.3951, -0.8150, -1.0815,\n",
      "        -0.4258, -0.4754, -0.8313, -2.2690, -0.8650, -1.0047, -0.2635, -4.1029,\n",
      "        -1.1553, -1.5925, -0.4885, -0.4615, -0.8192, -0.8885, -1.6280, -1.3548,\n",
      "        -0.2157, -1.1673, -1.9785, -1.5412, -1.6100, -1.2417, -0.7270, -2.4960,\n",
      "        -0.8065, -1.2201, -1.1368, -0.8159, -1.3745, -1.3831, -1.5051, -1.0323,\n",
      "        -1.9344, -0.8259, -2.0803, -0.7358, -0.3791, -1.4218, -1.2508, -0.8571,\n",
      "        -1.1922, -0.4919, -0.9371, -2.6991, -2.9999, -0.7295, -1.1847, -3.3248,\n",
      "        -2.1222, -1.6002, -0.6862, -2.5914, -0.6918, -3.2399, -0.9921, -1.0254,\n",
      "        -0.1130, -2.6462, -1.6869, -0.6757, -2.7903, -0.8407, -0.0653, -2.9889,\n",
      "        -0.8454, -1.1314, -1.3414, -1.6134, -1.0161, -0.1290, -0.6918, -0.3209,\n",
      "        -2.4660, -1.2971, -4.1949, -1.0374, -1.3251, -0.6930, -0.8050, -0.4826,\n",
      "        -1.6305, -3.5595, -1.7442, -1.3930, -1.4176, -1.0760, -1.2620, -3.8088,\n",
      "        -1.0659, -0.6625, -0.4634, -0.5871, -0.7928, -1.4905, -2.5206, -0.6154,\n",
      "        -0.7167, -0.6063, -1.0846, -0.8032, -1.4369, -1.0054, -1.3968, -1.4113,\n",
      "        -3.7246, -0.8006, -0.7236, -0.4813, -0.4346, -1.1232, -0.8401, -1.6943],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.conv3.weight', tensor([[[[-0.0399]],\n",
      "\n",
      "         [[ 0.0857]],\n",
      "\n",
      "         [[ 0.2080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0146]],\n",
      "\n",
      "         [[ 0.0296]],\n",
      "\n",
      "         [[ 0.0591]]],\n",
      "\n",
      "\n",
      "        [[[-0.0568]],\n",
      "\n",
      "         [[-0.0436]],\n",
      "\n",
      "         [[ 0.0447]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1187]],\n",
      "\n",
      "         [[-0.1218]],\n",
      "\n",
      "         [[-0.1214]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0169]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[-0.0199]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         [[ 0.0410]],\n",
      "\n",
      "         [[-0.0641]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0502]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0166]],\n",
      "\n",
      "         [[ 0.0339]],\n",
      "\n",
      "         [[-0.0546]]],\n",
      "\n",
      "\n",
      "        [[[-0.0075]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.0382]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0825]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         [[-0.0742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0299]],\n",
      "\n",
      "         [[ 0.0821]],\n",
      "\n",
      "         [[ 0.0494]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0507]],\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[ 0.0535]]]], device='cuda:0')), ('backbone.model.layer4.1.bn3.weight', tensor([-2.5672, -2.3754, -4.0941,  ...,  4.2259, -2.8889, -2.8292],\n",
      "       device='cuda:0')), ('backbone.model.layer4.1.bn3.bias', tensor([-0.0643, -0.1564, -0.5905,  ..., -0.1106,  0.1808, -0.3960],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.conv1.weight', tensor([[[[-0.0077]],\n",
      "\n",
      "         [[ 0.0734]],\n",
      "\n",
      "         [[-0.0834]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0989]],\n",
      "\n",
      "         [[-0.1062]],\n",
      "\n",
      "         [[-0.1794]]],\n",
      "\n",
      "\n",
      "        [[[-0.1203]],\n",
      "\n",
      "         [[ 0.0200]],\n",
      "\n",
      "         [[-0.0170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0093]],\n",
      "\n",
      "         [[ 0.0632]],\n",
      "\n",
      "         [[-0.0094]]],\n",
      "\n",
      "\n",
      "        [[[-0.0585]],\n",
      "\n",
      "         [[ 0.0371]],\n",
      "\n",
      "         [[-0.2583]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0743]],\n",
      "\n",
      "         [[ 0.0256]],\n",
      "\n",
      "         [[-0.0935]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0452]],\n",
      "\n",
      "         [[ 0.0422]],\n",
      "\n",
      "         [[-0.0758]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0649]],\n",
      "\n",
      "         [[-0.0334]],\n",
      "\n",
      "         [[-0.0312]]],\n",
      "\n",
      "\n",
      "        [[[-0.0787]],\n",
      "\n",
      "         [[ 0.0195]],\n",
      "\n",
      "         [[ 0.0532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         [[ 0.0796]],\n",
      "\n",
      "         [[-0.1334]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0881]],\n",
      "\n",
      "         [[-0.1099]],\n",
      "\n",
      "         [[-0.0500]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0090]],\n",
      "\n",
      "         [[-0.0352]],\n",
      "\n",
      "         [[-0.0540]]]], device='cuda:0')), ('backbone.model.layer4.2.bn1.weight', tensor([0.3368, 1.2404, 3.7873, 4.2119, 3.3377, 4.9257, 5.1942, 0.5783, 4.2024,\n",
      "        3.0010, 2.5283, 3.1915, 3.6558, 0.9524, 2.6945, 4.7798, 1.1760, 3.4175,\n",
      "        3.4622, 0.1061, 2.9341, 2.7215, 1.2425, 2.7715, 2.8132, 2.7178, 2.3072,\n",
      "        2.1156, 3.7392, 2.8828, 2.1026, 3.0060, 3.6666, 2.9093, 3.5852, 0.1023,\n",
      "        0.8239, 3.2705, 3.9174, 4.1574, 2.7249, 0.9926, 3.1868, 2.1785, 1.1711,\n",
      "        3.8426, 1.9415, 2.2567, 1.6149, 3.3087, 2.3254, 1.5495, 0.0513, 1.0793,\n",
      "        3.4240, 0.6471, 1.4294, 2.4232, 3.9285, 3.0102, 3.1478, 4.4571, 2.4567,\n",
      "        2.9874, 4.2474, 4.9545, 1.0487, 1.7774, 0.0978, 2.7495, 3.5135, 0.5343,\n",
      "        2.5650, 3.0869, 2.6378, 4.3600, 3.8155, 2.7363, 1.4792, 2.5205, 3.3485,\n",
      "        1.2677, 1.6529, 1.0610, 4.0384, 1.9029, 4.3920, 2.5398, 0.1041, 0.5030,\n",
      "        2.4846, 3.9355, 3.0617, 4.2935, 3.2057, 3.2600, 4.2375, 4.3006, 3.2438,\n",
      "        3.2792, 3.9063, 1.7483, 3.5923, 0.5657, 0.1294, 1.6525, 4.4143, 3.7637,\n",
      "        1.2534, 1.0138, 3.5659, 1.9104, 3.3013, 0.8711, 4.2860, 1.7949, 3.8327,\n",
      "        2.2329, 3.8656, 3.8038, 3.0967, 3.3424, 3.8080, 1.0246, 1.4234, 2.6791,\n",
      "        3.1997, 0.4519, 0.0401, 3.6044, 1.0451, 1.5153, 3.0645, 3.7059, 2.1804,\n",
      "        0.8146, 3.6026, 2.0163, 2.6730, 2.9057, 4.3326, 3.2520, 1.9205, 3.3418,\n",
      "        0.7316, 4.5990, 0.1456, 0.7470, 1.1874, 2.9131, 3.7183, 1.2537, 4.1204,\n",
      "        3.7558, 3.7821, 1.7927, 3.0109, 2.2329, 1.8674, 3.4286, 3.5297, 1.2679,\n",
      "        4.1434, 0.6314, 4.0867, 3.1437, 3.5224, 4.0237, 4.3091, 2.5144, 0.0954,\n",
      "        3.4365, 1.8160, 4.0107, 2.3851, 1.3189, 0.7797, 0.7774, 0.1259, 2.2012,\n",
      "        4.3218, 1.0823, 3.3053, 5.3729, 2.8608, 3.6647, 2.9430, 3.8408, 1.1048,\n",
      "        1.6561, 0.7790, 2.7376, 4.4452, 3.1462, 2.3850, 4.1645, 1.3151, 3.4021,\n",
      "        3.1030, 1.5468, 3.8547, 3.5520, 3.2076, 4.6806, 0.6747, 0.1508, 1.9941,\n",
      "        4.0569, 3.5235, 2.6210, 4.0470, 1.3139, 3.3511, 4.2225, 0.6496, 3.5329,\n",
      "        3.0521, 4.3541, 0.3899, 2.9304, 2.3164, 2.8473, 1.6500, 2.9899, 3.7564,\n",
      "        0.6377, 2.7592, 0.9692, 1.0367, 2.2290, 4.4721, 2.7687, 4.4113, 2.7712,\n",
      "        1.2061, 0.1072, 3.3809, 3.7312, 2.4254, 0.6689, 4.1594, 2.9724, 2.2854,\n",
      "        1.9215, 2.8009, 2.9663, 4.2375, 3.1929, 0.4539, 4.3265, 3.4597, 4.7680,\n",
      "        0.8470, 3.3937, 4.0941, 3.5650, 2.2399, 1.8234, 3.8025, 2.9865, 0.1422,\n",
      "        2.9549, 2.6466, 2.6327, 1.2318, 1.2301, 0.9514, 0.9666, 6.5264, 3.7544,\n",
      "        3.0347, 2.2564, 3.8834, 2.6941, 4.0237, 3.0957, 3.4456, 3.1417, 1.2100,\n",
      "        0.0513, 2.1700, 4.1778, 2.4202, 2.2086, 2.6857, 3.1039, 1.5845, 3.5775,\n",
      "        4.0894, 0.6563, 4.3436, 3.4315, 4.3181, 3.3433, 4.3639, 1.5866, 4.0682,\n",
      "        0.3791, 0.1053, 5.7390, 3.5305, 2.2030, 2.4280, 3.7595, 4.3310, 3.7585,\n",
      "        0.0659, 2.4763, 0.5311, 4.1208, 4.4092, 4.5438, 3.6428, 3.9190, 2.6357,\n",
      "        2.0522, 4.0827, 4.0326, 2.4505, 1.9966, 5.9095, 3.5534, 3.5439, 4.3125,\n",
      "        1.6131, 3.4242, 2.2998, 1.3907, 1.9295, 0.7218, 0.3003, 3.7376, 3.4895,\n",
      "        1.4777, 1.1289, 1.7856, 0.5017, 3.5403, 0.7437, 3.1674, 3.5823, 2.1576,\n",
      "        3.5028, 4.0101, 0.6142, 2.1050, 2.8176, 4.0729, 4.1077, 1.1580, 3.2980,\n",
      "        1.7076, 4.3441, 3.4759, 3.1620, 3.3423, 5.1602, 2.0446, 2.3910, 2.6058,\n",
      "        2.9759, 3.3123, 4.3459, 3.0756, 0.1350, 3.3100, 1.2853, 3.9127, 3.2748,\n",
      "        1.9686, 3.6841, 3.0667, 2.1464, 2.5231, 4.2638, 3.3116, 1.6756, 4.1338,\n",
      "        3.4092, 0.4564, 3.6255, 3.1445, 1.6324, 3.5427, 3.0722, 4.4590, 4.6963,\n",
      "        3.3331, 2.1054, 0.7626, 4.6054, 0.0922, 1.8920, 3.2071, 3.3954, 3.5988,\n",
      "        2.2405, 2.0394, 3.9292, 2.9337, 4.2624, 4.5251, 3.8580, 1.4637, 2.0882,\n",
      "        3.2220, 3.3738, 1.5978, 0.0436, 3.8645, 3.4588, 4.2093, 1.4535, 2.6906,\n",
      "        3.3268, 5.4094, 1.3737, 3.4031, 4.0350, 4.1636, 3.6246, 2.6126, 2.4942,\n",
      "        0.8612, 4.0264, 2.9625, 3.5160, 0.0842, 4.2225, 0.8231, 3.7634, 1.2219,\n",
      "        1.0626, 2.7898, 0.5261, 0.8266, 2.9302, 2.7338, 2.5269, 1.9796, 3.8460,\n",
      "        3.4408, 0.4670, 0.6619, 1.4296, 3.2750, 0.8275, 3.8343, 4.0349, 4.2995,\n",
      "        4.1212, 2.4292, 1.1434, 0.4301, 2.1368, 1.5975, 3.0299, 4.2500, 1.9865,\n",
      "        2.5910, 3.7753, 0.6876, 3.4829, 0.6637, 1.7691, 2.2520, 4.6379, 1.8056,\n",
      "        3.5084, 3.4743, 2.3986, 1.5696, 4.3049, 3.7821, 1.6312, 4.7932, 4.4525,\n",
      "        0.0897, 3.5907, 2.8033, 4.7182, 3.2714, 1.1037, 3.1747, 2.7622, 0.6471,\n",
      "        4.7565, 2.0260, 2.5997, 3.2259, 2.9342, 0.1029, 4.2967, 2.7205, 2.9606,\n",
      "        2.3162, 3.1822, 4.5063, 1.1952, 0.6591, 3.9564, 2.6812, 2.6267, 0.1325,\n",
      "        1.6490, 4.8581, 2.1496, 1.4328, 3.9240, 3.6022, 4.5672, 1.5115],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn1.bias', tensor([-1.8994,  0.7720, -5.9501, -1.4184, -1.1144, -1.9177, -1.8897, -0.4536,\n",
      "        -1.4320, -1.0455, -0.7207, -1.0062, -1.2897, -0.2664, -0.8527, -2.0719,\n",
      "        -0.4532, -1.5032, -1.5672, -2.6030, -1.2798, -1.0269, -0.5850, -1.2526,\n",
      "        -1.2137, -1.1437, -1.0900, -0.7820, -1.6093, -1.4275, -0.8029, -1.0270,\n",
      "        -1.9279, -1.2643, -1.6483, -2.3562, -0.3602, -1.5293, -1.9428, -1.9409,\n",
      "        -1.1894, -0.4876, -1.5456, -0.8275, -0.5255, -1.8294, -0.9194, -0.9412,\n",
      "        -0.8530, -1.0997, -0.8178, -0.6053, -1.8308, -0.2316, -1.2278, -0.6458,\n",
      "        -0.4552, -1.0276, -1.5043, -1.1128, -1.1917, -1.3813, -0.8894, -1.1685,\n",
      "        -1.7263, -1.9684, -0.3486, -0.6017, -2.3134, -1.0606, -1.4247, -0.7767,\n",
      "        -0.9282, -1.1066, -1.0291, -1.7700, -1.4677, -1.0035, -0.4635, -0.9777,\n",
      "        -1.1870, -0.5375, -0.5628, -0.2725, -1.6070, -0.6784, -1.6921, -0.8324,\n",
      "        -2.4094, -0.7986, -0.8511, -1.5533, -1.1000, -1.4517, -1.0552, -1.2065,\n",
      "        -1.6857, -1.5502, -1.2280, -1.5400, -1.4357, -0.5643, -1.2620, -0.7629,\n",
      "        -2.9009, -0.5194, -1.6877, -1.5014, -0.3403, -0.2445, -1.4053, -0.7143,\n",
      "        -1.7591, -0.2939, -1.9580, -0.7661, -1.6828, -0.7687, -1.4093, -1.4131,\n",
      "        -0.9789, -1.5381, -1.5744, -0.3821, -0.5160, -1.1550, -1.3618, -3.7983,\n",
      "        -1.8277, -1.5974, -0.3608, -0.8862, -1.3962, -1.4289, -0.9429, -0.2611,\n",
      "        -1.5681, -0.8688, -1.1769, -1.2274, -1.6243, -1.3753, -0.7499, -1.3428,\n",
      "        -0.3502, -1.8249, -3.3467, -0.4348, -0.3807, -1.0724, -1.5238, -0.5142,\n",
      "        -1.5990, -1.5053, -1.5204, -0.6994, -1.1561, -0.8958, -0.6754, -1.3352,\n",
      "        -1.2043, -0.3320, -1.6228,  0.1023, -1.6149, -1.0630, -1.3918, -1.5984,\n",
      "        -1.6219, -0.9883, -2.3674, -1.3435, -0.6336, -1.6462, -0.8598, -0.2858,\n",
      "        -0.2156, -1.2477, -3.2708, -0.6025, -1.4609, -0.3146, -1.2101, -2.9956,\n",
      "        -0.9583, -1.2123, -1.0812, -1.3552, -0.2938, -0.4029,  0.2478, -0.8708,\n",
      "        -1.8935, -1.1316, -0.8302, -1.9269, -0.5420, -1.4787, -1.2810, -0.6858,\n",
      "        -1.5565, -1.6617, -1.5330, -1.8304, -0.5217, -4.3132, -0.8598, -1.8820,\n",
      "        -1.6583, -1.3504, -1.9954, -0.4629, -1.3400, -1.7919, -0.3671, -1.4936,\n",
      "        -1.3277, -2.0570, -2.7753, -1.2635, -1.0497, -1.3813, -0.5808, -1.1431,\n",
      "        -1.3121, -0.1328, -0.9292, -0.3634, -0.3140, -0.8804, -1.8272, -0.9811,\n",
      "        -1.7050, -0.8504, -0.3184, -2.5355, -1.2241, -1.3230, -0.8171, -0.8056,\n",
      "        -1.8978, -1.4006, -2.4151, -0.7427, -1.2534, -1.2667, -1.8051, -1.4110,\n",
      "        -3.3668, -2.0075, -1.6068, -2.2404, -0.4170, -1.4985, -1.9872, -1.4460,\n",
      "        -0.8806, -0.7884, -1.6658, -1.3862, -3.2375, -1.2562, -1.0083, -1.2257,\n",
      "        -0.5423, -0.3740, -0.3766, -0.3428, -6.8788, -1.7598, -1.6371, -0.8694,\n",
      "        -1.7562, -1.1749, -1.7673, -1.4467, -1.5188, -1.2995, -1.1852, -2.4178,\n",
      "        -0.9043, -2.1220, -1.1333, -0.9206, -1.1049, -1.1973, -0.5700, -1.9180,\n",
      "        -1.6574, -0.6347, -1.8164, -1.3138, -1.8115, -1.4622, -1.9331, -0.7184,\n",
      "        -1.7369,  0.3377, -2.5936, -2.4982, -1.5808, -0.9719, -1.0499, -1.5459,\n",
      "        -1.8138, -1.5829, -2.2363, -1.0917, -0.7564, -1.8545, -1.7509, -1.9439,\n",
      "        -1.4280, -1.4344, -0.9172, -0.7669, -1.9096, -1.7714, -0.9585, -0.7160,\n",
      "        -1.8117, -1.5200, -1.3963, -1.7182, -0.6269, -1.2990, -0.8388, -1.7747,\n",
      "        -0.7885, -0.2265, -1.5624, -1.5698, -1.4411, -0.6413, -0.5090, -0.6182,\n",
      "        -3.9845, -1.4848, -0.3383, -1.4440, -1.5613, -0.8435, -1.6744, -1.7386,\n",
      "        -0.1525, -0.8342, -1.3513, -1.9113, -1.7859, -0.4676, -1.4776, -0.8535,\n",
      "        -2.0246, -1.5390, -1.3063, -1.3228, -2.4362, -0.9522, -1.1720, -1.2112,\n",
      "        -1.2100, -1.6532, -1.9887, -1.3514, -3.1340, -1.5824, -0.4540, -1.7239,\n",
      "        -1.4002, -0.8653, -1.5443, -4.8187, -0.8942, -1.0962, -2.1437, -1.4727,\n",
      "        -0.6863, -1.8178, -1.5645, -3.6511, -1.7042, -1.3306, -0.8740, -1.5911,\n",
      "        -1.2044, -1.7314, -1.7229, -1.0244, -0.5369, -1.8464, -1.5208, -2.3820,\n",
      "        -0.6229, -1.1839, -1.1857, -1.3289, -0.7562, -0.6712, -1.3163, -1.0117,\n",
      "        -1.8939, -2.1691, -1.9699, -0.5858, -1.0192, -1.5602, -1.6408, -0.7588,\n",
      "        -1.8540, -1.9014, -1.5113, -2.0679, -0.6437, -1.1365, -1.3699, -2.6495,\n",
      "        -0.3555, -1.2452, -1.6095, -1.6627, -1.6386, -0.9892, -1.0105, -0.5197,\n",
      "        -1.6604, -1.1150, -1.5357, -2.0059, -1.7692, -0.2549, -1.4533, -0.4058,\n",
      "        -0.2126, -0.7079,  0.1366, -0.3044, -0.7003, -0.8522, -0.7005, -0.4644,\n",
      "        -1.1665, -0.8646, -4.2463, -0.5594,  0.2945, -0.8693, -0.1302, -1.0266,\n",
      "        -1.7448, -1.8253, -2.9208, -1.0921, -0.4108, -3.1652, -0.8872, -0.6171,\n",
      "        -1.2806, -1.7905, -0.8213, -1.4450, -1.5555, -0.1661, -1.5423, -0.2772,\n",
      "        -0.6004, -0.9595, -2.0763, -0.8712, -1.4641, -4.7479, -1.0291, -0.8252,\n",
      "        -1.8140, -1.6347, -0.4907, -1.9313, -1.8216, -1.8971, -1.4094, -1.1601,\n",
      "        -2.0896, -1.5242, -0.3638, -1.3011, -1.2781, -0.1884, -2.1587, -1.1786,\n",
      "        -1.1954, -1.3326, -1.3293, -2.4634, -2.0125, -1.1237, -1.2449, -1.0251,\n",
      "        -1.5413, -1.9851, -0.4433, -0.7230, -1.5634, -0.9816, -0.8015, -2.7590,\n",
      "        -0.5604, -1.8482, -0.5638, -0.4523, -1.5278, -1.2643, -1.8095, -0.5594],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.conv2.weight', tensor([[[[ 4.4445e-02,  1.3422e-02,  9.3911e-03],\n",
      "          [ 2.2293e-02,  5.7773e-02,  4.3260e-02],\n",
      "          [-3.7550e-02, -6.4577e-02, -3.9765e-03]],\n",
      "\n",
      "         [[-1.5412e-02, -5.0461e-02,  4.5361e-06],\n",
      "          [-6.3681e-02, -1.8857e-01, -3.8627e-02],\n",
      "          [ 5.1088e-03, -6.3345e-02,  1.6185e-02]],\n",
      "\n",
      "         [[-7.5960e-03,  8.6050e-03, -1.0055e-01],\n",
      "          [ 2.0580e-03, -5.8172e-02, -3.3499e-02],\n",
      "          [ 8.1772e-02,  6.1836e-02,  3.4213e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0819e-02, -3.2936e-02, -4.2055e-02],\n",
      "          [-5.6262e-02, -2.3112e-02,  5.9709e-03],\n",
      "          [ 6.9150e-03, -2.4886e-02,  6.1047e-02]],\n",
      "\n",
      "         [[-2.8365e-02, -2.7701e-02, -5.2660e-03],\n",
      "          [-4.8448e-02, -1.6779e-02, -2.0284e-02],\n",
      "          [-6.7586e-02, -6.0849e-02, -6.3583e-02]],\n",
      "\n",
      "         [[-7.7858e-03, -7.1824e-03, -1.0607e-02],\n",
      "          [-2.1770e-02, -2.2448e-02, -4.5806e-02],\n",
      "          [ 1.6925e-02, -2.5112e-02, -2.7162e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7274e-02, -1.5223e-02,  2.4653e-02],\n",
      "          [ 3.1781e-02, -2.2641e-02,  2.1771e-02],\n",
      "          [-3.1642e-03, -6.0680e-02,  1.1053e-03]],\n",
      "\n",
      "         [[-6.3220e-03, -8.3209e-02,  7.7206e-03],\n",
      "          [-8.0090e-02, -2.4723e-01, -5.5579e-02],\n",
      "          [ 4.4880e-04, -6.5044e-02,  1.6376e-03]],\n",
      "\n",
      "         [[ 1.2458e-02, -7.9441e-03, -1.2750e-01],\n",
      "          [-7.2414e-03, -1.3224e-01, -1.0212e-01],\n",
      "          [-1.1707e-01, -5.3126e-02, -5.7510e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8043e-02, -2.0064e-02,  3.1362e-02],\n",
      "          [ 2.1829e-02, -8.4072e-02, -6.7592e-03],\n",
      "          [ 2.6564e-02, -3.2516e-02, -2.9661e-02]],\n",
      "\n",
      "         [[-6.8069e-02, -6.3192e-03, -4.1351e-02],\n",
      "          [-6.3132e-02,  1.3104e-02, -4.9112e-02],\n",
      "          [-1.8942e-02,  2.9097e-02, -3.7188e-02]],\n",
      "\n",
      "         [[ 1.1728e-02,  2.8323e-02,  6.9804e-02],\n",
      "          [-2.3887e-02, -5.3595e-02,  2.8201e-02],\n",
      "          [ 6.7474e-02, -8.1927e-03,  3.4837e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8518e-02,  6.9707e-03, -4.3215e-02],\n",
      "          [ 1.1238e-01,  6.3399e-02, -1.5595e-02],\n",
      "          [-7.3859e-03,  2.5356e-02, -8.9387e-02]],\n",
      "\n",
      "         [[ 1.3938e-02, -7.1635e-02,  2.8517e-02],\n",
      "          [-6.2360e-02, -2.3971e-01, -5.5877e-02],\n",
      "          [ 4.6538e-02, -2.6767e-02,  4.2214e-02]],\n",
      "\n",
      "         [[ 1.8449e-02, -1.8504e-04, -7.6615e-02],\n",
      "          [ 1.2333e-02, -4.6756e-02, -8.1990e-02],\n",
      "          [ 5.8645e-02,  4.2199e-02,  1.1797e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7022e-02,  4.8275e-02, -2.7804e-03],\n",
      "          [ 2.2890e-02,  1.6293e-02, -3.7312e-02],\n",
      "          [-6.9951e-02, -4.2068e-02, -5.4504e-02]],\n",
      "\n",
      "         [[-7.2129e-02,  1.1153e-02, -9.4313e-02],\n",
      "          [ 1.1063e-02,  4.5309e-02, -2.1445e-02],\n",
      "          [-6.4118e-04, -4.5718e-02,  6.7333e-02]],\n",
      "\n",
      "         [[-5.8155e-03, -1.2130e-02, -6.9599e-02],\n",
      "          [ 3.4159e-03, -3.4933e-02,  7.4820e-03],\n",
      "          [ 1.7613e-03, -2.4544e-02, -1.1863e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.2769e-02, -1.3134e-02, -6.1205e-03],\n",
      "          [-2.4432e-02, -1.4062e-02, -2.7120e-02],\n",
      "          [-1.9849e-03, -1.9122e-02, -6.0256e-02]],\n",
      "\n",
      "         [[ 1.0971e-02, -2.6049e-02,  1.1364e-02],\n",
      "          [-4.5428e-02, -2.1749e-01, -4.4689e-02],\n",
      "          [ 6.8380e-03, -2.2441e-02, -5.6900e-03]],\n",
      "\n",
      "         [[ 4.3562e-02,  1.0662e-02, -1.1031e-01],\n",
      "          [-1.4995e-02,  7.3961e-02, -6.4130e-02],\n",
      "          [-3.7269e-02, -2.5041e-02, -3.6129e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8158e-02, -1.9907e-02, -1.5402e-02],\n",
      "          [-2.8153e-02, -6.0561e-02, -3.2297e-02],\n",
      "          [ 2.5801e-02, -8.5543e-03,  2.0627e-02]],\n",
      "\n",
      "         [[-2.6275e-03,  1.2296e-02, -3.8324e-02],\n",
      "          [-4.5666e-02,  8.4424e-03, -4.2514e-02],\n",
      "          [ 3.7698e-02,  3.7235e-02, -6.0133e-02]],\n",
      "\n",
      "         [[-8.8733e-02, -6.1174e-02, -1.1378e-01],\n",
      "          [-7.4499e-02, -6.4427e-02, -1.2187e-01],\n",
      "          [-1.3871e-01, -8.5227e-02, -1.1415e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3074e-02,  8.9628e-03,  8.9112e-02],\n",
      "          [ 2.3401e-02, -3.0960e-02,  8.0934e-02],\n",
      "          [-3.0589e-02, -1.9576e-02, -1.1138e-02]],\n",
      "\n",
      "         [[-3.2567e-03, -4.8763e-02, -1.4270e-02],\n",
      "          [-7.4743e-02, -2.4604e-01, -8.1260e-02],\n",
      "          [ 1.4348e-02, -7.6858e-02, -8.2090e-04]],\n",
      "\n",
      "         [[-1.8433e-02, -1.1159e-02,  1.1416e-01],\n",
      "          [-1.1832e-02,  8.2227e-02,  1.9770e-02],\n",
      "          [ 1.0528e-01,  1.9558e-02, -6.0563e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.5645e-02, -1.6461e-02,  1.3996e-02],\n",
      "          [ 3.5306e-03, -5.9534e-02,  7.9915e-03],\n",
      "          [ 2.5062e-02, -5.7291e-02, -9.4536e-05]],\n",
      "\n",
      "         [[-5.5531e-02, -6.3085e-02, -3.9783e-02],\n",
      "          [-8.8946e-02, -9.8292e-02, -7.1150e-02],\n",
      "          [-9.0445e-02, -9.7021e-02, -6.3446e-02]],\n",
      "\n",
      "         [[ 1.3294e-01,  1.2049e-01,  1.1785e-01],\n",
      "          [ 1.2616e-01,  9.1127e-02,  8.8260e-02],\n",
      "          [ 8.0664e-02,  5.3519e-02,  9.3385e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0183e-02,  6.7105e-02,  2.8440e-02],\n",
      "          [ 3.9406e-02, -1.8608e-03,  5.5343e-02],\n",
      "          [ 3.5125e-02,  3.9414e-02,  3.8451e-02]],\n",
      "\n",
      "         [[ 2.6159e-02, -4.9367e-02,  9.0855e-03],\n",
      "          [-1.0286e-01, -2.7122e-01, -6.8579e-02],\n",
      "          [-7.9581e-03, -5.6271e-02,  1.0487e-02]],\n",
      "\n",
      "         [[ 1.4787e-02,  2.3495e-02,  5.5510e-02],\n",
      "          [ 1.6614e-02, -1.5464e-01,  7.3531e-02],\n",
      "          [ 7.0173e-02,  5.4278e-02,  1.0549e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9425e-02, -7.8736e-02, -6.0611e-02],\n",
      "          [-1.5397e-02, -5.0796e-02, -4.7329e-03],\n",
      "          [-1.7039e-02,  1.1146e-02,  1.8152e-02]],\n",
      "\n",
      "         [[ 2.9659e-02,  7.2558e-02,  4.7204e-02],\n",
      "          [ 6.0047e-02,  1.0421e-01,  8.8786e-02],\n",
      "          [ 4.3739e-02,  9.2682e-02,  3.0070e-02]],\n",
      "\n",
      "         [[-5.5929e-02, -1.7304e-01, -9.4187e-02],\n",
      "          [-7.4153e-02, -1.6428e-01, -8.7572e-02],\n",
      "          [-5.3347e-02, -1.2718e-01, -1.0945e-01]]]], device='cuda:0')), ('backbone.model.layer4.2.bn2.weight', tensor([1.7691, 2.4915, 2.1124, 1.6742, 1.7442, 2.7256, 1.5812, 1.9456, 2.2188,\n",
      "        2.3135, 2.4656, 1.5898, 2.0004, 2.2021, 1.7802, 1.5509, 2.2493, 2.1295,\n",
      "        1.3575, 2.4581, 1.9458, 1.8179, 2.6442, 2.2466, 2.2574, 2.0624, 2.1201,\n",
      "        2.3454, 1.8895, 1.8534, 1.6164, 1.6587, 2.3822, 2.9469, 0.0901, 3.9225,\n",
      "        2.4838, 4.0487, 3.0101, 2.8157, 3.0796, 3.1579, 2.7924, 5.1066, 2.0971,\n",
      "        2.3415, 3.0674, 3.7572, 1.9630, 2.0525, 2.5782, 2.5995, 2.3212, 1.5014,\n",
      "        1.9460, 1.5450, 2.2617, 1.6914, 2.5845, 2.3339, 1.7787, 1.7016, 1.3642,\n",
      "        1.6823, 2.4363, 1.3963, 2.4893, 1.8002, 2.4605, 2.2332, 2.6683, 2.7544,\n",
      "        2.5608, 2.4519, 2.5277, 1.9656, 2.4649, 2.9631, 1.9211, 1.5163, 2.8665,\n",
      "        0.1114, 2.9725, 2.3932, 3.3547, 2.4065, 3.2262, 4.2646, 2.4592, 3.5764,\n",
      "        2.3232, 2.6147, 3.1781, 2.4012, 4.2393, 3.1650, 1.7421, 1.8430, 1.9333,\n",
      "        2.3976, 2.2080, 1.4740, 2.2204, 1.5063, 1.9826, 2.1234, 2.2016, 1.5741,\n",
      "        1.5083, 2.1333, 1.7472, 1.4746, 1.8340, 2.3002, 1.8855, 1.8066, 1.6943,\n",
      "        1.6047, 1.8417, 2.1610, 2.4242, 1.8996, 1.7409, 1.9866, 2.2133, 2.0299,\n",
      "        1.5760, 2.0159, 2.5593, 3.1356, 3.6122, 4.3704, 3.4156, 3.3420, 3.7339,\n",
      "        3.3724, 3.0327, 3.2846, 3.5875, 3.8901, 4.2601, 3.9988, 3.7001, 3.6519,\n",
      "        2.0913, 2.1793, 1.6013, 1.7655, 1.6041, 2.3344, 1.3799, 2.2983, 2.2890,\n",
      "        3.0952, 1.8049, 1.6827, 2.2601, 2.3564, 1.7745, 2.4603, 2.0738, 2.1057,\n",
      "        2.1429, 1.5521, 1.5437, 1.9241, 2.4244, 2.1506, 2.2402, 1.8226, 1.6619,\n",
      "        1.6764, 1.8830, 1.4670, 1.6442, 1.5954, 1.7648, 2.4186, 1.8107, 1.4503,\n",
      "        2.1411, 1.9520, 2.1160, 2.0103, 1.7218, 1.7484, 2.0732, 1.9006, 2.2549,\n",
      "        1.7650, 2.1164, 1.7236, 3.0960, 2.4336, 2.1110, 2.1044, 1.9080, 1.3832,\n",
      "        1.9631, 2.3337, 1.7826, 2.5209, 1.9561, 1.7719, 1.9751, 2.1766, 1.7001,\n",
      "        2.5620, 1.5728, 2.0056, 2.0049, 2.6281, 2.3053, 2.6224, 2.2175, 1.8061,\n",
      "        2.0137, 2.2417, 1.6505, 2.5703, 2.1325, 2.5019, 1.7444, 2.1528, 3.3463,\n",
      "        2.2638, 1.8143, 3.1028, 1.8592, 3.2210, 3.5330, 2.4720, 2.5090, 2.0920,\n",
      "        0.0841, 2.5072, 2.3539, 3.6223, 2.4166, 2.1926, 2.0397, 2.3176, 2.1491,\n",
      "        1.5185, 2.4471, 1.7385, 1.9692, 2.0998, 1.8942, 1.7884, 2.2900, 1.9121,\n",
      "        2.0395, 2.3208, 1.5836, 1.7628, 1.5812, 2.4866, 2.2339, 2.5643, 1.6628,\n",
      "        2.1921, 1.9609, 2.1787, 2.5795, 2.0603, 2.0438, 1.7523, 2.1867, 2.3830,\n",
      "        2.6434, 2.2869, 2.2243, 2.3525, 1.9220, 1.6569, 2.0343, 1.4501, 1.9294,\n",
      "        1.5613, 1.6674, 2.5381, 2.1764, 1.6905, 1.7230, 2.3479, 2.1970, 1.4728,\n",
      "        1.7423, 2.1623, 1.7189, 1.5582, 2.6751, 1.8264, 1.9171, 2.0458, 1.6988,\n",
      "        2.0011, 1.5771, 1.5053, 2.3533, 1.7663, 1.7704, 1.9700, 1.9120, 1.7009,\n",
      "        2.4156, 2.0232, 1.7569, 2.7640, 1.9526, 2.2903, 1.9428, 2.1907, 2.0896,\n",
      "        1.5328, 1.8140, 1.3757, 1.6128, 1.7138, 8.6483, 6.7484, 4.9196, 4.8204,\n",
      "        4.9907, 0.0599, 6.9037, 5.6264, 5.8276, 4.4588, 4.6998, 7.0331, 7.3658,\n",
      "        3.4100, 3.8775, 5.2153, 2.1959, 1.5864, 3.1098, 2.1744, 1.8940, 2.7604,\n",
      "        1.7318, 1.8828, 2.4856, 1.8550, 1.7683, 1.9738, 2.3940, 2.0028, 1.6676,\n",
      "        1.9050, 1.8155, 0.0844, 3.1607, 3.0328, 3.2269, 3.5794, 2.8334, 2.4406,\n",
      "        3.0556, 3.2245, 3.2354, 3.1464, 2.9121, 2.8115, 2.7192, 3.2974, 2.5404,\n",
      "        3.0258, 4.1946, 3.6561, 5.1648, 4.1725, 3.3545, 5.1750, 3.6324, 4.5195,\n",
      "        3.3769, 4.8006, 4.4571, 4.5242, 0.0982, 3.3149, 2.4687, 3.8923, 3.1259,\n",
      "        2.6149, 3.2797, 4.0376, 3.8072, 3.4525, 2.8134, 2.4084, 2.3891, 1.9213,\n",
      "        2.6828, 2.9319, 3.0626, 0.1217, 2.9784, 1.9685, 2.3194, 2.1014, 1.9761,\n",
      "        1.9685, 1.9283, 1.9726, 2.1611, 1.9534, 2.5119, 2.2564, 2.1368, 1.5351,\n",
      "        2.2033, 1.7447, 3.3946, 2.9341, 4.3180, 2.6670, 3.4220, 4.0018, 2.1472,\n",
      "        1.9711, 0.0634, 3.5144, 3.4886, 4.0870, 2.4103, 2.4713, 2.4713, 3.4438,\n",
      "        2.2793, 1.7044, 1.9463, 2.3399, 2.6268, 2.2270, 1.9853, 2.0316, 1.8955,\n",
      "        2.1310, 2.2005, 2.2710, 2.0228, 1.9881, 2.1331, 1.9152, 1.5831, 1.6506,\n",
      "        1.8622, 1.6528, 2.5537, 1.8811, 1.7900, 1.7792, 1.5781, 1.8022, 1.8447,\n",
      "        2.4986, 1.6284, 1.7653, 2.2962, 1.8278, 1.6330, 1.8960, 2.5407, 1.4933,\n",
      "        1.7702, 2.0344, 1.8158, 2.2436, 2.6603, 1.6989, 1.3340, 2.0318, 2.3218,\n",
      "        2.1759, 2.3070, 1.6419, 1.7604, 2.0947, 1.9874, 2.1928, 2.1451, 1.9120,\n",
      "        1.5710, 2.3375, 1.4801, 1.4450, 1.5779, 1.6591, 2.2560, 1.3208, 1.5326,\n",
      "        2.1375, 2.1321, 2.2398, 1.3302, 1.9619, 2.1403, 1.6517, 1.5365, 1.7107,\n",
      "        1.8543, 2.9595, 1.7497, 1.8480, 1.9581, 1.4936, 1.4163, 2.1403],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn2.bias', tensor([-7.9175e-01, -1.3671e+00, -1.0833e+00, -9.5326e-01, -8.6891e-01,\n",
      "        -2.9064e+00, -5.0012e+00, -1.0431e+00, -1.9233e+00, -1.5428e+00,\n",
      "        -1.4881e+00, -9.6335e-01, -9.5385e-01, -1.2095e+00, -8.8031e-01,\n",
      "        -1.0898e+00, -1.6253e+00, -1.5157e+00, -1.5023e+00, -1.8526e+00,\n",
      "        -1.5990e+00, -1.3190e+00, -2.8556e+00, -1.5454e+00, -1.8313e+00,\n",
      "        -1.4028e+00, -9.4503e-01, -1.7483e+00, -1.2738e+00, -8.0035e-01,\n",
      "        -9.8203e-01, -1.4778e+00, -1.0462e+00, -1.0758e+00, -1.5380e+00,\n",
      "        -1.9832e+00, -4.6306e-01, -1.0724e+00, -3.2117e-01, -4.8164e-01,\n",
      "        -5.3183e-01, -1.5870e+00, -1.1266e+00,  1.4448e-01, -1.9372e-01,\n",
      "        -4.9337e-01, -4.9406e+00, -1.9074e+00, -7.4342e-01, -2.4163e+00,\n",
      "        -1.1646e+00, -3.5413e+00, -2.8948e+00, -1.5916e-01, -8.4375e-01,\n",
      "        -2.9051e-01, -1.2633e+00, -1.2875e+00, -2.0068e+00, -1.0100e+00,\n",
      "        -7.4026e-01, -9.6609e-01, -1.1825e+00, -1.7119e+00, -1.5323e+00,\n",
      "        -2.2778e+00, -9.8220e-01, -4.5108e-01, -7.6483e-01, -1.1102e+00,\n",
      "        -1.6434e+00, -1.2615e+00, -1.0934e+00, -4.9810e+00, -8.2915e-01,\n",
      "        -7.9782e-01, -8.9633e-01, -6.0762e+00, -1.7435e+00, -3.1686e-01,\n",
      "        -7.9721e-01, -1.5560e+00, -8.8574e-01, -3.6342e-01, -8.3473e-01,\n",
      "        -2.5135e+00, -5.3633e+00, -1.3145e+00, -1.9424e-01, -1.3477e+00,\n",
      "         2.3027e-01, -2.1779e-01, -1.0471e+00, -5.6146e-01, -1.4007e+00,\n",
      "        -1.5628e+00, -1.5367e+00, -7.4487e-01, -8.8330e-01, -1.1748e+00,\n",
      "        -1.6182e+00, -5.9983e-01, -1.4468e+00, -8.3820e-01, -2.9809e+00,\n",
      "        -9.9050e-01, -9.7084e-01, -6.4968e-01, -6.7692e-01, -1.3211e+00,\n",
      "        -7.0841e-01, -6.8242e-01, -1.0726e+00, -1.4024e+00, -1.2456e+00,\n",
      "        -7.1272e-01, -4.6091e-01, -5.8568e-01, -1.5465e+00, -1.2917e+00,\n",
      "        -1.8838e+00, -1.0101e+00, -4.3373e+00, -1.0903e+00, -1.1026e+00,\n",
      "        -1.0469e+00, -5.8335e-01, -1.0872e+00, -2.2984e+00, -5.7871e-01,\n",
      "        -1.0100e+00, -2.1685e+00, -6.4015e-01, -2.8804e-01, -4.3833e-01,\n",
      "        -4.8950e-01, -4.6549e-01, -6.0660e-01, -4.6269e-01, -1.1300e+00,\n",
      "        -8.3790e-01, -7.2713e-01, -9.1879e-01, -7.2848e-01, -1.9463e-01,\n",
      "        -2.0504e+00, -1.6409e-01, -2.2459e-03, -1.1936e-01, -8.4880e-01,\n",
      "         4.3946e-02, -5.8643e-01, -3.4412e+00, -1.3281e+00, -4.9990e-01,\n",
      "        -3.2195e-02, -1.1456e+00, -2.1465e+00, -5.0146e+00, -9.6719e-01,\n",
      "        -1.0439e+00, -1.3916e+00, -1.0686e+00, -6.1730e-01, -4.5711e-01,\n",
      "        -9.7506e-01, -1.2865e+00, -9.3089e-01, -1.4327e+00, -1.0044e+00,\n",
      "        -5.7277e-01, -3.6178e+00, -7.0791e-01, -1.5891e-01, -6.4402e-01,\n",
      "        -3.1404e-01, -1.0289e+00, -1.3741e+00, -1.9548e+00, -4.9465e-01,\n",
      "        -1.9779e+00, -1.1466e+00, -1.6566e+00, -2.1268e+00, -1.2232e+00,\n",
      "        -1.1179e+00, -7.3483e-01, -4.8202e-01, -1.4259e+00, -9.9801e-01,\n",
      "        -1.0053e+00, -1.1330e+00, -1.7372e+00, -1.1239e+00, -2.8080e+00,\n",
      "        -1.5010e+00, -1.2697e+00, -2.8034e-01, -5.1304e-01, -1.7025e+00,\n",
      "        -5.6512e-01, -1.1206e+00, -5.4896e-01, -5.4398e-01, -5.2421e+00,\n",
      "        -1.6849e+00, -3.6704e-01, -1.2528e+00, -1.0514e+00, -2.2662e+00,\n",
      "        -2.7409e+00, -4.3911e+00, -2.0172e+00, -2.1232e+00, -2.6583e+00,\n",
      "        -1.0070e+00, -1.3564e+00, -1.4416e+00, -1.4148e+00, -1.4803e+00,\n",
      "        -1.9090e+00, -1.8894e+00, -1.0000e+00, -1.6235e+00, -1.8699e+00,\n",
      "        -1.4841e-01, -2.2598e-01, -1.7601e+00, -2.0421e-01, -3.0132e-01,\n",
      "        -1.6171e+00, -5.5636e-01, -1.0843e-01, -2.7597e-01, -1.1739e+00,\n",
      "        -1.9096e-01, -6.5510e-01, -1.3739e+00, -2.4027e-01, -8.5969e-01,\n",
      "        -9.1960e-01, -1.4586e+00, -1.8692e+00, -7.0724e-01, -2.2335e+00,\n",
      "        -3.4057e+00, -1.3217e+00, -1.2034e+00, -7.6804e-01, -9.6053e-01,\n",
      "        -1.6806e+00, -5.0373e-01, -9.6467e-01, -1.7252e+00, -6.3950e-01,\n",
      "        -1.0306e+00, -7.2847e-01, -1.5051e+00, -1.6073e+00, -2.7688e+00,\n",
      "        -5.3272e+00, -2.0296e+00, -1.3353e+00, -2.4173e+00, -2.9626e+00,\n",
      "        -1.2735e+00, -1.0391e+00, -1.2984e+00, -1.6712e+00, -1.7706e+00,\n",
      "        -2.1535e+00, -1.6793e+00, -1.4301e+00, -1.5334e+00, -1.2759e+00,\n",
      "        -4.3288e+00, -1.0225e+00, -5.0339e-01, -6.0827e-01, -5.7712e-01,\n",
      "        -5.5457e-01, -1.5600e+00, -1.0026e+00, -3.3357e-01, -8.3212e-01,\n",
      "        -1.3425e+00, -1.5094e+00, -7.3351e-01, -1.1388e+00, -1.4320e+00,\n",
      "        -1.0261e+00, -1.0457e+00, -2.5424e+00, -1.1926e+00, -9.5573e-01,\n",
      "        -1.2021e+00, -6.6393e-01, -1.2599e+00, -1.0133e+00, -7.5581e-01,\n",
      "        -1.4149e+00, -7.4489e-01, -7.0495e-01, -1.9168e+00, -1.4155e+00,\n",
      "        -9.2405e-01, -1.8773e+00, -1.1913e+00, -9.7051e-01, -2.7586e+00,\n",
      "        -1.7863e+00, -1.0937e+00, -9.2042e-01, -1.7561e+00, -1.5567e+00,\n",
      "        -6.5727e-01, -1.3078e+00, -9.0296e-01, -1.2156e+00, -1.0324e+00,\n",
      "         5.2035e-01,  3.0635e-01,  6.6434e-01, -1.6697e-01,  6.2572e-01,\n",
      "        -1.1665e+00,  6.4430e-01, -2.3990e+00,  3.4293e-01,  6.8541e-01,\n",
      "        -3.5415e-01,  3.3426e-01,  3.2487e-01, -4.6085e+00,  3.6402e-01,\n",
      "         5.0425e-01, -8.2871e-01,  2.7456e-01, -1.4382e+00, -9.5108e-01,\n",
      "        -6.2524e-01, -1.3131e+00, -3.6936e-01, -1.2589e-01, -1.6537e+00,\n",
      "        -1.8542e+00, -4.0071e-01, -6.1698e-01, -1.1179e+00, -3.2610e-01,\n",
      "        -5.6026e-01, -5.9679e+00,  1.4960e-01, -1.4563e+00, -2.9005e-01,\n",
      "        -3.1721e+00,  1.4404e-01, -6.7792e-01,  3.5237e-01, -5.2152e+00,\n",
      "        -3.3669e-01, -4.1064e+00, -4.5190e-01, -5.0002e-01,  1.4562e-01,\n",
      "         1.6377e-01,  1.5138e-01, -5.2270e+00,  2.1103e-01,  3.1448e-01,\n",
      "         1.3221e-01, -5.8688e+00,  7.8000e-01,  4.3278e-01,  1.8302e-01,\n",
      "         1.5159e-01,  9.0752e-02, -2.1142e-01,  3.4001e-01,  4.3513e-01,\n",
      "        -4.7393e-01, -3.0634e+00, -1.5178e+00,  7.7333e-01, -7.6067e-02,\n",
      "        -1.5728e+00, -1.1223e+00, -4.9717e-01, -1.0127e+00, -1.7767e+00,\n",
      "        -1.8344e+00, -1.4330e+00, -5.4198e-01, -4.2219e-01, -5.1697e-01,\n",
      "        -3.5251e-01, -3.4845e-01, -1.1801e+00, -3.2191e-01, -1.9053e+00,\n",
      "        -1.9101e+00, -8.0433e-01, -3.0149e+00, -8.4541e-01, -1.7574e+00,\n",
      "        -1.3087e+00, -1.6132e+00, -1.3879e+00, -2.1133e+00, -7.9603e-01,\n",
      "        -2.5795e+00, -1.5557e+00, -2.4753e+00, -1.1709e+00, -2.0304e+00,\n",
      "        -1.1035e+00, -5.3329e+00, -9.7641e-01, -1.8126e+00,  1.2066e-01,\n",
      "        -1.2295e+00, -9.3812e-01, -3.9651e-01, -6.3787e-01, -1.0871e+00,\n",
      "        -1.5045e+00, -1.0442e+00, -6.9809e-01, -3.8291e-01,  3.5314e-01,\n",
      "        -8.5383e-02, -1.6916e+00, -1.9574e+00, -1.4648e+00, -1.6879e+00,\n",
      "        -2.3478e+00, -2.3765e+00, -2.0627e+00, -1.9957e+00, -1.2946e+00,\n",
      "        -2.6396e+00, -1.4161e+00, -1.5711e+00, -1.2249e+00, -2.0992e+00,\n",
      "        -1.8185e+00, -1.3451e+00, -1.1803e+00, -4.2479e-01, -6.7109e-01,\n",
      "        -1.2568e+00, -1.0642e+00, -4.4785e+00, -1.4591e+00, -1.3104e-01,\n",
      "        -7.8366e-01, -4.2093e-01, -1.9350e-01, -6.9758e-01, -1.9538e+00,\n",
      "        -9.1960e-01, -1.1077e+00, -1.9689e+00, -1.1614e+00, -1.6699e-01,\n",
      "        -7.0157e-01, -1.5871e+00, -2.2050e-01, -7.8789e-01, -9.1360e-01,\n",
      "        -3.4194e+00, -1.4689e+00, -2.7159e+00, -5.3250e-01, -1.6729e+00,\n",
      "        -1.2261e+00, -1.2833e+00, -7.5643e-01, -1.0683e+00, -6.0654e-01,\n",
      "         8.9925e-02, -8.9326e-01, -1.0690e+00, -1.4296e+00, -1.5919e+00,\n",
      "        -8.7958e-01, -4.0961e-01, -2.4319e+00, -2.4067e+00, -4.9095e-01,\n",
      "        -2.0822e-02, -9.9284e-01, -1.5285e+00, -3.2422e-01,  5.1024e-02,\n",
      "        -1.3472e+00, -1.0678e+00, -1.0548e+00, -4.0405e-01, -1.4922e+00,\n",
      "        -6.8784e-01, -1.1882e+00, -8.6106e-01, -6.9834e-01, -9.8198e-01,\n",
      "        -3.7834e+00, -8.2076e-01, -5.2978e-01, -1.9117e+00, -5.8863e-01,\n",
      "        -4.2552e-01, -1.0383e+00], device='cuda:0')), ('backbone.model.layer4.2.conv3.weight', tensor([[[[ 0.0527]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         [[-0.1376]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0154]],\n",
      "\n",
      "         [[-0.0655]],\n",
      "\n",
      "         [[ 0.0615]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0077]],\n",
      "\n",
      "         [[-0.0299]],\n",
      "\n",
      "         [[ 0.0368]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0221]],\n",
      "\n",
      "         [[ 0.0645]],\n",
      "\n",
      "         [[-0.0525]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0184]],\n",
      "\n",
      "         [[ 0.0439]],\n",
      "\n",
      "         [[ 0.0474]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0682]],\n",
      "\n",
      "         [[ 0.0694]],\n",
      "\n",
      "         [[-0.0089]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0275]],\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[ 0.0876]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         [[ 0.0808]],\n",
      "\n",
      "         [[-0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.1195]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         [[-0.0200]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0699]],\n",
      "\n",
      "         [[-0.0196]],\n",
      "\n",
      "         [[ 0.0437]]],\n",
      "\n",
      "\n",
      "        [[[-0.0816]],\n",
      "\n",
      "         [[-0.0646]],\n",
      "\n",
      "         [[ 0.1342]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1433]],\n",
      "\n",
      "         [[ 0.1463]],\n",
      "\n",
      "         [[-0.0070]]]], device='cuda:0')), ('backbone.model.layer4.2.bn3.weight', tensor([ 3.1467,  2.9796,  3.5381,  ..., -4.0625,  3.6846, -3.2800],\n",
      "       device='cuda:0')), ('backbone.model.layer4.2.bn3.bias', tensor([-0.1647, -0.0732,  0.0506,  ..., -0.0855,  0.0549, -0.0458],\n",
      "       device='cuda:0')), ('heads.bodypart.heatmap_head.deconv_layers.0.weight', tensor([[[[ 4.5745e-03,  3.5365e-03, -5.3904e-05],\n",
      "          [ 3.0810e-03,  1.6233e-03, -1.4993e-03],\n",
      "          [-1.1619e-03, -2.7563e-04,  9.9996e-04]],\n",
      "\n",
      "         [[ 2.0500e-03,  2.4230e-03, -1.3525e-03],\n",
      "          [ 1.9543e-04, -1.0506e-03, -4.7239e-04],\n",
      "          [ 1.5107e-05,  2.0520e-03,  1.8542e-03]],\n",
      "\n",
      "         [[ 3.2510e-03,  3.5625e-03, -1.0928e-03],\n",
      "          [ 1.1341e-03,  8.2989e-04, -2.8447e-04],\n",
      "          [ 4.0911e-04,  1.5806e-03,  5.0330e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.4474e-04, -2.9750e-04, -3.2006e-04],\n",
      "          [-1.6142e-03,  2.4558e-03,  3.5922e-03],\n",
      "          [-1.7402e-03,  1.5714e-03,  2.3839e-03]],\n",
      "\n",
      "         [[ 4.1788e-03,  4.8816e-03,  1.0130e-03],\n",
      "          [ 6.3152e-03,  6.2879e-03,  1.6920e-03],\n",
      "          [ 3.7218e-03,  3.8382e-03,  5.0317e-04]],\n",
      "\n",
      "         [[-9.0086e-04,  8.1618e-04, -5.1925e-04],\n",
      "          [-1.0373e-03, -1.1069e-03, -1.6622e-04],\n",
      "          [-6.9406e-04, -6.3202e-04,  2.5042e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8078e-05,  4.4300e-04,  3.6194e-05],\n",
      "          [ 2.7126e-05,  4.3309e-04,  2.5194e-04],\n",
      "          [ 7.1844e-04,  7.5536e-04,  2.9778e-04]],\n",
      "\n",
      "         [[-9.1652e-04,  1.6463e-04, -9.0776e-05],\n",
      "          [-2.0597e-04,  6.7657e-04,  3.6497e-04],\n",
      "          [ 8.9868e-04,  1.2566e-03,  7.3998e-04]],\n",
      "\n",
      "         [[-7.2596e-04, -7.0243e-04,  2.8967e-04],\n",
      "          [-4.2324e-04, -5.9376e-05, -3.0912e-04],\n",
      "          [ 9.5739e-04,  4.3546e-04,  3.6120e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.4634e-04, -1.6282e-03, -1.0613e-03],\n",
      "          [ 3.1665e-03, -6.3514e-05, -3.0237e-03],\n",
      "          [ 3.3238e-03,  2.3046e-03, -1.6260e-03]],\n",
      "\n",
      "         [[-9.9608e-04, -9.4505e-04, -8.5099e-05],\n",
      "          [-4.7692e-04, -1.1317e-03, -5.1328e-04],\n",
      "          [ 1.0900e-03,  7.0907e-04,  3.9561e-04]],\n",
      "\n",
      "         [[ 8.7180e-04,  1.0762e-03, -1.4787e-04],\n",
      "          [ 1.7836e-04,  5.9557e-04, -4.9842e-04],\n",
      "          [-4.9882e-04, -2.6017e-04, -7.4396e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.6764e-04, -9.1192e-04, -1.4252e-04],\n",
      "          [-1.0868e-03, -1.1576e-03, -1.0681e-04],\n",
      "          [-7.4198e-04, -9.4900e-04, -5.5327e-04]],\n",
      "\n",
      "         [[-1.6179e-04, -5.0009e-04,  3.8579e-04],\n",
      "          [-3.1636e-04,  1.9574e-04,  1.4132e-04],\n",
      "          [-2.2951e-04, -2.6815e-04, -4.0902e-04]],\n",
      "\n",
      "         [[-3.0580e-04, -3.2198e-04,  2.0972e-04],\n",
      "          [-3.3629e-04,  2.0617e-04, -2.7510e-04],\n",
      "          [-2.3841e-04, -5.1038e-06, -7.4311e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6810e-04,  3.0566e-03,  2.3643e-03],\n",
      "          [ 3.4388e-03,  1.1435e-02,  4.1142e-03],\n",
      "          [ 1.1475e-03,  6.0872e-03,  1.8321e-03]],\n",
      "\n",
      "         [[ 1.0783e-04, -9.1005e-04, -1.2958e-04],\n",
      "          [ 1.7342e-03,  8.0927e-04, -1.7751e-03],\n",
      "          [ 1.8443e-03,  1.8236e-03, -1.0988e-03]],\n",
      "\n",
      "         [[-7.6010e-05,  2.0035e-04,  2.0425e-04],\n",
      "          [ 5.5614e-05,  8.9881e-04,  1.4567e-04],\n",
      "          [-9.3111e-05,  1.9903e-04, -1.5402e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.2537e-04, -5.2437e-04,  4.9891e-04],\n",
      "          [-4.4556e-04, -1.0086e-03, -1.8878e-04],\n",
      "          [-6.9996e-05, -1.8882e-04, -4.8691e-05]],\n",
      "\n",
      "         [[-3.3142e-04, -2.0195e-04,  8.8394e-04],\n",
      "          [-9.2858e-04, -9.6530e-04, -5.8220e-05],\n",
      "          [-2.4707e-04, -4.2766e-04,  2.6945e-05]],\n",
      "\n",
      "         [[-3.9224e-04, -6.5290e-04,  5.8476e-04],\n",
      "          [-1.4988e-03, -1.3049e-03, -2.5374e-04],\n",
      "          [-3.6813e-04, -4.6487e-04,  1.4892e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.6422e-04,  1.8789e-03,  2.4787e-03],\n",
      "          [-7.0904e-04,  1.6238e-03,  3.3612e-03],\n",
      "          [-9.8145e-04, -4.0096e-04,  1.1114e-03]],\n",
      "\n",
      "         [[ 3.9663e-05, -7.8474e-04,  1.7475e-04],\n",
      "          [-8.8299e-04, -1.1854e-03,  6.8807e-05],\n",
      "          [-2.1368e-03, -1.8551e-03, -8.8342e-06]],\n",
      "\n",
      "         [[ 3.8269e-03,  6.1028e-03,  3.0579e-03],\n",
      "          [ 1.2251e-03,  2.9228e-03,  1.4290e-03],\n",
      "          [-3.8335e-04, -4.0619e-04, -1.7761e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.5862e-04, -2.1885e-03,  1.3294e-04],\n",
      "          [ 1.6914e-03, -4.5800e-04,  9.7152e-04],\n",
      "          [ 2.8799e-03,  2.8540e-03,  1.3936e-04]],\n",
      "\n",
      "         [[ 9.2973e-04, -1.7636e-03,  1.1392e-03],\n",
      "          [ 1.4499e-03, -2.0849e-03,  4.7154e-06],\n",
      "          [ 2.4550e-03,  1.8645e-03,  3.3377e-03]],\n",
      "\n",
      "         [[ 1.8515e-03,  2.3904e-04,  1.8204e-04],\n",
      "          [ 3.0422e-03, -1.0386e-03,  9.3707e-04],\n",
      "          [ 2.0466e-03,  8.4616e-05,  3.5363e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2462e-04, -3.1685e-04, -7.6951e-04],\n",
      "          [ 2.6703e-03,  7.6831e-03,  1.2995e-03],\n",
      "          [ 3.6273e-03,  9.2726e-03,  6.2008e-04]],\n",
      "\n",
      "         [[ 1.9627e-03,  3.8813e-03,  2.9801e-03],\n",
      "          [ 1.9915e-03,  6.6258e-03,  6.7060e-03],\n",
      "          [ 3.7089e-03,  1.5811e-03,  2.5167e-03]],\n",
      "\n",
      "         [[ 1.2215e-03,  2.3349e-03, -1.3431e-04],\n",
      "          [ 3.3877e-03,  4.2918e-03,  7.3581e-04],\n",
      "          [ 1.0652e-04,  7.3566e-04, -1.3240e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.8666e-04, -4.9113e-05, -8.8820e-04],\n",
      "          [ 5.6792e-05,  3.3918e-04, -1.0722e-03],\n",
      "          [-4.6137e-04, -1.0754e-03, -7.0967e-04]],\n",
      "\n",
      "         [[-6.2436e-04, -2.8342e-04, -9.0163e-04],\n",
      "          [-1.2065e-04, -4.1152e-04, -8.1204e-04],\n",
      "          [-3.9606e-04,  1.0911e-04, -6.7932e-05]],\n",
      "\n",
      "         [[-1.9169e-04,  1.2076e-03,  3.8723e-04],\n",
      "          [-8.2379e-05,  2.0266e-03,  1.9320e-03],\n",
      "          [ 4.1765e-04,  9.0121e-04,  1.9343e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.3579e-04,  8.0966e-04, -7.6275e-04],\n",
      "          [ 1.6683e-03, -3.5527e-04, -1.5291e-03],\n",
      "          [ 8.7151e-04, -1.7402e-05, -1.2041e-03]],\n",
      "\n",
      "         [[ 7.4610e-04,  9.2694e-04,  3.4977e-04],\n",
      "          [ 6.2762e-04, -2.0838e-04,  1.0298e-03],\n",
      "          [ 1.9952e-06, -5.2228e-04, -3.5076e-04]],\n",
      "\n",
      "         [[-3.4906e-05,  3.3202e-04,  1.9141e-04],\n",
      "          [ 6.0415e-04,  7.7920e-04, -8.3487e-05],\n",
      "          [ 8.1761e-05, -4.3629e-05, -3.8424e-04]]]], device='cuda:0')), ('heads.bodypart.heatmap_head.deconv_layers.0.bias', tensor([ 8.6940e-06, -6.1576e-06,  7.2428e-06,  1.3746e-04,  2.4619e-04,\n",
      "         5.5362e-05, -4.2505e-06,  1.3108e-04,  1.8960e-04,  1.2324e-04,\n",
      "         6.1530e-05], device='cuda:0')), ('heads.bodypart.locref_head.deconv_layers.0.weight', tensor([[[[-3.6984e-07,  3.3287e-03,  1.4184e-03],\n",
      "          [-1.6044e-03,  6.1992e-03, -2.8497e-05],\n",
      "          [-1.7738e-03,  2.4558e-03,  4.2275e-04]],\n",
      "\n",
      "         [[ 1.7079e-04, -3.5593e-03, -9.6510e-04],\n",
      "          [-3.8046e-03,  3.5058e-04, -8.6146e-04],\n",
      "          [-5.5178e-03, -1.6528e-03,  2.4964e-03]],\n",
      "\n",
      "         [[-4.3526e-04,  2.4444e-03, -3.9095e-03],\n",
      "          [-2.4245e-03,  1.8555e-03, -1.7132e-03],\n",
      "          [-3.2249e-03, -3.1784e-03, -2.7299e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0673e-03,  1.3291e-03, -6.4213e-04],\n",
      "          [-2.4680e-03,  2.8578e-03,  1.2131e-03],\n",
      "          [ 6.7255e-04, -1.5590e-03,  2.0590e-03]],\n",
      "\n",
      "         [[ 2.0912e-03, -2.1297e-03, -3.8766e-04],\n",
      "          [-2.5183e-03, -2.0608e-03,  3.7578e-03],\n",
      "          [-7.2185e-04, -1.9036e-03,  8.9262e-05]],\n",
      "\n",
      "         [[ 3.6372e-03,  2.0381e-03,  2.1197e-03],\n",
      "          [-1.3578e-03,  9.1782e-04,  1.6604e-03],\n",
      "          [-1.7659e-03, -1.8609e-03, -1.8538e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.4599e-03, -1.7946e-03, -8.5653e-03],\n",
      "          [-8.2845e-03, -6.6691e-03, -6.9900e-03],\n",
      "          [ 1.4471e-04, -2.5189e-03, -3.3894e-03]],\n",
      "\n",
      "         [[ 7.7437e-03,  3.3055e-03, -4.7894e-04],\n",
      "          [ 1.9096e-03, -1.0936e-03, -3.0007e-03],\n",
      "          [ 7.4213e-04, -1.6448e-03, -2.1883e-03]],\n",
      "\n",
      "         [[-8.2088e-03, -2.0525e-03,  5.8540e-04],\n",
      "          [-3.0490e-03, -3.7569e-03,  4.5553e-03],\n",
      "          [ 4.6774e-04, -2.6674e-03, -7.2901e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.1726e-03,  5.9823e-03,  3.6088e-03],\n",
      "          [ 6.8294e-04,  8.3981e-04,  1.0156e-03],\n",
      "          [-1.2101e-03,  1.2209e-03,  9.0694e-04]],\n",
      "\n",
      "         [[ 4.9303e-03,  3.2891e-03,  3.6241e-03],\n",
      "          [-3.5204e-03, -3.6310e-03, -1.6492e-03],\n",
      "          [-3.2776e-03, -5.3240e-03, -4.5901e-03]],\n",
      "\n",
      "         [[ 3.1348e-03,  1.1516e-03,  2.7889e-04],\n",
      "          [ 6.2283e-03,  5.4829e-03,  5.0845e-03],\n",
      "          [-2.0189e-03, -4.9252e-03, -3.8059e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.5934e-03, -5.7348e-03, -2.1527e-03],\n",
      "          [ 3.3991e-03, -2.5534e-03, -2.4544e-03],\n",
      "          [-2.3223e-03, -1.5068e-03, -1.3911e-03]],\n",
      "\n",
      "         [[-4.0027e-04, -5.3774e-04,  4.4089e-03],\n",
      "          [ 1.7022e-03, -1.8635e-03, -1.3564e-04],\n",
      "          [-1.1996e-03, -2.5732e-03,  1.1242e-03]],\n",
      "\n",
      "         [[ 3.6783e-03, -1.1743e-02, -7.5396e-04],\n",
      "          [ 8.2390e-04, -3.8923e-04,  6.9896e-04],\n",
      "          [ 8.7070e-04, -1.6213e-03, -2.8503e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.9480e-03,  2.8022e-03,  2.4684e-03],\n",
      "          [ 4.2581e-03,  6.0427e-03,  2.4235e-03],\n",
      "          [ 2.4127e-03,  1.8163e-03,  1.0667e-03]],\n",
      "\n",
      "         [[ 1.3829e-03,  5.4422e-03,  2.6133e-03],\n",
      "          [ 2.5821e-03,  5.0582e-03,  1.1025e-03],\n",
      "          [ 1.2829e-04,  1.0998e-03,  1.2378e-03]],\n",
      "\n",
      "         [[ 6.7148e-04, -5.8779e-03, -2.5386e-03],\n",
      "          [ 6.1650e-04, -9.6282e-03, -5.2430e-03],\n",
      "          [-3.8950e-04, -3.0610e-03, -4.1795e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.7133e-03,  8.3795e-04,  1.9417e-03],\n",
      "          [ 6.0039e-03,  4.8288e-03, -3.7002e-03],\n",
      "          [ 2.7542e-03,  2.3610e-03, -2.9751e-03]],\n",
      "\n",
      "         [[ 2.1101e-03,  5.1545e-03, -2.6033e-03],\n",
      "          [ 1.1585e-02,  1.0629e-02,  7.4310e-03],\n",
      "          [ 2.6636e-03,  2.7536e-03, -3.5243e-04]],\n",
      "\n",
      "         [[ 2.4708e-03,  1.6709e-03, -2.0233e-06],\n",
      "          [ 6.3407e-03,  2.8401e-03, -8.8848e-04],\n",
      "          [-9.0681e-04, -2.1404e-03,  7.0673e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7226e-03, -1.5429e-03, -2.8536e-04],\n",
      "          [-7.1945e-03, -7.7846e-03, -2.2399e-03],\n",
      "          [-1.4093e-03,  4.1183e-03,  1.2779e-03]],\n",
      "\n",
      "         [[ 1.5451e-03, -8.3687e-04, -5.8802e-03],\n",
      "          [-1.5400e-04, -3.5396e-03, -3.0190e-03],\n",
      "          [-2.0445e-03, -7.1533e-03, -4.7666e-03]],\n",
      "\n",
      "         [[ 1.8735e-03,  1.4470e-03, -4.4761e-03],\n",
      "          [-4.6384e-03, -5.7516e-03, -2.8011e-03],\n",
      "          [-7.2811e-03, -5.4767e-03,  1.4988e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0153e-03,  3.0578e-04,  5.7293e-04],\n",
      "          [ 1.2593e-03,  2.5290e-03, -1.7675e-03],\n",
      "          [-1.9134e-03, -2.3643e-03,  1.2812e-03]],\n",
      "\n",
      "         [[-1.6784e-03, -3.1248e-03, -1.9490e-04],\n",
      "          [ 1.1425e-03, -2.4076e-03, -3.3669e-04],\n",
      "          [ 1.3132e-03,  2.1017e-03, -2.2617e-03]],\n",
      "\n",
      "         [[ 8.1710e-04,  2.4984e-03,  4.9728e-03],\n",
      "          [ 1.0937e-03,  2.6213e-03, -2.0898e-03],\n",
      "          [ 2.4010e-03,  1.6596e-03, -6.3775e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1296e-03, -3.8729e-03, -4.8127e-03],\n",
      "          [-2.8473e-03, -2.6621e-03, -5.8175e-03],\n",
      "          [-1.1472e-03, -2.7813e-03, -4.0049e-03]],\n",
      "\n",
      "         [[ 1.5745e-03,  2.4493e-03,  9.3286e-04],\n",
      "          [-3.4616e-03, -2.9066e-03, -3.4016e-03],\n",
      "          [-1.1936e-03, -2.3647e-03, -5.7200e-04]],\n",
      "\n",
      "         [[ 4.4516e-03,  4.1522e-03,  1.6393e-03],\n",
      "          [-2.8798e-03,  1.3888e-04, -3.0603e-03],\n",
      "          [-3.3584e-03, -4.0189e-03, -5.6764e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2862e-04,  2.4632e-03, -2.1962e-03],\n",
      "          [ 1.3629e-03,  5.5554e-03, -4.9889e-05],\n",
      "          [ 1.5205e-03,  3.5941e-03,  1.6204e-03]],\n",
      "\n",
      "         [[-3.8872e-05, -1.5342e-03, -2.2161e-05],\n",
      "          [ 4.2136e-03,  2.0037e-03, -5.5311e-04],\n",
      "          [ 7.8968e-03,  3.8460e-03,  2.1397e-03]],\n",
      "\n",
      "         [[ 2.9894e-03,  8.5482e-04, -3.1672e-03],\n",
      "          [ 1.2546e-03,  3.3389e-03, -3.7876e-03],\n",
      "          [ 1.1582e-03, -4.5749e-04, -1.7613e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.8027e-03, -4.4796e-04, -3.3573e-03],\n",
      "          [-2.7631e-03, -9.0576e-04, -3.0229e-03],\n",
      "          [-8.6855e-04, -4.0997e-03, -5.1005e-03]],\n",
      "\n",
      "         [[-2.2329e-03, -2.3727e-03,  1.7342e-03],\n",
      "          [-1.4947e-03, -1.4577e-03,  1.8667e-04],\n",
      "          [ 1.3916e-03, -3.5212e-04,  1.4529e-03]],\n",
      "\n",
      "         [[ 8.5156e-05, -8.9214e-03, -4.1107e-03],\n",
      "          [-3.1265e-03,  2.1616e-03, -1.9609e-03],\n",
      "          [ 2.0291e-03,  2.4337e-03, -4.5667e-04]]]], device='cuda:0')), ('heads.bodypart.locref_head.deconv_layers.0.bias', tensor([ 0.0033, -0.0038,  0.0045, -0.0023,  0.0040,  0.0040,  0.0036,  0.0042,\n",
      "         0.0017, -0.0037, -0.0001,  0.0054, -0.0004, -0.0030,  0.0009,  0.0055,\n",
      "         0.0005,  0.0025, -0.0007, -0.0042, -0.0030,  0.0039], device='cuda:0'))])}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     30\u001b[0m         size_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_bytes\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m size_str\n\u001b[0;32m---> 35\u001b[0m \u001b[43mget_model_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/snapshot-263.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m, in \u001b[0;36mget_model_size\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m---> 19\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m())\n\u001b[1;32m     20\u001b[0m     size_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m*\u001b[39m p\u001b[38;5;241m.\u001b[39melement_size() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params])\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Convert to KB, MB, GB, etc.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_model_size(model_path):\n",
    "    \"\"\"\n",
    "    Calculates the size of an ONNX model in bytes.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): The path to the ONNX model file.\n",
    "\n",
    "    Returns:\n",
    "        int: The size of the model in bytes.\n",
    "    \"\"\"\n",
    "    if '.onnx' in model_path:\n",
    "        model = onnx.load(model_path)\n",
    "        size_bytes = len(model.SerializeToString())\n",
    "    elif \".pt\" in model_path:\n",
    "        model = torch.load(model_path)\n",
    "        print(model)\n",
    "        params = list(model.parameters())\n",
    "        size_bytes = sum([p.numel() * p.element_size() for p in params])\n",
    "        \n",
    "    # Convert to KB, MB, GB, etc.\n",
    "    if size_bytes < 1024:\n",
    "        size_str = f\"{size_bytes} B\"\n",
    "    elif size_bytes < 1024 * 1024:\n",
    "        size_str = f\"{size_bytes / 1024:.2f} KB\"\n",
    "    elif size_bytes < 1024 * 1024 * 1024:\n",
    "        size_str = f\"{size_bytes / (1024 * 1024):.2f} MB\"\n",
    "    else:\n",
    "        size_str = f\"{size_bytes / (1024 * 1024 * 1024):.2f} GB\"\n",
    "\n",
    "    return size_str\n",
    "\n",
    "\n",
    "get_model_size(\"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/snapshot-263.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 150.0\n",
      "Number of frames: 1500.0\n",
      "Video length (seconds): 10.0\n",
      "Frame size: (658, 302)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_characteristics(video_path):\n",
    "    \"\"\"\n",
    "    Extracts the FPS, number of frames, length in seconds, and frame size of a video.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): The path to the video file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the FPS, number of frames, length in seconds, and frame size.\n",
    "    \"\"\"\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Calculate video length in seconds\n",
    "    video_length = frame_count / fps\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return fps, frame_count, video_length, (frame_width, frame_height)\n",
    "\n",
    "# Example usage:\n",
    "video_path = \"/media/dikra/PhD/DATA/DLC24_Data/dlc-live-dummy/ventral-gait/1_20cms_0degUP_first.avi\"\n",
    "fps, frame_count, video_length, frame_size = get_video_characteristics(video_path)\n",
    "\n",
    "print(\"FPS:\", fps)\n",
    "print(\"Number of frames:\", frame_count)\n",
    "print(\"Video length (seconds):\", video_length)\n",
    "print(\"Frame size:\", frame_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
