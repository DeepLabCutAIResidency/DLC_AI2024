{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b286eb56",
   "metadata": {},
   "source": [
    "# Exercices Part 2: Convolutional Neural Networks\n",
    "\n",
    "Convolutional neural network examples for computer vision. Written for the 2024 DeepLabCut AI Residency.\n",
    "\n",
    "While these CNNs are written to process 2-dimensional images, they can of course be adapted to deal with 1d or 3d inputs!\n",
    "\n",
    "This notebook uses PyTorch to define and train neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2cad21",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25baaf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa576f",
   "metadata": {},
   "source": [
    "## Image Classification with LeNet5\n",
    "\n",
    "Some computer vision tasks are very difficult and require large, slow models. Other tasks, like image classification on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset are much easier and smaller models can be used to achieve good results.\n",
    "\n",
    "The LeNet model family (developed by Yann LeCun in 1998) are really the first . They're well described on [wikipedia](https://en.wikipedia.org/wiki/LeNet), but you can also go read [Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791), which has been cited more than 67'000 times.\n",
    "\n",
    "In this notebook, you'll implement LeNet5 and train it on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebefc6",
   "metadata": {},
   "source": [
    "### Loading the Dataset\n",
    "\n",
    "PyTorch has an [api method](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) to download MNIST dataset, so we can just use that to download the dataset.\n",
    "\n",
    "In this example, I download the dataset to the folder this notebook is in, but you can change the path where the dataset is downloaded if you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3096481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_base = torchvision.datasets.MNIST(\n",
    "    root=Path(\".\"),\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset_base = torchvision.datasets.MNIST(\n",
    "    root=Path(\".\"),\n",
    "    train=False,\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d06419",
   "metadata": {},
   "source": [
    "We can then look through a few images to see what the data looks like. Datasets in PyTorch define the `__getitem__` method, which allows to retrieve elements from the dataset as we would from a list.\n",
    "\n",
    "As per their documentation, the `__getitem__` method returns `(image, target)` where target is index of the target class. As you can see in the plot, the images contain integer values between 0 and 255.\n",
    "\n",
    "You can play around with the index returned to look at different images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c798e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training images: {len(train_dataset_base)}\")\n",
    "print(f\"Test images:     {len(test_dataset_base)}\\n\")\n",
    "image, target = train_dataset_base[0]\n",
    "\n",
    "print(f\"Target: {target}\")\n",
    "print(f\"Image size: {image.size}\")\n",
    "\n",
    "plt.figure()\n",
    "cbar = plt.imshow(image, cmap=\"gray\")\n",
    "plt.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452f347",
   "metadata": {},
   "source": [
    "### Image Preprocessing - Transformations\n",
    "\n",
    "One very important step when training computer vision models is normalizing your data, so that your data has mean ~0 and standard deviation ~1. This is to help your model converge. You can read more about it in any machine learning textbook, or a bit more about it in this [discussion on the PyTorch forum](https://discuss.pytorch.org/t/why-image-datasets-need-normalizing-with-means-and-stds-specified-like-in-transforms-normalize-mean-0-485-0-456-0-406-std-0-229-0-224-0-225/187818/4)\n",
    "\n",
    "A set of normalization parameters you'll often see are computed from the ImageNet dataset:\n",
    "\n",
    "```\n",
    "mean=[0.485, 0.456, 0.406]\n",
    "std=[0.229, 0.224, 0.225]\n",
    "```\n",
    "\n",
    "When working with \"natural\" images, it's very common to normalize using these parameters. This is discussed in [this thread](https://discuss.pytorch.org/t/discussion-why-normalise-according-to-imagenet-mean-and-std-dev-for-transfer-learning/115670). In our case, we can just normalize with `0.5`. We could also compute the mean and standard deviation of pixels in the dataset and use those to Normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "image, target = train_dataset_base[0]\n",
    "image = transform(image)\n",
    "\n",
    "plt.figure()\n",
    "cbar = plt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19627007",
   "metadata": {},
   "source": [
    "We can re-build the dataset while directly using these transformations, so we receive the images in the format we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5cec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(0.5, 0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=Path(\".\"),\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=Path(\".\"),\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "image, target = train_dataset[0]\n",
    "\n",
    "plt.figure()\n",
    "cbar = plt.imshow(image.squeeze().numpy(), cmap=\"gray\")\n",
    "plt.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05418e7f",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks - 2D Convolutions in PyTorch\n",
    "\n",
    "A CNN consists of different layers of convolutions, where the kernels are **learned**, instead of manually defined like we saw in the exercises about convolutions.\n",
    "\n",
    "A convolutional layer in PyTorch is implemented through the [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) class. We can create a convolutional layer easily, as shown below. When we create the layer, the weights are initialized randomly (but according to a specified distribution - the distribution chosen is actually very important - there are many resources online to learn about this) This was also described by Yann LeCun in [Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791) (check out the paper for more info):\n",
    "\n",
    "> Before training, the weights are initialized with random values using a uniform distribution ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662d19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "print(f\"Conv Kernel Weight: {conv.weight}\")\n",
    "print()\n",
    "print(f\"Conv Kernel Bias: {conv.bias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473dfe75",
   "metadata": {},
   "source": [
    "We \"apply\" this convolution to our image. But as mentioned in the docs, an [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) expects the inputs to be a Tensor of shape `(N, C_in, H, W)`, where N is the batch size. Our images are of shape `(1, H, W)` (which is `(1, 28, 28)` for MNIST). We can simply add a dimension to our image for the batch size (which is 1 of course). We can do that with `unsqueeze()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0a5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = train_dataset[0]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "img = img.unsqueeze(dim=0)\n",
    "print(f\"Batched image shape: {img.shape}\")\n",
    "\n",
    "img_out = conv(img)\n",
    "img_out = img_out.detach().numpy().squeeze()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_out, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49b8184",
   "metadata": {},
   "source": [
    "Note that this is **never** done in practice, but we can set the weights of our 2d convolution to be a Sobel detector, just like we did in the convolutions notebook. This is just to illustrate the while the kernel for the convolution is learned, the operation is exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e13cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_detector = nn.Conv2d(1, 1, 3)\n",
    "edge_detector.weight = nn.Parameter(\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [1.0, 0.0, -1.0],\n",
    "            [2.0, 0.0, -2.0],\n",
    "            [1.0, 0.0, -1.0],\n",
    "        ],\n",
    "    ).unsqueeze(dim=0).unsqueeze(dim=0)\n",
    ")\n",
    "edge_detector.bias = nn.Parameter(torch.tensor([0.0]))\n",
    "\n",
    "img, target = train_dataset[0]\n",
    "img = img.unsqueeze(dim=0)\n",
    "\n",
    "img_out = edge_detector(img)\n",
    "img_out = img_out.detach().numpy().squeeze()\n",
    "\n",
    "plt.figure()\n",
    "cbar = plt.imshow(img_out, cmap=\"gray\")\n",
    "plt.colorbar(cbar)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081b49f",
   "metadata": {},
   "source": [
    "### Designing Neural Networks in PyTorch\n",
    "\n",
    "Most of this part of the notebook is taken from this [tutorial from PyTorch](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html). It's very well written, and if you want to learn more you can check it out. **HOWEVER**, they use a LeNet5 as their example model, and I think it would be more beneficial to write the LeNet from scratch, without looking at the solution. So I would suggest first coding it up yourselves, and then looking at _a_ solution in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcec0c5",
   "metadata": {},
   "source": [
    "A neural net in PyTorch is an `nn.Module`. As neural networks have conceptually, these modules have layers (which themselves are modules). They have a forward method which returns the output of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca63256",
   "metadata": {},
   "source": [
    "As an example, let's train a neural network to approximate an affine function, say `10x + 5`. We can \"learn\" this function with a very simple network, composed of a single linear layer. A linear layer is composed of weights $W$ and a bias $b$, and for input $x$ outputs:\n",
    "\n",
    "> $f(x) = Wx + b$\n",
    "\n",
    "We can train this network to learn the affine function we defined. Some resources for loss functions and optimizers:\n",
    "- [PyTorch loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "- [PyTorch optimizers](https://pytorch.org/docs/stable/optim.html#module-torch.optim)\n",
    "\n",
    "Here, you can play around with the loss criterion, optimizer, learning rate and number of iterations used to see how quickly the model converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineNet(nn.Module):\n",
    "    \"\"\"A net to learn an affine function\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "net = AffineNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = []\n",
    "for i in range(num_iterations):  # run 1000 iterations\n",
    "    inputs = torch.rand(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        targets = 10 * inputs + 5\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # get statistics\n",
    "    running_loss.append(loss.item())\n",
    "\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(f\"Final loss: {running_loss[-1]}\")\n",
    "print(f\"Final weight: {net.layer.weight}\")\n",
    "print(f\"Final bias: {net.layer.bias}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(running_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e868b465",
   "metadata": {},
   "source": [
    "We can add more layers to this neural network. By adding a second layer, our neural network is now composed of two layers $L_1$ and $L_2$, with weights and bias $W_1$, $b_1$ and $W_2$, $b_2$ respectively. Now, for input $x$, the net outputs:\n",
    "\n",
    "> $f(x) = W_2(W_1x + b_1) + b_2$\n",
    "\n",
    "Notice how larger nets might not perform better (in this case, it's more difficult to train). There are also many ways to set the model parameters so that $f(x)$ represents the affine function $10x + 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428153b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    \"\"\"A net to learn an affine function\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(1, 1)\n",
    "        self.layer_2 = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = self.layer_1(x)\n",
    "        out_2 = self.layer_2(out_1)\n",
    "        return out_2\n",
    "\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "net = TwoLayerNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = []\n",
    "for i in range(num_iterations):  # run 1000 iterations\n",
    "    inputs = torch.rand(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        targets = 10 * inputs + 5\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # get statistics\n",
    "    running_loss.append(loss.item())\n",
    "\n",
    "\n",
    "print(\"Finished Training\")\n",
    "print(f\"Final loss: {running_loss[-1]}\")\n",
    "print(f\"Final weight 1: {net.layer_1.weight}\")\n",
    "print(f\"Final bias 1:   {net.layer_1.bias}\")\n",
    "print(f\"Final weight 2: {net.layer_2.weight}\")\n",
    "print(f\"Final bias 2:   {net.layer_2.bias}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(running_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29f972",
   "metadata": {},
   "source": [
    "### Exercise - Implementing LeNet5\n",
    "\n",
    "Based on the [wikipedia article](https://en.wikipedia.org/wiki/LeNet), or the [paper's description](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=726791), implement a LeNet5 model and train it on the MNIST dataset. You'll need the following building blocks:\n",
    "\n",
    "- [`MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
    "- [`Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "- [`Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
    "- [`Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid)\n",
    "- [`torch.flatten`](https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f07a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    \"\"\"PyTorch tutorial Neural Network\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: implement the model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e1fe6",
   "metadata": {},
   "source": [
    "Once your model is defined, you can train it on the MNIST dataset: look at the tutorial for more information about that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0db1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
